{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import warnings  # 提供了一种处理警告信息的机制\n",
    "import torch\n",
    "from train import Train\n",
    "from utils import plot_auc_curves, plot_prc_curves"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T03:39:00.871301100Z",
     "start_time": "2024-05-07T03:38:57.900503900Z"
    }
   },
   "id": "b3112d9d5ef5a53f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_num 50\n",
      "dropout 0.2\n",
      "## vertices: 285\n",
      "## edges: 2760\n",
      "## disease nodes: 44\n",
      "## metabolite nodes:  241\n",
      "## microbe nodes:  308\n",
      "Training for Fold 1\n",
      "## Training edges: 2208\n",
      "## Testing edges: 552\n",
      "Epoch: 1 Train Loss: 1.0353 Val Loss: 1.3492 Acc: 0.6558 Pre: 0.6098 Recall: 0.9190 F1: 0.7331 Train AUC: 0.4427 Val AUC: 0.6674 Time: 12.77\n",
      "Epoch: 2 Train Loss: 1.4891 Val Loss: 1.1157 Acc: 0.5217 Pre: 1.0000 Recall: 0.0704 F1: 0.1316 Train AUC: 0.5602 Val AUC: 0.7277 Time: 11.42\n",
      "Epoch: 3 Train Loss: 1.5243 Val Loss: 0.5385 Acc: 0.7228 Pre: 0.6795 Recall: 0.8732 F1: 0.7643 Train AUC: 0.5705 Val AUC: 0.8364 Time: 11.38\n",
      "Epoch: 4 Train Loss: 0.7830 Val Loss: 0.6248 Acc: 0.6232 Pre: 0.5798 Recall: 0.9718 F1: 0.7263 Train AUC: 0.6649 Val AUC: 0.8985 Time: 11.50\n",
      "Epoch: 5 Train Loss: 0.7628 Val Loss: 0.4676 Acc: 0.7572 Pre: 0.7143 Recall: 0.8803 F1: 0.7886 Train AUC: 0.7923 Val AUC: 0.8864 Time: 11.38\n",
      "Epoch: 6 Train Loss: 0.6186 Val Loss: 0.4279 Acc: 0.7953 Pre: 0.8940 Recall: 0.6831 F1: 0.7745 Train AUC: 0.8014 Val AUC: 0.8938 Time: 11.34\n",
      "Epoch: 7 Train Loss: 0.6892 Val Loss: 0.4362 Acc: 0.8406 Pre: 0.9804 Recall: 0.7042 F1: 0.8197 Train AUC: 0.7307 Val AUC: 0.9198 Time: 11.52\n",
      "Epoch: 8 Train Loss: 0.6944 Val Loss: 0.3855 Acc: 0.8406 Pre: 0.9336 Recall: 0.7430 F1: 0.8275 Train AUC: 0.7799 Val AUC: 0.9117 Time: 11.41\n",
      "Epoch: 9 Train Loss: 0.5357 Val Loss: 0.3524 Acc: 0.8460 Pre: 0.8645 Recall: 0.8310 F1: 0.8474 Train AUC: 0.8310 Val AUC: 0.9154 Time: 11.39\n",
      "Epoch: 10 Train Loss: 0.4828 Val Loss: 0.3497 Acc: 0.8333 Pre: 0.8288 Recall: 0.8521 F1: 0.8403 Train AUC: 0.8606 Val AUC: 0.9218 Time: 11.41\n",
      "Epoch: 11 Train Loss: 0.5107 Val Loss: 0.3394 Acc: 0.8496 Pre: 0.8454 Recall: 0.8662 F1: 0.8557 Train AUC: 0.8617 Val AUC: 0.9277 Time: 11.36\n",
      "Epoch: 12 Train Loss: 0.4917 Val Loss: 0.3229 Acc: 0.8659 Pre: 0.8918 Recall: 0.8415 F1: 0.8659 Train AUC: 0.8748 Val AUC: 0.9306 Time: 11.36\n",
      "Epoch: 13 Train Loss: 0.4440 Val Loss: 0.3229 Acc: 0.8659 Pre: 0.9234 Recall: 0.8063 F1: 0.8609 Train AUC: 0.8898 Val AUC: 0.9301 Time: 15.82\n",
      "Epoch: 14 Train Loss: 0.4335 Val Loss: 0.3374 Acc: 0.8514 Pre: 0.9280 Recall: 0.7711 F1: 0.8423 Train AUC: 0.8861 Val AUC: 0.9294 Time: 14.86\n",
      "Epoch: 15 Train Loss: 0.4771 Val Loss: 0.3516 Acc: 0.8514 Pre: 0.9391 Recall: 0.7606 F1: 0.8405 Train AUC: 0.8729 Val AUC: 0.9292 Time: 13.08\n",
      "Epoch: 16 Train Loss: 0.5338 Val Loss: 0.3409 Acc: 0.8587 Pre: 0.9402 Recall: 0.7746 F1: 0.8494 Train AUC: 0.8542 Val AUC: 0.9303 Time: 12.38\n",
      "Epoch: 17 Train Loss: 0.4659 Val Loss: 0.3263 Acc: 0.8641 Pre: 0.9265 Recall: 0.7993 F1: 0.8582 Train AUC: 0.8818 Val AUC: 0.9311 Time: 11.40\n",
      "Epoch: 18 Train Loss: 0.4352 Val Loss: 0.3224 Acc: 0.8514 Pre: 0.9008 Recall: 0.7993 F1: 0.8470 Train AUC: 0.8871 Val AUC: 0.9311 Time: 11.33\n",
      "Epoch: 19 Train Loss: 0.4386 Val Loss: 0.3268 Acc: 0.8587 Pre: 0.8843 Recall: 0.8345 F1: 0.8587 Train AUC: 0.8838 Val AUC: 0.9311 Time: 11.38\n",
      "Epoch: 20 Train Loss: 0.4197 Val Loss: 0.3307 Acc: 0.8587 Pre: 0.8787 Recall: 0.8415 F1: 0.8597 Train AUC: 0.8909 Val AUC: 0.9300 Time: 11.36\n",
      "Epoch: 21 Train Loss: 0.4311 Val Loss: 0.3303 Acc: 0.8569 Pre: 0.8839 Recall: 0.8310 F1: 0.8566 Train AUC: 0.8843 Val AUC: 0.9290 Time: 11.47\n",
      "Epoch: 22 Train Loss: 0.4378 Val Loss: 0.3272 Acc: 0.8569 Pre: 0.8927 Recall: 0.8204 F1: 0.8550 Train AUC: 0.8889 Val AUC: 0.9291 Time: 11.67\n",
      "Epoch: 23 Train Loss: 0.4264 Val Loss: 0.3278 Acc: 0.8533 Pre: 0.9109 Recall: 0.7923 F1: 0.8475 Train AUC: 0.8849 Val AUC: 0.9295 Time: 11.82\n",
      "Epoch: 24 Train Loss: 0.3940 Val Loss: 0.3329 Acc: 0.8569 Pre: 0.9253 Recall: 0.7852 F1: 0.8495 Train AUC: 0.8984 Val AUC: 0.9297 Time: 12.73\n",
      "Epoch: 25 Train Loss: 0.3895 Val Loss: 0.3368 Acc: 0.8569 Pre: 0.9289 Recall: 0.7817 F1: 0.8489 Train AUC: 0.9079 Val AUC: 0.9305 Time: 13.04\n",
      "Epoch: 26 Train Loss: 0.4065 Val Loss: 0.3344 Acc: 0.8587 Pre: 0.9328 Recall: 0.7817 F1: 0.8506 Train AUC: 0.9028 Val AUC: 0.9310 Time: 13.44\n",
      "Epoch: 27 Train Loss: 0.3916 Val Loss: 0.3307 Acc: 0.8623 Pre: 0.9298 Recall: 0.7923 F1: 0.8555 Train AUC: 0.9063 Val AUC: 0.9310 Time: 13.93\n",
      "Epoch: 28 Train Loss: 0.3824 Val Loss: 0.3275 Acc: 0.8533 Pre: 0.9109 Recall: 0.7923 F1: 0.8475 Train AUC: 0.9086 Val AUC: 0.9307 Time: 13.65\n",
      "Epoch: 29 Train Loss: 0.3720 Val Loss: 0.3264 Acc: 0.8514 Pre: 0.9008 Recall: 0.7993 F1: 0.8470 Train AUC: 0.9102 Val AUC: 0.9300 Time: 12.58\n",
      "Epoch: 30 Train Loss: 0.3855 Val Loss: 0.3270 Acc: 0.8478 Pre: 0.8876 Recall: 0.8063 F1: 0.8450 Train AUC: 0.9030 Val AUC: 0.9294 Time: 11.66\n",
      "Epoch: 31 Train Loss: 0.3863 Val Loss: 0.3284 Acc: 0.8478 Pre: 0.8846 Recall: 0.8099 F1: 0.8456 Train AUC: 0.9022 Val AUC: 0.9294 Time: 11.43\n",
      "Epoch: 32 Train Loss: 0.3985 Val Loss: 0.3279 Acc: 0.8496 Pre: 0.8851 Recall: 0.8134 F1: 0.8477 Train AUC: 0.8978 Val AUC: 0.9294 Time: 11.62\n",
      "Epoch: 33 Train Loss: 0.3934 Val Loss: 0.3267 Acc: 0.8496 Pre: 0.8851 Recall: 0.8134 F1: 0.8477 Train AUC: 0.9040 Val AUC: 0.9298 Time: 12.21\n",
      "Epoch: 34 Train Loss: 0.4153 Val Loss: 0.3233 Acc: 0.8424 Pre: 0.8803 Recall: 0.8028 F1: 0.8398 Train AUC: 0.8914 Val AUC: 0.9310 Time: 12.80\n",
      "Epoch: 35 Train Loss: 0.3663 Val Loss: 0.3206 Acc: 0.8478 Pre: 0.8937 Recall: 0.7993 F1: 0.8439 Train AUC: 0.9118 Val AUC: 0.9326 Time: 13.06\n",
      "Epoch: 36 Train Loss: 0.3619 Val Loss: 0.3192 Acc: 0.8460 Pre: 0.8964 Recall: 0.7923 F1: 0.8411 Train AUC: 0.9156 Val AUC: 0.9341 Time: 13.01\n",
      "Epoch: 37 Train Loss: 0.3410 Val Loss: 0.3187 Acc: 0.8478 Pre: 0.9000 Recall: 0.7923 F1: 0.8427 Train AUC: 0.9252 Val AUC: 0.9346 Time: 13.20\n",
      "Epoch: 38 Train Loss: 0.3738 Val Loss: 0.3177 Acc: 0.8496 Pre: 0.9004 Recall: 0.7958 F1: 0.8449 Train AUC: 0.9129 Val AUC: 0.9349 Time: 12.62\n",
      "Epoch: 39 Train Loss: 0.3721 Val Loss: 0.3171 Acc: 0.8514 Pre: 0.9008 Recall: 0.7993 F1: 0.8470 Train AUC: 0.9108 Val AUC: 0.9353 Time: 11.74\n",
      "Epoch: 40 Train Loss: 0.3823 Val Loss: 0.3163 Acc: 0.8533 Pre: 0.9044 Recall: 0.7993 F1: 0.8486 Train AUC: 0.9069 Val AUC: 0.9359 Time: 11.74\n",
      "Epoch: 41 Train Loss: 0.3525 Val Loss: 0.3158 Acc: 0.8533 Pre: 0.9044 Recall: 0.7993 F1: 0.8486 Train AUC: 0.9211 Val AUC: 0.9359 Time: 12.05\n",
      "Epoch: 42 Train Loss: 0.3809 Val Loss: 0.3144 Acc: 0.8496 Pre: 0.8911 Recall: 0.8063 F1: 0.8466 Train AUC: 0.9117 Val AUC: 0.9358 Time: 12.51\n",
      "Epoch: 43 Train Loss: 0.3758 Val Loss: 0.3126 Acc: 0.8496 Pre: 0.8851 Recall: 0.8134 F1: 0.8477 Train AUC: 0.9098 Val AUC: 0.9364 Time: 13.12\n",
      "Epoch: 44 Train Loss: 0.3589 Val Loss: 0.3114 Acc: 0.8514 Pre: 0.8855 Recall: 0.8169 F1: 0.8498 Train AUC: 0.9176 Val AUC: 0.9368 Time: 13.36\n",
      "Epoch: 45 Train Loss: 0.3554 Val Loss: 0.3103 Acc: 0.8533 Pre: 0.8830 Recall: 0.8239 F1: 0.8525 Train AUC: 0.9200 Val AUC: 0.9374 Time: 12.63\n",
      "Epoch: 46 Train Loss: 0.3585 Val Loss: 0.3091 Acc: 0.8587 Pre: 0.8843 Recall: 0.8345 F1: 0.8587 Train AUC: 0.9190 Val AUC: 0.9377 Time: 12.50\n",
      "Epoch: 47 Train Loss: 0.3499 Val Loss: 0.3078 Acc: 0.8605 Pre: 0.8848 Recall: 0.8380 F1: 0.8608 Train AUC: 0.9235 Val AUC: 0.9381 Time: 12.10\n",
      "Epoch: 48 Train Loss: 0.3488 Val Loss: 0.3073 Acc: 0.8569 Pre: 0.8897 Recall: 0.8239 F1: 0.8556 Train AUC: 0.9215 Val AUC: 0.9385 Time: 12.61\n",
      "Epoch: 49 Train Loss: 0.3914 Val Loss: 0.3066 Acc: 0.8551 Pre: 0.8953 Recall: 0.8134 F1: 0.8524 Train AUC: 0.9046 Val AUC: 0.9392 Time: 13.14\n",
      "Epoch: 50 Train Loss: 0.3525 Val Loss: 0.3073 Acc: 0.8551 Pre: 0.9048 Recall: 0.8028 F1: 0.8507 Train AUC: 0.9210 Val AUC: 0.9398 Time: 13.36\n",
      "Epoch: 51 Train Loss: 0.3486 Val Loss: 0.3085 Acc: 0.8569 Pre: 0.9150 Recall: 0.7958 F1: 0.8512 Train AUC: 0.9230 Val AUC: 0.9403 Time: 12.83\n",
      "Epoch: 52 Train Loss: 0.3406 Val Loss: 0.3104 Acc: 0.8533 Pre: 0.9109 Recall: 0.7923 F1: 0.8475 Train AUC: 0.9242 Val AUC: 0.9405 Time: 12.25\n",
      "Epoch: 53 Train Loss: 0.3293 Val Loss: 0.3114 Acc: 0.8569 Pre: 0.9084 Recall: 0.8028 F1: 0.8523 Train AUC: 0.9321 Val AUC: 0.9405 Time: 12.11\n",
      "Epoch: 54 Train Loss: 0.3493 Val Loss: 0.3136 Acc: 0.8587 Pre: 0.8962 Recall: 0.8204 F1: 0.8566 Train AUC: 0.9247 Val AUC: 0.9402 Time: 12.52\n",
      "Epoch: 55 Train Loss: 0.3470 Val Loss: 0.3135 Acc: 0.8569 Pre: 0.8810 Recall: 0.8345 F1: 0.8571 Train AUC: 0.9278 Val AUC: 0.9398 Time: 13.08\n",
      "Epoch: 56 Train Loss: 0.3305 Val Loss: 0.3131 Acc: 0.8659 Pre: 0.8804 Recall: 0.8556 F1: 0.8679 Train AUC: 0.9328 Val AUC: 0.9393 Time: 13.11\n",
      "Epoch: 57 Train Loss: 0.3433 Val Loss: 0.3094 Acc: 0.8659 Pre: 0.8804 Recall: 0.8556 F1: 0.8679 Train AUC: 0.9270 Val AUC: 0.9399 Time: 12.88\n",
      "Epoch: 58 Train Loss: 0.3453 Val Loss: 0.3029 Acc: 0.8641 Pre: 0.8828 Recall: 0.8486 F1: 0.8654 Train AUC: 0.9273 Val AUC: 0.9408 Time: 12.15\n",
      "Epoch: 59 Train Loss: 0.3320 Val Loss: 0.2989 Acc: 0.8623 Pre: 0.8852 Recall: 0.8415 F1: 0.8628 Train AUC: 0.9314 Val AUC: 0.9413 Time: 11.84\n",
      "Epoch: 60 Train Loss: 0.3265 Val Loss: 0.2977 Acc: 0.8678 Pre: 0.8981 Recall: 0.8380 F1: 0.8670 Train AUC: 0.9313 Val AUC: 0.9415 Time: 12.16\n",
      "Epoch: 61 Train Loss: 0.3377 Val Loss: 0.2983 Acc: 0.8714 Pre: 0.9080 Recall: 0.8345 F1: 0.8697 Train AUC: 0.9285 Val AUC: 0.9419 Time: 12.56\n",
      "Epoch: 62 Train Loss: 0.3513 Val Loss: 0.2971 Acc: 0.8696 Pre: 0.9015 Recall: 0.8380 F1: 0.8686 Train AUC: 0.9267 Val AUC: 0.9419 Time: 13.05\n",
      "Epoch: 63 Train Loss: 0.3479 Val Loss: 0.2960 Acc: 0.8641 Pre: 0.8856 Recall: 0.8451 F1: 0.8649 Train AUC: 0.9259 Val AUC: 0.9421 Time: 13.27\n",
      "Epoch: 64 Train Loss: 0.3287 Val Loss: 0.2961 Acc: 0.8641 Pre: 0.8828 Recall: 0.8486 F1: 0.8654 Train AUC: 0.9311 Val AUC: 0.9423 Time: 13.34\n",
      "Epoch: 65 Train Loss: 0.3275 Val Loss: 0.2970 Acc: 0.8641 Pre: 0.8800 Recall: 0.8521 F1: 0.8658 Train AUC: 0.9318 Val AUC: 0.9427 Time: 12.90\n",
      "Epoch: 66 Train Loss: 0.3179 Val Loss: 0.2993 Acc: 0.8623 Pre: 0.8796 Recall: 0.8486 F1: 0.8638 Train AUC: 0.9358 Val AUC: 0.9430 Time: 12.05\n",
      "Epoch: 67 Train Loss: 0.3110 Val Loss: 0.3025 Acc: 0.8641 Pre: 0.8885 Recall: 0.8415 F1: 0.8644 Train AUC: 0.9395 Val AUC: 0.9428 Time: 11.58\n",
      "Epoch: 68 Train Loss: 0.3482 Val Loss: 0.3021 Acc: 0.8678 Pre: 0.8951 Recall: 0.8415 F1: 0.8675 Train AUC: 0.9259 Val AUC: 0.9435 Time: 11.79\n",
      "Epoch: 69 Train Loss: 0.3317 Val Loss: 0.2998 Acc: 0.8678 Pre: 0.8981 Recall: 0.8380 F1: 0.8670 Train AUC: 0.9336 Val AUC: 0.9442 Time: 12.29\n",
      "Epoch: 70 Train Loss: 0.3285 Val Loss: 0.2987 Acc: 0.8659 Pre: 0.8977 Recall: 0.8345 F1: 0.8650 Train AUC: 0.9313 Val AUC: 0.9448 Time: 12.81\n",
      "Epoch: 71 Train Loss: 0.3345 Val Loss: 0.2960 Acc: 0.8678 Pre: 0.9105 Recall: 0.8239 F1: 0.8651 Train AUC: 0.9314 Val AUC: 0.9449 Time: 13.28\n",
      "Epoch: 72 Train Loss: 0.3239 Val Loss: 0.2941 Acc: 0.8714 Pre: 0.9080 Recall: 0.8345 F1: 0.8697 Train AUC: 0.9331 Val AUC: 0.9448 Time: 13.94\n",
      "Epoch: 73 Train Loss: 0.3159 Val Loss: 0.2926 Acc: 0.8714 Pre: 0.8989 Recall: 0.8451 F1: 0.8711 Train AUC: 0.9385 Val AUC: 0.9446 Time: 14.01\n",
      "Epoch: 74 Train Loss: 0.3159 Val Loss: 0.2924 Acc: 0.8678 Pre: 0.8864 Recall: 0.8521 F1: 0.8689 Train AUC: 0.9374 Val AUC: 0.9441 Time: 12.89\n",
      "Epoch: 75 Train Loss: 0.3241 Val Loss: 0.2935 Acc: 0.8678 Pre: 0.8809 Recall: 0.8592 F1: 0.8699 Train AUC: 0.9345 Val AUC: 0.9440 Time: 11.84\n",
      "Epoch: 76 Train Loss: 0.3176 Val Loss: 0.2949 Acc: 0.8659 Pre: 0.8777 Recall: 0.8592 F1: 0.8683 Train AUC: 0.9360 Val AUC: 0.9437 Time: 11.65\n",
      "Epoch: 77 Train Loss: 0.3105 Val Loss: 0.2953 Acc: 0.8659 Pre: 0.8777 Recall: 0.8592 F1: 0.8683 Train AUC: 0.9399 Val AUC: 0.9434 Time: 11.62\n",
      "Epoch: 78 Train Loss: 0.3246 Val Loss: 0.2944 Acc: 0.8659 Pre: 0.8804 Recall: 0.8556 F1: 0.8679 Train AUC: 0.9348 Val AUC: 0.9437 Time: 12.09\n",
      "Epoch: 79 Train Loss: 0.3141 Val Loss: 0.2955 Acc: 0.8641 Pre: 0.8914 Recall: 0.8380 F1: 0.8639 Train AUC: 0.9379 Val AUC: 0.9438 Time: 12.60\n",
      "Epoch: 80 Train Loss: 0.3089 Val Loss: 0.2983 Acc: 0.8605 Pre: 0.8996 Recall: 0.8204 F1: 0.8582 Train AUC: 0.9396 Val AUC: 0.9439 Time: 13.05\n",
      "Epoch: 81 Train Loss: 0.3132 Val Loss: 0.2993 Acc: 0.8605 Pre: 0.8966 Recall: 0.8239 F1: 0.8587 Train AUC: 0.9418 Val AUC: 0.9437 Time: 13.50\n",
      "Epoch: 82 Train Loss: 0.3115 Val Loss: 0.2997 Acc: 0.8569 Pre: 0.8839 Recall: 0.8310 F1: 0.8566 Train AUC: 0.9396 Val AUC: 0.9436 Time: 12.83\n",
      "Epoch: 83 Train Loss: 0.3081 Val Loss: 0.3007 Acc: 0.8569 Pre: 0.8782 Recall: 0.8380 F1: 0.8577 Train AUC: 0.9407 Val AUC: 0.9433 Time: 12.36\n",
      "Epoch: 84 Train Loss: 0.3078 Val Loss: 0.3025 Acc: 0.8659 Pre: 0.8777 Recall: 0.8592 F1: 0.8683 Train AUC: 0.9413 Val AUC: 0.9429 Time: 11.61\n",
      "Epoch: 85 Train Loss: 0.3000 Val Loss: 0.3044 Acc: 0.8641 Pre: 0.8693 Recall: 0.8662 F1: 0.8677 Train AUC: 0.9434 Val AUC: 0.9428 Time: 11.43\n",
      "Epoch: 86 Train Loss: 0.3119 Val Loss: 0.3006 Acc: 0.8623 Pre: 0.8741 Recall: 0.8556 F1: 0.8648 Train AUC: 0.9411 Val AUC: 0.9438 Time: 11.99\n",
      "Epoch: 87 Train Loss: 0.2895 Val Loss: 0.2976 Acc: 0.8623 Pre: 0.8910 Recall: 0.8345 F1: 0.8618 Train AUC: 0.9479 Val AUC: 0.9446 Time: 12.36\n",
      "Epoch: 88 Train Loss: 0.3046 Val Loss: 0.2965 Acc: 0.8641 Pre: 0.8973 Recall: 0.8310 F1: 0.8629 Train AUC: 0.9432 Val AUC: 0.9451 Time: 12.97\n",
      "Epoch: 89 Train Loss: 0.3149 Val Loss: 0.2943 Acc: 0.8641 Pre: 0.9035 Recall: 0.8239 F1: 0.8619 Train AUC: 0.9398 Val AUC: 0.9456 Time: 13.33\n",
      "Epoch: 90 Train Loss: 0.3089 Val Loss: 0.2921 Acc: 0.8659 Pre: 0.9008 Recall: 0.8310 F1: 0.8645 Train AUC: 0.9411 Val AUC: 0.9458 Time: 13.91\n",
      "Epoch: 91 Train Loss: 0.2938 Val Loss: 0.2905 Acc: 0.8623 Pre: 0.8881 Recall: 0.8380 F1: 0.8623 Train AUC: 0.9463 Val AUC: 0.9459 Time: 14.12\n",
      "Epoch: 92 Train Loss: 0.3153 Val Loss: 0.2909 Acc: 0.8696 Pre: 0.8813 Recall: 0.8627 F1: 0.8719 Train AUC: 0.9400 Val AUC: 0.9458 Time: 12.73\n",
      "Epoch: 93 Train Loss: 0.2929 Val Loss: 0.2927 Acc: 0.8659 Pre: 0.8723 Recall: 0.8662 F1: 0.8693 Train AUC: 0.9452 Val AUC: 0.9455 Time: 12.20\n",
      "Epoch: 94 Train Loss: 0.3057 Val Loss: 0.2926 Acc: 0.8641 Pre: 0.8693 Recall: 0.8662 F1: 0.8677 Train AUC: 0.9431 Val AUC: 0.9456 Time: 11.83\n",
      "Epoch: 95 Train Loss: 0.3023 Val Loss: 0.2910 Acc: 0.8714 Pre: 0.8845 Recall: 0.8627 F1: 0.8734 Train AUC: 0.9432 Val AUC: 0.9459 Time: 11.83\n",
      "Epoch: 96 Train Loss: 0.3113 Val Loss: 0.2897 Acc: 0.8659 Pre: 0.8860 Recall: 0.8486 F1: 0.8669 Train AUC: 0.9401 Val AUC: 0.9462 Time: 12.17\n",
      "Epoch: 97 Train Loss: 0.2985 Val Loss: 0.2901 Acc: 0.8678 Pre: 0.8981 Recall: 0.8380 F1: 0.8670 Train AUC: 0.9435 Val AUC: 0.9464 Time: 12.70\n",
      "Epoch: 98 Train Loss: 0.3041 Val Loss: 0.2907 Acc: 0.8659 Pre: 0.9008 Recall: 0.8310 F1: 0.8645 Train AUC: 0.9435 Val AUC: 0.9465 Time: 13.23\n",
      "Epoch: 99 Train Loss: 0.2880 Val Loss: 0.2911 Acc: 0.8641 Pre: 0.8973 Recall: 0.8310 F1: 0.8629 Train AUC: 0.9486 Val AUC: 0.9464 Time: 13.61\n",
      "Epoch: 100 Train Loss: 0.2938 Val Loss: 0.2913 Acc: 0.8641 Pre: 0.8885 Recall: 0.8415 F1: 0.8644 Train AUC: 0.9468 Val AUC: 0.9458 Time: 13.94\n",
      "Epoch: 101 Train Loss: 0.2961 Val Loss: 0.2927 Acc: 0.8641 Pre: 0.8828 Recall: 0.8486 F1: 0.8654 Train AUC: 0.9455 Val AUC: 0.9452 Time: 13.10\n",
      "Epoch: 102 Train Loss: 0.2871 Val Loss: 0.2941 Acc: 0.8659 Pre: 0.8750 Recall: 0.8627 F1: 0.8688 Train AUC: 0.9503 Val AUC: 0.9450 Time: 12.18\n",
      "Epoch: 103 Train Loss: 0.2980 Val Loss: 0.2915 Acc: 0.8641 Pre: 0.8773 Recall: 0.8556 F1: 0.8663 Train AUC: 0.9460 Val AUC: 0.9456 Time: 12.20\n",
      "Epoch: 104 Train Loss: 0.2911 Val Loss: 0.2893 Acc: 0.8696 Pre: 0.8955 Recall: 0.8451 F1: 0.8696 Train AUC: 0.9478 Val AUC: 0.9462 Time: 12.27\n",
      "Epoch: 105 Train Loss: 0.2863 Val Loss: 0.2882 Acc: 0.8678 Pre: 0.8981 Recall: 0.8380 F1: 0.8670 Train AUC: 0.9500 Val AUC: 0.9466 Time: 12.53\n",
      "Epoch: 106 Train Loss: 0.2929 Val Loss: 0.2882 Acc: 0.8696 Pre: 0.9046 Recall: 0.8345 F1: 0.8681 Train AUC: 0.9475 Val AUC: 0.9470 Time: 13.06\n",
      "Epoch: 107 Train Loss: 0.2903 Val Loss: 0.2870 Acc: 0.8678 Pre: 0.8981 Recall: 0.8380 F1: 0.8670 Train AUC: 0.9493 Val AUC: 0.9470 Time: 13.42\n",
      "Epoch: 108 Train Loss: 0.2994 Val Loss: 0.2869 Acc: 0.8714 Pre: 0.8901 Recall: 0.8556 F1: 0.8725 Train AUC: 0.9447 Val AUC: 0.9469 Time: 13.21\n",
      "Epoch: 109 Train Loss: 0.3043 Val Loss: 0.2893 Acc: 0.8659 Pre: 0.8697 Recall: 0.8697 F1: 0.8697 Train AUC: 0.9430 Val AUC: 0.9463 Time: 12.55\n",
      "Epoch: 110 Train Loss: 0.2886 Val Loss: 0.2914 Acc: 0.8678 Pre: 0.8702 Recall: 0.8732 F1: 0.8717 Train AUC: 0.9488 Val AUC: 0.9460 Time: 11.89\n",
      "Epoch: 111 Train Loss: 0.2925 Val Loss: 0.2918 Acc: 0.8678 Pre: 0.8781 Recall: 0.8627 F1: 0.8703 Train AUC: 0.9491 Val AUC: 0.9458 Time: 12.01\n",
      "Epoch: 112 Train Loss: 0.2877 Val Loss: 0.2927 Acc: 0.8659 Pre: 0.8889 Recall: 0.8451 F1: 0.8664 Train AUC: 0.9493 Val AUC: 0.9459 Time: 12.51\n",
      "Epoch: 113 Train Loss: 0.2883 Val Loss: 0.2937 Acc: 0.8659 Pre: 0.9008 Recall: 0.8310 F1: 0.8645 Train AUC: 0.9504 Val AUC: 0.9460 Time: 12.92\n",
      "Epoch: 114 Train Loss: 0.2856 Val Loss: 0.2928 Acc: 0.8678 Pre: 0.9011 Recall: 0.8345 F1: 0.8665 Train AUC: 0.9514 Val AUC: 0.9459 Time: 13.45\n",
      "Epoch: 115 Train Loss: 0.2758 Val Loss: 0.2909 Acc: 0.8678 Pre: 0.8951 Recall: 0.8415 F1: 0.8675 Train AUC: 0.9544 Val AUC: 0.9458 Time: 13.54\n",
      "Epoch: 116 Train Loss: 0.2863 Val Loss: 0.2901 Acc: 0.8678 Pre: 0.8864 Recall: 0.8521 F1: 0.8689 Train AUC: 0.9499 Val AUC: 0.9458 Time: 13.16\n",
      "Epoch: 117 Train Loss: 0.2796 Val Loss: 0.2921 Acc: 0.8659 Pre: 0.8697 Recall: 0.8697 F1: 0.8697 Train AUC: 0.9513 Val AUC: 0.9456 Time: 12.51\n",
      "Epoch: 118 Train Loss: 0.2878 Val Loss: 0.2919 Acc: 0.8659 Pre: 0.8697 Recall: 0.8697 F1: 0.8697 Train AUC: 0.9509 Val AUC: 0.9455 Time: 11.79\n",
      "Epoch: 119 Train Loss: 0.2832 Val Loss: 0.2897 Acc: 0.8750 Pre: 0.8938 Recall: 0.8592 F1: 0.8761 Train AUC: 0.9513 Val AUC: 0.9457 Time: 12.00\n",
      "Epoch: 120 Train Loss: 0.2769 Val Loss: 0.2892 Acc: 0.8696 Pre: 0.9015 Recall: 0.8380 F1: 0.8686 Train AUC: 0.9526 Val AUC: 0.9462 Time: 11.89\n",
      "Epoch: 121 Train Loss: 0.2829 Val Loss: 0.2896 Acc: 0.8678 Pre: 0.9011 Recall: 0.8345 F1: 0.8665 Train AUC: 0.9505 Val AUC: 0.9462 Time: 12.38\n",
      "Epoch: 122 Train Loss: 0.2817 Val Loss: 0.2891 Acc: 0.8732 Pre: 0.8905 Recall: 0.8592 F1: 0.8746 Train AUC: 0.9538 Val AUC: 0.9459 Time: 12.72\n",
      "Epoch: 123 Train Loss: 0.2771 Val Loss: 0.2929 Acc: 0.8659 Pre: 0.8646 Recall: 0.8768 F1: 0.8706 Train AUC: 0.9520 Val AUC: 0.9456 Time: 13.34\n",
      "Epoch: 124 Train Loss: 0.2831 Val Loss: 0.2946 Acc: 0.8659 Pre: 0.8646 Recall: 0.8768 F1: 0.8706 Train AUC: 0.9512 Val AUC: 0.9456 Time: 13.85\n",
      "Epoch: 125 Train Loss: 0.2778 Val Loss: 0.2906 Acc: 0.8714 Pre: 0.8817 Recall: 0.8662 F1: 0.8739 Train AUC: 0.9544 Val AUC: 0.9464 Time: 14.08\n",
      "Epoch: 126 Train Loss: 0.2873 Val Loss: 0.2893 Acc: 0.8659 Pre: 0.8947 Recall: 0.8380 F1: 0.8655 Train AUC: 0.9486 Val AUC: 0.9471 Time: 13.00\n",
      "Epoch: 127 Train Loss: 0.2875 Val Loss: 0.2887 Acc: 0.8659 Pre: 0.9008 Recall: 0.8310 F1: 0.8645 Train AUC: 0.9508 Val AUC: 0.9469 Time: 12.04\n",
      "Epoch: 128 Train Loss: 0.2866 Val Loss: 0.2861 Acc: 0.8696 Pre: 0.9015 Recall: 0.8380 F1: 0.8686 Train AUC: 0.9513 Val AUC: 0.9473 Time: 11.77\n",
      "Epoch: 129 Train Loss: 0.2731 Val Loss: 0.2846 Acc: 0.8696 Pre: 0.8841 Recall: 0.8592 F1: 0.8714 Train AUC: 0.9539 Val AUC: 0.9473 Time: 12.11\n",
      "Epoch: 130 Train Loss: 0.2689 Val Loss: 0.2861 Acc: 0.8714 Pre: 0.8790 Recall: 0.8697 F1: 0.8743 Train AUC: 0.9556 Val AUC: 0.9471 Time: 12.75\n",
      "Epoch: 131 Train Loss: 0.2732 Val Loss: 0.2877 Acc: 0.8678 Pre: 0.8728 Recall: 0.8697 F1: 0.8713 Train AUC: 0.9553 Val AUC: 0.9473 Time: 13.10\n",
      "Epoch: 132 Train Loss: 0.2863 Val Loss: 0.2844 Acc: 0.8714 Pre: 0.8790 Recall: 0.8697 F1: 0.8743 Train AUC: 0.9520 Val AUC: 0.9477 Time: 13.51\n",
      "Epoch: 133 Train Loss: 0.2731 Val Loss: 0.2849 Acc: 0.8732 Pre: 0.8993 Recall: 0.8486 F1: 0.8732 Train AUC: 0.9535 Val AUC: 0.9478 Time: 13.62\n",
      "Epoch: 134 Train Loss: 0.2739 Val Loss: 0.2873 Acc: 0.8696 Pre: 0.9046 Recall: 0.8345 F1: 0.8681 Train AUC: 0.9546 Val AUC: 0.9477 Time: 12.63\n",
      "Epoch: 135 Train Loss: 0.2781 Val Loss: 0.2867 Acc: 0.8714 Pre: 0.8989 Recall: 0.8451 F1: 0.8711 Train AUC: 0.9562 Val AUC: 0.9480 Time: 12.28\n",
      "Epoch: 136 Train Loss: 0.2745 Val Loss: 0.2860 Acc: 0.8714 Pre: 0.8873 Recall: 0.8592 F1: 0.8730 Train AUC: 0.9562 Val AUC: 0.9480 Time: 12.57\n",
      "Epoch: 137 Train Loss: 0.2748 Val Loss: 0.2855 Acc: 0.8696 Pre: 0.8841 Recall: 0.8592 F1: 0.8714 Train AUC: 0.9541 Val AUC: 0.9482 Time: 12.67\n",
      "Epoch: 138 Train Loss: 0.2588 Val Loss: 0.2853 Acc: 0.8696 Pre: 0.8869 Recall: 0.8556 F1: 0.8710 Train AUC: 0.9597 Val AUC: 0.9479 Time: 13.21\n",
      "Epoch: 139 Train Loss: 0.2719 Val Loss: 0.2854 Acc: 0.8714 Pre: 0.8930 Recall: 0.8521 F1: 0.8721 Train AUC: 0.9557 Val AUC: 0.9479 Time: 13.58\n",
      "Epoch: 140 Train Loss: 0.2592 Val Loss: 0.2861 Acc: 0.8641 Pre: 0.8914 Recall: 0.8380 F1: 0.8639 Train AUC: 0.9593 Val AUC: 0.9478 Time: 13.18\n",
      "Epoch: 141 Train Loss: 0.2755 Val Loss: 0.2865 Acc: 0.8623 Pre: 0.8910 Recall: 0.8345 F1: 0.8618 Train AUC: 0.9544 Val AUC: 0.9474 Time: 12.34\n",
      "Epoch: 142 Train Loss: 0.2683 Val Loss: 0.2856 Acc: 0.8732 Pre: 0.8934 Recall: 0.8556 F1: 0.8741 Train AUC: 0.9574 Val AUC: 0.9471 Time: 12.94\n",
      "Epoch: 143 Train Loss: 0.2569 Val Loss: 0.2866 Acc: 0.8714 Pre: 0.8817 Recall: 0.8662 F1: 0.8739 Train AUC: 0.9600 Val AUC: 0.9474 Time: 12.89\n",
      "Epoch: 144 Train Loss: 0.2621 Val Loss: 0.2859 Acc: 0.8750 Pre: 0.8881 Recall: 0.8662 F1: 0.8770 Train AUC: 0.9584 Val AUC: 0.9480 Time: 12.21\n",
      "Epoch: 145 Train Loss: 0.2564 Val Loss: 0.2832 Acc: 0.8714 Pre: 0.8901 Recall: 0.8556 F1: 0.8725 Train AUC: 0.9604 Val AUC: 0.9486 Time: 12.59\n",
      "Epoch: 146 Train Loss: 0.2604 Val Loss: 0.2826 Acc: 0.8732 Pre: 0.9023 Recall: 0.8451 F1: 0.8727 Train AUC: 0.9590 Val AUC: 0.9494 Time: 12.43\n",
      "Epoch: 147 Train Loss: 0.2542 Val Loss: 0.2829 Acc: 0.8750 Pre: 0.9057 Recall: 0.8451 F1: 0.8743 Train AUC: 0.9610 Val AUC: 0.9495 Time: 12.98\n",
      "Epoch: 148 Train Loss: 0.2668 Val Loss: 0.2826 Acc: 0.8768 Pre: 0.9000 Recall: 0.8556 F1: 0.8773 Train AUC: 0.9563 Val AUC: 0.9495 Time: 13.54\n",
      "Epoch: 149 Train Loss: 0.2594 Val Loss: 0.2824 Acc: 0.8732 Pre: 0.8905 Recall: 0.8592 F1: 0.8746 Train AUC: 0.9594 Val AUC: 0.9494 Time: 12.89\n",
      "Epoch: 150 Train Loss: 0.2604 Val Loss: 0.2832 Acc: 0.8714 Pre: 0.8845 Recall: 0.8627 F1: 0.8734 Train AUC: 0.9584 Val AUC: 0.9493 Time: 12.81\n",
      "Epoch: 151 Train Loss: 0.2562 Val Loss: 0.2833 Acc: 0.8732 Pre: 0.8877 Recall: 0.8627 F1: 0.8750 Train AUC: 0.9607 Val AUC: 0.9489 Time: 13.04\n",
      "Epoch: 152 Train Loss: 0.2629 Val Loss: 0.2847 Acc: 0.8714 Pre: 0.8901 Recall: 0.8556 F1: 0.8725 Train AUC: 0.9579 Val AUC: 0.9480 Time: 13.21\n",
      "Epoch: 153 Train Loss: 0.2679 Val Loss: 0.2864 Acc: 0.8714 Pre: 0.8901 Recall: 0.8556 F1: 0.8725 Train AUC: 0.9554 Val AUC: 0.9475 Time: 13.02\n",
      "Epoch: 154 Train Loss: 0.2591 Val Loss: 0.2877 Acc: 0.8714 Pre: 0.8901 Recall: 0.8556 F1: 0.8725 Train AUC: 0.9588 Val AUC: 0.9468 Time: 13.22\n",
      "Epoch: 155 Train Loss: 0.2578 Val Loss: 0.2881 Acc: 0.8732 Pre: 0.8905 Recall: 0.8592 F1: 0.8746 Train AUC: 0.9588 Val AUC: 0.9462 Time: 12.62\n",
      "Epoch: 156 Train Loss: 0.2563 Val Loss: 0.2881 Acc: 0.8678 Pre: 0.8809 Recall: 0.8592 F1: 0.8699 Train AUC: 0.9595 Val AUC: 0.9465 Time: 12.45\n",
      "Epoch: 157 Train Loss: 0.2502 Val Loss: 0.2869 Acc: 0.8696 Pre: 0.8813 Recall: 0.8627 F1: 0.8719 Train AUC: 0.9620 Val AUC: 0.9476 Time: 13.17\n",
      "Epoch: 158 Train Loss: 0.2582 Val Loss: 0.2854 Acc: 0.8696 Pre: 0.8841 Recall: 0.8592 F1: 0.8714 Train AUC: 0.9609 Val AUC: 0.9482 Time: 12.86\n",
      "Epoch: 159 Train Loss: 0.2487 Val Loss: 0.2821 Acc: 0.8786 Pre: 0.9004 Recall: 0.8592 F1: 0.8793 Train AUC: 0.9640 Val AUC: 0.9488 Time: 13.07\n",
      "Epoch: 160 Train Loss: 0.2470 Val Loss: 0.2818 Acc: 0.8768 Pre: 0.9091 Recall: 0.8451 F1: 0.8759 Train AUC: 0.9635 Val AUC: 0.9494 Time: 13.18\n",
      "Epoch: 161 Train Loss: 0.2574 Val Loss: 0.2817 Acc: 0.8714 Pre: 0.8873 Recall: 0.8592 F1: 0.8730 Train AUC: 0.9610 Val AUC: 0.9495 Time: 12.66\n",
      "Epoch: 162 Train Loss: 0.2529 Val Loss: 0.2857 Acc: 0.8786 Pre: 0.8834 Recall: 0.8803 F1: 0.8818 Train AUC: 0.9604 Val AUC: 0.9487 Time: 12.28\n",
      "Epoch: 163 Train Loss: 0.2550 Val Loss: 0.2872 Acc: 0.8696 Pre: 0.8813 Recall: 0.8627 F1: 0.8719 Train AUC: 0.9614 Val AUC: 0.9474 Time: 13.01\n",
      "Epoch: 164 Train Loss: 0.2483 Val Loss: 0.2882 Acc: 0.8696 Pre: 0.8955 Recall: 0.8451 F1: 0.8696 Train AUC: 0.9632 Val AUC: 0.9465 Time: 13.01\n",
      "Epoch: 165 Train Loss: 0.2512 Val Loss: 0.2906 Acc: 0.8768 Pre: 0.9154 Recall: 0.8380 F1: 0.8750 Train AUC: 0.9621 Val AUC: 0.9470 Time: 13.36\n",
      "Epoch: 166 Train Loss: 0.2480 Val Loss: 0.2883 Acc: 0.8804 Pre: 0.9160 Recall: 0.8451 F1: 0.8791 Train AUC: 0.9632 Val AUC: 0.9471 Time: 13.89\n",
      "Epoch: 167 Train Loss: 0.2478 Val Loss: 0.2904 Acc: 0.8678 Pre: 0.8702 Recall: 0.8732 F1: 0.8717 Train AUC: 0.9635 Val AUC: 0.9469 Time: 13.33\n",
      "Epoch: 168 Train Loss: 0.2501 Val Loss: 0.2900 Acc: 0.8678 Pre: 0.8702 Recall: 0.8732 F1: 0.8717 Train AUC: 0.9648 Val AUC: 0.9469 Time: 12.34\n",
      "Epoch: 169 Train Loss: 0.2527 Val Loss: 0.2890 Acc: 0.8732 Pre: 0.8905 Recall: 0.8592 F1: 0.8746 Train AUC: 0.9624 Val AUC: 0.9460 Time: 11.68\n",
      "Epoch: 170 Train Loss: 0.2481 Val Loss: 0.2956 Acc: 0.8659 Pre: 0.9008 Recall: 0.8310 F1: 0.8645 Train AUC: 0.9628 Val AUC: 0.9451 Time: 11.60\n",
      "Epoch: 171 Train Loss: 0.2615 Val Loss: 0.2933 Acc: 0.8641 Pre: 0.8914 Recall: 0.8380 F1: 0.8639 Train AUC: 0.9611 Val AUC: 0.9450 Time: 12.19\n",
      "Epoch: 172 Train Loss: 0.2544 Val Loss: 0.2932 Acc: 0.8678 Pre: 0.8702 Recall: 0.8732 F1: 0.8717 Train AUC: 0.9617 Val AUC: 0.9463 Time: 12.77\n",
      "Epoch: 173 Train Loss: 0.2498 Val Loss: 0.2874 Acc: 0.8750 Pre: 0.8772 Recall: 0.8803 F1: 0.8787 Train AUC: 0.9640 Val AUC: 0.9482 Time: 13.12\n",
      "Epoch: 174 Train Loss: 0.2493 Val Loss: 0.2801 Acc: 0.8841 Pre: 0.9044 Recall: 0.8662 F1: 0.8849 Train AUC: 0.9635 Val AUC: 0.9500 Time: 13.57\n",
      "Epoch: 175 Train Loss: 0.2509 Val Loss: 0.2805 Acc: 0.8768 Pre: 0.9060 Recall: 0.8486 F1: 0.8764 Train AUC: 0.9622 Val AUC: 0.9506 Time: 13.32\n",
      "Epoch: 176 Train Loss: 0.2505 Val Loss: 0.2826 Acc: 0.8804 Pre: 0.9129 Recall: 0.8486 F1: 0.8796 Train AUC: 0.9619 Val AUC: 0.9500 Time: 12.62\n",
      "Epoch: 177 Train Loss: 0.2533 Val Loss: 0.2851 Acc: 0.8822 Pre: 0.9132 Recall: 0.8521 F1: 0.8816 Train AUC: 0.9611 Val AUC: 0.9482 Time: 12.75\n",
      "Epoch: 178 Train Loss: 0.2415 Val Loss: 0.2894 Acc: 0.8732 Pre: 0.8963 Recall: 0.8521 F1: 0.8736 Train AUC: 0.9660 Val AUC: 0.9460 Time: 12.74\n",
      "Epoch: 179 Train Loss: 0.2403 Val Loss: 0.2932 Acc: 0.8714 Pre: 0.8959 Recall: 0.8486 F1: 0.8716 Train AUC: 0.9656 Val AUC: 0.9448 Time: 13.05\n",
      "Epoch: 180 Train Loss: 0.2455 Val Loss: 0.2901 Acc: 0.8678 Pre: 0.8836 Recall: 0.8556 F1: 0.8694 Train AUC: 0.9648 Val AUC: 0.9461 Time: 12.83\n",
      "Epoch: 181 Train Loss: 0.2375 Val Loss: 0.2856 Acc: 0.8696 Pre: 0.8841 Recall: 0.8592 F1: 0.8714 Train AUC: 0.9663 Val AUC: 0.9480 Time: 12.48\n",
      "Epoch: 182 Train Loss: 0.2407 Val Loss: 0.2812 Acc: 0.8768 Pre: 0.9000 Recall: 0.8556 F1: 0.8773 Train AUC: 0.9656 Val AUC: 0.9499 Time: 13.16\n",
      "Epoch: 183 Train Loss: 0.2378 Val Loss: 0.2800 Acc: 0.8822 Pre: 0.9041 Recall: 0.8627 F1: 0.8829 Train AUC: 0.9665 Val AUC: 0.9506 Time: 13.45\n",
      "Epoch: 184 Train Loss: 0.2365 Val Loss: 0.2800 Acc: 0.8877 Pre: 0.8993 Recall: 0.8803 F1: 0.8897 Train AUC: 0.9669 Val AUC: 0.9508 Time: 13.80\n",
      "Epoch: 185 Train Loss: 0.2493 Val Loss: 0.2817 Acc: 0.8822 Pre: 0.9011 Recall: 0.8662 F1: 0.8833 Train AUC: 0.9625 Val AUC: 0.9500 Time: 12.43\n",
      "Epoch: 186 Train Loss: 0.2464 Val Loss: 0.2874 Acc: 0.8786 Pre: 0.8974 Recall: 0.8627 F1: 0.8797 Train AUC: 0.9637 Val AUC: 0.9476 Time: 11.97\n",
      "Epoch: 187 Train Loss: 0.2371 Val Loss: 0.2924 Acc: 0.8714 Pre: 0.8873 Recall: 0.8592 F1: 0.8730 Train AUC: 0.9665 Val AUC: 0.9457 Time: 12.08\n",
      "Epoch: 188 Train Loss: 0.2434 Val Loss: 0.2954 Acc: 0.8732 Pre: 0.8905 Recall: 0.8592 F1: 0.8746 Train AUC: 0.9647 Val AUC: 0.9448 Time: 12.64\n",
      "Epoch: 189 Train Loss: 0.2476 Val Loss: 0.2931 Acc: 0.8732 Pre: 0.8877 Recall: 0.8627 F1: 0.8750 Train AUC: 0.9638 Val AUC: 0.9455 Time: 13.03\n",
      "Epoch: 190 Train Loss: 0.2372 Val Loss: 0.2888 Acc: 0.8768 Pre: 0.8971 Recall: 0.8592 F1: 0.8777 Train AUC: 0.9669 Val AUC: 0.9469 Time: 13.51\n",
      "Epoch: 191 Train Loss: 0.2454 Val Loss: 0.2840 Acc: 0.8804 Pre: 0.9067 Recall: 0.8556 F1: 0.8804 Train AUC: 0.9639 Val AUC: 0.9490 Time: 13.64\n",
      "Epoch: 192 Train Loss: 0.2428 Val Loss: 0.2816 Acc: 0.8931 Pre: 0.9061 Recall: 0.8838 F1: 0.8948 Train AUC: 0.9644 Val AUC: 0.9499 Time: 12.97\n",
      "Epoch: 193 Train Loss: 0.2405 Val Loss: 0.2817 Acc: 0.8949 Pre: 0.9094 Recall: 0.8838 F1: 0.8964 Train AUC: 0.9659 Val AUC: 0.9497 Time: 12.23\n",
      "Epoch: 194 Train Loss: 0.2368 Val Loss: 0.2834 Acc: 0.8931 Pre: 0.9121 Recall: 0.8768 F1: 0.8941 Train AUC: 0.9667 Val AUC: 0.9488 Time: 12.00\n",
      "Epoch: 195 Train Loss: 0.2398 Val Loss: 0.2868 Acc: 0.8931 Pre: 0.9061 Recall: 0.8838 F1: 0.8948 Train AUC: 0.9671 Val AUC: 0.9477 Time: 12.43\n",
      "Epoch: 196 Train Loss: 0.2397 Val Loss: 0.2947 Acc: 0.8786 Pre: 0.9033 Recall: 0.8556 F1: 0.8788 Train AUC: 0.9654 Val AUC: 0.9444 Time: 13.08\n",
      "Epoch: 197 Train Loss: 0.2431 Val Loss: 0.2981 Acc: 0.8732 Pre: 0.8821 Recall: 0.8697 F1: 0.8759 Train AUC: 0.9653 Val AUC: 0.9433 Time: 13.42\n",
      "Epoch: 198 Train Loss: 0.2343 Val Loss: 0.2969 Acc: 0.8732 Pre: 0.8741 Recall: 0.8803 F1: 0.8772 Train AUC: 0.9670 Val AUC: 0.9444 Time: 13.99\n",
      "Epoch: 199 Train Loss: 0.2391 Val Loss: 0.2878 Acc: 0.8931 Pre: 0.9091 Recall: 0.8803 F1: 0.8945 Train AUC: 0.9671 Val AUC: 0.9472 Time: 13.27\n",
      "Epoch: 200 Train Loss: 0.2384 Val Loss: 0.2829 Acc: 0.8822 Pre: 0.9132 Recall: 0.8521 F1: 0.8816 Train AUC: 0.9670 Val AUC: 0.9491 Time: 12.19\n",
      "Epoch: 201 Train Loss: 0.2322 Val Loss: 0.2790 Acc: 0.8949 Pre: 0.9154 Recall: 0.8768 F1: 0.8957 Train AUC: 0.9681 Val AUC: 0.9505 Time: 12.57\n",
      "Epoch: 202 Train Loss: 0.2419 Val Loss: 0.2771 Acc: 0.8949 Pre: 0.9154 Recall: 0.8768 F1: 0.8957 Train AUC: 0.9640 Val AUC: 0.9514 Time: 12.56\n",
      "Epoch: 203 Train Loss: 0.2367 Val Loss: 0.2778 Acc: 0.9004 Pre: 0.9134 Recall: 0.8908 F1: 0.9020 Train AUC: 0.9660 Val AUC: 0.9510 Time: 12.97\n",
      "Epoch: 204 Train Loss: 0.2369 Val Loss: 0.2805 Acc: 0.8913 Pre: 0.9118 Recall: 0.8732 F1: 0.8921 Train AUC: 0.9668 Val AUC: 0.9501 Time: 13.68\n",
      "Epoch: 205 Train Loss: 0.2398 Val Loss: 0.2842 Acc: 0.8786 Pre: 0.9157 Recall: 0.8415 F1: 0.8771 Train AUC: 0.9660 Val AUC: 0.9485 Time: 13.63\n",
      "Epoch: 206 Train Loss: 0.2292 Val Loss: 0.2892 Acc: 0.8804 Pre: 0.9225 Recall: 0.8380 F1: 0.8782 Train AUC: 0.9692 Val AUC: 0.9470 Time: 13.17\n",
      "Epoch: 207 Train Loss: 0.2316 Val Loss: 0.2891 Acc: 0.8841 Pre: 0.9167 Recall: 0.8521 F1: 0.8832 Train AUC: 0.9686 Val AUC: 0.9468 Time: 12.54\n",
      "Epoch: 208 Train Loss: 0.2378 Val Loss: 0.2845 Acc: 0.8822 Pre: 0.8953 Recall: 0.8732 F1: 0.8841 Train AUC: 0.9672 Val AUC: 0.9489 Time: 12.19\n",
      "Epoch: 209 Train Loss: 0.2329 Val Loss: 0.2791 Acc: 0.8895 Pre: 0.9055 Recall: 0.8768 F1: 0.8909 Train AUC: 0.9690 Val AUC: 0.9508 Time: 12.47\n",
      "Epoch: 210 Train Loss: 0.2354 Val Loss: 0.2773 Acc: 0.8895 Pre: 0.9176 Recall: 0.8627 F1: 0.8893 Train AUC: 0.9682 Val AUC: 0.9515 Time: 13.14\n",
      "Epoch: 211 Train Loss: 0.2356 Val Loss: 0.2784 Acc: 0.8822 Pre: 0.9163 Recall: 0.8486 F1: 0.8812 Train AUC: 0.9666 Val AUC: 0.9512 Time: 12.96\n",
      "Epoch: 212 Train Loss: 0.2311 Val Loss: 0.2795 Acc: 0.8877 Pre: 0.9142 Recall: 0.8627 F1: 0.8877 Train AUC: 0.9682 Val AUC: 0.9502 Time: 13.52\n",
      "Epoch: 213 Train Loss: 0.2338 Val Loss: 0.2833 Acc: 0.8895 Pre: 0.9084 Recall: 0.8732 F1: 0.8905 Train AUC: 0.9680 Val AUC: 0.9486 Time: 13.64\n",
      "Epoch: 214 Train Loss: 0.2305 Val Loss: 0.2869 Acc: 0.8877 Pre: 0.9081 Recall: 0.8697 F1: 0.8885 Train AUC: 0.9682 Val AUC: 0.9472 Time: 12.69\n",
      "Epoch: 215 Train Loss: 0.2415 Val Loss: 0.2891 Acc: 0.8841 Pre: 0.9015 Recall: 0.8697 F1: 0.8853 Train AUC: 0.9673 Val AUC: 0.9465 Time: 12.21\n",
      "Epoch: 216 Train Loss: 0.2321 Val Loss: 0.2888 Acc: 0.8859 Pre: 0.9170 Recall: 0.8556 F1: 0.8852 Train AUC: 0.9684 Val AUC: 0.9469 Time: 11.89\n",
      "Epoch: 217 Train Loss: 0.2286 Val Loss: 0.2916 Acc: 0.8768 Pre: 0.9154 Recall: 0.8380 F1: 0.8750 Train AUC: 0.9693 Val AUC: 0.9467 Time: 12.52\n",
      "Epoch: 218 Train Loss: 0.2290 Val Loss: 0.2901 Acc: 0.8877 Pre: 0.9111 Recall: 0.8662 F1: 0.8881 Train AUC: 0.9694 Val AUC: 0.9465 Time: 12.83\n",
      "Epoch: 219 Train Loss: 0.2272 Val Loss: 0.2906 Acc: 0.8877 Pre: 0.9022 Recall: 0.8768 F1: 0.8893 Train AUC: 0.9697 Val AUC: 0.9464 Time: 13.51\n",
      "Epoch: 220 Train Loss: 0.2263 Val Loss: 0.2903 Acc: 0.8877 Pre: 0.9051 Recall: 0.8732 F1: 0.8889 Train AUC: 0.9702 Val AUC: 0.9465 Time: 13.77\n",
      "Epoch: 221 Train Loss: 0.2286 Val Loss: 0.2898 Acc: 0.8877 Pre: 0.9051 Recall: 0.8732 F1: 0.8889 Train AUC: 0.9692 Val AUC: 0.9469 Time: 13.20\n",
      "Epoch: 222 Train Loss: 0.2308 Val Loss: 0.2916 Acc: 0.8841 Pre: 0.8929 Recall: 0.8803 F1: 0.8865 Train AUC: 0.9682 Val AUC: 0.9469 Time: 12.77\n",
      "Epoch: 223 Train Loss: 0.2273 Val Loss: 0.2901 Acc: 0.8841 Pre: 0.9104 Recall: 0.8592 F1: 0.8841 Train AUC: 0.9699 Val AUC: 0.9468 Time: 12.48\n",
      "Epoch: 224 Train Loss: 0.2223 Val Loss: 0.2922 Acc: 0.8786 Pre: 0.9157 Recall: 0.8415 F1: 0.8771 Train AUC: 0.9706 Val AUC: 0.9466 Time: 12.54\n",
      "Epoch: 225 Train Loss: 0.2304 Val Loss: 0.2877 Acc: 0.8895 Pre: 0.9145 Recall: 0.8662 F1: 0.8897 Train AUC: 0.9695 Val AUC: 0.9478 Time: 12.31\n",
      "Epoch: 226 Train Loss: 0.2246 Val Loss: 0.2883 Acc: 0.8913 Pre: 0.9088 Recall: 0.8768 F1: 0.8925 Train AUC: 0.9705 Val AUC: 0.9479 Time: 12.97\n",
      "Epoch: 227 Train Loss: 0.2315 Val Loss: 0.2865 Acc: 0.8859 Pre: 0.9139 Recall: 0.8592 F1: 0.8857 Train AUC: 0.9683 Val AUC: 0.9479 Time: 13.52\n",
      "Epoch: 228 Train Loss: 0.2217 Val Loss: 0.2899 Acc: 0.8768 Pre: 0.9154 Recall: 0.8380 F1: 0.8750 Train AUC: 0.9711 Val AUC: 0.9477 Time: 13.68\n",
      "Epoch: 229 Train Loss: 0.2327 Val Loss: 0.2883 Acc: 0.8931 Pre: 0.9151 Recall: 0.8732 F1: 0.8937 Train AUC: 0.9701 Val AUC: 0.9473 Time: 13.04\n",
      "Epoch: 230 Train Loss: 0.2249 Val Loss: 0.2907 Acc: 0.8768 Pre: 0.8750 Recall: 0.8873 F1: 0.8811 Train AUC: 0.9704 Val AUC: 0.9469 Time: 12.05\n",
      "Epoch: 231 Train Loss: 0.2247 Val Loss: 0.2853 Acc: 0.8967 Pre: 0.9068 Recall: 0.8908 F1: 0.8988 Train AUC: 0.9709 Val AUC: 0.9485 Time: 12.59\n",
      "Epoch: 232 Train Loss: 0.2236 Val Loss: 0.2819 Acc: 0.8877 Pre: 0.9111 Recall: 0.8662 F1: 0.8881 Train AUC: 0.9712 Val AUC: 0.9495 Time: 12.78\n",
      "Epoch: 233 Train Loss: 0.2227 Val Loss: 0.2801 Acc: 0.8949 Pre: 0.9124 Recall: 0.8803 F1: 0.8961 Train AUC: 0.9710 Val AUC: 0.9499 Time: 12.80\n",
      "Epoch: 234 Train Loss: 0.2236 Val Loss: 0.2794 Acc: 0.8895 Pre: 0.9114 Recall: 0.8697 F1: 0.8901 Train AUC: 0.9707 Val AUC: 0.9502 Time: 13.70\n",
      "Epoch: 235 Train Loss: 0.2201 Val Loss: 0.2815 Acc: 0.8949 Pre: 0.9036 Recall: 0.8908 F1: 0.8972 Train AUC: 0.9713 Val AUC: 0.9496 Time: 12.83\n",
      "Epoch: 236 Train Loss: 0.2199 Val Loss: 0.2837 Acc: 0.8895 Pre: 0.9025 Recall: 0.8803 F1: 0.8913 Train AUC: 0.9721 Val AUC: 0.9486 Time: 12.61\n",
      "Epoch: 237 Train Loss: 0.2262 Val Loss: 0.2822 Acc: 0.8913 Pre: 0.9088 Recall: 0.8768 F1: 0.8925 Train AUC: 0.9699 Val AUC: 0.9493 Time: 13.03\n",
      "Epoch: 238 Train Loss: 0.2263 Val Loss: 0.2831 Acc: 0.8859 Pre: 0.9202 Recall: 0.8521 F1: 0.8848 Train AUC: 0.9694 Val AUC: 0.9493 Time: 12.81\n",
      "Epoch: 239 Train Loss: 0.2164 Val Loss: 0.2797 Acc: 0.8841 Pre: 0.9104 Recall: 0.8592 F1: 0.8841 Train AUC: 0.9734 Val AUC: 0.9504 Time: 12.88\n",
      "Epoch: 240 Train Loss: 0.2219 Val Loss: 0.2794 Acc: 0.8895 Pre: 0.9025 Recall: 0.8803 F1: 0.8913 Train AUC: 0.9709 Val AUC: 0.9509 Time: 13.33\n",
      "Epoch: 241 Train Loss: 0.2265 Val Loss: 0.2790 Acc: 0.8913 Pre: 0.9029 Recall: 0.8838 F1: 0.8932 Train AUC: 0.9707 Val AUC: 0.9507 Time: 13.36\n",
      "Epoch: 242 Train Loss: 0.2186 Val Loss: 0.2880 Acc: 0.8786 Pre: 0.9157 Recall: 0.8415 F1: 0.8771 Train AUC: 0.9724 Val AUC: 0.9481 Time: 12.52\n",
      "Epoch: 243 Train Loss: 0.2287 Val Loss: 0.2928 Acc: 0.8822 Pre: 0.9071 Recall: 0.8592 F1: 0.8825 Train AUC: 0.9694 Val AUC: 0.9466 Time: 12.02\n",
      "Epoch: 244 Train Loss: 0.2161 Val Loss: 0.2932 Acc: 0.8786 Pre: 0.8974 Recall: 0.8627 F1: 0.8797 Train AUC: 0.9728 Val AUC: 0.9462 Time: 12.56\n",
      "Epoch: 245 Train Loss: 0.2233 Val Loss: 0.2814 Acc: 0.8931 Pre: 0.9061 Recall: 0.8838 F1: 0.8948 Train AUC: 0.9699 Val AUC: 0.9497 Time: 13.12\n",
      "Epoch: 246 Train Loss: 0.2181 Val Loss: 0.2796 Acc: 0.8859 Pre: 0.8961 Recall: 0.8803 F1: 0.8881 Train AUC: 0.9714 Val AUC: 0.9513 Time: 13.42\n",
      "Epoch: 247 Train Loss: 0.2220 Val Loss: 0.2768 Acc: 0.8877 Pre: 0.9051 Recall: 0.8732 F1: 0.8889 Train AUC: 0.9727 Val AUC: 0.9520 Time: 12.93\n",
      "Epoch: 248 Train Loss: 0.2277 Val Loss: 0.2731 Acc: 0.8931 Pre: 0.9151 Recall: 0.8732 F1: 0.8937 Train AUC: 0.9720 Val AUC: 0.9528 Time: 12.72\n",
      "Epoch: 249 Train Loss: 0.2144 Val Loss: 0.2785 Acc: 0.8931 Pre: 0.9151 Recall: 0.8732 F1: 0.8937 Train AUC: 0.9729 Val AUC: 0.9507 Time: 13.34\n",
      "Epoch: 250 Train Loss: 0.2147 Val Loss: 0.2876 Acc: 0.8841 Pre: 0.9135 Recall: 0.8556 F1: 0.8836 Train AUC: 0.9729 Val AUC: 0.9487 Time: 12.96\n",
      "Epoch: 251 Train Loss: 0.2141 Val Loss: 0.2876 Acc: 0.8841 Pre: 0.9104 Recall: 0.8592 F1: 0.8841 Train AUC: 0.9727 Val AUC: 0.9479 Time: 12.78\n",
      "Epoch: 252 Train Loss: 0.2162 Val Loss: 0.2830 Acc: 0.8986 Pre: 0.9191 Recall: 0.8803 F1: 0.8993 Train AUC: 0.9718 Val AUC: 0.9491 Time: 12.68\n",
      "Epoch: 253 Train Loss: 0.2170 Val Loss: 0.2863 Acc: 0.8859 Pre: 0.8850 Recall: 0.8944 F1: 0.8897 Train AUC: 0.9729 Val AUC: 0.9496 Time: 13.18\n",
      "Epoch: 254 Train Loss: 0.2205 Val Loss: 0.2802 Acc: 0.8859 Pre: 0.8961 Recall: 0.8803 F1: 0.8881 Train AUC: 0.9725 Val AUC: 0.9510 Time: 12.77\n",
      "Epoch: 255 Train Loss: 0.2136 Val Loss: 0.2764 Acc: 0.8877 Pre: 0.9051 Recall: 0.8732 F1: 0.8889 Train AUC: 0.9736 Val AUC: 0.9521 Time: 12.46\n",
      "Epoch: 256 Train Loss: 0.2176 Val Loss: 0.2756 Acc: 0.8913 Pre: 0.9179 Recall: 0.8662 F1: 0.8913 Train AUC: 0.9720 Val AUC: 0.9518 Time: 12.73\n",
      "Epoch: 257 Train Loss: 0.2082 Val Loss: 0.2841 Acc: 0.8913 Pre: 0.8972 Recall: 0.8908 F1: 0.8940 Train AUC: 0.9748 Val AUC: 0.9495 Time: 13.20\n",
      "Epoch: 258 Train Loss: 0.2134 Val Loss: 0.2931 Acc: 0.8804 Pre: 0.8785 Recall: 0.8908 F1: 0.8846 Train AUC: 0.9734 Val AUC: 0.9480 Time: 13.47\n",
      "Epoch: 259 Train Loss: 0.2153 Val Loss: 0.2858 Acc: 0.8859 Pre: 0.8905 Recall: 0.8873 F1: 0.8889 Train AUC: 0.9730 Val AUC: 0.9487 Time: 12.67\n",
      "Epoch: 260 Train Loss: 0.2097 Val Loss: 0.2777 Acc: 0.8859 Pre: 0.9170 Recall: 0.8556 F1: 0.8852 Train AUC: 0.9743 Val AUC: 0.9516 Time: 12.29\n",
      "Epoch: 261 Train Loss: 0.2176 Val Loss: 0.2738 Acc: 0.8877 Pre: 0.9022 Recall: 0.8768 F1: 0.8893 Train AUC: 0.9738 Val AUC: 0.9526 Time: 12.71\n",
      "Epoch: 262 Train Loss: 0.2065 Val Loss: 0.2784 Acc: 0.8804 Pre: 0.8838 Recall: 0.8838 F1: 0.8838 Train AUC: 0.9758 Val AUC: 0.9525 Time: 12.81\n",
      "Epoch: 263 Train Loss: 0.2198 Val Loss: 0.2724 Acc: 0.8931 Pre: 0.9121 Recall: 0.8768 F1: 0.8941 Train AUC: 0.9728 Val AUC: 0.9530 Time: 13.25\n",
      "Epoch: 264 Train Loss: 0.2120 Val Loss: 0.2788 Acc: 0.8786 Pre: 0.9189 Recall: 0.8380 F1: 0.8766 Train AUC: 0.9754 Val AUC: 0.9532 Time: 13.39\n",
      "Epoch: 265 Train Loss: 0.2158 Val Loss: 0.2761 Acc: 0.8913 Pre: 0.9118 Recall: 0.8732 F1: 0.8921 Train AUC: 0.9745 Val AUC: 0.9518 Time: 12.47\n",
      "Epoch: 266 Train Loss: 0.2152 Val Loss: 0.2856 Acc: 0.8877 Pre: 0.8881 Recall: 0.8944 F1: 0.8912 Train AUC: 0.9727 Val AUC: 0.9505 Time: 11.81\n",
      "Epoch: 267 Train Loss: 0.2197 Val Loss: 0.2783 Acc: 0.8931 Pre: 0.9004 Recall: 0.8908 F1: 0.8956 Train AUC: 0.9726 Val AUC: 0.9513 Time: 12.33\n",
      "Epoch: 268 Train Loss: 0.2177 Val Loss: 0.2737 Acc: 0.8931 Pre: 0.9182 Recall: 0.8697 F1: 0.8933 Train AUC: 0.9719 Val AUC: 0.9525 Time: 13.15\n",
      "Epoch: 269 Train Loss: 0.2150 Val Loss: 0.2744 Acc: 0.8949 Pre: 0.9065 Recall: 0.8873 F1: 0.8968 Train AUC: 0.9733 Val AUC: 0.9523 Time: 13.12\n",
      "Epoch: 270 Train Loss: 0.2080 Val Loss: 0.2763 Acc: 0.8895 Pre: 0.8912 Recall: 0.8944 F1: 0.8928 Train AUC: 0.9749 Val AUC: 0.9528 Time: 13.22\n",
      "Epoch: 271 Train Loss: 0.2135 Val Loss: 0.2708 Acc: 0.8913 Pre: 0.9118 Recall: 0.8732 F1: 0.8921 Train AUC: 0.9755 Val AUC: 0.9535 Time: 13.46\n",
      "Epoch: 272 Train Loss: 0.2029 Val Loss: 0.2744 Acc: 0.8877 Pre: 0.9173 Recall: 0.8592 F1: 0.8873 Train AUC: 0.9774 Val AUC: 0.9533 Time: 12.98\n",
      "Epoch: 273 Train Loss: 0.2147 Val Loss: 0.2761 Acc: 0.8967 Pre: 0.9068 Recall: 0.8908 F1: 0.8988 Train AUC: 0.9743 Val AUC: 0.9522 Time: 12.39\n",
      "Epoch: 274 Train Loss: 0.2024 Val Loss: 0.2840 Acc: 0.8859 Pre: 0.8850 Recall: 0.8944 F1: 0.8897 Train AUC: 0.9761 Val AUC: 0.9507 Time: 12.37\n",
      "Epoch: 275 Train Loss: 0.2178 Val Loss: 0.2715 Acc: 0.8986 Pre: 0.9191 Recall: 0.8803 F1: 0.8993 Train AUC: 0.9746 Val AUC: 0.9532 Time: 12.72\n",
      "Epoch: 276 Train Loss: 0.2086 Val Loss: 0.2710 Acc: 0.8841 Pre: 0.9135 Recall: 0.8556 F1: 0.8836 Train AUC: 0.9750 Val AUC: 0.9544 Time: 13.28\n",
      "Epoch: 277 Train Loss: 0.2084 Val Loss: 0.2714 Acc: 0.8822 Pre: 0.8982 Recall: 0.8697 F1: 0.8837 Train AUC: 0.9747 Val AUC: 0.9540 Time: 14.06\n",
      "Epoch: 278 Train Loss: 0.2126 Val Loss: 0.2743 Acc: 0.8859 Pre: 0.8877 Recall: 0.8908 F1: 0.8893 Train AUC: 0.9734 Val AUC: 0.9537 Time: 13.36\n",
      "Epoch: 279 Train Loss: 0.2110 Val Loss: 0.2766 Acc: 0.8895 Pre: 0.9055 Recall: 0.8768 F1: 0.8909 Train AUC: 0.9748 Val AUC: 0.9513 Time: 12.27\n",
      "Epoch: 280 Train Loss: 0.2057 Val Loss: 0.2815 Acc: 0.8877 Pre: 0.9111 Recall: 0.8662 F1: 0.8881 Train AUC: 0.9768 Val AUC: 0.9496 Time: 11.68\n",
      "Epoch: 281 Train Loss: 0.2048 Val Loss: 0.2851 Acc: 0.8877 Pre: 0.9142 Recall: 0.8627 F1: 0.8877 Train AUC: 0.9754 Val AUC: 0.9491 Time: 11.72\n",
      "Epoch: 282 Train Loss: 0.2067 Val Loss: 0.2835 Acc: 0.8877 Pre: 0.9051 Recall: 0.8732 F1: 0.8889 Train AUC: 0.9754 Val AUC: 0.9489 Time: 12.44\n",
      "Epoch: 283 Train Loss: 0.2054 Val Loss: 0.2801 Acc: 0.8877 Pre: 0.8936 Recall: 0.8873 F1: 0.8905 Train AUC: 0.9752 Val AUC: 0.9508 Time: 12.79\n",
      "Epoch: 284 Train Loss: 0.2099 Val Loss: 0.2747 Acc: 0.8931 Pre: 0.9151 Recall: 0.8732 F1: 0.8937 Train AUC: 0.9748 Val AUC: 0.9517 Time: 13.15\n",
      "Epoch: 285 Train Loss: 0.2048 Val Loss: 0.2741 Acc: 0.8877 Pre: 0.9173 Recall: 0.8592 F1: 0.8873 Train AUC: 0.9755 Val AUC: 0.9518 Time: 13.72\n",
      "Epoch: 286 Train Loss: 0.2018 Val Loss: 0.2698 Acc: 0.8895 Pre: 0.9145 Recall: 0.8662 F1: 0.8897 Train AUC: 0.9777 Val AUC: 0.9534 Time: 14.35\n",
      "Epoch: 287 Train Loss: 0.1987 Val Loss: 0.2680 Acc: 0.8949 Pre: 0.9124 Recall: 0.8803 F1: 0.8961 Train AUC: 0.9776 Val AUC: 0.9540 Time: 13.15\n",
      "Epoch: 288 Train Loss: 0.1989 Val Loss: 0.2701 Acc: 0.8949 Pre: 0.8979 Recall: 0.8979 F1: 0.8979 Train AUC: 0.9775 Val AUC: 0.9538 Time: 12.11\n",
      "Epoch: 289 Train Loss: 0.1993 Val Loss: 0.2654 Acc: 0.8986 Pre: 0.9161 Recall: 0.8838 F1: 0.8996 Train AUC: 0.9778 Val AUC: 0.9547 Time: 11.56\n",
      "Epoch: 290 Train Loss: 0.2012 Val Loss: 0.2656 Acc: 0.8895 Pre: 0.9208 Recall: 0.8592 F1: 0.8889 Train AUC: 0.9762 Val AUC: 0.9555 Time: 11.50\n",
      "Epoch: 291 Train Loss: 0.2056 Val Loss: 0.2630 Acc: 0.8931 Pre: 0.9151 Recall: 0.8732 F1: 0.8937 Train AUC: 0.9767 Val AUC: 0.9556 Time: 12.15\n",
      "Epoch: 292 Train Loss: 0.2021 Val Loss: 0.2665 Acc: 0.8913 Pre: 0.8972 Recall: 0.8908 F1: 0.8940 Train AUC: 0.9758 Val AUC: 0.9551 Time: 12.69\n",
      "Epoch: 293 Train Loss: 0.2091 Val Loss: 0.2672 Acc: 0.8931 Pre: 0.9032 Recall: 0.8873 F1: 0.8952 Train AUC: 0.9757 Val AUC: 0.9543 Time: 12.98\n",
      "Epoch: 294 Train Loss: 0.1943 Val Loss: 0.2691 Acc: 0.8949 Pre: 0.9124 Recall: 0.8803 F1: 0.8961 Train AUC: 0.9788 Val AUC: 0.9534 Time: 13.41\n",
      "Epoch: 295 Train Loss: 0.1991 Val Loss: 0.2698 Acc: 0.8949 Pre: 0.9124 Recall: 0.8803 F1: 0.8961 Train AUC: 0.9773 Val AUC: 0.9532 Time: 14.24\n",
      "Epoch: 296 Train Loss: 0.1926 Val Loss: 0.2712 Acc: 0.9004 Pre: 0.9075 Recall: 0.8979 F1: 0.9027 Train AUC: 0.9786 Val AUC: 0.9530 Time: 14.36\n",
      "Epoch: 297 Train Loss: 0.1938 Val Loss: 0.2718 Acc: 0.8931 Pre: 0.8947 Recall: 0.8979 F1: 0.8963 Train AUC: 0.9784 Val AUC: 0.9532 Time: 13.11\n",
      "Epoch: 298 Train Loss: 0.1992 Val Loss: 0.2676 Acc: 0.8913 Pre: 0.9118 Recall: 0.8732 F1: 0.8921 Train AUC: 0.9777 Val AUC: 0.9540 Time: 12.18\n",
      "Epoch: 299 Train Loss: 0.1921 Val Loss: 0.2679 Acc: 0.8877 Pre: 0.9111 Recall: 0.8662 F1: 0.8881 Train AUC: 0.9789 Val AUC: 0.9544 Time: 11.99\n",
      "Epoch: 300 Train Loss: 0.2021 Val Loss: 0.2651 Acc: 0.8877 Pre: 0.8993 Recall: 0.8803 F1: 0.8897 Train AUC: 0.9772 Val AUC: 0.9549 Time: 12.44\n",
      "Epoch: 301 Train Loss: 0.2008 Val Loss: 0.2667 Acc: 0.8931 Pre: 0.8920 Recall: 0.9014 F1: 0.8967 Train AUC: 0.9775 Val AUC: 0.9555 Time: 13.04\n",
      "Epoch: 302 Train Loss: 0.1994 Val Loss: 0.2640 Acc: 0.8986 Pre: 0.9191 Recall: 0.8803 F1: 0.8993 Train AUC: 0.9779 Val AUC: 0.9557 Time: 13.63\n",
      "Epoch: 303 Train Loss: 0.1989 Val Loss: 0.2690 Acc: 0.8895 Pre: 0.9176 Recall: 0.8627 F1: 0.8893 Train AUC: 0.9768 Val AUC: 0.9544 Time: 14.05\n",
      "Epoch: 304 Train Loss: 0.1945 Val Loss: 0.2701 Acc: 0.8949 Pre: 0.9154 Recall: 0.8768 F1: 0.8957 Train AUC: 0.9779 Val AUC: 0.9532 Time: 14.12\n",
      "Epoch: 305 Train Loss: 0.1915 Val Loss: 0.2737 Acc: 0.8877 Pre: 0.8908 Recall: 0.8908 F1: 0.8908 Train AUC: 0.9789 Val AUC: 0.9521 Time: 12.66\n",
      "Epoch: 306 Train Loss: 0.1970 Val Loss: 0.2696 Acc: 0.8895 Pre: 0.9114 Recall: 0.8697 F1: 0.8901 Train AUC: 0.9780 Val AUC: 0.9535 Time: 11.68\n",
      "Epoch: 307 Train Loss: 0.1892 Val Loss: 0.2671 Acc: 0.8949 Pre: 0.9094 Recall: 0.8838 F1: 0.8964 Train AUC: 0.9799 Val AUC: 0.9548 Time: 11.47\n",
      "Epoch: 308 Train Loss: 0.1927 Val Loss: 0.2701 Acc: 0.8986 Pre: 0.9014 Recall: 0.9014 F1: 0.9014 Train AUC: 0.9781 Val AUC: 0.9542 Time: 11.78\n",
      "Epoch: 309 Train Loss: 0.1931 Val Loss: 0.2683 Acc: 0.8949 Pre: 0.9065 Recall: 0.8873 F1: 0.8968 Train AUC: 0.9792 Val AUC: 0.9543 Time: 12.50\n",
      "Epoch: 310 Train Loss: 0.1905 Val Loss: 0.2694 Acc: 0.9004 Pre: 0.9194 Recall: 0.8838 F1: 0.9013 Train AUC: 0.9794 Val AUC: 0.9539 Time: 12.96\n",
      "Epoch: 311 Train Loss: 0.1945 Val Loss: 0.2723 Acc: 0.8895 Pre: 0.8940 Recall: 0.8908 F1: 0.8924 Train AUC: 0.9784 Val AUC: 0.9534 Time: 13.23\n",
      "Epoch: 312 Train Loss: 0.1894 Val Loss: 0.2719 Acc: 0.8913 Pre: 0.8916 Recall: 0.8979 F1: 0.8947 Train AUC: 0.9787 Val AUC: 0.9539 Time: 13.87\n",
      "Epoch: 313 Train Loss: 0.1992 Val Loss: 0.2659 Acc: 0.9004 Pre: 0.9164 Recall: 0.8873 F1: 0.9016 Train AUC: 0.9772 Val AUC: 0.9548 Time: 14.24\n",
      "Epoch: 314 Train Loss: 0.1895 Val Loss: 0.2635 Acc: 0.8967 Pre: 0.9097 Recall: 0.8873 F1: 0.8984 Train AUC: 0.9793 Val AUC: 0.9560 Time: 13.19\n",
      "Epoch: 315 Train Loss: 0.1870 Val Loss: 0.2622 Acc: 0.8913 Pre: 0.9000 Recall: 0.8873 F1: 0.8936 Train AUC: 0.9799 Val AUC: 0.9563 Time: 12.04\n",
      "Epoch: 316 Train Loss: 0.1941 Val Loss: 0.2624 Acc: 0.8949 Pre: 0.8951 Recall: 0.9014 F1: 0.8982 Train AUC: 0.9784 Val AUC: 0.9568 Time: 11.71\n",
      "Epoch: 317 Train Loss: 0.1858 Val Loss: 0.2674 Acc: 0.8895 Pre: 0.8805 Recall: 0.9085 F1: 0.8943 Train AUC: 0.9804 Val AUC: 0.9559 Time: 11.60\n",
      "Epoch: 318 Train Loss: 0.1897 Val Loss: 0.2658 Acc: 0.8967 Pre: 0.9127 Recall: 0.8838 F1: 0.8980 Train AUC: 0.9809 Val AUC: 0.9548 Time: 12.30\n",
      "Epoch: 319 Train Loss: 0.1808 Val Loss: 0.2673 Acc: 0.8986 Pre: 0.9101 Recall: 0.8908 F1: 0.9004 Train AUC: 0.9812 Val AUC: 0.9541 Time: 12.69\n",
      "Epoch: 320 Train Loss: 0.1818 Val Loss: 0.2666 Acc: 0.8913 Pre: 0.9029 Recall: 0.8838 F1: 0.8932 Train AUC: 0.9811 Val AUC: 0.9544 Time: 13.09\n",
      "Epoch: 321 Train Loss: 0.1841 Val Loss: 0.2680 Acc: 0.8949 Pre: 0.8979 Recall: 0.8979 F1: 0.8979 Train AUC: 0.9809 Val AUC: 0.9541 Time: 13.59\n",
      "Epoch: 322 Train Loss: 0.1915 Val Loss: 0.2645 Acc: 0.8931 Pre: 0.9004 Recall: 0.8908 F1: 0.8956 Train AUC: 0.9803 Val AUC: 0.9551 Time: 13.98\n",
      "Epoch: 323 Train Loss: 0.1857 Val Loss: 0.2644 Acc: 0.8967 Pre: 0.9158 Recall: 0.8803 F1: 0.8977 Train AUC: 0.9809 Val AUC: 0.9563 Time: 13.98\n",
      "Epoch: 324 Train Loss: 0.1844 Val Loss: 0.2678 Acc: 0.8931 Pre: 0.8947 Recall: 0.8979 F1: 0.8963 Train AUC: 0.9816 Val AUC: 0.9555 Time: 13.03\n",
      "Epoch: 325 Train Loss: 0.1844 Val Loss: 0.2737 Acc: 0.8931 Pre: 0.8866 Recall: 0.9085 F1: 0.8974 Train AUC: 0.9807 Val AUC: 0.9549 Time: 12.07\n",
      "Epoch: 326 Train Loss: 0.1813 Val Loss: 0.2671 Acc: 0.8949 Pre: 0.9094 Recall: 0.8838 F1: 0.8964 Train AUC: 0.9817 Val AUC: 0.9548 Time: 12.07\n",
      "Epoch: 327 Train Loss: 0.1846 Val Loss: 0.2690 Acc: 0.8931 Pre: 0.9151 Recall: 0.8732 F1: 0.8937 Train AUC: 0.9801 Val AUC: 0.9550 Time: 12.51\n",
      "Epoch: 328 Train Loss: 0.1873 Val Loss: 0.2674 Acc: 0.8913 Pre: 0.9000 Recall: 0.8873 F1: 0.8936 Train AUC: 0.9802 Val AUC: 0.9546 Time: 13.14\n",
      "Epoch: 329 Train Loss: 0.1806 Val Loss: 0.2714 Acc: 0.8895 Pre: 0.8858 Recall: 0.9014 F1: 0.8935 Train AUC: 0.9813 Val AUC: 0.9546 Time: 13.39\n",
      "Epoch: 330 Train Loss: 0.1865 Val Loss: 0.2630 Acc: 0.8949 Pre: 0.9036 Recall: 0.8908 F1: 0.8972 Train AUC: 0.9811 Val AUC: 0.9563 Time: 12.74\n",
      "Epoch: 331 Train Loss: 0.1897 Val Loss: 0.2694 Acc: 0.8949 Pre: 0.9185 Recall: 0.8732 F1: 0.8953 Train AUC: 0.9785 Val AUC: 0.9558 Time: 12.79\n",
      "Epoch: 332 Train Loss: 0.1907 Val Loss: 0.2696 Acc: 0.8986 Pre: 0.8986 Recall: 0.9049 F1: 0.9018 Train AUC: 0.9821 Val AUC: 0.9548 Time: 12.67\n",
      "Epoch: 333 Train Loss: 0.1845 Val Loss: 0.2699 Acc: 0.8895 Pre: 0.8912 Recall: 0.8944 F1: 0.8928 Train AUC: 0.9815 Val AUC: 0.9542 Time: 13.28\n",
      "Epoch: 334 Train Loss: 0.1880 Val Loss: 0.2640 Acc: 0.8986 Pre: 0.9161 Recall: 0.8838 F1: 0.8996 Train AUC: 0.9794 Val AUC: 0.9557 Time: 13.61\n",
      "Epoch: 335 Train Loss: 0.1722 Val Loss: 0.2656 Acc: 0.8949 Pre: 0.9124 Recall: 0.8803 F1: 0.8961 Train AUC: 0.9834 Val AUC: 0.9564 Time: 13.70\n",
      "Epoch: 336 Train Loss: 0.1855 Val Loss: 0.2618 Acc: 0.8931 Pre: 0.8893 Recall: 0.9049 F1: 0.8970 Train AUC: 0.9809 Val AUC: 0.9564 Time: 12.53\n",
      "Epoch: 337 Train Loss: 0.1801 Val Loss: 0.2768 Acc: 0.8804 Pre: 0.8609 Recall: 0.9155 F1: 0.8874 Train AUC: 0.9815 Val AUC: 0.9566 Time: 12.25\n",
      "Epoch: 338 Train Loss: 0.1921 Val Loss: 0.2617 Acc: 0.8986 Pre: 0.9130 Recall: 0.8873 F1: 0.9000 Train AUC: 0.9821 Val AUC: 0.9561 Time: 12.54\n",
      "Epoch: 339 Train Loss: 0.1773 Val Loss: 0.2735 Acc: 0.8859 Pre: 0.9234 Recall: 0.8486 F1: 0.8844 Train AUC: 0.9815 Val AUC: 0.9544 Time: 12.74\n",
      "Epoch: 340 Train Loss: 0.1868 Val Loss: 0.2649 Acc: 0.9004 Pre: 0.9194 Recall: 0.8838 F1: 0.9013 Train AUC: 0.9808 Val AUC: 0.9553 Time: 13.24\n",
      "Epoch: 341 Train Loss: 0.1777 Val Loss: 0.2705 Acc: 0.8822 Pre: 0.8712 Recall: 0.9049 F1: 0.8877 Train AUC: 0.9813 Val AUC: 0.9556 Time: 13.71\n",
      "Epoch: 342 Train Loss: 0.1803 Val Loss: 0.2613 Acc: 0.8949 Pre: 0.8979 Recall: 0.8979 F1: 0.8979 Train AUC: 0.9829 Val AUC: 0.9569 Time: 13.13\n",
      "Epoch: 343 Train Loss: 0.1882 Val Loss: 0.2585 Acc: 0.8967 Pre: 0.9188 Recall: 0.8768 F1: 0.8973 Train AUC: 0.9796 Val AUC: 0.9584 Time: 12.44\n",
      "Epoch: 344 Train Loss: 0.1738 Val Loss: 0.2583 Acc: 0.9040 Pre: 0.9170 Recall: 0.8944 F1: 0.9055 Train AUC: 0.9842 Val AUC: 0.9582 Time: 12.60\n",
      "Epoch: 345 Train Loss: 0.1779 Val Loss: 0.2694 Acc: 0.8967 Pre: 0.8847 Recall: 0.9190 F1: 0.9016 Train AUC: 0.9813 Val AUC: 0.9558 Time: 12.82\n",
      "Epoch: 346 Train Loss: 0.1747 Val Loss: 0.2776 Acc: 0.8822 Pre: 0.8687 Recall: 0.9085 F1: 0.8881 Train AUC: 0.9825 Val AUC: 0.9541 Time: 13.45\n",
      "Epoch: 347 Train Loss: 0.1784 Val Loss: 0.2736 Acc: 0.8895 Pre: 0.9055 Recall: 0.8768 F1: 0.8909 Train AUC: 0.9837 Val AUC: 0.9525 Time: 13.74\n",
      "Epoch: 348 Train Loss: 0.1741 Val Loss: 0.2780 Acc: 0.8841 Pre: 0.9167 Recall: 0.8521 F1: 0.8832 Train AUC: 0.9830 Val AUC: 0.9521 Time: 13.37\n",
      "Epoch: 349 Train Loss: 0.1797 Val Loss: 0.2653 Acc: 0.8949 Pre: 0.9036 Recall: 0.8908 F1: 0.8972 Train AUC: 0.9831 Val AUC: 0.9556 Time: 12.41\n",
      "Epoch: 350 Train Loss: 0.1651 Val Loss: 0.2594 Acc: 0.9040 Pre: 0.9110 Recall: 0.9014 F1: 0.9062 Train AUC: 0.9844 Val AUC: 0.9585 Time: 11.94\n",
      "Epoch: 351 Train Loss: 0.1758 Val Loss: 0.2575 Acc: 0.9058 Pre: 0.9056 Recall: 0.9120 F1: 0.9088 Train AUC: 0.9815 Val AUC: 0.9596 Time: 12.42\n",
      "Epoch: 352 Train Loss: 0.1760 Val Loss: 0.2564 Acc: 0.9040 Pre: 0.8997 Recall: 0.9155 F1: 0.9075 Train AUC: 0.9816 Val AUC: 0.9590 Time: 13.05\n",
      "Epoch: 353 Train Loss: 0.1738 Val Loss: 0.2637 Acc: 0.8913 Pre: 0.8810 Recall: 0.9120 F1: 0.8962 Train AUC: 0.9819 Val AUC: 0.9579 Time: 13.32\n",
      "Epoch: 354 Train Loss: 0.1740 Val Loss: 0.2608 Acc: 0.8931 Pre: 0.9032 Recall: 0.8873 F1: 0.8952 Train AUC: 0.9833 Val AUC: 0.9566 Time: 13.75\n",
      "Epoch: 355 Train Loss: 0.1771 Val Loss: 0.2622 Acc: 0.8931 Pre: 0.8947 Recall: 0.8979 F1: 0.8963 Train AUC: 0.9822 Val AUC: 0.9564 Time: 13.44\n",
      "Epoch: 356 Train Loss: 0.1644 Val Loss: 0.2612 Acc: 0.8913 Pre: 0.8836 Recall: 0.9085 F1: 0.8958 Train AUC: 0.9845 Val AUC: 0.9570 Time: 13.00\n",
      "Epoch: 357 Train Loss: 0.1700 Val Loss: 0.2555 Acc: 0.9040 Pre: 0.9053 Recall: 0.9085 F1: 0.9069 Train AUC: 0.9837 Val AUC: 0.9585 Time: 12.37\n",
      "Epoch: 358 Train Loss: 0.1630 Val Loss: 0.2515 Acc: 0.9004 Pre: 0.9134 Recall: 0.8908 F1: 0.9020 Train AUC: 0.9845 Val AUC: 0.9594 Time: 12.43\n",
      "Epoch: 359 Train Loss: 0.1673 Val Loss: 0.2523 Acc: 0.8967 Pre: 0.8927 Recall: 0.9085 F1: 0.9005 Train AUC: 0.9840 Val AUC: 0.9594 Time: 12.82\n",
      "Epoch: 360 Train Loss: 0.1666 Val Loss: 0.2562 Acc: 0.8859 Pre: 0.8746 Recall: 0.9085 F1: 0.8912 Train AUC: 0.9842 Val AUC: 0.9584 Time: 13.26\n",
      "Epoch: 361 Train Loss: 0.1700 Val Loss: 0.2503 Acc: 0.8949 Pre: 0.8924 Recall: 0.9049 F1: 0.8986 Train AUC: 0.9844 Val AUC: 0.9597 Time: 12.80\n",
      "Epoch: 362 Train Loss: 0.1632 Val Loss: 0.2498 Acc: 0.8967 Pre: 0.9039 Recall: 0.8944 F1: 0.8991 Train AUC: 0.9855 Val AUC: 0.9598 Time: 12.50\n",
      "Epoch: 363 Train Loss: 0.1660 Val Loss: 0.2488 Acc: 0.9022 Pre: 0.9078 Recall: 0.9014 F1: 0.9046 Train AUC: 0.9839 Val AUC: 0.9605 Time: 12.12\n",
      "Epoch: 364 Train Loss: 0.1743 Val Loss: 0.2548 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9823 Val AUC: 0.9603 Time: 12.56\n",
      "Epoch: 365 Train Loss: 0.1667 Val Loss: 0.2534 Acc: 0.8967 Pre: 0.8982 Recall: 0.9014 F1: 0.8998 Train AUC: 0.9851 Val AUC: 0.9595 Time: 12.91\n",
      "Epoch: 366 Train Loss: 0.1710 Val Loss: 0.2515 Acc: 0.8986 Pre: 0.9071 Recall: 0.8944 F1: 0.9007 Train AUC: 0.9843 Val AUC: 0.9599 Time: 13.38\n",
      "Epoch: 367 Train Loss: 0.1593 Val Loss: 0.2499 Acc: 0.8967 Pre: 0.8982 Recall: 0.9014 F1: 0.8998 Train AUC: 0.9863 Val AUC: 0.9605 Time: 13.40\n",
      "Epoch: 368 Train Loss: 0.1668 Val Loss: 0.2564 Acc: 0.8895 Pre: 0.8729 Recall: 0.9190 F1: 0.8954 Train AUC: 0.9843 Val AUC: 0.9604 Time: 13.04\n",
      "Epoch: 369 Train Loss: 0.1607 Val Loss: 0.2541 Acc: 0.8859 Pre: 0.8696 Recall: 0.9155 F1: 0.8919 Train AUC: 0.9860 Val AUC: 0.9600 Time: 12.18\n",
      "Epoch: 370 Train Loss: 0.1726 Val Loss: 0.2512 Acc: 0.8949 Pre: 0.9007 Recall: 0.8944 F1: 0.8975 Train AUC: 0.9829 Val AUC: 0.9602 Time: 12.02\n",
      "Epoch: 371 Train Loss: 0.1643 Val Loss: 0.2532 Acc: 0.8949 Pre: 0.9036 Recall: 0.8908 F1: 0.8972 Train AUC: 0.9843 Val AUC: 0.9597 Time: 12.50\n",
      "Epoch: 372 Train Loss: 0.1676 Val Loss: 0.2668 Acc: 0.8750 Pre: 0.8571 Recall: 0.9085 F1: 0.8821 Train AUC: 0.9848 Val AUC: 0.9595 Time: 12.85\n",
      "Epoch: 373 Train Loss: 0.1676 Val Loss: 0.2532 Acc: 0.8895 Pre: 0.8729 Recall: 0.9190 F1: 0.8954 Train AUC: 0.9858 Val AUC: 0.9621 Time: 13.46\n",
      "Epoch: 374 Train Loss: 0.1679 Val Loss: 0.2435 Acc: 0.9058 Pre: 0.9143 Recall: 0.9014 F1: 0.9078 Train AUC: 0.9846 Val AUC: 0.9629 Time: 14.27\n",
      "Epoch: 375 Train Loss: 0.1631 Val Loss: 0.2456 Acc: 0.9040 Pre: 0.9140 Recall: 0.8979 F1: 0.9059 Train AUC: 0.9842 Val AUC: 0.9623 Time: 15.70\n",
      "Epoch: 376 Train Loss: 0.1634 Val Loss: 0.2453 Acc: 0.9004 Pre: 0.9104 Recall: 0.8944 F1: 0.9023 Train AUC: 0.9849 Val AUC: 0.9622 Time: 18.32\n",
      "Epoch: 377 Train Loss: 0.1606 Val Loss: 0.2563 Acc: 0.8877 Pre: 0.8750 Recall: 0.9120 F1: 0.8931 Train AUC: 0.9851 Val AUC: 0.9607 Time: 18.23\n",
      "Epoch: 378 Train Loss: 0.1618 Val Loss: 0.2541 Acc: 0.8949 Pre: 0.8951 Recall: 0.9014 F1: 0.8982 Train AUC: 0.9863 Val AUC: 0.9598 Time: 16.59\n",
      "Epoch: 379 Train Loss: 0.1507 Val Loss: 0.2514 Acc: 0.9022 Pre: 0.9197 Recall: 0.8873 F1: 0.9032 Train AUC: 0.9882 Val AUC: 0.9605 Time: 15.29\n",
      "Epoch: 380 Train Loss: 0.1617 Val Loss: 0.2496 Acc: 0.9004 Pre: 0.9134 Recall: 0.8908 F1: 0.9020 Train AUC: 0.9850 Val AUC: 0.9605 Time: 15.16\n",
      "Epoch: 381 Train Loss: 0.1584 Val Loss: 0.2573 Acc: 0.8877 Pre: 0.8675 Recall: 0.9225 F1: 0.8942 Train AUC: 0.9852 Val AUC: 0.9607 Time: 13.41\n",
      "Epoch: 382 Train Loss: 0.1559 Val Loss: 0.2567 Acc: 0.8841 Pre: 0.8642 Recall: 0.9190 F1: 0.8908 Train AUC: 0.9867 Val AUC: 0.9615 Time: 13.15\n",
      "Epoch: 383 Train Loss: 0.1636 Val Loss: 0.2493 Acc: 0.8986 Pre: 0.8986 Recall: 0.9049 F1: 0.9018 Train AUC: 0.9850 Val AUC: 0.9615 Time: 12.66\n",
      "Epoch: 384 Train Loss: 0.1604 Val Loss: 0.2549 Acc: 0.8949 Pre: 0.9065 Recall: 0.8873 F1: 0.8968 Train AUC: 0.9850 Val AUC: 0.9611 Time: 11.76\n",
      "Epoch: 385 Train Loss: 0.1703 Val Loss: 0.2464 Acc: 0.8931 Pre: 0.8893 Recall: 0.9049 F1: 0.8970 Train AUC: 0.9852 Val AUC: 0.9620 Time: 11.91\n",
      "Epoch: 386 Train Loss: 0.1465 Val Loss: 0.2531 Acc: 0.8895 Pre: 0.8704 Recall: 0.9225 F1: 0.8957 Train AUC: 0.9881 Val AUC: 0.9624 Time: 11.94\n",
      "Epoch: 387 Train Loss: 0.1578 Val Loss: 0.2501 Acc: 0.8877 Pre: 0.8675 Recall: 0.9225 F1: 0.8942 Train AUC: 0.9864 Val AUC: 0.9623 Time: 12.51\n",
      "Epoch: 388 Train Loss: 0.1610 Val Loss: 0.2464 Acc: 0.9040 Pre: 0.9140 Recall: 0.8979 F1: 0.9059 Train AUC: 0.9859 Val AUC: 0.9620 Time: 13.09\n",
      "Epoch: 389 Train Loss: 0.1697 Val Loss: 0.2439 Acc: 0.8986 Pre: 0.8958 Recall: 0.9085 F1: 0.9021 Train AUC: 0.9835 Val AUC: 0.9630 Time: 13.47\n",
      "Epoch: 390 Train Loss: 0.1526 Val Loss: 0.2562 Acc: 0.8913 Pre: 0.8810 Recall: 0.9120 F1: 0.8962 Train AUC: 0.9864 Val AUC: 0.9612 Time: 13.98\n",
      "Epoch: 391 Train Loss: 0.1605 Val Loss: 0.2545 Acc: 0.8931 Pre: 0.8840 Recall: 0.9120 F1: 0.8977 Train AUC: 0.9853 Val AUC: 0.9617 Time: 13.84\n",
      "Epoch: 392 Train Loss: 0.1572 Val Loss: 0.2502 Acc: 0.8967 Pre: 0.9068 Recall: 0.8908 F1: 0.8988 Train AUC: 0.9856 Val AUC: 0.9610 Time: 12.55\n",
      "Epoch: 393 Train Loss: 0.1509 Val Loss: 0.2573 Acc: 0.8986 Pre: 0.9101 Recall: 0.8908 F1: 0.9004 Train AUC: 0.9867 Val AUC: 0.9587 Time: 12.13\n",
      "Epoch: 394 Train Loss: 0.1554 Val Loss: 0.2702 Acc: 0.8569 Pre: 0.8296 Recall: 0.9085 F1: 0.8672 Train AUC: 0.9864 Val AUC: 0.9585 Time: 11.96\n",
      "Epoch: 395 Train Loss: 0.1478 Val Loss: 0.2580 Acc: 0.8750 Pre: 0.8548 Recall: 0.9120 F1: 0.8825 Train AUC: 0.9887 Val AUC: 0.9614 Time: 12.33\n",
      "Epoch: 396 Train Loss: 0.1492 Val Loss: 0.2387 Acc: 0.9040 Pre: 0.9110 Recall: 0.9014 F1: 0.9062 Train AUC: 0.9886 Val AUC: 0.9638 Time: 12.83\n",
      "Epoch: 397 Train Loss: 0.1502 Val Loss: 0.2410 Acc: 0.9040 Pre: 0.9200 Recall: 0.8908 F1: 0.9052 Train AUC: 0.9869 Val AUC: 0.9647 Time: 13.47\n",
      "Epoch: 398 Train Loss: 0.1565 Val Loss: 0.2361 Acc: 0.8986 Pre: 0.8931 Recall: 0.9120 F1: 0.9024 Train AUC: 0.9859 Val AUC: 0.9656 Time: 13.78\n",
      "Epoch: 399 Train Loss: 0.1497 Val Loss: 0.2446 Acc: 0.8913 Pre: 0.8784 Recall: 0.9155 F1: 0.8966 Train AUC: 0.9872 Val AUC: 0.9647 Time: 13.55\n",
      "Epoch: 400 Train Loss: 0.1541 Val Loss: 0.2428 Acc: 0.8967 Pre: 0.8900 Recall: 0.9120 F1: 0.9009 Train AUC: 0.9870 Val AUC: 0.9634 Time: 12.75\n",
      "Epoch: 401 Train Loss: 0.1466 Val Loss: 0.2503 Acc: 0.9004 Pre: 0.9134 Recall: 0.8908 F1: 0.9020 Train AUC: 0.9885 Val AUC: 0.9609 Time: 11.73\n",
      "Epoch: 402 Train Loss: 0.1567 Val Loss: 0.2506 Acc: 0.8949 Pre: 0.9036 Recall: 0.8908 F1: 0.8972 Train AUC: 0.9861 Val AUC: 0.9608 Time: 11.76\n",
      "Epoch: 403 Train Loss: 0.1557 Val Loss: 0.2620 Acc: 0.8750 Pre: 0.8525 Recall: 0.9155 F1: 0.8829 Train AUC: 0.9863 Val AUC: 0.9617 Time: 12.40\n",
      "Epoch: 404 Train Loss: 0.1551 Val Loss: 0.2529 Acc: 0.8913 Pre: 0.8836 Recall: 0.9085 F1: 0.8958 Train AUC: 0.9878 Val AUC: 0.9627 Time: 12.76\n",
      "Epoch: 405 Train Loss: 0.1520 Val Loss: 0.2480 Acc: 0.8913 Pre: 0.8862 Recall: 0.9049 F1: 0.8955 Train AUC: 0.9865 Val AUC: 0.9626 Time: 13.20\n",
      "Epoch: 406 Train Loss: 0.1532 Val Loss: 0.2491 Acc: 0.8931 Pre: 0.9151 Recall: 0.8732 F1: 0.8937 Train AUC: 0.9865 Val AUC: 0.9632 Time: 13.92\n",
      "Epoch: 407 Train Loss: 0.1521 Val Loss: 0.2428 Acc: 0.8931 Pre: 0.9032 Recall: 0.8873 F1: 0.8952 Train AUC: 0.9879 Val AUC: 0.9634 Time: 13.99\n",
      "Epoch: 408 Train Loss: 0.1530 Val Loss: 0.2568 Acc: 0.8786 Pre: 0.8557 Recall: 0.9190 F1: 0.8862 Train AUC: 0.9875 Val AUC: 0.9636 Time: 12.92\n",
      "Epoch: 409 Train Loss: 0.1552 Val Loss: 0.2490 Acc: 0.8913 Pre: 0.8836 Recall: 0.9085 F1: 0.8958 Train AUC: 0.9878 Val AUC: 0.9627 Time: 11.95\n",
      "Epoch: 410 Train Loss: 0.1563 Val Loss: 0.2465 Acc: 0.9076 Pre: 0.9176 Recall: 0.9014 F1: 0.9094 Train AUC: 0.9856 Val AUC: 0.9624 Time: 11.65\n",
      "Epoch: 411 Train Loss: 0.1513 Val Loss: 0.2527 Acc: 0.8859 Pre: 0.8746 Recall: 0.9085 F1: 0.8912 Train AUC: 0.9872 Val AUC: 0.9614 Time: 12.17\n",
      "Epoch: 412 Train Loss: 0.1532 Val Loss: 0.2660 Acc: 0.8804 Pre: 0.8609 Recall: 0.9155 F1: 0.8874 Train AUC: 0.9863 Val AUC: 0.9610 Time: 12.65\n",
      "Epoch: 413 Train Loss: 0.1509 Val Loss: 0.2450 Acc: 0.8913 Pre: 0.8784 Recall: 0.9155 F1: 0.8966 Train AUC: 0.9877 Val AUC: 0.9639 Time: 13.04\n",
      "Epoch: 414 Train Loss: 0.1453 Val Loss: 0.2403 Acc: 0.9076 Pre: 0.9206 Recall: 0.8979 F1: 0.9091 Train AUC: 0.9884 Val AUC: 0.9639 Time: 13.58\n",
      "Epoch: 415 Train Loss: 0.1491 Val Loss: 0.2352 Acc: 0.9022 Pre: 0.9021 Recall: 0.9085 F1: 0.9053 Train AUC: 0.9883 Val AUC: 0.9653 Time: 14.26\n",
      "Epoch: 416 Train Loss: 0.1461 Val Loss: 0.2388 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9880 Val AUC: 0.9665 Time: 13.21\n",
      "Epoch: 417 Train Loss: 0.1483 Val Loss: 0.2309 Acc: 0.9022 Pre: 0.8966 Recall: 0.9155 F1: 0.9059 Train AUC: 0.9891 Val AUC: 0.9674 Time: 12.11\n",
      "Epoch: 418 Train Loss: 0.1381 Val Loss: 0.2340 Acc: 0.8986 Pre: 0.8904 Recall: 0.9155 F1: 0.9028 Train AUC: 0.9892 Val AUC: 0.9668 Time: 11.88\n",
      "Epoch: 419 Train Loss: 0.1433 Val Loss: 0.2370 Acc: 0.8986 Pre: 0.8958 Recall: 0.9085 F1: 0.9021 Train AUC: 0.9883 Val AUC: 0.9656 Time: 11.40\n",
      "Epoch: 420 Train Loss: 0.1477 Val Loss: 0.2390 Acc: 0.8895 Pre: 0.8780 Recall: 0.9120 F1: 0.8946 Train AUC: 0.9878 Val AUC: 0.9649 Time: 11.95\n",
      "Epoch: 421 Train Loss: 0.1442 Val Loss: 0.2429 Acc: 0.8967 Pre: 0.8955 Recall: 0.9049 F1: 0.9002 Train AUC: 0.9880 Val AUC: 0.9635 Time: 12.55\n",
      "Epoch: 422 Train Loss: 0.1453 Val Loss: 0.2414 Acc: 0.9022 Pre: 0.9107 Recall: 0.8979 F1: 0.9043 Train AUC: 0.9877 Val AUC: 0.9632 Time: 12.76\n",
      "Epoch: 423 Train Loss: 0.1455 Val Loss: 0.2402 Acc: 0.8913 Pre: 0.8836 Recall: 0.9085 F1: 0.8958 Train AUC: 0.9883 Val AUC: 0.9650 Time: 13.27\n",
      "Epoch: 424 Train Loss: 0.1457 Val Loss: 0.2394 Acc: 0.8877 Pre: 0.8750 Recall: 0.9120 F1: 0.8931 Train AUC: 0.9882 Val AUC: 0.9662 Time: 13.88\n",
      "Epoch: 425 Train Loss: 0.1398 Val Loss: 0.2366 Acc: 0.8913 Pre: 0.8862 Recall: 0.9049 F1: 0.8955 Train AUC: 0.9894 Val AUC: 0.9662 Time: 13.11\n",
      "Epoch: 426 Train Loss: 0.1398 Val Loss: 0.2375 Acc: 0.8949 Pre: 0.8924 Recall: 0.9049 F1: 0.8986 Train AUC: 0.9886 Val AUC: 0.9655 Time: 12.67\n",
      "Epoch: 427 Train Loss: 0.1484 Val Loss: 0.2415 Acc: 0.8967 Pre: 0.8955 Recall: 0.9049 F1: 0.9002 Train AUC: 0.9878 Val AUC: 0.9645 Time: 12.82\n",
      "Epoch: 428 Train Loss: 0.1337 Val Loss: 0.2529 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9900 Val AUC: 0.9617 Time: 12.96\n",
      "Epoch: 429 Train Loss: 0.1434 Val Loss: 0.2423 Acc: 0.9040 Pre: 0.9081 Recall: 0.9049 F1: 0.9065 Train AUC: 0.9896 Val AUC: 0.9635 Time: 13.60\n",
      "Epoch: 430 Train Loss: 0.1399 Val Loss: 0.2402 Acc: 0.9040 Pre: 0.9110 Recall: 0.9014 F1: 0.9062 Train AUC: 0.9897 Val AUC: 0.9637 Time: 12.92\n",
      "Epoch: 431 Train Loss: 0.1488 Val Loss: 0.2369 Acc: 0.9022 Pre: 0.9049 Recall: 0.9049 F1: 0.9049 Train AUC: 0.9869 Val AUC: 0.9655 Time: 12.29\n",
      "Epoch: 432 Train Loss: 0.1510 Val Loss: 0.2353 Acc: 0.8931 Pre: 0.8840 Recall: 0.9120 F1: 0.8977 Train AUC: 0.9864 Val AUC: 0.9670 Time: 12.02\n",
      "Epoch: 433 Train Loss: 0.1340 Val Loss: 0.2425 Acc: 0.8949 Pre: 0.8951 Recall: 0.9014 F1: 0.8982 Train AUC: 0.9907 Val AUC: 0.9635 Time: 12.58\n",
      "Epoch: 434 Train Loss: 0.1474 Val Loss: 0.2401 Acc: 0.8986 Pre: 0.9101 Recall: 0.8908 F1: 0.9004 Train AUC: 0.9882 Val AUC: 0.9652 Time: 13.07\n",
      "Epoch: 435 Train Loss: 0.1399 Val Loss: 0.2376 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9894 Val AUC: 0.9658 Time: 13.64\n",
      "Epoch: 436 Train Loss: 0.1360 Val Loss: 0.2583 Acc: 0.8696 Pre: 0.8442 Recall: 0.9155 F1: 0.8784 Train AUC: 0.9894 Val AUC: 0.9650 Time: 13.87\n",
      "Epoch: 437 Train Loss: 0.1472 Val Loss: 0.2447 Acc: 0.8913 Pre: 0.8836 Recall: 0.9085 F1: 0.8958 Train AUC: 0.9888 Val AUC: 0.9645 Time: 12.63\n",
      "Epoch: 438 Train Loss: 0.1371 Val Loss: 0.2417 Acc: 0.9004 Pre: 0.9164 Recall: 0.8873 F1: 0.9016 Train AUC: 0.9893 Val AUC: 0.9649 Time: 11.72\n",
      "Epoch: 439 Train Loss: 0.1402 Val Loss: 0.2393 Acc: 0.8913 Pre: 0.9000 Recall: 0.8873 F1: 0.8936 Train AUC: 0.9892 Val AUC: 0.9647 Time: 11.51\n",
      "Epoch: 440 Train Loss: 0.1403 Val Loss: 0.2487 Acc: 0.8859 Pre: 0.8746 Recall: 0.9085 F1: 0.8912 Train AUC: 0.9900 Val AUC: 0.9645 Time: 11.86\n",
      "Epoch: 441 Train Loss: 0.1369 Val Loss: 0.2311 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9913 Val AUC: 0.9677 Time: 12.30\n",
      "Epoch: 442 Train Loss: 0.1388 Val Loss: 0.2370 Acc: 0.9076 Pre: 0.9206 Recall: 0.8979 F1: 0.9091 Train AUC: 0.9898 Val AUC: 0.9667 Time: 12.88\n",
      "Epoch: 443 Train Loss: 0.1431 Val Loss: 0.2357 Acc: 0.9040 Pre: 0.9081 Recall: 0.9049 F1: 0.9065 Train AUC: 0.9876 Val AUC: 0.9667 Time: 13.75\n",
      "Epoch: 444 Train Loss: 0.1351 Val Loss: 0.2380 Acc: 0.8931 Pre: 0.8840 Recall: 0.9120 F1: 0.8977 Train AUC: 0.9892 Val AUC: 0.9668 Time: 13.88\n",
      "Epoch: 445 Train Loss: 0.1315 Val Loss: 0.2477 Acc: 0.8895 Pre: 0.8805 Recall: 0.9085 F1: 0.8943 Train AUC: 0.9905 Val AUC: 0.9634 Time: 13.59\n",
      "Epoch: 446 Train Loss: 0.1366 Val Loss: 0.2389 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9897 Val AUC: 0.9657 Time: 12.48\n",
      "Epoch: 447 Train Loss: 0.1291 Val Loss: 0.2344 Acc: 0.9112 Pre: 0.9273 Recall: 0.8979 F1: 0.9123 Train AUC: 0.9906 Val AUC: 0.9662 Time: 12.06\n",
      "Epoch: 448 Train Loss: 0.1357 Val Loss: 0.2309 Acc: 0.9004 Pre: 0.9018 Recall: 0.9049 F1: 0.9033 Train AUC: 0.9896 Val AUC: 0.9676 Time: 12.33\n",
      "Epoch: 449 Train Loss: 0.1316 Val Loss: 0.2308 Acc: 0.8967 Pre: 0.8847 Recall: 0.9190 F1: 0.9016 Train AUC: 0.9902 Val AUC: 0.9690 Time: 12.77\n",
      "Epoch: 450 Train Loss: 0.1296 Val Loss: 0.2329 Acc: 0.8931 Pre: 0.8763 Recall: 0.9225 F1: 0.8988 Train AUC: 0.9917 Val AUC: 0.9695 Time: 12.69\n",
      "Epoch: 451 Train Loss: 0.1299 Val Loss: 0.2274 Acc: 0.8949 Pre: 0.8818 Recall: 0.9190 F1: 0.9000 Train AUC: 0.9911 Val AUC: 0.9699 Time: 13.14\n",
      "Epoch: 452 Train Loss: 0.1345 Val Loss: 0.2279 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9898 Val AUC: 0.9693 Time: 12.69\n",
      "Epoch: 453 Train Loss: 0.1314 Val Loss: 0.2300 Acc: 0.8949 Pre: 0.8870 Recall: 0.9120 F1: 0.8993 Train AUC: 0.9912 Val AUC: 0.9693 Time: 13.06\n",
      "Epoch: 454 Train Loss: 0.1309 Val Loss: 0.2312 Acc: 0.8931 Pre: 0.8840 Recall: 0.9120 F1: 0.8977 Train AUC: 0.9909 Val AUC: 0.9687 Time: 13.08\n",
      "Epoch: 455 Train Loss: 0.1311 Val Loss: 0.2393 Acc: 0.8913 Pre: 0.8784 Recall: 0.9155 F1: 0.8966 Train AUC: 0.9913 Val AUC: 0.9679 Time: 12.85\n",
      "Epoch: 456 Train Loss: 0.1319 Val Loss: 0.2429 Acc: 0.8949 Pre: 0.8844 Recall: 0.9155 F1: 0.8997 Train AUC: 0.9900 Val AUC: 0.9660 Time: 12.71\n",
      "Epoch: 457 Train Loss: 0.1176 Val Loss: 0.2469 Acc: 0.8877 Pre: 0.8801 Recall: 0.9049 F1: 0.8924 Train AUC: 0.9926 Val AUC: 0.9636 Time: 12.86\n",
      "Epoch: 458 Train Loss: 0.1320 Val Loss: 0.2422 Acc: 0.8895 Pre: 0.9025 Recall: 0.8803 F1: 0.8913 Train AUC: 0.9905 Val AUC: 0.9651 Time: 12.87\n",
      "Epoch: 459 Train Loss: 0.1389 Val Loss: 0.2320 Acc: 0.8949 Pre: 0.8870 Recall: 0.9120 F1: 0.8993 Train AUC: 0.9894 Val AUC: 0.9687 Time: 12.67\n",
      "Epoch: 460 Train Loss: 0.1374 Val Loss: 0.2431 Acc: 0.8841 Pre: 0.8618 Recall: 0.9225 F1: 0.8912 Train AUC: 0.9886 Val AUC: 0.9701 Time: 15.76\n",
      "Epoch: 461 Train Loss: 0.1236 Val Loss: 0.2283 Acc: 0.9004 Pre: 0.8881 Recall: 0.9225 F1: 0.9050 Train AUC: 0.9930 Val AUC: 0.9703 Time: 13.48\n",
      "Epoch: 462 Train Loss: 0.1298 Val Loss: 0.2300 Acc: 0.9076 Pre: 0.9267 Recall: 0.8908 F1: 0.9084 Train AUC: 0.9910 Val AUC: 0.9697 Time: 12.29\n",
      "Epoch: 463 Train Loss: 0.1336 Val Loss: 0.2291 Acc: 0.8967 Pre: 0.9011 Recall: 0.8979 F1: 0.8995 Train AUC: 0.9902 Val AUC: 0.9687 Time: 12.47\n",
      "Epoch: 464 Train Loss: 0.1282 Val Loss: 0.2493 Acc: 0.8877 Pre: 0.8725 Recall: 0.9155 F1: 0.8935 Train AUC: 0.9912 Val AUC: 0.9654 Time: 12.83\n",
      "Epoch: 465 Train Loss: 0.1348 Val Loss: 0.2407 Acc: 0.8949 Pre: 0.8818 Recall: 0.9190 F1: 0.9000 Train AUC: 0.9909 Val AUC: 0.9668 Time: 13.21\n",
      "Epoch: 466 Train Loss: 0.1296 Val Loss: 0.2324 Acc: 0.9094 Pre: 0.9209 Recall: 0.9014 F1: 0.9110 Train AUC: 0.9909 Val AUC: 0.9680 Time: 13.26\n",
      "Epoch: 467 Train Loss: 0.1336 Val Loss: 0.2314 Acc: 0.9149 Pre: 0.9278 Recall: 0.9049 F1: 0.9162 Train AUC: 0.9896 Val AUC: 0.9691 Time: 13.04\n",
      "Epoch: 468 Train Loss: 0.1303 Val Loss: 0.2393 Acc: 0.8895 Pre: 0.8680 Recall: 0.9261 F1: 0.8961 Train AUC: 0.9901 Val AUC: 0.9708 Time: 12.51\n",
      "Epoch: 469 Train Loss: 0.1239 Val Loss: 0.2395 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9921 Val AUC: 0.9692 Time: 12.55\n",
      "Epoch: 470 Train Loss: 0.1296 Val Loss: 0.2291 Acc: 0.9004 Pre: 0.9018 Recall: 0.9049 F1: 0.9033 Train AUC: 0.9914 Val AUC: 0.9687 Time: 12.75\n",
      "Epoch: 471 Train Loss: 0.1135 Val Loss: 0.2333 Acc: 0.9076 Pre: 0.9267 Recall: 0.8908 F1: 0.9084 Train AUC: 0.9939 Val AUC: 0.9680 Time: 12.71\n",
      "Epoch: 472 Train Loss: 0.1297 Val Loss: 0.2369 Acc: 0.8949 Pre: 0.8870 Recall: 0.9120 F1: 0.8993 Train AUC: 0.9911 Val AUC: 0.9673 Time: 12.88\n",
      "Epoch: 473 Train Loss: 0.1155 Val Loss: 0.2487 Acc: 0.8841 Pre: 0.8571 Recall: 0.9296 F1: 0.8919 Train AUC: 0.9932 Val AUC: 0.9672 Time: 13.08\n",
      "Epoch: 474 Train Loss: 0.1198 Val Loss: 0.2366 Acc: 0.8913 Pre: 0.8810 Recall: 0.9120 F1: 0.8962 Train AUC: 0.9929 Val AUC: 0.9676 Time: 13.01\n",
      "Epoch: 475 Train Loss: 0.1259 Val Loss: 0.2339 Acc: 0.9058 Pre: 0.9203 Recall: 0.8944 F1: 0.9071 Train AUC: 0.9907 Val AUC: 0.9685 Time: 12.68\n",
      "Epoch: 476 Train Loss: 0.1333 Val Loss: 0.2270 Acc: 0.8986 Pre: 0.8931 Recall: 0.9120 F1: 0.9024 Train AUC: 0.9904 Val AUC: 0.9695 Time: 12.28\n",
      "Epoch: 477 Train Loss: 0.1218 Val Loss: 0.2330 Acc: 0.8986 Pre: 0.8826 Recall: 0.9261 F1: 0.9038 Train AUC: 0.9926 Val AUC: 0.9712 Time: 12.51\n",
      "Epoch: 478 Train Loss: 0.1259 Val Loss: 0.2228 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9926 Val AUC: 0.9718 Time: 12.94\n",
      "Epoch: 479 Train Loss: 0.1179 Val Loss: 0.2249 Acc: 0.9185 Pre: 0.9377 Recall: 0.9014 F1: 0.9192 Train AUC: 0.9927 Val AUC: 0.9707 Time: 13.43\n",
      "Epoch: 480 Train Loss: 0.1280 Val Loss: 0.2205 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9911 Val AUC: 0.9712 Time: 13.46\n",
      "Epoch: 481 Train Loss: 0.1195 Val Loss: 0.2288 Acc: 0.8986 Pre: 0.8851 Recall: 0.9225 F1: 0.9034 Train AUC: 0.9927 Val AUC: 0.9700 Time: 13.07\n",
      "Epoch: 482 Train Loss: 0.1272 Val Loss: 0.2277 Acc: 0.9004 Pre: 0.8935 Recall: 0.9155 F1: 0.9043 Train AUC: 0.9915 Val AUC: 0.9693 Time: 12.13\n",
      "Epoch: 483 Train Loss: 0.1146 Val Loss: 0.2293 Acc: 0.8986 Pre: 0.8931 Recall: 0.9120 F1: 0.9024 Train AUC: 0.9924 Val AUC: 0.9689 Time: 12.23\n",
      "Epoch: 484 Train Loss: 0.1210 Val Loss: 0.2279 Acc: 0.9076 Pre: 0.9117 Recall: 0.9085 F1: 0.9101 Train AUC: 0.9915 Val AUC: 0.9688 Time: 12.35\n",
      "Epoch: 485 Train Loss: 0.1191 Val Loss: 0.2301 Acc: 0.9022 Pre: 0.8938 Recall: 0.9190 F1: 0.9062 Train AUC: 0.9921 Val AUC: 0.9692 Time: 13.00\n",
      "Epoch: 486 Train Loss: 0.1172 Val Loss: 0.2273 Acc: 0.9022 Pre: 0.8912 Recall: 0.9225 F1: 0.9066 Train AUC: 0.9929 Val AUC: 0.9705 Time: 13.33\n",
      "Epoch: 487 Train Loss: 0.1120 Val Loss: 0.2244 Acc: 0.9022 Pre: 0.8966 Recall: 0.9155 F1: 0.9059 Train AUC: 0.9936 Val AUC: 0.9713 Time: 13.86\n",
      "Epoch: 488 Train Loss: 0.1043 Val Loss: 0.2238 Acc: 0.9022 Pre: 0.8993 Recall: 0.9120 F1: 0.9056 Train AUC: 0.9944 Val AUC: 0.9711 Time: 13.02\n",
      "Epoch: 489 Train Loss: 0.1130 Val Loss: 0.2226 Acc: 0.9004 Pre: 0.8962 Recall: 0.9120 F1: 0.9040 Train AUC: 0.9931 Val AUC: 0.9711 Time: 12.02\n",
      "Epoch: 490 Train Loss: 0.1158 Val Loss: 0.2265 Acc: 0.8967 Pre: 0.8982 Recall: 0.9014 F1: 0.8998 Train AUC: 0.9928 Val AUC: 0.9698 Time: 11.80\n",
      "Epoch: 491 Train Loss: 0.1196 Val Loss: 0.2318 Acc: 0.8986 Pre: 0.8958 Recall: 0.9085 F1: 0.9021 Train AUC: 0.9925 Val AUC: 0.9690 Time: 11.74\n",
      "Epoch: 492 Train Loss: 0.1142 Val Loss: 0.2291 Acc: 0.8949 Pre: 0.8924 Recall: 0.9049 F1: 0.8986 Train AUC: 0.9939 Val AUC: 0.9698 Time: 12.20\n",
      "Epoch: 493 Train Loss: 0.1148 Val Loss: 0.2319 Acc: 0.8949 Pre: 0.8844 Recall: 0.9155 F1: 0.8997 Train AUC: 0.9927 Val AUC: 0.9695 Time: 12.73\n",
      "Epoch: 494 Train Loss: 0.1143 Val Loss: 0.2344 Acc: 0.8931 Pre: 0.8814 Recall: 0.9155 F1: 0.8981 Train AUC: 0.9931 Val AUC: 0.9694 Time: 13.33\n",
      "Epoch: 495 Train Loss: 0.1154 Val Loss: 0.2289 Acc: 0.8967 Pre: 0.8874 Recall: 0.9155 F1: 0.9012 Train AUC: 0.9927 Val AUC: 0.9691 Time: 13.90\n",
      "Epoch: 496 Train Loss: 0.1118 Val Loss: 0.2286 Acc: 0.8949 Pre: 0.8870 Recall: 0.9120 F1: 0.8993 Train AUC: 0.9937 Val AUC: 0.9696 Time: 14.12\n",
      "Epoch: 497 Train Loss: 0.1100 Val Loss: 0.2254 Acc: 0.8986 Pre: 0.8931 Recall: 0.9120 F1: 0.9024 Train AUC: 0.9936 Val AUC: 0.9702 Time: 12.99\n",
      "Epoch: 498 Train Loss: 0.1178 Val Loss: 0.2227 Acc: 0.9112 Pre: 0.9152 Recall: 0.9120 F1: 0.9136 Train AUC: 0.9930 Val AUC: 0.9709 Time: 12.44\n",
      "Epoch: 499 Train Loss: 0.1184 Val Loss: 0.2258 Acc: 0.9022 Pre: 0.8966 Recall: 0.9155 F1: 0.9059 Train AUC: 0.9929 Val AUC: 0.9717 Time: 12.35\n",
      "Epoch: 500 Train Loss: 0.1168 Val Loss: 0.2337 Acc: 0.8986 Pre: 0.8851 Recall: 0.9225 F1: 0.9034 Train AUC: 0.9923 Val AUC: 0.9709 Time: 12.81\n",
      "Epoch: 501 Train Loss: 0.1078 Val Loss: 0.2357 Acc: 0.8986 Pre: 0.8878 Recall: 0.9190 F1: 0.9031 Train AUC: 0.9943 Val AUC: 0.9697 Time: 13.02\n",
      "Epoch: 502 Train Loss: 0.1162 Val Loss: 0.2358 Acc: 0.8986 Pre: 0.9071 Recall: 0.8944 F1: 0.9007 Train AUC: 0.9925 Val AUC: 0.9685 Time: 13.26\n",
      "Epoch: 503 Train Loss: 0.1086 Val Loss: 0.2383 Acc: 0.8949 Pre: 0.8951 Recall: 0.9014 F1: 0.8982 Train AUC: 0.9940 Val AUC: 0.9683 Time: 13.68\n",
      "Epoch: 504 Train Loss: 0.1062 Val Loss: 0.2539 Acc: 0.8877 Pre: 0.8651 Recall: 0.9261 F1: 0.8946 Train AUC: 0.9940 Val AUC: 0.9681 Time: 12.90\n",
      "Epoch: 505 Train Loss: 0.1253 Val Loss: 0.2287 Acc: 0.9004 Pre: 0.9018 Recall: 0.9049 F1: 0.9033 Train AUC: 0.9918 Val AUC: 0.9703 Time: 12.34\n",
      "Epoch: 506 Train Loss: 0.1143 Val Loss: 0.2237 Acc: 0.9076 Pre: 0.9146 Recall: 0.9049 F1: 0.9097 Train AUC: 0.9927 Val AUC: 0.9714 Time: 12.31\n",
      "Epoch: 507 Train Loss: 0.1133 Val Loss: 0.2218 Acc: 0.9004 Pre: 0.8990 Recall: 0.9085 F1: 0.9037 Train AUC: 0.9934 Val AUC: 0.9723 Time: 12.74\n",
      "Epoch: 508 Train Loss: 0.1171 Val Loss: 0.2218 Acc: 0.9022 Pre: 0.8966 Recall: 0.9155 F1: 0.9059 Train AUC: 0.9925 Val AUC: 0.9726 Time: 13.31\n",
      "Epoch: 509 Train Loss: 0.1120 Val Loss: 0.2245 Acc: 0.8967 Pre: 0.8927 Recall: 0.9085 F1: 0.9005 Train AUC: 0.9936 Val AUC: 0.9713 Time: 13.28\n",
      "Epoch: 510 Train Loss: 0.1104 Val Loss: 0.2275 Acc: 0.8986 Pre: 0.9014 Recall: 0.9014 F1: 0.9014 Train AUC: 0.9935 Val AUC: 0.9694 Time: 12.49\n",
      "Epoch: 511 Train Loss: 0.1170 Val Loss: 0.2318 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9925 Val AUC: 0.9693 Time: 12.49\n",
      "Epoch: 512 Train Loss: 0.1151 Val Loss: 0.2377 Acc: 0.8895 Pre: 0.8729 Recall: 0.9190 F1: 0.8954 Train AUC: 0.9928 Val AUC: 0.9698 Time: 12.60\n",
      "Epoch: 513 Train Loss: 0.1171 Val Loss: 0.2238 Acc: 0.8967 Pre: 0.8874 Recall: 0.9155 F1: 0.9012 Train AUC: 0.9924 Val AUC: 0.9717 Time: 13.40\n",
      "Epoch: 514 Train Loss: 0.1107 Val Loss: 0.2178 Acc: 0.9058 Pre: 0.9028 Recall: 0.9155 F1: 0.9091 Train AUC: 0.9935 Val AUC: 0.9728 Time: 13.44\n",
      "Epoch: 515 Train Loss: 0.1085 Val Loss: 0.2208 Acc: 0.9076 Pre: 0.8949 Recall: 0.9296 F1: 0.9119 Train AUC: 0.9940 Val AUC: 0.9723 Time: 12.94\n",
      "Epoch: 516 Train Loss: 0.1163 Val Loss: 0.2311 Acc: 0.8931 Pre: 0.8664 Recall: 0.9366 F1: 0.9002 Train AUC: 0.9933 Val AUC: 0.9712 Time: 12.38\n",
      "Epoch: 517 Train Loss: 0.1176 Val Loss: 0.2232 Acc: 0.9112 Pre: 0.9152 Recall: 0.9120 F1: 0.9136 Train AUC: 0.9934 Val AUC: 0.9723 Time: 12.53\n",
      "Epoch: 518 Train Loss: 0.1133 Val Loss: 0.2353 Acc: 0.9094 Pre: 0.9270 Recall: 0.8944 F1: 0.9104 Train AUC: 0.9930 Val AUC: 0.9712 Time: 13.02\n",
      "Epoch: 519 Train Loss: 0.1198 Val Loss: 0.2258 Acc: 0.8967 Pre: 0.8927 Recall: 0.9085 F1: 0.9005 Train AUC: 0.9914 Val AUC: 0.9716 Time: 13.15\n",
      "Epoch: 520 Train Loss: 0.1083 Val Loss: 0.2699 Acc: 0.8877 Pre: 0.8581 Recall: 0.9366 F1: 0.8956 Train AUC: 0.9938 Val AUC: 0.9655 Time: 12.87\n",
      "Epoch: 521 Train Loss: 0.1287 Val Loss: 0.2282 Acc: 0.8967 Pre: 0.8927 Recall: 0.9085 F1: 0.9005 Train AUC: 0.9929 Val AUC: 0.9703 Time: 12.87\n",
      "Epoch: 522 Train Loss: 0.1189 Val Loss: 0.2280 Acc: 0.9112 Pre: 0.9242 Recall: 0.9014 F1: 0.9127 Train AUC: 0.9919 Val AUC: 0.9701 Time: 12.72\n",
      "Epoch: 523 Train Loss: 0.0993 Val Loss: 0.2279 Acc: 0.9112 Pre: 0.9152 Recall: 0.9120 F1: 0.9136 Train AUC: 0.9945 Val AUC: 0.9708 Time: 13.41\n",
      "Epoch: 524 Train Loss: 0.1139 Val Loss: 0.2244 Acc: 0.8967 Pre: 0.8874 Recall: 0.9155 F1: 0.9012 Train AUC: 0.9923 Val AUC: 0.9717 Time: 13.35\n",
      "Epoch: 525 Train Loss: 0.1130 Val Loss: 0.2241 Acc: 0.8949 Pre: 0.8844 Recall: 0.9155 F1: 0.8997 Train AUC: 0.9929 Val AUC: 0.9715 Time: 12.81\n",
      "Epoch: 526 Train Loss: 0.1017 Val Loss: 0.2217 Acc: 0.9004 Pre: 0.9046 Recall: 0.9014 F1: 0.9030 Train AUC: 0.9943 Val AUC: 0.9712 Time: 12.89\n",
      "Epoch: 527 Train Loss: 0.1114 Val Loss: 0.2257 Acc: 0.8986 Pre: 0.8851 Recall: 0.9225 F1: 0.9034 Train AUC: 0.9946 Val AUC: 0.9718 Time: 12.79\n",
      "Epoch: 528 Train Loss: 0.1017 Val Loss: 0.2361 Acc: 0.9040 Pre: 0.8915 Recall: 0.9261 F1: 0.9085 Train AUC: 0.9950 Val AUC: 0.9714 Time: 13.36\n",
      "Epoch: 529 Train Loss: 0.1130 Val Loss: 0.2271 Acc: 0.9076 Pre: 0.9117 Recall: 0.9085 F1: 0.9101 Train AUC: 0.9928 Val AUC: 0.9714 Time: 12.43\n",
      "Epoch: 530 Train Loss: 0.1075 Val Loss: 0.2209 Acc: 0.9058 Pre: 0.9143 Recall: 0.9014 F1: 0.9078 Train AUC: 0.9935 Val AUC: 0.9720 Time: 11.89\n",
      "Epoch: 531 Train Loss: 0.1141 Val Loss: 0.2342 Acc: 0.8877 Pre: 0.8700 Recall: 0.9190 F1: 0.8938 Train AUC: 0.9933 Val AUC: 0.9715 Time: 12.15\n",
      "Epoch: 532 Train Loss: 0.1119 Val Loss: 0.2243 Acc: 0.8913 Pre: 0.8758 Recall: 0.9190 F1: 0.8969 Train AUC: 0.9949 Val AUC: 0.9727 Time: 12.48\n",
      "Epoch: 533 Train Loss: 0.1071 Val Loss: 0.2184 Acc: 0.9076 Pre: 0.9117 Recall: 0.9085 F1: 0.9101 Train AUC: 0.9946 Val AUC: 0.9734 Time: 12.94\n",
      "Epoch: 534 Train Loss: 0.1132 Val Loss: 0.2188 Acc: 0.9022 Pre: 0.9078 Recall: 0.9014 F1: 0.9046 Train AUC: 0.9929 Val AUC: 0.9733 Time: 13.41\n",
      "Epoch: 535 Train Loss: 0.1053 Val Loss: 0.2245 Acc: 0.8967 Pre: 0.8900 Recall: 0.9120 F1: 0.9009 Train AUC: 0.9939 Val AUC: 0.9718 Time: 13.61\n",
      "Epoch: 536 Train Loss: 0.1075 Val Loss: 0.2330 Acc: 0.8967 Pre: 0.8822 Recall: 0.9225 F1: 0.9019 Train AUC: 0.9944 Val AUC: 0.9712 Time: 12.98\n",
      "Epoch: 537 Train Loss: 0.1062 Val Loss: 0.2320 Acc: 0.9058 Pre: 0.9085 Recall: 0.9085 F1: 0.9085 Train AUC: 0.9945 Val AUC: 0.9707 Time: 13.23\n",
      "Epoch: 538 Train Loss: 0.1142 Val Loss: 0.2304 Acc: 0.9149 Pre: 0.9247 Recall: 0.9085 F1: 0.9165 Train AUC: 0.9923 Val AUC: 0.9701 Time: 13.69\n",
      "Epoch: 539 Train Loss: 0.1163 Val Loss: 0.2312 Acc: 0.9149 Pre: 0.9129 Recall: 0.9225 F1: 0.9177 Train AUC: 0.9921 Val AUC: 0.9703 Time: 13.03\n",
      "Epoch: 540 Train Loss: 0.0985 Val Loss: 0.2322 Acc: 0.9094 Pre: 0.9120 Recall: 0.9120 F1: 0.9120 Train AUC: 0.9952 Val AUC: 0.9682 Time: 12.73\n",
      "Epoch: 541 Train Loss: 0.1161 Val Loss: 0.2202 Acc: 0.9149 Pre: 0.9247 Recall: 0.9085 F1: 0.9165 Train AUC: 0.9935 Val AUC: 0.9719 Time: 11.77\n",
      "Epoch: 542 Train Loss: 0.0993 Val Loss: 0.2225 Acc: 0.9130 Pre: 0.9245 Recall: 0.9049 F1: 0.9146 Train AUC: 0.9950 Val AUC: 0.9726 Time: 12.29\n",
      "Epoch: 543 Train Loss: 0.1096 Val Loss: 0.2299 Acc: 0.8913 Pre: 0.8784 Recall: 0.9155 F1: 0.8966 Train AUC: 0.9928 Val AUC: 0.9732 Time: 12.61\n",
      "Epoch: 544 Train Loss: 0.1140 Val Loss: 0.2417 Acc: 0.8822 Pre: 0.8638 Recall: 0.9155 F1: 0.8889 Train AUC: 0.9931 Val AUC: 0.9717 Time: 13.23\n",
      "Epoch: 545 Train Loss: 0.1033 Val Loss: 0.2338 Acc: 0.8877 Pre: 0.8776 Recall: 0.9085 F1: 0.8927 Train AUC: 0.9947 Val AUC: 0.9692 Time: 13.94\n",
      "Epoch: 546 Train Loss: 0.1148 Val Loss: 0.2342 Acc: 0.9022 Pre: 0.9107 Recall: 0.8979 F1: 0.9043 Train AUC: 0.9928 Val AUC: 0.9693 Time: 14.22\n",
      "Epoch: 547 Train Loss: 0.1073 Val Loss: 0.2318 Acc: 0.8949 Pre: 0.8951 Recall: 0.9014 F1: 0.8982 Train AUC: 0.9937 Val AUC: 0.9713 Time: 13.09\n",
      "Epoch: 548 Train Loss: 0.1053 Val Loss: 0.2409 Acc: 0.8913 Pre: 0.8684 Recall: 0.9296 F1: 0.8980 Train AUC: 0.9940 Val AUC: 0.9719 Time: 12.47\n",
      "Epoch: 549 Train Loss: 0.1179 Val Loss: 0.2362 Acc: 0.8841 Pre: 0.8691 Recall: 0.9120 F1: 0.8900 Train AUC: 0.9934 Val AUC: 0.9713 Time: 12.27\n",
      "Epoch: 550 Train Loss: 0.0992 Val Loss: 0.2340 Acc: 0.8986 Pre: 0.9043 Recall: 0.8979 F1: 0.9011 Train AUC: 0.9946 Val AUC: 0.9707 Time: 12.80\n",
      "Epoch: 551 Train Loss: 0.1090 Val Loss: 0.2300 Acc: 0.9040 Pre: 0.9140 Recall: 0.8979 F1: 0.9059 Train AUC: 0.9932 Val AUC: 0.9710 Time: 13.20\n",
      "Epoch: 552 Train Loss: 0.1117 Val Loss: 0.2323 Acc: 0.8913 Pre: 0.8784 Recall: 0.9155 F1: 0.8966 Train AUC: 0.9936 Val AUC: 0.9705 Time: 13.24\n",
      "Epoch: 553 Train Loss: 0.0983 Val Loss: 0.2476 Acc: 0.8859 Pre: 0.8553 Recall: 0.9366 F1: 0.8941 Train AUC: 0.9956 Val AUC: 0.9692 Time: 12.57\n",
      "Epoch: 554 Train Loss: 0.1158 Val Loss: 0.2228 Acc: 0.8986 Pre: 0.8931 Recall: 0.9120 F1: 0.9024 Train AUC: 0.9946 Val AUC: 0.9712 Time: 11.98\n",
      "Epoch: 555 Train Loss: 0.0993 Val Loss: 0.2225 Acc: 0.9094 Pre: 0.9270 Recall: 0.8944 F1: 0.9104 Train AUC: 0.9950 Val AUC: 0.9729 Time: 12.37\n",
      "Epoch: 556 Train Loss: 0.1043 Val Loss: 0.2175 Acc: 0.9040 Pre: 0.9170 Recall: 0.8944 F1: 0.9055 Train AUC: 0.9943 Val AUC: 0.9735 Time: 12.84\n",
      "Epoch: 557 Train Loss: 0.1039 Val Loss: 0.2328 Acc: 0.8931 Pre: 0.8713 Recall: 0.9296 F1: 0.8995 Train AUC: 0.9944 Val AUC: 0.9728 Time: 13.27\n",
      "Epoch: 558 Train Loss: 0.1039 Val Loss: 0.2457 Acc: 0.8877 Pre: 0.8604 Recall: 0.9331 F1: 0.8953 Train AUC: 0.9951 Val AUC: 0.9728 Time: 13.63\n",
      "Epoch: 559 Train Loss: 0.1115 Val Loss: 0.2261 Acc: 0.9112 Pre: 0.9273 Recall: 0.8979 F1: 0.9123 Train AUC: 0.9949 Val AUC: 0.9721 Time: 13.36\n",
      "Epoch: 560 Train Loss: 0.1009 Val Loss: 0.2367 Acc: 0.9167 Pre: 0.9312 Recall: 0.9049 F1: 0.9179 Train AUC: 0.9943 Val AUC: 0.9704 Time: 12.48\n",
      "Epoch: 561 Train Loss: 0.1268 Val Loss: 0.2302 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9914 Val AUC: 0.9704 Time: 12.28\n",
      "Epoch: 562 Train Loss: 0.1158 Val Loss: 0.2439 Acc: 0.8877 Pre: 0.8604 Recall: 0.9331 F1: 0.8953 Train AUC: 0.9936 Val AUC: 0.9730 Time: 12.40\n",
      "Epoch: 563 Train Loss: 0.1175 Val Loss: 0.2279 Acc: 0.9004 Pre: 0.8962 Recall: 0.9120 F1: 0.9040 Train AUC: 0.9946 Val AUC: 0.9724 Time: 12.76\n",
      "Epoch: 564 Train Loss: 0.1113 Val Loss: 0.2319 Acc: 0.9022 Pre: 0.9137 Recall: 0.8944 F1: 0.9039 Train AUC: 0.9927 Val AUC: 0.9713 Time: 13.24\n",
      "Epoch: 565 Train Loss: 0.1276 Val Loss: 0.2280 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9914 Val AUC: 0.9716 Time: 13.92\n",
      "Epoch: 566 Train Loss: 0.1062 Val Loss: 0.2330 Acc: 0.9004 Pre: 0.8779 Recall: 0.9366 F1: 0.9063 Train AUC: 0.9939 Val AUC: 0.9717 Time: 13.95\n",
      "Epoch: 567 Train Loss: 0.1174 Val Loss: 0.2237 Acc: 0.9058 Pre: 0.8919 Recall: 0.9296 F1: 0.9103 Train AUC: 0.9932 Val AUC: 0.9719 Time: 12.74\n",
      "Epoch: 568 Train Loss: 0.1080 Val Loss: 0.2290 Acc: 0.9221 Pre: 0.9382 Recall: 0.9085 F1: 0.9231 Train AUC: 0.9944 Val AUC: 0.9707 Time: 12.05\n",
      "Epoch: 569 Train Loss: 0.1173 Val Loss: 0.2257 Acc: 0.9167 Pre: 0.9312 Recall: 0.9049 F1: 0.9179 Train AUC: 0.9921 Val AUC: 0.9725 Time: 11.64\n",
      "Epoch: 570 Train Loss: 0.1024 Val Loss: 0.2437 Acc: 0.8768 Pre: 0.8529 Recall: 0.9190 F1: 0.8847 Train AUC: 0.9939 Val AUC: 0.9702 Time: 12.26\n",
      "Epoch: 571 Train Loss: 0.1058 Val Loss: 0.2524 Acc: 0.8786 Pre: 0.8534 Recall: 0.9225 F1: 0.8866 Train AUC: 0.9941 Val AUC: 0.9687 Time: 12.67\n",
      "Epoch: 572 Train Loss: 0.1165 Val Loss: 0.2315 Acc: 0.8931 Pre: 0.8920 Recall: 0.9014 F1: 0.8967 Train AUC: 0.9919 Val AUC: 0.9717 Time: 13.13\n",
      "Epoch: 573 Train Loss: 0.1038 Val Loss: 0.2225 Acc: 0.8967 Pre: 0.9011 Recall: 0.8979 F1: 0.8995 Train AUC: 0.9937 Val AUC: 0.9730 Time: 13.66\n",
      "Epoch: 574 Train Loss: 0.0996 Val Loss: 0.2276 Acc: 0.8895 Pre: 0.8754 Recall: 0.9155 F1: 0.8950 Train AUC: 0.9946 Val AUC: 0.9726 Time: 14.16\n",
      "Epoch: 575 Train Loss: 0.1000 Val Loss: 0.2339 Acc: 0.8750 Pre: 0.8479 Recall: 0.9225 F1: 0.8836 Train AUC: 0.9950 Val AUC: 0.9710 Time: 12.93\n",
      "Epoch: 576 Train Loss: 0.1180 Val Loss: 0.2170 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9941 Val AUC: 0.9740 Time: 12.03\n",
      "Epoch: 577 Train Loss: 0.1083 Val Loss: 0.2260 Acc: 0.9022 Pre: 0.9107 Recall: 0.8979 F1: 0.9043 Train AUC: 0.9944 Val AUC: 0.9728 Time: 11.48\n",
      "Epoch: 578 Train Loss: 0.1134 Val Loss: 0.2334 Acc: 0.8931 Pre: 0.8947 Recall: 0.8979 F1: 0.8963 Train AUC: 0.9924 Val AUC: 0.9716 Time: 11.42\n",
      "Epoch: 579 Train Loss: 0.1099 Val Loss: 0.2479 Acc: 0.8931 Pre: 0.8763 Recall: 0.9225 F1: 0.8988 Train AUC: 0.9929 Val AUC: 0.9692 Time: 12.08\n",
      "Epoch: 580 Train Loss: 0.1126 Val Loss: 0.2350 Acc: 0.8931 Pre: 0.8893 Recall: 0.9049 F1: 0.8970 Train AUC: 0.9931 Val AUC: 0.9688 Time: 12.65\n",
      "Epoch: 581 Train Loss: 0.0964 Val Loss: 0.2261 Acc: 0.9167 Pre: 0.9375 Recall: 0.8979 F1: 0.9173 Train AUC: 0.9957 Val AUC: 0.9713 Time: 13.10\n",
      "Epoch: 582 Train Loss: 0.1047 Val Loss: 0.2319 Acc: 0.9149 Pre: 0.9309 Recall: 0.9014 F1: 0.9159 Train AUC: 0.9944 Val AUC: 0.9706 Time: 13.30\n",
      "Epoch: 583 Train Loss: 0.1161 Val Loss: 0.2263 Acc: 0.9004 Pre: 0.8935 Recall: 0.9155 F1: 0.9043 Train AUC: 0.9923 Val AUC: 0.9725 Time: 14.61\n",
      "Epoch: 584 Train Loss: 0.1144 Val Loss: 0.2384 Acc: 0.8931 Pre: 0.8738 Recall: 0.9261 F1: 0.8991 Train AUC: 0.9928 Val AUC: 0.9700 Time: 14.84\n",
      "Epoch: 585 Train Loss: 0.1093 Val Loss: 0.2303 Acc: 0.8949 Pre: 0.8897 Recall: 0.9085 F1: 0.8990 Train AUC: 0.9946 Val AUC: 0.9697 Time: 14.16\n",
      "Epoch: 586 Train Loss: 0.1005 Val Loss: 0.2178 Acc: 0.8967 Pre: 0.8982 Recall: 0.9014 F1: 0.8998 Train AUC: 0.9953 Val AUC: 0.9736 Time: 12.99\n",
      "Epoch: 587 Train Loss: 0.1026 Val Loss: 0.2198 Acc: 0.9058 Pre: 0.9085 Recall: 0.9085 F1: 0.9085 Train AUC: 0.9941 Val AUC: 0.9745 Time: 11.92\n",
      "Epoch: 588 Train Loss: 0.1083 Val Loss: 0.2172 Acc: 0.9076 Pre: 0.9003 Recall: 0.9225 F1: 0.9113 Train AUC: 0.9928 Val AUC: 0.9753 Time: 11.46\n",
      "Epoch: 589 Train Loss: 0.0987 Val Loss: 0.2226 Acc: 0.8895 Pre: 0.8656 Recall: 0.9296 F1: 0.8964 Train AUC: 0.9945 Val AUC: 0.9750 Time: 12.08\n",
      "Epoch: 590 Train Loss: 0.0956 Val Loss: 0.2299 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9960 Val AUC: 0.9708 Time: 12.26\n",
      "Epoch: 591 Train Loss: 0.0941 Val Loss: 0.2289 Acc: 0.8949 Pre: 0.9124 Recall: 0.8803 F1: 0.8961 Train AUC: 0.9962 Val AUC: 0.9696 Time: 12.64\n",
      "Epoch: 592 Train Loss: 0.1088 Val Loss: 0.2215 Acc: 0.9058 Pre: 0.9203 Recall: 0.8944 F1: 0.9071 Train AUC: 0.9938 Val AUC: 0.9717 Time: 13.29\n",
      "Epoch: 593 Train Loss: 0.1034 Val Loss: 0.2214 Acc: 0.9058 Pre: 0.8946 Recall: 0.9261 F1: 0.9100 Train AUC: 0.9948 Val AUC: 0.9736 Time: 13.88\n",
      "Epoch: 594 Train Loss: 0.0984 Val Loss: 0.2249 Acc: 0.9076 Pre: 0.8976 Recall: 0.9261 F1: 0.9116 Train AUC: 0.9948 Val AUC: 0.9744 Time: 14.40\n",
      "Epoch: 595 Train Loss: 0.1019 Val Loss: 0.2174 Acc: 0.9094 Pre: 0.9062 Recall: 0.9190 F1: 0.9126 Train AUC: 0.9942 Val AUC: 0.9749 Time: 13.48\n",
      "Epoch: 596 Train Loss: 0.0945 Val Loss: 0.2150 Acc: 0.9058 Pre: 0.9056 Recall: 0.9120 F1: 0.9088 Train AUC: 0.9954 Val AUC: 0.9738 Time: 12.35\n",
      "Epoch: 597 Train Loss: 0.0943 Val Loss: 0.2246 Acc: 0.9004 Pre: 0.8881 Recall: 0.9225 F1: 0.9050 Train AUC: 0.9949 Val AUC: 0.9714 Time: 11.57\n",
      "Epoch: 598 Train Loss: 0.0922 Val Loss: 0.2326 Acc: 0.9040 Pre: 0.8915 Recall: 0.9261 F1: 0.9085 Train AUC: 0.9958 Val AUC: 0.9692 Time: 11.78\n",
      "Epoch: 599 Train Loss: 0.1016 Val Loss: 0.2251 Acc: 0.8895 Pre: 0.8729 Recall: 0.9190 F1: 0.8954 Train AUC: 0.9954 Val AUC: 0.9732 Time: 12.07\n",
      "Epoch: 600 Train Loss: 0.0946 Val Loss: 0.2261 Acc: 0.8967 Pre: 0.8874 Recall: 0.9155 F1: 0.9012 Train AUC: 0.9955 Val AUC: 0.9730 Time: 12.56\n",
      "Epoch: 601 Train Loss: 0.0985 Val Loss: 0.2245 Acc: 0.9004 Pre: 0.9018 Recall: 0.9049 F1: 0.9033 Train AUC: 0.9944 Val AUC: 0.9736 Time: 13.12\n",
      "Epoch: 602 Train Loss: 0.0959 Val Loss: 0.2167 Acc: 0.9040 Pre: 0.9110 Recall: 0.9014 F1: 0.9062 Train AUC: 0.9950 Val AUC: 0.9743 Time: 13.53\n",
      "Epoch: 603 Train Loss: 0.0942 Val Loss: 0.2191 Acc: 0.8967 Pre: 0.8955 Recall: 0.9049 F1: 0.9002 Train AUC: 0.9948 Val AUC: 0.9722 Time: 14.14\n",
      "Epoch: 604 Train Loss: 0.1023 Val Loss: 0.2222 Acc: 0.8967 Pre: 0.8874 Recall: 0.9155 F1: 0.9012 Train AUC: 0.9948 Val AUC: 0.9718 Time: 13.30\n",
      "Epoch: 605 Train Loss: 0.0940 Val Loss: 0.2192 Acc: 0.8913 Pre: 0.8784 Recall: 0.9155 F1: 0.8966 Train AUC: 0.9957 Val AUC: 0.9745 Time: 12.25\n",
      "Epoch: 606 Train Loss: 0.0918 Val Loss: 0.2250 Acc: 0.9058 Pre: 0.9056 Recall: 0.9120 F1: 0.9088 Train AUC: 0.9959 Val AUC: 0.9747 Time: 11.96\n",
      "Epoch: 607 Train Loss: 0.1016 Val Loss: 0.2276 Acc: 0.8986 Pre: 0.8958 Recall: 0.9085 F1: 0.9021 Train AUC: 0.9939 Val AUC: 0.9744 Time: 12.69\n",
      "Epoch: 608 Train Loss: 0.1045 Val Loss: 0.2354 Acc: 0.8859 Pre: 0.8647 Recall: 0.9225 F1: 0.8927 Train AUC: 0.9939 Val AUC: 0.9727 Time: 13.03\n",
      "Epoch: 609 Train Loss: 0.1006 Val Loss: 0.2398 Acc: 0.9004 Pre: 0.8935 Recall: 0.9155 F1: 0.9043 Train AUC: 0.9947 Val AUC: 0.9690 Time: 13.51\n",
      "Epoch: 610 Train Loss: 0.1001 Val Loss: 0.2276 Acc: 0.9130 Pre: 0.9214 Recall: 0.9085 F1: 0.9149 Train AUC: 0.9949 Val AUC: 0.9712 Time: 14.11\n",
      "Epoch: 611 Train Loss: 0.0949 Val Loss: 0.2222 Acc: 0.9058 Pre: 0.9028 Recall: 0.9155 F1: 0.9091 Train AUC: 0.9957 Val AUC: 0.9731 Time: 13.18\n",
      "Epoch: 612 Train Loss: 0.0877 Val Loss: 0.2256 Acc: 0.9022 Pre: 0.8912 Recall: 0.9225 F1: 0.9066 Train AUC: 0.9958 Val AUC: 0.9733 Time: 12.20\n",
      "Epoch: 613 Train Loss: 0.1008 Val Loss: 0.2291 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9944 Val AUC: 0.9739 Time: 12.09\n",
      "Epoch: 614 Train Loss: 0.0841 Val Loss: 0.2248 Acc: 0.9022 Pre: 0.8966 Recall: 0.9155 F1: 0.9059 Train AUC: 0.9967 Val AUC: 0.9739 Time: 11.98\n",
      "Epoch: 615 Train Loss: 0.0936 Val Loss: 0.2269 Acc: 0.8986 Pre: 0.8904 Recall: 0.9155 F1: 0.9028 Train AUC: 0.9950 Val AUC: 0.9728 Time: 12.36\n",
      "Epoch: 616 Train Loss: 0.0849 Val Loss: 0.2378 Acc: 0.8913 Pre: 0.8784 Recall: 0.9155 F1: 0.8966 Train AUC: 0.9964 Val AUC: 0.9709 Time: 13.05\n",
      "Epoch: 617 Train Loss: 0.0943 Val Loss: 0.2412 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9957 Val AUC: 0.9713 Time: 13.42\n",
      "Epoch: 618 Train Loss: 0.0933 Val Loss: 0.2327 Acc: 0.8877 Pre: 0.8675 Recall: 0.9225 F1: 0.8942 Train AUC: 0.9952 Val AUC: 0.9727 Time: 14.06\n",
      "Epoch: 619 Train Loss: 0.0916 Val Loss: 0.2274 Acc: 0.8967 Pre: 0.8927 Recall: 0.9085 F1: 0.9005 Train AUC: 0.9960 Val AUC: 0.9731 Time: 13.52\n",
      "Epoch: 620 Train Loss: 0.0942 Val Loss: 0.2263 Acc: 0.9058 Pre: 0.9113 Recall: 0.9049 F1: 0.9081 Train AUC: 0.9952 Val AUC: 0.9731 Time: 12.41\n",
      "Epoch: 621 Train Loss: 0.0886 Val Loss: 0.2218 Acc: 0.8986 Pre: 0.8986 Recall: 0.9049 F1: 0.9018 Train AUC: 0.9956 Val AUC: 0.9732 Time: 11.99\n",
      "Epoch: 622 Train Loss: 0.0954 Val Loss: 0.2235 Acc: 0.8967 Pre: 0.8847 Recall: 0.9190 F1: 0.9016 Train AUC: 0.9952 Val AUC: 0.9724 Time: 11.78\n",
      "Epoch: 623 Train Loss: 0.0907 Val Loss: 0.2235 Acc: 0.8895 Pre: 0.8704 Recall: 0.9225 F1: 0.8957 Train AUC: 0.9965 Val AUC: 0.9744 Time: 11.78\n",
      "Epoch: 624 Train Loss: 0.0943 Val Loss: 0.2216 Acc: 0.8913 Pre: 0.8758 Recall: 0.9190 F1: 0.8969 Train AUC: 0.9956 Val AUC: 0.9752 Time: 12.20\n",
      "Epoch: 625 Train Loss: 0.1001 Val Loss: 0.2198 Acc: 0.9112 Pre: 0.9123 Recall: 0.9155 F1: 0.9139 Train AUC: 0.9951 Val AUC: 0.9743 Time: 12.83\n",
      "Epoch: 626 Train Loss: 0.0975 Val Loss: 0.2209 Acc: 0.9112 Pre: 0.9123 Recall: 0.9155 F1: 0.9139 Train AUC: 0.9946 Val AUC: 0.9733 Time: 13.19\n",
      "Epoch: 627 Train Loss: 0.0861 Val Loss: 0.2307 Acc: 0.8859 Pre: 0.8671 Recall: 0.9190 F1: 0.8923 Train AUC: 0.9963 Val AUC: 0.9730 Time: 13.67\n",
      "Epoch: 628 Train Loss: 0.1013 Val Loss: 0.2344 Acc: 0.8895 Pre: 0.8729 Recall: 0.9190 F1: 0.8954 Train AUC: 0.9942 Val AUC: 0.9737 Time: 14.29\n",
      "Epoch: 629 Train Loss: 0.0824 Val Loss: 0.2300 Acc: 0.8986 Pre: 0.8904 Recall: 0.9155 F1: 0.9028 Train AUC: 0.9967 Val AUC: 0.9742 Time: 13.35\n",
      "Epoch: 630 Train Loss: 0.0802 Val Loss: 0.2227 Acc: 0.9058 Pre: 0.9028 Recall: 0.9155 F1: 0.9091 Train AUC: 0.9967 Val AUC: 0.9749 Time: 12.45\n",
      "Epoch: 631 Train Loss: 0.0859 Val Loss: 0.2207 Acc: 0.9094 Pre: 0.9034 Recall: 0.9225 F1: 0.9129 Train AUC: 0.9963 Val AUC: 0.9732 Time: 12.06\n",
      "Epoch: 632 Train Loss: 0.0897 Val Loss: 0.2277 Acc: 0.9058 Pre: 0.8919 Recall: 0.9296 F1: 0.9103 Train AUC: 0.9962 Val AUC: 0.9708 Time: 12.09\n",
      "Epoch: 633 Train Loss: 0.1025 Val Loss: 0.2219 Acc: 0.9004 Pre: 0.8935 Recall: 0.9155 F1: 0.9043 Train AUC: 0.9956 Val AUC: 0.9748 Time: 12.58\n",
      "Epoch: 634 Train Loss: 0.0936 Val Loss: 0.2299 Acc: 0.9022 Pre: 0.8966 Recall: 0.9155 F1: 0.9059 Train AUC: 0.9955 Val AUC: 0.9745 Time: 13.16\n",
      "Epoch: 635 Train Loss: 0.0926 Val Loss: 0.2333 Acc: 0.8913 Pre: 0.8810 Recall: 0.9120 F1: 0.8962 Train AUC: 0.9951 Val AUC: 0.9728 Time: 13.56\n",
      "Epoch: 636 Train Loss: 0.0926 Val Loss: 0.2429 Acc: 0.8895 Pre: 0.8780 Recall: 0.9120 F1: 0.8946 Train AUC: 0.9952 Val AUC: 0.9695 Time: 13.32\n",
      "Epoch: 637 Train Loss: 0.0981 Val Loss: 0.2395 Acc: 0.8877 Pre: 0.8750 Recall: 0.9120 F1: 0.8931 Train AUC: 0.9951 Val AUC: 0.9709 Time: 12.61\n",
      "Epoch: 638 Train Loss: 0.0905 Val Loss: 0.2299 Acc: 0.8967 Pre: 0.8927 Recall: 0.9085 F1: 0.9005 Train AUC: 0.9955 Val AUC: 0.9727 Time: 12.25\n",
      "Epoch: 639 Train Loss: 0.0860 Val Loss: 0.2242 Acc: 0.9094 Pre: 0.9091 Recall: 0.9155 F1: 0.9123 Train AUC: 0.9958 Val AUC: 0.9733 Time: 12.70\n",
      "Epoch: 640 Train Loss: 0.0904 Val Loss: 0.2271 Acc: 0.9022 Pre: 0.8885 Recall: 0.9261 F1: 0.9069 Train AUC: 0.9955 Val AUC: 0.9728 Time: 13.32\n",
      "Epoch: 641 Train Loss: 0.0894 Val Loss: 0.2315 Acc: 0.8986 Pre: 0.8826 Recall: 0.9261 F1: 0.9038 Train AUC: 0.9961 Val AUC: 0.9726 Time: 13.60\n",
      "Epoch: 642 Train Loss: 0.0889 Val Loss: 0.2248 Acc: 0.8986 Pre: 0.8931 Recall: 0.9120 F1: 0.9024 Train AUC: 0.9967 Val AUC: 0.9729 Time: 12.66\n",
      "Epoch: 643 Train Loss: 0.0974 Val Loss: 0.2253 Acc: 0.9040 Pre: 0.9110 Recall: 0.9014 F1: 0.9062 Train AUC: 0.9950 Val AUC: 0.9735 Time: 11.89\n",
      "Epoch: 644 Train Loss: 0.0927 Val Loss: 0.2274 Acc: 0.9040 Pre: 0.8997 Recall: 0.9155 F1: 0.9075 Train AUC: 0.9949 Val AUC: 0.9734 Time: 11.67\n",
      "Epoch: 645 Train Loss: 0.0875 Val Loss: 0.2232 Acc: 0.8986 Pre: 0.8904 Recall: 0.9155 F1: 0.9028 Train AUC: 0.9955 Val AUC: 0.9742 Time: 12.19\n",
      "Epoch: 646 Train Loss: 0.0857 Val Loss: 0.2198 Acc: 0.8986 Pre: 0.8851 Recall: 0.9225 F1: 0.9034 Train AUC: 0.9962 Val AUC: 0.9746 Time: 12.67\n",
      "Epoch: 647 Train Loss: 0.0915 Val Loss: 0.2175 Acc: 0.9130 Pre: 0.9126 Recall: 0.9190 F1: 0.9158 Train AUC: 0.9960 Val AUC: 0.9732 Time: 13.11\n",
      "Epoch: 648 Train Loss: 0.0907 Val Loss: 0.2187 Acc: 0.9149 Pre: 0.9187 Recall: 0.9155 F1: 0.9171 Train AUC: 0.9962 Val AUC: 0.9729 Time: 13.60\n",
      "Epoch: 649 Train Loss: 0.0907 Val Loss: 0.2249 Acc: 0.9076 Pre: 0.8976 Recall: 0.9261 F1: 0.9116 Train AUC: 0.9962 Val AUC: 0.9735 Time: 14.15\n",
      "Epoch: 650 Train Loss: 0.0939 Val Loss: 0.2364 Acc: 0.9022 Pre: 0.8885 Recall: 0.9261 F1: 0.9069 Train AUC: 0.9952 Val AUC: 0.9738 Time: 12.92\n",
      "Epoch: 651 Train Loss: 0.0966 Val Loss: 0.2338 Acc: 0.8895 Pre: 0.8754 Recall: 0.9155 F1: 0.8950 Train AUC: 0.9946 Val AUC: 0.9734 Time: 11.96\n",
      "Epoch: 652 Train Loss: 0.0895 Val Loss: 0.2324 Acc: 0.8841 Pre: 0.8716 Recall: 0.9085 F1: 0.8897 Train AUC: 0.9958 Val AUC: 0.9729 Time: 12.26\n",
      "Epoch: 653 Train Loss: 0.0944 Val Loss: 0.2287 Acc: 0.8931 Pre: 0.8814 Recall: 0.9155 F1: 0.8981 Train AUC: 0.9952 Val AUC: 0.9723 Time: 12.62\n",
      "Epoch: 654 Train Loss: 0.0942 Val Loss: 0.2299 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9953 Val AUC: 0.9719 Time: 13.71\n",
      "Epoch: 655 Train Loss: 0.0937 Val Loss: 0.2348 Acc: 0.8967 Pre: 0.8900 Recall: 0.9120 F1: 0.9009 Train AUC: 0.9963 Val AUC: 0.9731 Time: 13.67\n",
      "Epoch: 656 Train Loss: 0.0929 Val Loss: 0.2351 Acc: 0.8986 Pre: 0.8958 Recall: 0.9085 F1: 0.9021 Train AUC: 0.9959 Val AUC: 0.9732 Time: 12.82\n",
      "Epoch: 657 Train Loss: 0.0851 Val Loss: 0.2338 Acc: 0.8913 Pre: 0.8836 Recall: 0.9085 F1: 0.8958 Train AUC: 0.9960 Val AUC: 0.9733 Time: 12.70\n",
      "Epoch: 658 Train Loss: 0.0899 Val Loss: 0.2364 Acc: 0.8913 Pre: 0.8810 Recall: 0.9120 F1: 0.8962 Train AUC: 0.9957 Val AUC: 0.9710 Time: 12.78\n",
      "Epoch: 659 Train Loss: 0.0903 Val Loss: 0.2367 Acc: 0.8967 Pre: 0.8900 Recall: 0.9120 F1: 0.9009 Train AUC: 0.9960 Val AUC: 0.9698 Time: 12.72\n",
      "Epoch: 660 Train Loss: 0.0910 Val Loss: 0.2286 Acc: 0.8949 Pre: 0.8844 Recall: 0.9155 F1: 0.8997 Train AUC: 0.9962 Val AUC: 0.9720 Time: 13.10\n",
      "Epoch: 661 Train Loss: 0.0900 Val Loss: 0.2265 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9961 Val AUC: 0.9736 Time: 12.95\n",
      "Epoch: 662 Train Loss: 0.0916 Val Loss: 0.2284 Acc: 0.9040 Pre: 0.8915 Recall: 0.9261 F1: 0.9085 Train AUC: 0.9954 Val AUC: 0.9735 Time: 12.49\n",
      "Epoch: 663 Train Loss: 0.0948 Val Loss: 0.2250 Acc: 0.9130 Pre: 0.9214 Recall: 0.9085 F1: 0.9149 Train AUC: 0.9957 Val AUC: 0.9733 Time: 13.24\n",
      "Epoch: 664 Train Loss: 0.0854 Val Loss: 0.2260 Acc: 0.9058 Pre: 0.9203 Recall: 0.8944 F1: 0.9071 Train AUC: 0.9964 Val AUC: 0.9732 Time: 12.82\n",
      "Epoch: 665 Train Loss: 0.0895 Val Loss: 0.2298 Acc: 0.8949 Pre: 0.8870 Recall: 0.9120 F1: 0.8993 Train AUC: 0.9963 Val AUC: 0.9723 Time: 12.80\n",
      "Epoch: 666 Train Loss: 0.0928 Val Loss: 0.2466 Acc: 0.8877 Pre: 0.8675 Recall: 0.9225 F1: 0.8942 Train AUC: 0.9955 Val AUC: 0.9729 Time: 12.73\n",
      "Epoch: 667 Train Loss: 0.0903 Val Loss: 0.2403 Acc: 0.8949 Pre: 0.8792 Recall: 0.9225 F1: 0.9003 Train AUC: 0.9960 Val AUC: 0.9734 Time: 13.39\n",
      "Epoch: 668 Train Loss: 0.0818 Val Loss: 0.2296 Acc: 0.8967 Pre: 0.8900 Recall: 0.9120 F1: 0.9009 Train AUC: 0.9964 Val AUC: 0.9739 Time: 13.62\n",
      "Epoch: 669 Train Loss: 0.0906 Val Loss: 0.2248 Acc: 0.8986 Pre: 0.8878 Recall: 0.9190 F1: 0.9031 Train AUC: 0.9956 Val AUC: 0.9737 Time: 12.57\n",
      "Epoch: 670 Train Loss: 0.0789 Val Loss: 0.2253 Acc: 0.8967 Pre: 0.8796 Recall: 0.9261 F1: 0.9022 Train AUC: 0.9973 Val AUC: 0.9733 Time: 12.36\n",
      "Epoch: 671 Train Loss: 0.0859 Val Loss: 0.2206 Acc: 0.8986 Pre: 0.8826 Recall: 0.9261 F1: 0.9038 Train AUC: 0.9964 Val AUC: 0.9741 Time: 11.70\n",
      "Epoch: 672 Train Loss: 0.0869 Val Loss: 0.2195 Acc: 0.9167 Pre: 0.9220 Recall: 0.9155 F1: 0.9187 Train AUC: 0.9963 Val AUC: 0.9749 Time: 12.29\n",
      "Epoch: 673 Train Loss: 0.0764 Val Loss: 0.2225 Acc: 0.9076 Pre: 0.9059 Recall: 0.9155 F1: 0.9107 Train AUC: 0.9973 Val AUC: 0.9741 Time: 12.80\n",
      "Epoch: 674 Train Loss: 0.0850 Val Loss: 0.2294 Acc: 0.8931 Pre: 0.8788 Recall: 0.9190 F1: 0.8985 Train AUC: 0.9957 Val AUC: 0.9729 Time: 13.22\n",
      "Epoch: 675 Train Loss: 0.0802 Val Loss: 0.2272 Acc: 0.9004 Pre: 0.8881 Recall: 0.9225 F1: 0.9050 Train AUC: 0.9972 Val AUC: 0.9731 Time: 13.63\n",
      "Epoch: 676 Train Loss: 0.0790 Val Loss: 0.2225 Acc: 0.8986 Pre: 0.8851 Recall: 0.9225 F1: 0.9034 Train AUC: 0.9967 Val AUC: 0.9743 Time: 13.75\n",
      "Epoch: 677 Train Loss: 0.0788 Val Loss: 0.2187 Acc: 0.9040 Pre: 0.9024 Recall: 0.9120 F1: 0.9072 Train AUC: 0.9973 Val AUC: 0.9751 Time: 12.85\n",
      "Epoch: 678 Train Loss: 0.0885 Val Loss: 0.2193 Acc: 0.9022 Pre: 0.8938 Recall: 0.9190 F1: 0.9062 Train AUC: 0.9959 Val AUC: 0.9750 Time: 11.95\n",
      "Epoch: 679 Train Loss: 0.0952 Val Loss: 0.2228 Acc: 0.8931 Pre: 0.8763 Recall: 0.9225 F1: 0.8988 Train AUC: 0.9948 Val AUC: 0.9748 Time: 12.28\n",
      "Epoch: 680 Train Loss: 0.0788 Val Loss: 0.2284 Acc: 0.8895 Pre: 0.8704 Recall: 0.9225 F1: 0.8957 Train AUC: 0.9972 Val AUC: 0.9744 Time: 12.64\n",
      "Epoch: 681 Train Loss: 0.0906 Val Loss: 0.2312 Acc: 0.9040 Pre: 0.9024 Recall: 0.9120 F1: 0.9072 Train AUC: 0.9961 Val AUC: 0.9735 Time: 12.56\n",
      "Epoch: 682 Train Loss: 0.0817 Val Loss: 0.2322 Acc: 0.9058 Pre: 0.9113 Recall: 0.9049 F1: 0.9081 Train AUC: 0.9966 Val AUC: 0.9729 Time: 13.17\n",
      "Epoch: 683 Train Loss: 0.0847 Val Loss: 0.2285 Acc: 0.9058 Pre: 0.9056 Recall: 0.9120 F1: 0.9088 Train AUC: 0.9961 Val AUC: 0.9723 Time: 13.56\n",
      "Epoch: 684 Train Loss: 0.0903 Val Loss: 0.2463 Acc: 0.8913 Pre: 0.8709 Recall: 0.9261 F1: 0.8976 Train AUC: 0.9963 Val AUC: 0.9707 Time: 12.97\n",
      "Epoch: 685 Train Loss: 0.0847 Val Loss: 0.2496 Acc: 0.8859 Pre: 0.8623 Recall: 0.9261 F1: 0.8930 Train AUC: 0.9972 Val AUC: 0.9718 Time: 11.91\n",
      "Epoch: 686 Train Loss: 0.0932 Val Loss: 0.2274 Acc: 0.9112 Pre: 0.9181 Recall: 0.9085 F1: 0.9133 Train AUC: 0.9965 Val AUC: 0.9731 Time: 11.65\n",
      "Epoch: 687 Train Loss: 0.0847 Val Loss: 0.2308 Acc: 0.9130 Pre: 0.9245 Recall: 0.9049 F1: 0.9146 Train AUC: 0.9965 Val AUC: 0.9735 Time: 12.19\n",
      "Epoch: 688 Train Loss: 0.0921 Val Loss: 0.2271 Acc: 0.9058 Pre: 0.9028 Recall: 0.9155 F1: 0.9091 Train AUC: 0.9953 Val AUC: 0.9742 Time: 12.64\n",
      "Epoch: 689 Train Loss: 0.0832 Val Loss: 0.2366 Acc: 0.8931 Pre: 0.8713 Recall: 0.9296 F1: 0.8995 Train AUC: 0.9961 Val AUC: 0.9729 Time: 13.03\n",
      "Epoch: 690 Train Loss: 0.0767 Val Loss: 0.2527 Acc: 0.8913 Pre: 0.8636 Recall: 0.9366 F1: 0.8986 Train AUC: 0.9972 Val AUC: 0.9690 Time: 13.60\n",
      "Epoch: 691 Train Loss: 0.0789 Val Loss: 0.2359 Acc: 0.8895 Pre: 0.8729 Recall: 0.9190 F1: 0.8954 Train AUC: 0.9975 Val AUC: 0.9700 Time: 14.22\n",
      "Epoch: 692 Train Loss: 0.0917 Val Loss: 0.2270 Acc: 0.8986 Pre: 0.8986 Recall: 0.9049 F1: 0.9018 Train AUC: 0.9953 Val AUC: 0.9741 Time: 13.03\n",
      "Epoch: 693 Train Loss: 0.0889 Val Loss: 0.2313 Acc: 0.9040 Pre: 0.8997 Recall: 0.9155 F1: 0.9075 Train AUC: 0.9957 Val AUC: 0.9749 Time: 12.57\n",
      "Epoch: 694 Train Loss: 0.0830 Val Loss: 0.2372 Acc: 0.8967 Pre: 0.8721 Recall: 0.9366 F1: 0.9032 Train AUC: 0.9958 Val AUC: 0.9747 Time: 12.15\n",
      "Epoch: 695 Train Loss: 0.0839 Val Loss: 0.2343 Acc: 0.8949 Pre: 0.8693 Recall: 0.9366 F1: 0.9017 Train AUC: 0.9966 Val AUC: 0.9741 Time: 12.53\n",
      "Epoch: 696 Train Loss: 0.0834 Val Loss: 0.2208 Acc: 0.9149 Pre: 0.9100 Recall: 0.9261 F1: 0.9180 Train AUC: 0.9974 Val AUC: 0.9733 Time: 13.04\n",
      "Epoch: 697 Train Loss: 0.0856 Val Loss: 0.2230 Acc: 0.9094 Pre: 0.9270 Recall: 0.8944 F1: 0.9104 Train AUC: 0.9965 Val AUC: 0.9737 Time: 13.03\n",
      "Epoch: 698 Train Loss: 0.0942 Val Loss: 0.2193 Acc: 0.9094 Pre: 0.9034 Recall: 0.9225 F1: 0.9129 Train AUC: 0.9963 Val AUC: 0.9750 Time: 12.93\n",
      "Epoch: 699 Train Loss: 0.0814 Val Loss: 0.2337 Acc: 0.8895 Pre: 0.8656 Recall: 0.9296 F1: 0.8964 Train AUC: 0.9968 Val AUC: 0.9738 Time: 12.52\n",
      "Epoch: 700 Train Loss: 0.0878 Val Loss: 0.2298 Acc: 0.8895 Pre: 0.8754 Recall: 0.9155 F1: 0.8950 Train AUC: 0.9963 Val AUC: 0.9733 Time: 12.77\n",
      "Epoch: 701 Train Loss: 0.0864 Val Loss: 0.2221 Acc: 0.9022 Pre: 0.8938 Recall: 0.9190 F1: 0.9062 Train AUC: 0.9960 Val AUC: 0.9731 Time: 13.31\n",
      "Epoch: 702 Train Loss: 0.0761 Val Loss: 0.2208 Acc: 0.9112 Pre: 0.9181 Recall: 0.9085 F1: 0.9133 Train AUC: 0.9974 Val AUC: 0.9737 Time: 13.78\n",
      "Epoch: 703 Train Loss: 0.0864 Val Loss: 0.2192 Acc: 0.8986 Pre: 0.8986 Recall: 0.9049 F1: 0.9018 Train AUC: 0.9967 Val AUC: 0.9754 Time: 13.22\n",
      "Epoch: 704 Train Loss: 0.0959 Val Loss: 0.2329 Acc: 0.8949 Pre: 0.8693 Recall: 0.9366 F1: 0.9017 Train AUC: 0.9950 Val AUC: 0.9759 Time: 12.21\n",
      "Epoch: 705 Train Loss: 0.0912 Val Loss: 0.2399 Acc: 0.8967 Pre: 0.8673 Recall: 0.9437 F1: 0.9039 Train AUC: 0.9966 Val AUC: 0.9753 Time: 11.43\n",
      "Epoch: 706 Train Loss: 0.0859 Val Loss: 0.2241 Acc: 0.9040 Pre: 0.8969 Recall: 0.9190 F1: 0.9078 Train AUC: 0.9971 Val AUC: 0.9748 Time: 11.76\n",
      "Epoch: 707 Train Loss: 0.0748 Val Loss: 0.2307 Acc: 0.9040 Pre: 0.9200 Recall: 0.8908 F1: 0.9052 Train AUC: 0.9975 Val AUC: 0.9744 Time: 12.11\n",
      "Epoch: 708 Train Loss: 0.0918 Val Loss: 0.2246 Acc: 0.9058 Pre: 0.8973 Recall: 0.9225 F1: 0.9097 Train AUC: 0.9970 Val AUC: 0.9736 Time: 12.61\n",
      "Epoch: 709 Train Loss: 0.0788 Val Loss: 0.2475 Acc: 0.8913 Pre: 0.8684 Recall: 0.9296 F1: 0.8980 Train AUC: 0.9969 Val AUC: 0.9733 Time: 13.50\n",
      "Epoch: 710 Train Loss: 0.0890 Val Loss: 0.2352 Acc: 0.8931 Pre: 0.8763 Recall: 0.9225 F1: 0.8988 Train AUC: 0.9973 Val AUC: 0.9737 Time: 13.81\n",
      "Epoch: 711 Train Loss: 0.0961 Val Loss: 0.2259 Acc: 0.9112 Pre: 0.9123 Recall: 0.9155 F1: 0.9139 Train AUC: 0.9951 Val AUC: 0.9736 Time: 14.13\n",
      "Epoch: 712 Train Loss: 0.0877 Val Loss: 0.2308 Acc: 0.8986 Pre: 0.8878 Recall: 0.9190 F1: 0.9031 Train AUC: 0.9960 Val AUC: 0.9719 Time: 13.73\n",
      "Epoch: 713 Train Loss: 0.0810 Val Loss: 0.2394 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9966 Val AUC: 0.9706 Time: 12.51\n",
      "Epoch: 714 Train Loss: 0.0931 Val Loss: 0.2407 Acc: 0.9004 Pre: 0.8881 Recall: 0.9225 F1: 0.9050 Train AUC: 0.9960 Val AUC: 0.9724 Time: 12.00\n",
      "Epoch: 715 Train Loss: 0.0847 Val Loss: 0.2411 Acc: 0.9004 Pre: 0.8962 Recall: 0.9120 F1: 0.9040 Train AUC: 0.9966 Val AUC: 0.9737 Time: 12.25\n",
      "Epoch: 716 Train Loss: 0.0800 Val Loss: 0.2294 Acc: 0.9040 Pre: 0.9081 Recall: 0.9049 F1: 0.9065 Train AUC: 0.9966 Val AUC: 0.9745 Time: 12.80\n",
      "Epoch: 717 Train Loss: 0.0802 Val Loss: 0.2280 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9968 Val AUC: 0.9728 Time: 13.03\n",
      "Epoch: 718 Train Loss: 0.0802 Val Loss: 0.2472 Acc: 0.9112 Pre: 0.9010 Recall: 0.9296 F1: 0.9151 Train AUC: 0.9970 Val AUC: 0.9678 Time: 13.60\n",
      "Epoch: 719 Train Loss: 0.0879 Val Loss: 0.2323 Acc: 0.9004 Pre: 0.8855 Recall: 0.9261 F1: 0.9053 Train AUC: 0.9961 Val AUC: 0.9731 Time: 13.08\n",
      "Epoch: 720 Train Loss: 0.0807 Val Loss: 0.2340 Acc: 0.9094 Pre: 0.9091 Recall: 0.9155 F1: 0.9123 Train AUC: 0.9968 Val AUC: 0.9738 Time: 12.62\n",
      "Epoch: 721 Train Loss: 0.0843 Val Loss: 0.2359 Acc: 0.9149 Pre: 0.9129 Recall: 0.9225 F1: 0.9177 Train AUC: 0.9958 Val AUC: 0.9732 Time: 12.79\n",
      "Epoch: 722 Train Loss: 0.0805 Val Loss: 0.2287 Acc: 0.9004 Pre: 0.8829 Recall: 0.9296 F1: 0.9057 Train AUC: 0.9965 Val AUC: 0.9740 Time: 13.13\n",
      "Epoch: 723 Train Loss: 0.0866 Val Loss: 0.2226 Acc: 0.9112 Pre: 0.9094 Recall: 0.9190 F1: 0.9142 Train AUC: 0.9959 Val AUC: 0.9717 Time: 13.04\n",
      "Epoch: 724 Train Loss: 0.0852 Val Loss: 0.2239 Acc: 0.9185 Pre: 0.9283 Recall: 0.9120 F1: 0.9201 Train AUC: 0.9964 Val AUC: 0.9718 Time: 13.86\n",
      "Epoch: 725 Train Loss: 0.0975 Val Loss: 0.2237 Acc: 0.8986 Pre: 0.8878 Recall: 0.9190 F1: 0.9031 Train AUC: 0.9955 Val AUC: 0.9747 Time: 12.72\n",
      "Epoch: 726 Train Loss: 0.0820 Val Loss: 0.2419 Acc: 0.8913 Pre: 0.8684 Recall: 0.9296 F1: 0.8980 Train AUC: 0.9963 Val AUC: 0.9745 Time: 12.03\n",
      "Epoch: 727 Train Loss: 0.0826 Val Loss: 0.2533 Acc: 0.8913 Pre: 0.8660 Recall: 0.9331 F1: 0.8983 Train AUC: 0.9967 Val AUC: 0.9742 Time: 12.51\n",
      "Epoch: 728 Train Loss: 0.0812 Val Loss: 0.2428 Acc: 0.8949 Pre: 0.8717 Recall: 0.9331 F1: 0.9014 Train AUC: 0.9970 Val AUC: 0.9740 Time: 12.19\n",
      "Epoch: 729 Train Loss: 0.0840 Val Loss: 0.2261 Acc: 0.8967 Pre: 0.8822 Recall: 0.9225 F1: 0.9019 Train AUC: 0.9962 Val AUC: 0.9745 Time: 12.70\n",
      "Epoch: 730 Train Loss: 0.0829 Val Loss: 0.2214 Acc: 0.9112 Pre: 0.9123 Recall: 0.9155 F1: 0.9139 Train AUC: 0.9963 Val AUC: 0.9737 Time: 13.23\n",
      "Epoch: 731 Train Loss: 0.0791 Val Loss: 0.2194 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9974 Val AUC: 0.9739 Time: 13.60\n",
      "Epoch: 732 Train Loss: 0.0817 Val Loss: 0.2218 Acc: 0.9076 Pre: 0.8949 Recall: 0.9296 F1: 0.9119 Train AUC: 0.9974 Val AUC: 0.9743 Time: 13.34\n",
      "Epoch: 733 Train Loss: 0.0838 Val Loss: 0.2261 Acc: 0.9185 Pre: 0.9135 Recall: 0.9296 F1: 0.9215 Train AUC: 0.9969 Val AUC: 0.9748 Time: 12.88\n",
      "Epoch: 734 Train Loss: 0.0802 Val Loss: 0.2301 Acc: 0.9167 Pre: 0.9132 Recall: 0.9261 F1: 0.9196 Train AUC: 0.9965 Val AUC: 0.9737 Time: 12.53\n",
      "Epoch: 735 Train Loss: 0.0829 Val Loss: 0.2466 Acc: 0.8967 Pre: 0.8771 Recall: 0.9296 F1: 0.9026 Train AUC: 0.9963 Val AUC: 0.9719 Time: 12.11\n",
      "Epoch: 736 Train Loss: 0.0840 Val Loss: 0.2491 Acc: 0.9004 Pre: 0.8804 Recall: 0.9331 F1: 0.9060 Train AUC: 0.9965 Val AUC: 0.9694 Time: 12.76\n",
      "Epoch: 737 Train Loss: 0.0875 Val Loss: 0.2404 Acc: 0.9004 Pre: 0.8881 Recall: 0.9225 F1: 0.9050 Train AUC: 0.9958 Val AUC: 0.9704 Time: 13.11\n",
      "Epoch: 738 Train Loss: 0.0887 Val Loss: 0.2384 Acc: 0.9167 Pre: 0.9161 Recall: 0.9225 F1: 0.9193 Train AUC: 0.9962 Val AUC: 0.9725 Time: 13.71\n",
      "Epoch: 739 Train Loss: 0.0953 Val Loss: 0.2353 Acc: 0.9130 Pre: 0.9184 Recall: 0.9120 F1: 0.9152 Train AUC: 0.9942 Val AUC: 0.9747 Time: 13.18\n",
      "Epoch: 740 Train Loss: 0.0912 Val Loss: 0.2338 Acc: 0.9004 Pre: 0.8829 Recall: 0.9296 F1: 0.9057 Train AUC: 0.9954 Val AUC: 0.9747 Time: 13.03\n",
      "Epoch: 741 Train Loss: 0.0767 Val Loss: 0.2593 Acc: 0.8877 Pre: 0.8581 Recall: 0.9366 F1: 0.8956 Train AUC: 0.9972 Val AUC: 0.9701 Time: 12.09\n",
      "Epoch: 742 Train Loss: 0.0876 Val Loss: 0.2345 Acc: 0.9058 Pre: 0.8973 Recall: 0.9225 F1: 0.9097 Train AUC: 0.9971 Val AUC: 0.9720 Time: 12.29\n",
      "Epoch: 743 Train Loss: 0.0962 Val Loss: 0.2309 Acc: 0.9112 Pre: 0.9242 Recall: 0.9014 F1: 0.9127 Train AUC: 0.9945 Val AUC: 0.9742 Time: 12.70\n",
      "Epoch: 744 Train Loss: 0.0887 Val Loss: 0.2233 Acc: 0.8931 Pre: 0.8788 Recall: 0.9190 F1: 0.8985 Train AUC: 0.9960 Val AUC: 0.9737 Time: 13.09\n",
      "Epoch: 745 Train Loss: 0.0772 Val Loss: 0.2500 Acc: 0.8877 Pre: 0.8581 Recall: 0.9366 F1: 0.8956 Train AUC: 0.9973 Val AUC: 0.9700 Time: 13.84\n",
      "Epoch: 746 Train Loss: 0.0933 Val Loss: 0.2354 Acc: 0.8895 Pre: 0.8704 Recall: 0.9225 F1: 0.8957 Train AUC: 0.9959 Val AUC: 0.9731 Time: 13.34\n",
      "Epoch: 747 Train Loss: 0.0764 Val Loss: 0.2281 Acc: 0.9040 Pre: 0.9053 Recall: 0.9085 F1: 0.9069 Train AUC: 0.9977 Val AUC: 0.9741 Time: 12.50\n",
      "Epoch: 748 Train Loss: 0.0756 Val Loss: 0.2333 Acc: 0.9058 Pre: 0.9203 Recall: 0.8944 F1: 0.9071 Train AUC: 0.9970 Val AUC: 0.9740 Time: 12.44\n",
      "Epoch: 749 Train Loss: 0.0828 Val Loss: 0.2280 Acc: 0.8949 Pre: 0.8818 Recall: 0.9190 F1: 0.9000 Train AUC: 0.9967 Val AUC: 0.9731 Time: 12.69\n",
      "Epoch: 750 Train Loss: 0.0859 Val Loss: 0.2451 Acc: 0.9022 Pre: 0.8758 Recall: 0.9437 F1: 0.9085 Train AUC: 0.9965 Val AUC: 0.9715 Time: 13.14\n",
      "Epoch: 751 Train Loss: 0.0832 Val Loss: 0.2233 Acc: 0.9040 Pre: 0.8863 Recall: 0.9331 F1: 0.9091 Train AUC: 0.9977 Val AUC: 0.9740 Time: 13.20\n",
      "Epoch: 752 Train Loss: 0.0829 Val Loss: 0.2151 Acc: 0.9040 Pre: 0.9053 Recall: 0.9085 F1: 0.9069 Train AUC: 0.9970 Val AUC: 0.9754 Time: 12.75\n",
      "Epoch: 753 Train Loss: 0.0843 Val Loss: 0.2218 Acc: 0.9112 Pre: 0.9181 Recall: 0.9085 F1: 0.9133 Train AUC: 0.9964 Val AUC: 0.9750 Time: 12.43\n",
      "Epoch: 754 Train Loss: 0.0769 Val Loss: 0.2228 Acc: 0.9076 Pre: 0.9031 Recall: 0.9190 F1: 0.9110 Train AUC: 0.9971 Val AUC: 0.9744 Time: 13.02\n",
      "Epoch: 755 Train Loss: 0.0770 Val Loss: 0.2265 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9970 Val AUC: 0.9735 Time: 13.45\n",
      "Epoch: 756 Train Loss: 0.0789 Val Loss: 0.2317 Acc: 0.8895 Pre: 0.8656 Recall: 0.9296 F1: 0.8964 Train AUC: 0.9970 Val AUC: 0.9740 Time: 13.40\n",
      "Epoch: 757 Train Loss: 0.0739 Val Loss: 0.2252 Acc: 0.8986 Pre: 0.8904 Recall: 0.9155 F1: 0.9028 Train AUC: 0.9973 Val AUC: 0.9736 Time: 12.97\n",
      "Epoch: 758 Train Loss: 0.0740 Val Loss: 0.2278 Acc: 0.9076 Pre: 0.9059 Recall: 0.9155 F1: 0.9107 Train AUC: 0.9977 Val AUC: 0.9731 Time: 12.98\n",
      "Epoch: 759 Train Loss: 0.0811 Val Loss: 0.2346 Acc: 0.9004 Pre: 0.8804 Recall: 0.9331 F1: 0.9060 Train AUC: 0.9965 Val AUC: 0.9731 Time: 13.30\n",
      "Epoch: 760 Train Loss: 0.0880 Val Loss: 0.2236 Acc: 0.8931 Pre: 0.8713 Recall: 0.9296 F1: 0.8995 Train AUC: 0.9961 Val AUC: 0.9752 Time: 12.78\n",
      "Epoch: 761 Train Loss: 0.0812 Val Loss: 0.2102 Acc: 0.9185 Pre: 0.9164 Recall: 0.9261 F1: 0.9212 Train AUC: 0.9970 Val AUC: 0.9759 Time: 12.36\n",
      "Epoch: 762 Train Loss: 0.0840 Val Loss: 0.2188 Acc: 0.9112 Pre: 0.9094 Recall: 0.9190 F1: 0.9142 Train AUC: 0.9965 Val AUC: 0.9752 Time: 12.89\n",
      "Epoch: 763 Train Loss: 0.0793 Val Loss: 0.2251 Acc: 0.9040 Pre: 0.9053 Recall: 0.9085 F1: 0.9069 Train AUC: 0.9967 Val AUC: 0.9742 Time: 13.28\n",
      "Epoch: 764 Train Loss: 0.0823 Val Loss: 0.2228 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9962 Val AUC: 0.9738 Time: 13.18\n",
      "Epoch: 765 Train Loss: 0.0821 Val Loss: 0.2222 Acc: 0.9058 Pre: 0.8919 Recall: 0.9296 F1: 0.9103 Train AUC: 0.9970 Val AUC: 0.9736 Time: 13.20\n",
      "Epoch: 766 Train Loss: 0.0804 Val Loss: 0.2304 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9968 Val AUC: 0.9725 Time: 12.21\n",
      "Epoch: 767 Train Loss: 0.0846 Val Loss: 0.2325 Acc: 0.8967 Pre: 0.8771 Recall: 0.9296 F1: 0.9026 Train AUC: 0.9964 Val AUC: 0.9734 Time: 11.91\n",
      "Epoch: 768 Train Loss: 0.0800 Val Loss: 0.2260 Acc: 0.8986 Pre: 0.8826 Recall: 0.9261 F1: 0.9038 Train AUC: 0.9968 Val AUC: 0.9746 Time: 12.39\n",
      "Epoch: 769 Train Loss: 0.0825 Val Loss: 0.2254 Acc: 0.9076 Pre: 0.8976 Recall: 0.9261 F1: 0.9116 Train AUC: 0.9965 Val AUC: 0.9744 Time: 13.13\n",
      "Epoch: 770 Train Loss: 0.0768 Val Loss: 0.2236 Acc: 0.9076 Pre: 0.8976 Recall: 0.9261 F1: 0.9116 Train AUC: 0.9967 Val AUC: 0.9737 Time: 13.42\n",
      "Epoch: 771 Train Loss: 0.0776 Val Loss: 0.2251 Acc: 0.9112 Pre: 0.9038 Recall: 0.9261 F1: 0.9148 Train AUC: 0.9971 Val AUC: 0.9719 Time: 13.97\n",
      "Epoch: 772 Train Loss: 0.0744 Val Loss: 0.2281 Acc: 0.9004 Pre: 0.8855 Recall: 0.9261 F1: 0.9053 Train AUC: 0.9979 Val AUC: 0.9720 Time: 13.75\n",
      "Epoch: 773 Train Loss: 0.0971 Val Loss: 0.2399 Acc: 0.9112 Pre: 0.9010 Recall: 0.9296 F1: 0.9151 Train AUC: 0.9962 Val AUC: 0.9749 Time: 12.51\n",
      "Epoch: 774 Train Loss: 0.0835 Val Loss: 0.2534 Acc: 0.9130 Pre: 0.9069 Recall: 0.9261 F1: 0.9164 Train AUC: 0.9964 Val AUC: 0.9737 Time: 12.18\n",
      "Epoch: 775 Train Loss: 0.0961 Val Loss: 0.2532 Acc: 0.9004 Pre: 0.8779 Recall: 0.9366 F1: 0.9063 Train AUC: 0.9945 Val AUC: 0.9723 Time: 11.91\n",
      "Epoch: 776 Train Loss: 0.0917 Val Loss: 0.2644 Acc: 0.9004 Pre: 0.8779 Recall: 0.9366 F1: 0.9063 Train AUC: 0.9953 Val AUC: 0.9682 Time: 12.34\n",
      "Epoch: 777 Train Loss: 0.0948 Val Loss: 0.2454 Acc: 0.9004 Pre: 0.9018 Recall: 0.9049 F1: 0.9033 Train AUC: 0.9956 Val AUC: 0.9685 Time: 12.76\n",
      "Epoch: 778 Train Loss: 0.0887 Val Loss: 0.2298 Acc: 0.9130 Pre: 0.9338 Recall: 0.8944 F1: 0.9137 Train AUC: 0.9962 Val AUC: 0.9725 Time: 13.43\n",
      "Epoch: 779 Train Loss: 0.0863 Val Loss: 0.2312 Acc: 0.9058 Pre: 0.9085 Recall: 0.9085 F1: 0.9085 Train AUC: 0.9967 Val AUC: 0.9735 Time: 13.69\n",
      "Epoch: 780 Train Loss: 0.1004 Val Loss: 0.2582 Acc: 0.8931 Pre: 0.8664 Recall: 0.9366 F1: 0.9002 Train AUC: 0.9940 Val AUC: 0.9735 Time: 13.29\n",
      "Epoch: 781 Train Loss: 0.1003 Val Loss: 0.2441 Acc: 0.8949 Pre: 0.8645 Recall: 0.9437 F1: 0.9024 Train AUC: 0.9953 Val AUC: 0.9744 Time: 12.58\n",
      "Epoch: 782 Train Loss: 0.0939 Val Loss: 0.2257 Acc: 0.8967 Pre: 0.8874 Recall: 0.9155 F1: 0.9012 Train AUC: 0.9956 Val AUC: 0.9736 Time: 12.80\n",
      "Epoch: 783 Train Loss: 0.0872 Val Loss: 0.2394 Acc: 0.9094 Pre: 0.9149 Recall: 0.9085 F1: 0.9117 Train AUC: 0.9963 Val AUC: 0.9688 Time: 12.53\n",
      "Epoch: 784 Train Loss: 0.1039 Val Loss: 0.2404 Acc: 0.8986 Pre: 0.8750 Recall: 0.9366 F1: 0.9048 Train AUC: 0.9951 Val AUC: 0.9710 Time: 12.31\n",
      "Epoch: 785 Train Loss: 0.0846 Val Loss: 0.2332 Acc: 0.8931 Pre: 0.8664 Recall: 0.9366 F1: 0.9002 Train AUC: 0.9966 Val AUC: 0.9751 Time: 12.70\n",
      "Epoch: 786 Train Loss: 0.0830 Val Loss: 0.2350 Acc: 0.9058 Pre: 0.8867 Recall: 0.9366 F1: 0.9110 Train AUC: 0.9965 Val AUC: 0.9755 Time: 13.17\n",
      "Epoch: 787 Train Loss: 0.0896 Val Loss: 0.2257 Acc: 0.9257 Pre: 0.9293 Recall: 0.9261 F1: 0.9277 Train AUC: 0.9966 Val AUC: 0.9752 Time: 13.79\n",
      "Epoch: 788 Train Loss: 0.0830 Val Loss: 0.2245 Acc: 0.9203 Pre: 0.9286 Recall: 0.9155 F1: 0.9220 Train AUC: 0.9965 Val AUC: 0.9741 Time: 13.24\n",
      "Epoch: 789 Train Loss: 0.0841 Val Loss: 0.2308 Acc: 0.9058 Pre: 0.8973 Recall: 0.9225 F1: 0.9097 Train AUC: 0.9970 Val AUC: 0.9718 Time: 12.83\n",
      "Epoch: 790 Train Loss: 0.0792 Val Loss: 0.2611 Acc: 0.8913 Pre: 0.8613 Recall: 0.9401 F1: 0.8990 Train AUC: 0.9969 Val AUC: 0.9689 Time: 13.02\n",
      "Epoch: 791 Train Loss: 0.0919 Val Loss: 0.2218 Acc: 0.9185 Pre: 0.9135 Recall: 0.9296 F1: 0.9215 Train AUC: 0.9961 Val AUC: 0.9742 Time: 12.91\n",
      "Epoch: 792 Train Loss: 0.0725 Val Loss: 0.2224 Acc: 0.9112 Pre: 0.9211 Recall: 0.9049 F1: 0.9130 Train AUC: 0.9978 Val AUC: 0.9750 Time: 13.28\n",
      "Epoch: 793 Train Loss: 0.0864 Val Loss: 0.2247 Acc: 0.9167 Pre: 0.9220 Recall: 0.9155 F1: 0.9187 Train AUC: 0.9964 Val AUC: 0.9752 Time: 12.74\n",
      "Epoch: 794 Train Loss: 0.0869 Val Loss: 0.2338 Acc: 0.8931 Pre: 0.8713 Recall: 0.9296 F1: 0.8995 Train AUC: 0.9958 Val AUC: 0.9754 Time: 13.14\n",
      "Epoch: 795 Train Loss: 0.0790 Val Loss: 0.2383 Acc: 0.8895 Pre: 0.8656 Recall: 0.9296 F1: 0.8964 Train AUC: 0.9978 Val AUC: 0.9744 Time: 12.75\n",
      "Epoch: 796 Train Loss: 0.0720 Val Loss: 0.2290 Acc: 0.8986 Pre: 0.8851 Recall: 0.9225 F1: 0.9034 Train AUC: 0.9975 Val AUC: 0.9736 Time: 13.27\n",
      "Epoch: 797 Train Loss: 0.0805 Val Loss: 0.2239 Acc: 0.9149 Pre: 0.9129 Recall: 0.9225 F1: 0.9177 Train AUC: 0.9968 Val AUC: 0.9740 Time: 13.41\n",
      "Epoch: 798 Train Loss: 0.0755 Val Loss: 0.2253 Acc: 0.9076 Pre: 0.8949 Recall: 0.9296 F1: 0.9119 Train AUC: 0.9975 Val AUC: 0.9741 Time: 13.14\n",
      "Epoch: 799 Train Loss: 0.0824 Val Loss: 0.2329 Acc: 0.9004 Pre: 0.8829 Recall: 0.9296 F1: 0.9057 Train AUC: 0.9963 Val AUC: 0.9732 Time: 12.75\n",
      "Epoch: 800 Train Loss: 0.0790 Val Loss: 0.2304 Acc: 0.9040 Pre: 0.8915 Recall: 0.9261 F1: 0.9085 Train AUC: 0.9970 Val AUC: 0.9729 Time: 11.82\n",
      "Epoch: 801 Train Loss: 0.0774 Val Loss: 0.2281 Acc: 0.9076 Pre: 0.8976 Recall: 0.9261 F1: 0.9116 Train AUC: 0.9974 Val AUC: 0.9749 Time: 12.09\n",
      "Epoch: 802 Train Loss: 0.0681 Val Loss: 0.2307 Acc: 0.9094 Pre: 0.9034 Recall: 0.9225 F1: 0.9129 Train AUC: 0.9979 Val AUC: 0.9749 Time: 12.64\n",
      "Epoch: 803 Train Loss: 0.0774 Val Loss: 0.2333 Acc: 0.9004 Pre: 0.8829 Recall: 0.9296 F1: 0.9057 Train AUC: 0.9967 Val AUC: 0.9741 Time: 13.01\n",
      "Epoch: 804 Train Loss: 0.0667 Val Loss: 0.2380 Acc: 0.8949 Pre: 0.8742 Recall: 0.9296 F1: 0.9010 Train AUC: 0.9981 Val AUC: 0.9728 Time: 13.69\n",
      "Epoch: 805 Train Loss: 0.0759 Val Loss: 0.2406 Acc: 0.8895 Pre: 0.8656 Recall: 0.9296 F1: 0.8964 Train AUC: 0.9977 Val AUC: 0.9723 Time: 14.42\n",
      "Epoch: 806 Train Loss: 0.0752 Val Loss: 0.2310 Acc: 0.8967 Pre: 0.8771 Recall: 0.9296 F1: 0.9026 Train AUC: 0.9976 Val AUC: 0.9731 Time: 13.28\n",
      "Epoch: 807 Train Loss: 0.0682 Val Loss: 0.2286 Acc: 0.9112 Pre: 0.9038 Recall: 0.9261 F1: 0.9148 Train AUC: 0.9985 Val AUC: 0.9738 Time: 12.23\n",
      "Epoch: 808 Train Loss: 0.0747 Val Loss: 0.2319 Acc: 0.9076 Pre: 0.9059 Recall: 0.9155 F1: 0.9107 Train AUC: 0.9972 Val AUC: 0.9741 Time: 11.96\n",
      "Epoch: 809 Train Loss: 0.0706 Val Loss: 0.2377 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9978 Val AUC: 0.9736 Time: 12.27\n",
      "Epoch: 810 Train Loss: 0.0707 Val Loss: 0.2520 Acc: 0.8986 Pre: 0.8750 Recall: 0.9366 F1: 0.9048 Train AUC: 0.9977 Val AUC: 0.9726 Time: 12.58\n",
      "Epoch: 811 Train Loss: 0.0802 Val Loss: 0.2444 Acc: 0.8913 Pre: 0.8733 Recall: 0.9225 F1: 0.8973 Train AUC: 0.9971 Val AUC: 0.9728 Time: 13.20\n",
      "Epoch: 812 Train Loss: 0.0872 Val Loss: 0.2319 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9956 Val AUC: 0.9738 Time: 13.52\n",
      "Epoch: 813 Train Loss: 0.0805 Val Loss: 0.2259 Acc: 0.9185 Pre: 0.9135 Recall: 0.9296 F1: 0.9215 Train AUC: 0.9966 Val AUC: 0.9730 Time: 14.00\n",
      "Epoch: 814 Train Loss: 0.0836 Val Loss: 0.2267 Acc: 0.9004 Pre: 0.8829 Recall: 0.9296 F1: 0.9057 Train AUC: 0.9972 Val AUC: 0.9741 Time: 13.55\n",
      "Epoch: 815 Train Loss: 0.0740 Val Loss: 0.2266 Acc: 0.8986 Pre: 0.8800 Recall: 0.9296 F1: 0.9041 Train AUC: 0.9976 Val AUC: 0.9751 Time: 12.83\n",
      "Epoch: 816 Train Loss: 0.0715 Val Loss: 0.2276 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9976 Val AUC: 0.9751 Time: 12.42\n",
      "Epoch: 817 Train Loss: 0.0754 Val Loss: 0.2303 Acc: 0.9004 Pre: 0.8829 Recall: 0.9296 F1: 0.9057 Train AUC: 0.9972 Val AUC: 0.9733 Time: 12.62\n",
      "Epoch: 818 Train Loss: 0.0782 Val Loss: 0.2491 Acc: 0.9004 Pre: 0.8779 Recall: 0.9366 F1: 0.9063 Train AUC: 0.9970 Val AUC: 0.9692 Time: 12.01\n",
      "Epoch: 819 Train Loss: 0.0873 Val Loss: 0.2349 Acc: 0.9022 Pre: 0.8833 Recall: 0.9331 F1: 0.9075 Train AUC: 0.9966 Val AUC: 0.9729 Time: 12.55\n",
      "Epoch: 820 Train Loss: 0.0754 Val Loss: 0.2305 Acc: 0.9130 Pre: 0.9041 Recall: 0.9296 F1: 0.9167 Train AUC: 0.9969 Val AUC: 0.9748 Time: 13.02\n",
      "Epoch: 821 Train Loss: 0.0696 Val Loss: 0.2335 Acc: 0.9130 Pre: 0.9041 Recall: 0.9296 F1: 0.9167 Train AUC: 0.9978 Val AUC: 0.9754 Time: 13.28\n",
      "Epoch: 822 Train Loss: 0.0799 Val Loss: 0.2418 Acc: 0.9022 Pre: 0.8808 Recall: 0.9366 F1: 0.9078 Train AUC: 0.9965 Val AUC: 0.9747 Time: 13.94\n",
      "Epoch: 823 Train Loss: 0.0813 Val Loss: 0.2392 Acc: 0.9040 Pre: 0.8787 Recall: 0.9437 F1: 0.9100 Train AUC: 0.9968 Val AUC: 0.9736 Time: 14.37\n",
      "Epoch: 824 Train Loss: 0.0737 Val Loss: 0.2288 Acc: 0.8986 Pre: 0.8800 Recall: 0.9296 F1: 0.9041 Train AUC: 0.9977 Val AUC: 0.9727 Time: 13.16\n",
      "Epoch: 825 Train Loss: 0.0768 Val Loss: 0.2229 Acc: 0.9130 Pre: 0.9155 Recall: 0.9155 F1: 0.9155 Train AUC: 0.9977 Val AUC: 0.9733 Time: 12.20\n",
      "Epoch: 826 Train Loss: 0.0787 Val Loss: 0.2176 Acc: 0.9130 Pre: 0.9069 Recall: 0.9261 F1: 0.9164 Train AUC: 0.9975 Val AUC: 0.9752 Time: 11.79\n",
      "Epoch: 827 Train Loss: 0.0735 Val Loss: 0.2257 Acc: 0.9022 Pre: 0.8912 Recall: 0.9225 F1: 0.9066 Train AUC: 0.9981 Val AUC: 0.9752 Time: 11.68\n",
      "Epoch: 828 Train Loss: 0.0796 Val Loss: 0.2303 Acc: 0.9112 Pre: 0.9038 Recall: 0.9261 F1: 0.9148 Train AUC: 0.9969 Val AUC: 0.9756 Time: 12.28\n",
      "Epoch: 829 Train Loss: 0.0914 Val Loss: 0.2258 Acc: 0.9058 Pre: 0.8919 Recall: 0.9296 F1: 0.9103 Train AUC: 0.9955 Val AUC: 0.9756 Time: 12.68\n",
      "Epoch: 830 Train Loss: 0.0666 Val Loss: 0.2290 Acc: 0.9094 Pre: 0.8980 Recall: 0.9296 F1: 0.9135 Train AUC: 0.9981 Val AUC: 0.9733 Time: 13.14\n",
      "Epoch: 831 Train Loss: 0.0902 Val Loss: 0.2290 Acc: 0.9167 Pre: 0.9161 Recall: 0.9225 F1: 0.9193 Train AUC: 0.9958 Val AUC: 0.9723 Time: 13.74\n",
      "Epoch: 832 Train Loss: 0.0826 Val Loss: 0.2303 Acc: 0.9076 Pre: 0.9003 Recall: 0.9225 F1: 0.9113 Train AUC: 0.9975 Val AUC: 0.9732 Time: 14.18\n",
      "Epoch: 833 Train Loss: 0.0783 Val Loss: 0.2359 Acc: 0.8931 Pre: 0.8738 Recall: 0.9261 F1: 0.8991 Train AUC: 0.9970 Val AUC: 0.9732 Time: 13.65\n",
      "Epoch: 834 Train Loss: 0.0722 Val Loss: 0.2310 Acc: 0.8967 Pre: 0.8771 Recall: 0.9296 F1: 0.9026 Train AUC: 0.9975 Val AUC: 0.9740 Time: 12.57\n",
      "Epoch: 835 Train Loss: 0.0745 Val Loss: 0.2242 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9975 Val AUC: 0.9743 Time: 11.73\n",
      "Epoch: 836 Train Loss: 0.0726 Val Loss: 0.2255 Acc: 0.9112 Pre: 0.9152 Recall: 0.9120 F1: 0.9136 Train AUC: 0.9977 Val AUC: 0.9731 Time: 11.53\n",
      "Epoch: 837 Train Loss: 0.0887 Val Loss: 0.2223 Acc: 0.9203 Pre: 0.9225 Recall: 0.9225 F1: 0.9225 Train AUC: 0.9960 Val AUC: 0.9751 Time: 11.95\n",
      "Epoch: 838 Train Loss: 0.0833 Val Loss: 0.2346 Acc: 0.9130 Pre: 0.8882 Recall: 0.9507 F1: 0.9184 Train AUC: 0.9962 Val AUC: 0.9754 Time: 12.68\n",
      "Epoch: 839 Train Loss: 0.0765 Val Loss: 0.2389 Acc: 0.9040 Pre: 0.8738 Recall: 0.9507 F1: 0.9106 Train AUC: 0.9973 Val AUC: 0.9752 Time: 12.97\n",
      "Epoch: 840 Train Loss: 0.0877 Val Loss: 0.2208 Acc: 0.9185 Pre: 0.9164 Recall: 0.9261 F1: 0.9212 Train AUC: 0.9960 Val AUC: 0.9760 Time: 13.52\n",
      "Epoch: 841 Train Loss: 0.0724 Val Loss: 0.2245 Acc: 0.9167 Pre: 0.9312 Recall: 0.9049 F1: 0.9179 Train AUC: 0.9975 Val AUC: 0.9752 Time: 14.29\n",
      "Epoch: 842 Train Loss: 0.0890 Val Loss: 0.2211 Acc: 0.9112 Pre: 0.9010 Recall: 0.9296 F1: 0.9151 Train AUC: 0.9965 Val AUC: 0.9729 Time: 14.16\n",
      "Epoch: 843 Train Loss: 0.0794 Val Loss: 0.2420 Acc: 0.8986 Pre: 0.8701 Recall: 0.9437 F1: 0.9054 Train AUC: 0.9973 Val AUC: 0.9745 Time: 12.86\n",
      "Epoch: 844 Train Loss: 0.0871 Val Loss: 0.2398 Acc: 0.9167 Pre: 0.9048 Recall: 0.9366 F1: 0.9204 Train AUC: 0.9969 Val AUC: 0.9742 Time: 12.00\n",
      "Epoch: 845 Train Loss: 0.0754 Val Loss: 0.2450 Acc: 0.9167 Pre: 0.9250 Recall: 0.9120 F1: 0.9184 Train AUC: 0.9969 Val AUC: 0.9743 Time: 12.04\n",
      "Epoch: 846 Train Loss: 0.0934 Val Loss: 0.2316 Acc: 0.9130 Pre: 0.9097 Recall: 0.9225 F1: 0.9161 Train AUC: 0.9948 Val AUC: 0.9748 Time: 12.38\n",
      "Epoch: 847 Train Loss: 0.0652 Val Loss: 0.2343 Acc: 0.9058 Pre: 0.8919 Recall: 0.9296 F1: 0.9103 Train AUC: 0.9980 Val AUC: 0.9710 Time: 13.16\n",
      "Epoch: 848 Train Loss: 0.0762 Val Loss: 0.2497 Acc: 0.8986 Pre: 0.8750 Recall: 0.9366 F1: 0.9048 Train AUC: 0.9971 Val AUC: 0.9682 Time: 13.91\n",
      "Epoch: 849 Train Loss: 0.0768 Val Loss: 0.2280 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9981 Val AUC: 0.9730 Time: 14.51\n",
      "Epoch: 850 Train Loss: 0.0719 Val Loss: 0.2402 Acc: 0.9203 Pre: 0.9225 Recall: 0.9225 F1: 0.9225 Train AUC: 0.9981 Val AUC: 0.9745 Time: 13.54\n",
      "Epoch: 851 Train Loss: 0.0755 Val Loss: 0.2469 Acc: 0.9130 Pre: 0.9126 Recall: 0.9190 F1: 0.9158 Train AUC: 0.9968 Val AUC: 0.9740 Time: 12.47\n",
      "Epoch: 852 Train Loss: 0.0763 Val Loss: 0.2466 Acc: 0.8986 Pre: 0.8800 Recall: 0.9296 F1: 0.9041 Train AUC: 0.9969 Val AUC: 0.9736 Time: 12.01\n",
      "Epoch: 853 Train Loss: 0.0730 Val Loss: 0.2584 Acc: 0.8895 Pre: 0.8585 Recall: 0.9401 F1: 0.8975 Train AUC: 0.9978 Val AUC: 0.9706 Time: 12.59\n",
      "Epoch: 854 Train Loss: 0.0883 Val Loss: 0.2339 Acc: 0.9112 Pre: 0.9038 Recall: 0.9261 F1: 0.9148 Train AUC: 0.9963 Val AUC: 0.9717 Time: 13.24\n",
      "Epoch: 855 Train Loss: 0.0755 Val Loss: 0.2241 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9975 Val AUC: 0.9745 Time: 15.30\n",
      "Epoch: 856 Train Loss: 0.0753 Val Loss: 0.2272 Acc: 0.9058 Pre: 0.8946 Recall: 0.9261 F1: 0.9100 Train AUC: 0.9973 Val AUC: 0.9749 Time: 15.98\n",
      "Epoch: 857 Train Loss: 0.0844 Val Loss: 0.2250 Acc: 0.9094 Pre: 0.8926 Recall: 0.9366 F1: 0.9141 Train AUC: 0.9966 Val AUC: 0.9753 Time: 13.01\n",
      "Epoch: 858 Train Loss: 0.0702 Val Loss: 0.2207 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9979 Val AUC: 0.9750 Time: 12.62\n",
      "Epoch: 859 Train Loss: 0.0698 Val Loss: 0.2235 Acc: 0.9149 Pre: 0.9100 Recall: 0.9261 F1: 0.9180 Train AUC: 0.9980 Val AUC: 0.9737 Time: 13.79\n",
      "Epoch: 860 Train Loss: 0.0791 Val Loss: 0.2278 Acc: 0.9094 Pre: 0.9007 Recall: 0.9261 F1: 0.9132 Train AUC: 0.9972 Val AUC: 0.9739 Time: 12.86\n",
      "Epoch: 861 Train Loss: 0.0717 Val Loss: 0.2380 Acc: 0.9022 Pre: 0.8758 Recall: 0.9437 F1: 0.9085 Train AUC: 0.9976 Val AUC: 0.9744 Time: 13.82\n",
      "Epoch: 862 Train Loss: 0.0753 Val Loss: 0.2315 Acc: 0.9040 Pre: 0.8837 Recall: 0.9366 F1: 0.9094 Train AUC: 0.9976 Val AUC: 0.9745 Time: 15.08\n",
      "Epoch: 863 Train Loss: 0.0753 Val Loss: 0.2211 Acc: 0.9076 Pre: 0.9059 Recall: 0.9155 F1: 0.9107 Train AUC: 0.9975 Val AUC: 0.9733 Time: 14.37\n",
      "Epoch: 864 Train Loss: 0.0889 Val Loss: 0.2206 Acc: 0.9040 Pre: 0.8942 Recall: 0.9225 F1: 0.9081 Train AUC: 0.9963 Val AUC: 0.9731 Time: 13.82\n",
      "Epoch: 865 Train Loss: 0.0757 Val Loss: 0.2304 Acc: 0.8931 Pre: 0.8713 Recall: 0.9296 F1: 0.8995 Train AUC: 0.9976 Val AUC: 0.9747 Time: 13.69\n",
      "Epoch: 866 Train Loss: 0.0646 Val Loss: 0.2325 Acc: 0.8986 Pre: 0.8750 Recall: 0.9366 F1: 0.9048 Train AUC: 0.9985 Val AUC: 0.9757 Time: 13.12\n",
      "Epoch: 867 Train Loss: 0.0778 Val Loss: 0.2309 Acc: 0.9076 Pre: 0.8923 Recall: 0.9331 F1: 0.9122 Train AUC: 0.9969 Val AUC: 0.9756 Time: 13.58\n",
      "Epoch: 868 Train Loss: 0.0772 Val Loss: 0.2240 Acc: 0.9112 Pre: 0.9066 Recall: 0.9225 F1: 0.9145 Train AUC: 0.9968 Val AUC: 0.9762 Time: 14.01\n",
      "Epoch: 869 Train Loss: 0.0744 Val Loss: 0.2183 Acc: 0.9130 Pre: 0.9041 Recall: 0.9296 F1: 0.9167 Train AUC: 0.9970 Val AUC: 0.9748 Time: 15.21\n",
      "Epoch: 870 Train Loss: 0.0826 Val Loss: 0.2278 Acc: 0.9130 Pre: 0.9014 Recall: 0.9331 F1: 0.9170 Train AUC: 0.9969 Val AUC: 0.9712 Time: 16.99\n",
      "Epoch: 871 Train Loss: 0.0752 Val Loss: 0.2305 Acc: 0.8986 Pre: 0.8800 Recall: 0.9296 F1: 0.9041 Train AUC: 0.9979 Val AUC: 0.9730 Time: 15.46\n",
      "Epoch: 872 Train Loss: 0.0646 Val Loss: 0.2400 Acc: 0.9004 Pre: 0.8754 Recall: 0.9401 F1: 0.9066 Train AUC: 0.9987 Val AUC: 0.9739 Time: 13.41\n",
      "Epoch: 873 Train Loss: 0.0657 Val Loss: 0.2443 Acc: 0.9094 Pre: 0.8953 Recall: 0.9331 F1: 0.9138 Train AUC: 0.9983 Val AUC: 0.9738 Time: 13.03\n",
      "Epoch: 874 Train Loss: 0.0775 Val Loss: 0.2348 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9967 Val AUC: 0.9745 Time: 13.92\n",
      "Epoch: 875 Train Loss: 0.0819 Val Loss: 0.2221 Acc: 0.9094 Pre: 0.8980 Recall: 0.9296 F1: 0.9135 Train AUC: 0.9964 Val AUC: 0.9750 Time: 13.54\n",
      "Epoch: 876 Train Loss: 0.0695 Val Loss: 0.2283 Acc: 0.9004 Pre: 0.8804 Recall: 0.9331 F1: 0.9060 Train AUC: 0.9980 Val AUC: 0.9728 Time: 14.53\n",
      "Epoch: 877 Train Loss: 0.0787 Val Loss: 0.2243 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9973 Val AUC: 0.9745 Time: 15.48\n",
      "Epoch: 878 Train Loss: 0.0723 Val Loss: 0.2226 Acc: 0.9167 Pre: 0.9103 Recall: 0.9296 F1: 0.9199 Train AUC: 0.9980 Val AUC: 0.9754 Time: 16.53\n",
      "Epoch: 879 Train Loss: 0.0761 Val Loss: 0.2265 Acc: 0.9094 Pre: 0.8980 Recall: 0.9296 F1: 0.9135 Train AUC: 0.9972 Val AUC: 0.9751 Time: 15.02\n",
      "Epoch: 880 Train Loss: 0.0703 Val Loss: 0.2349 Acc: 0.9004 Pre: 0.8804 Recall: 0.9331 F1: 0.9060 Train AUC: 0.9980 Val AUC: 0.9746 Time: 14.06\n",
      "Epoch: 881 Train Loss: 0.0874 Val Loss: 0.2267 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9956 Val AUC: 0.9752 Time: 15.30\n",
      "Epoch: 882 Train Loss: 0.0641 Val Loss: 0.2217 Acc: 0.9112 Pre: 0.9010 Recall: 0.9296 F1: 0.9151 Train AUC: 0.9981 Val AUC: 0.9747 Time: 12.34\n",
      "Epoch: 883 Train Loss: 0.0718 Val Loss: 0.2238 Acc: 0.9112 Pre: 0.9038 Recall: 0.9261 F1: 0.9148 Train AUC: 0.9980 Val AUC: 0.9745 Time: 12.74\n",
      "Epoch: 884 Train Loss: 0.0763 Val Loss: 0.2268 Acc: 0.9094 Pre: 0.9007 Recall: 0.9261 F1: 0.9132 Train AUC: 0.9972 Val AUC: 0.9742 Time: 13.25\n",
      "Epoch: 885 Train Loss: 0.0830 Val Loss: 0.2394 Acc: 0.8967 Pre: 0.8721 Recall: 0.9366 F1: 0.9032 Train AUC: 0.9960 Val AUC: 0.9723 Time: 13.76\n",
      "Epoch: 886 Train Loss: 0.0750 Val Loss: 0.2358 Acc: 0.9076 Pre: 0.8949 Recall: 0.9296 F1: 0.9119 Train AUC: 0.9976 Val AUC: 0.9715 Time: 14.12\n",
      "Epoch: 887 Train Loss: 0.0819 Val Loss: 0.2290 Acc: 0.9112 Pre: 0.9123 Recall: 0.9155 F1: 0.9139 Train AUC: 0.9965 Val AUC: 0.9725 Time: 12.85\n",
      "Epoch: 888 Train Loss: 0.0837 Val Loss: 0.2244 Acc: 0.9167 Pre: 0.9103 Recall: 0.9296 F1: 0.9199 Train AUC: 0.9967 Val AUC: 0.9731 Time: 12.00\n",
      "Epoch: 889 Train Loss: 0.0908 Val Loss: 0.2359 Acc: 0.9058 Pre: 0.8919 Recall: 0.9296 F1: 0.9103 Train AUC: 0.9967 Val AUC: 0.9749 Time: 12.47\n",
      "Epoch: 890 Train Loss: 0.0817 Val Loss: 0.2456 Acc: 0.9112 Pre: 0.8904 Recall: 0.9437 F1: 0.9162 Train AUC: 0.9970 Val AUC: 0.9750 Time: 14.32\n",
      "Epoch: 891 Train Loss: 0.0971 Val Loss: 0.2386 Acc: 0.9058 Pre: 0.8893 Recall: 0.9331 F1: 0.9107 Train AUC: 0.9955 Val AUC: 0.9742 Time: 15.64\n",
      "Epoch: 892 Train Loss: 0.0781 Val Loss: 0.2473 Acc: 0.8986 Pre: 0.8800 Recall: 0.9296 F1: 0.9041 Train AUC: 0.9969 Val AUC: 0.9701 Time: 14.63\n",
      "Epoch: 893 Train Loss: 0.0736 Val Loss: 0.2512 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9977 Val AUC: 0.9670 Time: 13.79\n",
      "Epoch: 894 Train Loss: 0.0889 Val Loss: 0.2416 Acc: 0.9130 Pre: 0.9069 Recall: 0.9261 F1: 0.9164 Train AUC: 0.9963 Val AUC: 0.9699 Time: 12.74\n",
      "Epoch: 895 Train Loss: 0.0811 Val Loss: 0.2384 Acc: 0.9167 Pre: 0.9048 Recall: 0.9366 F1: 0.9204 Train AUC: 0.9971 Val AUC: 0.9719 Time: 13.05\n",
      "Epoch: 896 Train Loss: 0.0842 Val Loss: 0.2337 Acc: 0.9167 Pre: 0.9048 Recall: 0.9366 F1: 0.9204 Train AUC: 0.9961 Val AUC: 0.9742 Time: 13.11\n",
      "Epoch: 897 Train Loss: 0.0752 Val Loss: 0.2387 Acc: 0.9130 Pre: 0.8960 Recall: 0.9401 F1: 0.9175 Train AUC: 0.9978 Val AUC: 0.9751 Time: 13.75\n",
      "Epoch: 898 Train Loss: 0.0832 Val Loss: 0.2347 Acc: 0.9112 Pre: 0.8956 Recall: 0.9366 F1: 0.9157 Train AUC: 0.9966 Val AUC: 0.9753 Time: 15.95\n",
      "Epoch: 899 Train Loss: 0.0875 Val Loss: 0.2246 Acc: 0.9076 Pre: 0.9003 Recall: 0.9225 F1: 0.9113 Train AUC: 0.9965 Val AUC: 0.9749 Time: 14.48\n",
      "Epoch: 900 Train Loss: 0.0795 Val Loss: 0.2259 Acc: 0.9112 Pre: 0.9123 Recall: 0.9155 F1: 0.9139 Train AUC: 0.9963 Val AUC: 0.9731 Time: 13.26\n",
      "Epoch: 901 Train Loss: 0.0755 Val Loss: 0.2300 Acc: 0.9004 Pre: 0.8855 Recall: 0.9261 F1: 0.9053 Train AUC: 0.9974 Val AUC: 0.9728 Time: 13.01\n",
      "Epoch: 902 Train Loss: 0.0881 Val Loss: 0.2407 Acc: 0.9022 Pre: 0.8758 Recall: 0.9437 F1: 0.9085 Train AUC: 0.9959 Val AUC: 0.9721 Time: 12.70\n",
      "Epoch: 903 Train Loss: 0.0839 Val Loss: 0.2343 Acc: 0.9167 Pre: 0.9048 Recall: 0.9366 F1: 0.9204 Train AUC: 0.9970 Val AUC: 0.9727 Time: 13.10\n",
      "Epoch: 904 Train Loss: 0.0784 Val Loss: 0.2392 Acc: 0.9130 Pre: 0.9184 Recall: 0.9120 F1: 0.9152 Train AUC: 0.9971 Val AUC: 0.9732 Time: 13.93\n",
      "Epoch: 905 Train Loss: 0.0722 Val Loss: 0.2368 Acc: 0.9040 Pre: 0.8997 Recall: 0.9155 F1: 0.9075 Train AUC: 0.9976 Val AUC: 0.9736 Time: 16.30\n",
      "Epoch: 906 Train Loss: 0.0794 Val Loss: 0.2404 Acc: 0.9076 Pre: 0.8923 Recall: 0.9331 F1: 0.9122 Train AUC: 0.9968 Val AUC: 0.9729 Time: 15.50\n",
      "Epoch: 907 Train Loss: 0.0808 Val Loss: 0.2554 Acc: 0.8986 Pre: 0.8701 Recall: 0.9437 F1: 0.9054 Train AUC: 0.9969 Val AUC: 0.9735 Time: 12.49\n",
      "Epoch: 908 Train Loss: 0.0738 Val Loss: 0.2442 Acc: 0.8967 Pre: 0.8771 Recall: 0.9296 F1: 0.9026 Train AUC: 0.9979 Val AUC: 0.9730 Time: 12.45\n",
      "Epoch: 909 Train Loss: 0.0747 Val Loss: 0.2392 Acc: 0.9149 Pre: 0.9247 Recall: 0.9085 F1: 0.9165 Train AUC: 0.9974 Val AUC: 0.9741 Time: 15.07\n",
      "Epoch: 910 Train Loss: 0.0837 Val Loss: 0.2372 Acc: 0.9275 Pre: 0.9236 Recall: 0.9366 F1: 0.9301 Train AUC: 0.9965 Val AUC: 0.9741 Time: 13.41\n",
      "Epoch: 911 Train Loss: 0.0746 Val Loss: 0.2358 Acc: 0.9149 Pre: 0.9017 Recall: 0.9366 F1: 0.9188 Train AUC: 0.9972 Val AUC: 0.9733 Time: 15.57\n",
      "Epoch: 912 Train Loss: 0.0868 Val Loss: 0.2327 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9962 Val AUC: 0.9711 Time: 13.76\n",
      "Epoch: 913 Train Loss: 0.0803 Val Loss: 0.2300 Acc: 0.9130 Pre: 0.9041 Recall: 0.9296 F1: 0.9167 Train AUC: 0.9969 Val AUC: 0.9708 Time: 14.08\n",
      "Epoch: 914 Train Loss: 0.0707 Val Loss: 0.2365 Acc: 0.9058 Pre: 0.8946 Recall: 0.9261 F1: 0.9100 Train AUC: 0.9979 Val AUC: 0.9713 Time: 13.98\n",
      "Epoch: 915 Train Loss: 0.0766 Val Loss: 0.2381 Acc: 0.8967 Pre: 0.8874 Recall: 0.9155 F1: 0.9012 Train AUC: 0.9972 Val AUC: 0.9729 Time: 13.62\n",
      "Epoch: 916 Train Loss: 0.0840 Val Loss: 0.2552 Acc: 0.8913 Pre: 0.8636 Recall: 0.9366 F1: 0.8986 Train AUC: 0.9958 Val AUC: 0.9723 Time: 13.09\n",
      "Epoch: 917 Train Loss: 0.0746 Val Loss: 0.2459 Acc: 0.9022 Pre: 0.8808 Recall: 0.9366 F1: 0.9078 Train AUC: 0.9975 Val AUC: 0.9742 Time: 13.54\n",
      "Epoch: 918 Train Loss: 0.0794 Val Loss: 0.2289 Acc: 0.9167 Pre: 0.9103 Recall: 0.9296 F1: 0.9199 Train AUC: 0.9965 Val AUC: 0.9746 Time: 14.17\n",
      "Epoch: 919 Train Loss: 0.0720 Val Loss: 0.2245 Acc: 0.9167 Pre: 0.9161 Recall: 0.9225 F1: 0.9193 Train AUC: 0.9974 Val AUC: 0.9738 Time: 13.53\n",
      "Epoch: 920 Train Loss: 0.0725 Val Loss: 0.2195 Acc: 0.9221 Pre: 0.9199 Recall: 0.9296 F1: 0.9247 Train AUC: 0.9977 Val AUC: 0.9736 Time: 12.70\n",
      "Epoch: 921 Train Loss: 0.0702 Val Loss: 0.2263 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9982 Val AUC: 0.9758 Time: 13.53\n",
      "Epoch: 922 Train Loss: 0.0729 Val Loss: 0.2404 Acc: 0.9004 Pre: 0.8730 Recall: 0.9437 F1: 0.9069 Train AUC: 0.9978 Val AUC: 0.9753 Time: 13.36\n",
      "Epoch: 923 Train Loss: 0.0802 Val Loss: 0.2292 Acc: 0.9094 Pre: 0.9007 Recall: 0.9261 F1: 0.9132 Train AUC: 0.9969 Val AUC: 0.9754 Time: 13.23\n",
      "Epoch: 924 Train Loss: 0.0701 Val Loss: 0.2256 Acc: 0.9130 Pre: 0.9069 Recall: 0.9261 F1: 0.9164 Train AUC: 0.9976 Val AUC: 0.9740 Time: 13.70\n",
      "Epoch: 925 Train Loss: 0.0783 Val Loss: 0.2210 Acc: 0.9257 Pre: 0.9263 Recall: 0.9296 F1: 0.9279 Train AUC: 0.9969 Val AUC: 0.9737 Time: 13.37\n",
      "Epoch: 926 Train Loss: 0.0846 Val Loss: 0.2356 Acc: 0.8986 Pre: 0.8750 Recall: 0.9366 F1: 0.9048 Train AUC: 0.9967 Val AUC: 0.9739 Time: 12.90\n",
      "Epoch: 927 Train Loss: 0.0818 Val Loss: 0.2326 Acc: 0.9130 Pre: 0.8986 Recall: 0.9366 F1: 0.9172 Train AUC: 0.9969 Val AUC: 0.9731 Time: 13.62\n",
      "Epoch: 928 Train Loss: 0.0807 Val Loss: 0.2248 Acc: 0.9185 Pre: 0.9135 Recall: 0.9296 F1: 0.9215 Train AUC: 0.9964 Val AUC: 0.9748 Time: 14.22\n",
      "Epoch: 929 Train Loss: 0.0676 Val Loss: 0.2244 Acc: 0.9130 Pre: 0.9041 Recall: 0.9296 F1: 0.9167 Train AUC: 0.9983 Val AUC: 0.9748 Time: 13.26\n",
      "Epoch: 930 Train Loss: 0.0689 Val Loss: 0.2378 Acc: 0.9004 Pre: 0.8779 Recall: 0.9366 F1: 0.9063 Train AUC: 0.9975 Val AUC: 0.9727 Time: 12.97\n",
      "Epoch: 931 Train Loss: 0.0772 Val Loss: 0.2503 Acc: 0.8949 Pre: 0.8693 Recall: 0.9366 F1: 0.9017 Train AUC: 0.9971 Val AUC: 0.9714 Time: 13.68\n",
      "Epoch: 932 Train Loss: 0.0819 Val Loss: 0.2322 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9967 Val AUC: 0.9742 Time: 13.21\n",
      "Epoch: 933 Train Loss: 0.0714 Val Loss: 0.2385 Acc: 0.9203 Pre: 0.9196 Recall: 0.9261 F1: 0.9228 Train AUC: 0.9979 Val AUC: 0.9754 Time: 13.69\n",
      "Epoch: 934 Train Loss: 0.0830 Val Loss: 0.2367 Acc: 0.9257 Pre: 0.9204 Recall: 0.9366 F1: 0.9284 Train AUC: 0.9963 Val AUC: 0.9761 Time: 14.71\n",
      "Epoch: 935 Train Loss: 0.0774 Val Loss: 0.2232 Acc: 0.9130 Pre: 0.9041 Recall: 0.9296 F1: 0.9167 Train AUC: 0.9969 Val AUC: 0.9751 Time: 14.40\n",
      "Epoch: 936 Train Loss: 0.0722 Val Loss: 0.2227 Acc: 0.9130 Pre: 0.9041 Recall: 0.9296 F1: 0.9167 Train AUC: 0.9975 Val AUC: 0.9722 Time: 13.30\n",
      "Epoch: 937 Train Loss: 0.0867 Val Loss: 0.2175 Acc: 0.9239 Pre: 0.9231 Recall: 0.9296 F1: 0.9263 Train AUC: 0.9975 Val AUC: 0.9744 Time: 12.87\n",
      "Epoch: 938 Train Loss: 0.0816 Val Loss: 0.2272 Acc: 0.9203 Pre: 0.9225 Recall: 0.9225 F1: 0.9225 Train AUC: 0.9975 Val AUC: 0.9754 Time: 13.25\n",
      "Epoch: 939 Train Loss: 0.0786 Val Loss: 0.2406 Acc: 0.9004 Pre: 0.8779 Recall: 0.9366 F1: 0.9063 Train AUC: 0.9968 Val AUC: 0.9742 Time: 13.33\n",
      "Epoch: 940 Train Loss: 0.0839 Val Loss: 0.2640 Acc: 0.9022 Pre: 0.8710 Recall: 0.9507 F1: 0.9091 Train AUC: 0.9960 Val AUC: 0.9717 Time: 14.30\n",
      "Epoch: 941 Train Loss: 0.0852 Val Loss: 0.2330 Acc: 0.9112 Pre: 0.9038 Recall: 0.9261 F1: 0.9148 Train AUC: 0.9965 Val AUC: 0.9731 Time: 13.64\n",
      "Epoch: 942 Train Loss: 0.0775 Val Loss: 0.2272 Acc: 0.9293 Pre: 0.9329 Recall: 0.9296 F1: 0.9312 Train AUC: 0.9971 Val AUC: 0.9735 Time: 12.80\n",
      "Epoch: 943 Train Loss: 0.0797 Val Loss: 0.2269 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9970 Val AUC: 0.9732 Time: 12.89\n",
      "Epoch: 944 Train Loss: 0.0722 Val Loss: 0.2346 Acc: 0.8913 Pre: 0.8684 Recall: 0.9296 F1: 0.8980 Train AUC: 0.9976 Val AUC: 0.9722 Time: 13.52\n",
      "Epoch: 945 Train Loss: 0.0814 Val Loss: 0.2255 Acc: 0.9076 Pre: 0.8949 Recall: 0.9296 F1: 0.9119 Train AUC: 0.9972 Val AUC: 0.9744 Time: 13.69\n",
      "Epoch: 946 Train Loss: 0.0691 Val Loss: 0.2231 Acc: 0.9040 Pre: 0.9081 Recall: 0.9049 F1: 0.9065 Train AUC: 0.9984 Val AUC: 0.9748 Time: 14.42\n",
      "Epoch: 947 Train Loss: 0.0789 Val Loss: 0.2238 Acc: 0.9112 Pre: 0.9038 Recall: 0.9261 F1: 0.9148 Train AUC: 0.9976 Val AUC: 0.9750 Time: 14.38\n",
      "Epoch: 948 Train Loss: 0.0867 Val Loss: 0.2380 Acc: 0.9022 Pre: 0.8783 Recall: 0.9401 F1: 0.9082 Train AUC: 0.9960 Val AUC: 0.9746 Time: 13.00\n",
      "Epoch: 949 Train Loss: 0.0739 Val Loss: 0.2440 Acc: 0.8967 Pre: 0.8650 Recall: 0.9472 F1: 0.9042 Train AUC: 0.9980 Val AUC: 0.9749 Time: 12.25\n",
      "Epoch: 950 Train Loss: 0.0714 Val Loss: 0.2257 Acc: 0.9076 Pre: 0.8976 Recall: 0.9261 F1: 0.9116 Train AUC: 0.9982 Val AUC: 0.9759 Time: 11.67\n",
      "Epoch: 951 Train Loss: 0.0701 Val Loss: 0.2310 Acc: 0.9094 Pre: 0.9149 Recall: 0.9085 F1: 0.9117 Train AUC: 0.9976 Val AUC: 0.9753 Time: 11.97\n",
      "Epoch: 952 Train Loss: 0.0776 Val Loss: 0.2220 Acc: 0.9112 Pre: 0.9094 Recall: 0.9190 F1: 0.9142 Train AUC: 0.9971 Val AUC: 0.9750 Time: 12.59\n",
      "Epoch: 953 Train Loss: 0.0701 Val Loss: 0.2217 Acc: 0.9167 Pre: 0.9103 Recall: 0.9296 F1: 0.9199 Train AUC: 0.9975 Val AUC: 0.9724 Time: 13.08\n",
      "Epoch: 954 Train Loss: 0.0744 Val Loss: 0.2289 Acc: 0.9167 Pre: 0.9048 Recall: 0.9366 F1: 0.9204 Train AUC: 0.9979 Val AUC: 0.9729 Time: 13.47\n",
      "Epoch: 955 Train Loss: 0.0684 Val Loss: 0.2367 Acc: 0.9076 Pre: 0.8896 Recall: 0.9366 F1: 0.9125 Train AUC: 0.9980 Val AUC: 0.9735 Time: 14.23\n",
      "Epoch: 956 Train Loss: 0.0695 Val Loss: 0.2443 Acc: 0.9040 Pre: 0.8863 Recall: 0.9331 F1: 0.9091 Train AUC: 0.9981 Val AUC: 0.9731 Time: 14.89\n",
      "Epoch: 957 Train Loss: 0.0785 Val Loss: 0.2373 Acc: 0.9130 Pre: 0.9097 Recall: 0.9225 F1: 0.9161 Train AUC: 0.9971 Val AUC: 0.9738 Time: 14.82\n",
      "Epoch: 958 Train Loss: 0.0811 Val Loss: 0.2293 Acc: 0.9058 Pre: 0.8973 Recall: 0.9225 F1: 0.9097 Train AUC: 0.9964 Val AUC: 0.9750 Time: 13.29\n",
      "Epoch: 959 Train Loss: 0.0810 Val Loss: 0.2458 Acc: 0.8949 Pre: 0.8645 Recall: 0.9437 F1: 0.9024 Train AUC: 0.9965 Val AUC: 0.9735 Time: 12.27\n",
      "Epoch: 960 Train Loss: 0.0753 Val Loss: 0.2288 Acc: 0.9022 Pre: 0.8808 Recall: 0.9366 F1: 0.9078 Train AUC: 0.9982 Val AUC: 0.9748 Time: 12.32\n",
      "Epoch: 961 Train Loss: 0.0806 Val Loss: 0.2221 Acc: 0.9167 Pre: 0.9103 Recall: 0.9296 F1: 0.9199 Train AUC: 0.9970 Val AUC: 0.9759 Time: 12.90\n",
      "Epoch: 962 Train Loss: 0.0776 Val Loss: 0.2279 Acc: 0.9149 Pre: 0.9100 Recall: 0.9261 F1: 0.9180 Train AUC: 0.9972 Val AUC: 0.9761 Time: 12.99\n",
      "Epoch: 963 Train Loss: 0.0740 Val Loss: 0.2292 Acc: 0.9076 Pre: 0.8949 Recall: 0.9296 F1: 0.9119 Train AUC: 0.9972 Val AUC: 0.9755 Time: 13.56\n",
      "Epoch: 964 Train Loss: 0.0678 Val Loss: 0.2313 Acc: 0.9022 Pre: 0.8808 Recall: 0.9366 F1: 0.9078 Train AUC: 0.9978 Val AUC: 0.9748 Time: 14.15\n",
      "Epoch: 965 Train Loss: 0.0676 Val Loss: 0.2311 Acc: 0.9076 Pre: 0.8923 Recall: 0.9331 F1: 0.9122 Train AUC: 0.9984 Val AUC: 0.9719 Time: 14.51\n",
      "Epoch: 966 Train Loss: 0.0697 Val Loss: 0.2263 Acc: 0.9094 Pre: 0.8980 Recall: 0.9296 F1: 0.9135 Train AUC: 0.9979 Val AUC: 0.9745 Time: 16.08\n",
      "Epoch: 967 Train Loss: 0.0691 Val Loss: 0.2276 Acc: 0.9076 Pre: 0.8896 Recall: 0.9366 F1: 0.9125 Train AUC: 0.9977 Val AUC: 0.9758 Time: 13.39\n",
      "Epoch: 968 Train Loss: 0.0684 Val Loss: 0.2322 Acc: 0.9094 Pre: 0.8874 Recall: 0.9437 F1: 0.9147 Train AUC: 0.9975 Val AUC: 0.9764 Time: 12.22\n",
      "Epoch: 969 Train Loss: 0.0707 Val Loss: 0.2246 Acc: 0.9058 Pre: 0.8893 Recall: 0.9331 F1: 0.9107 Train AUC: 0.9978 Val AUC: 0.9767 Time: 12.99\n",
      "Epoch: 970 Train Loss: 0.0713 Val Loss: 0.2180 Acc: 0.9094 Pre: 0.8980 Recall: 0.9296 F1: 0.9135 Train AUC: 0.9977 Val AUC: 0.9762 Time: 13.27\n",
      "Epoch: 971 Train Loss: 0.0713 Val Loss: 0.2178 Acc: 0.9167 Pre: 0.9103 Recall: 0.9296 F1: 0.9199 Train AUC: 0.9977 Val AUC: 0.9755 Time: 14.07\n",
      "Epoch: 972 Train Loss: 0.0703 Val Loss: 0.2217 Acc: 0.9149 Pre: 0.9072 Recall: 0.9296 F1: 0.9183 Train AUC: 0.9980 Val AUC: 0.9746 Time: 13.78\n",
      "Epoch: 973 Train Loss: 0.0786 Val Loss: 0.2309 Acc: 0.9094 Pre: 0.8900 Recall: 0.9401 F1: 0.9144 Train AUC: 0.9971 Val AUC: 0.9746 Time: 13.75\n",
      "Epoch: 974 Train Loss: 0.0732 Val Loss: 0.2329 Acc: 0.9076 Pre: 0.8870 Recall: 0.9401 F1: 0.9128 Train AUC: 0.9977 Val AUC: 0.9749 Time: 13.09\n",
      "Epoch: 975 Train Loss: 0.0736 Val Loss: 0.2264 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9973 Val AUC: 0.9753 Time: 13.50\n",
      "Epoch: 976 Train Loss: 0.0635 Val Loss: 0.2276 Acc: 0.9058 Pre: 0.8893 Recall: 0.9331 F1: 0.9107 Train AUC: 0.9984 Val AUC: 0.9745 Time: 13.23\n",
      "Epoch: 977 Train Loss: 0.0698 Val Loss: 0.2271 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9982 Val AUC: 0.9745 Time: 13.36\n",
      "Epoch: 978 Train Loss: 0.0694 Val Loss: 0.2320 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9983 Val AUC: 0.9743 Time: 14.16\n",
      "Epoch: 979 Train Loss: 0.0712 Val Loss: 0.2382 Acc: 0.9022 Pre: 0.8859 Recall: 0.9296 F1: 0.9072 Train AUC: 0.9979 Val AUC: 0.9746 Time: 13.82\n",
      "Epoch: 980 Train Loss: 0.0756 Val Loss: 0.2375 Acc: 0.9094 Pre: 0.8926 Recall: 0.9366 F1: 0.9141 Train AUC: 0.9973 Val AUC: 0.9743 Time: 12.84\n",
      "Epoch: 981 Train Loss: 0.0705 Val Loss: 0.2245 Acc: 0.9058 Pre: 0.8893 Recall: 0.9331 F1: 0.9107 Train AUC: 0.9973 Val AUC: 0.9746 Time: 13.51\n",
      "Epoch: 982 Train Loss: 0.0673 Val Loss: 0.2218 Acc: 0.9185 Pre: 0.9107 Recall: 0.9331 F1: 0.9217 Train AUC: 0.9981 Val AUC: 0.9723 Time: 13.81\n",
      "Epoch: 983 Train Loss: 0.0734 Val Loss: 0.2183 Acc: 0.9203 Pre: 0.9138 Recall: 0.9331 F1: 0.9233 Train AUC: 0.9977 Val AUC: 0.9733 Time: 14.30\n",
      "Epoch: 984 Train Loss: 0.0760 Val Loss: 0.2187 Acc: 0.9167 Pre: 0.9075 Recall: 0.9331 F1: 0.9201 Train AUC: 0.9974 Val AUC: 0.9763 Time: 14.95\n",
      "Epoch: 985 Train Loss: 0.0662 Val Loss: 0.2299 Acc: 0.9239 Pre: 0.9116 Recall: 0.9437 F1: 0.9273 Train AUC: 0.9983 Val AUC: 0.9765 Time: 14.11\n",
      "Epoch: 986 Train Loss: 0.0804 Val Loss: 0.2250 Acc: 0.9112 Pre: 0.8956 Recall: 0.9366 F1: 0.9157 Train AUC: 0.9966 Val AUC: 0.9761 Time: 12.52\n",
      "Epoch: 987 Train Loss: 0.0718 Val Loss: 0.2249 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9972 Val AUC: 0.9737 Time: 12.77\n",
      "Epoch: 988 Train Loss: 0.0787 Val Loss: 0.2309 Acc: 0.9040 Pre: 0.8889 Recall: 0.9296 F1: 0.9088 Train AUC: 0.9971 Val AUC: 0.9716 Time: 13.49\n",
      "Epoch: 989 Train Loss: 0.0747 Val Loss: 0.2232 Acc: 0.9076 Pre: 0.8949 Recall: 0.9296 F1: 0.9119 Train AUC: 0.9978 Val AUC: 0.9747 Time: 13.60\n",
      "Epoch: 990 Train Loss: 0.0669 Val Loss: 0.2335 Acc: 0.9149 Pre: 0.9044 Recall: 0.9331 F1: 0.9185 Train AUC: 0.9980 Val AUC: 0.9749 Time: 14.01\n",
      "Epoch: 991 Train Loss: 0.0723 Val Loss: 0.2342 Acc: 0.9130 Pre: 0.8986 Recall: 0.9366 F1: 0.9172 Train AUC: 0.9973 Val AUC: 0.9752 Time: 16.02\n",
      "Epoch: 992 Train Loss: 0.0723 Val Loss: 0.2345 Acc: 0.9094 Pre: 0.8874 Recall: 0.9437 F1: 0.9147 Train AUC: 0.9973 Val AUC: 0.9747 Time: 16.13\n",
      "Epoch: 993 Train Loss: 0.0658 Val Loss: 0.2470 Acc: 0.9094 Pre: 0.8874 Recall: 0.9437 F1: 0.9147 Train AUC: 0.9981 Val AUC: 0.9702 Time: 13.17\n",
      "Epoch: 994 Train Loss: 0.0727 Val Loss: 0.2373 Acc: 0.9094 Pre: 0.8980 Recall: 0.9296 F1: 0.9135 Train AUC: 0.9984 Val AUC: 0.9718 Time: 12.42\n",
      "Epoch: 995 Train Loss: 0.0717 Val Loss: 0.2283 Acc: 0.9112 Pre: 0.9066 Recall: 0.9225 F1: 0.9145 Train AUC: 0.9979 Val AUC: 0.9739 Time: 13.95\n",
      "Epoch: 996 Train Loss: 0.0685 Val Loss: 0.2348 Acc: 0.9203 Pre: 0.9054 Recall: 0.9437 F1: 0.9241 Train AUC: 0.9980 Val AUC: 0.9753 Time: 13.47\n",
      "Epoch: 997 Train Loss: 0.0687 Val Loss: 0.2408 Acc: 0.9130 Pre: 0.8933 Recall: 0.9437 F1: 0.9178 Train AUC: 0.9978 Val AUC: 0.9745 Time: 17.52\n",
      "Epoch: 998 Train Loss: 0.0655 Val Loss: 0.2330 Acc: 0.9112 Pre: 0.8956 Recall: 0.9366 F1: 0.9157 Train AUC: 0.9986 Val AUC: 0.9740 Time: 16.03\n",
      "Epoch: 999 Train Loss: 0.0694 Val Loss: 0.2248 Acc: 0.9167 Pre: 0.9103 Recall: 0.9296 F1: 0.9199 Train AUC: 0.9979 Val AUC: 0.9738 Time: 14.86\n",
      "Epoch: 1000 Train Loss: 0.0716 Val Loss: 0.2293 Acc: 0.9004 Pre: 0.8935 Recall: 0.9155 F1: 0.9043 Train AUC: 0.9978 Val AUC: 0.9723 Time: 14.35\n",
      "Fold: 1 Best Epoch: 969 Test acc: 0.9058 Test Pre: 0.8893 Test Recall: 0.9331 Test F1: 0.9107 Test PRC: 0.9794 Test AUC: 0.9767\n",
      "Training for Fold 2\n",
      "## Training edges: 2208\n",
      "## Testing edges: 552\n",
      "Epoch: 1 Train Loss: 1.0727 Val Loss: 1.9289 Acc: 0.5290 Pre: 0.5290 Recall: 1.0000 F1: 0.6919 Train AUC: 0.4213 Val AUC: 0.7873 Time: 14.91\n",
      "Epoch: 2 Train Loss: 1.9406 Val Loss: 1.2028 Acc: 0.5054 Pre: 0.7879 Recall: 0.0890 F1: 0.1600 Train AUC: 0.6998 Val AUC: 0.6359 Time: 14.94\n",
      "Epoch: 3 Train Loss: 1.5643 Val Loss: 0.6973 Acc: 0.6159 Pre: 0.9082 Recall: 0.3048 F1: 0.4564 Train AUC: 0.5483 Val AUC: 0.7680 Time: 14.29\n",
      "Epoch: 4 Train Loss: 0.7007 Val Loss: 0.5575 Acc: 0.7083 Pre: 0.6866 Recall: 0.8253 F1: 0.7496 Train AUC: 0.7318 Val AUC: 0.7915 Time: 15.08\n",
      "Epoch: 5 Train Loss: 0.7778 Val Loss: 0.6016 Acc: 0.6612 Pre: 0.6207 Recall: 0.9247 F1: 0.7428 Train AUC: 0.6543 Val AUC: 0.8447 Time: 14.64\n",
      "Epoch: 6 Train Loss: 0.6803 Val Loss: 0.5506 Acc: 0.6938 Pre: 0.6549 Recall: 0.8904 F1: 0.7547 Train AUC: 0.8058 Val AUC: 0.8460 Time: 12.63\n",
      "Epoch: 7 Train Loss: 0.6620 Val Loss: 0.4751 Acc: 0.7663 Pre: 0.7690 Recall: 0.7979 F1: 0.7832 Train AUC: 0.7935 Val AUC: 0.8517 Time: 12.17\n",
      "Epoch: 8 Train Loss: 0.6033 Val Loss: 0.4766 Acc: 0.7989 Pre: 0.8987 Recall: 0.6986 F1: 0.7861 Train AUC: 0.7728 Val AUC: 0.8742 Time: 13.18\n",
      "Epoch: 9 Train Loss: 0.5842 Val Loss: 0.5169 Acc: 0.8188 Pre: 0.9615 Recall: 0.6849 F1: 0.8000 Train AUC: 0.8070 Val AUC: 0.8783 Time: 13.35\n",
      "Epoch: 10 Train Loss: 0.6377 Val Loss: 0.5018 Acc: 0.8025 Pre: 0.9140 Recall: 0.6918 F1: 0.7875 Train AUC: 0.8016 Val AUC: 0.8735 Time: 13.71\n",
      "Epoch: 11 Train Loss: 0.4711 Val Loss: 0.4635 Acc: 0.8098 Pre: 0.8912 Recall: 0.7295 F1: 0.8023 Train AUC: 0.8775 Val AUC: 0.8751 Time: 14.12\n",
      "Epoch: 12 Train Loss: 0.4939 Val Loss: 0.4356 Acc: 0.8062 Pre: 0.8656 Recall: 0.7500 F1: 0.8037 Train AUC: 0.8540 Val AUC: 0.8786 Time: 13.90\n",
      "Epoch: 13 Train Loss: 0.4850 Val Loss: 0.4256 Acc: 0.7935 Pre: 0.8248 Recall: 0.7740 F1: 0.7986 Train AUC: 0.8574 Val AUC: 0.8810 Time: 13.38\n",
      "Epoch: 14 Train Loss: 0.4727 Val Loss: 0.4270 Acc: 0.7862 Pre: 0.8063 Recall: 0.7842 F1: 0.7951 Train AUC: 0.8723 Val AUC: 0.8840 Time: 13.09\n",
      "Epoch: 15 Train Loss: 0.4311 Val Loss: 0.4301 Acc: 0.7971 Pre: 0.8147 Recall: 0.7979 F1: 0.8062 Train AUC: 0.8849 Val AUC: 0.8844 Time: 12.65\n",
      "Epoch: 16 Train Loss: 0.4690 Val Loss: 0.4278 Acc: 0.7917 Pre: 0.8172 Recall: 0.7808 F1: 0.7986 Train AUC: 0.8783 Val AUC: 0.8862 Time: 12.25\n",
      "Epoch: 17 Train Loss: 0.4751 Val Loss: 0.4185 Acc: 0.8043 Pre: 0.8651 Recall: 0.7466 F1: 0.8015 Train AUC: 0.8708 Val AUC: 0.8909 Time: 12.48\n",
      "Epoch: 18 Train Loss: 0.4333 Val Loss: 0.4120 Acc: 0.8062 Pre: 0.8807 Recall: 0.7329 F1: 0.8000 Train AUC: 0.8861 Val AUC: 0.8964 Time: 13.96\n",
      "Epoch: 19 Train Loss: 0.4375 Val Loss: 0.4113 Acc: 0.8062 Pre: 0.9039 Recall: 0.7089 F1: 0.7946 Train AUC: 0.8859 Val AUC: 0.9013 Time: 13.81\n",
      "Epoch: 20 Train Loss: 0.4336 Val Loss: 0.4107 Acc: 0.8043 Pre: 0.9107 Recall: 0.6986 F1: 0.7907 Train AUC: 0.8907 Val AUC: 0.9029 Time: 14.27\n",
      "Epoch: 21 Train Loss: 0.4132 Val Loss: 0.4048 Acc: 0.8062 Pre: 0.9004 Recall: 0.7123 F1: 0.7954 Train AUC: 0.8999 Val AUC: 0.9031 Time: 15.05\n",
      "Epoch: 22 Train Loss: 0.4106 Val Loss: 0.3977 Acc: 0.8080 Pre: 0.8843 Recall: 0.7329 F1: 0.8015 Train AUC: 0.9005 Val AUC: 0.9018 Time: 13.14\n",
      "Epoch: 23 Train Loss: 0.3934 Val Loss: 0.3919 Acc: 0.8098 Pre: 0.8725 Recall: 0.7500 F1: 0.8066 Train AUC: 0.8997 Val AUC: 0.9012 Time: 13.02\n",
      "Epoch: 24 Train Loss: 0.4087 Val Loss: 0.3871 Acc: 0.8098 Pre: 0.8638 Recall: 0.7603 F1: 0.8087 Train AUC: 0.8944 Val AUC: 0.9025 Time: 12.55\n",
      "Epoch: 25 Train Loss: 0.3959 Val Loss: 0.3818 Acc: 0.8098 Pre: 0.8528 Recall: 0.7740 F1: 0.8115 Train AUC: 0.8994 Val AUC: 0.9048 Time: 12.61\n",
      "Epoch: 26 Train Loss: 0.3861 Val Loss: 0.3776 Acc: 0.8116 Pre: 0.8534 Recall: 0.7774 F1: 0.8136 Train AUC: 0.9020 Val AUC: 0.9072 Time: 12.63\n",
      "Epoch: 27 Train Loss: 0.3828 Val Loss: 0.3755 Acc: 0.8152 Pre: 0.8545 Recall: 0.7842 F1: 0.8179 Train AUC: 0.9030 Val AUC: 0.9078 Time: 13.89\n",
      "Epoch: 28 Train Loss: 0.4044 Val Loss: 0.3769 Acc: 0.8170 Pre: 0.8604 Recall: 0.7808 F1: 0.8187 Train AUC: 0.8951 Val AUC: 0.9070 Time: 13.94\n",
      "Epoch: 29 Train Loss: 0.3884 Val Loss: 0.3807 Acc: 0.8170 Pre: 0.8631 Recall: 0.7774 F1: 0.8180 Train AUC: 0.9024 Val AUC: 0.9048 Time: 14.67\n",
      "Epoch: 30 Train Loss: 0.3894 Val Loss: 0.3846 Acc: 0.8116 Pre: 0.8643 Recall: 0.7637 F1: 0.8109 Train AUC: 0.9039 Val AUC: 0.9038 Time: 14.55\n",
      "Epoch: 31 Train Loss: 0.3976 Val Loss: 0.3873 Acc: 0.8116 Pre: 0.8760 Recall: 0.7500 F1: 0.8081 Train AUC: 0.8989 Val AUC: 0.9043 Time: 12.66\n",
      "Epoch: 32 Train Loss: 0.3702 Val Loss: 0.3864 Acc: 0.8116 Pre: 0.8790 Recall: 0.7466 F1: 0.8074 Train AUC: 0.9119 Val AUC: 0.9058 Time: 13.11\n",
      "Epoch: 33 Train Loss: 0.3753 Val Loss: 0.3823 Acc: 0.8098 Pre: 0.8755 Recall: 0.7466 F1: 0.8059 Train AUC: 0.9099 Val AUC: 0.9080 Time: 12.53\n",
      "Epoch: 34 Train Loss: 0.4036 Val Loss: 0.3770 Acc: 0.8170 Pre: 0.8775 Recall: 0.7603 F1: 0.8147 Train AUC: 0.8982 Val AUC: 0.9102 Time: 12.63\n",
      "Epoch: 35 Train Loss: 0.3700 Val Loss: 0.3722 Acc: 0.8170 Pre: 0.8745 Recall: 0.7637 F1: 0.8154 Train AUC: 0.9102 Val AUC: 0.9113 Time: 13.31\n",
      "Epoch: 36 Train Loss: 0.3743 Val Loss: 0.3703 Acc: 0.8188 Pre: 0.8664 Recall: 0.7774 F1: 0.8195 Train AUC: 0.9092 Val AUC: 0.9113 Time: 14.14\n",
      "Epoch: 37 Train Loss: 0.3583 Val Loss: 0.3697 Acc: 0.8207 Pre: 0.8669 Recall: 0.7808 F1: 0.8216 Train AUC: 0.9160 Val AUC: 0.9112 Time: 14.63\n",
      "Epoch: 38 Train Loss: 0.3701 Val Loss: 0.3692 Acc: 0.8207 Pre: 0.8587 Recall: 0.7911 F1: 0.8235 Train AUC: 0.9132 Val AUC: 0.9117 Time: 16.34\n",
      "Epoch: 39 Train Loss: 0.3600 Val Loss: 0.3677 Acc: 0.8207 Pre: 0.8561 Recall: 0.7945 F1: 0.8242 Train AUC: 0.9150 Val AUC: 0.9122 Time: 12.84\n",
      "Epoch: 40 Train Loss: 0.3671 Val Loss: 0.3657 Acc: 0.8225 Pre: 0.8647 Recall: 0.7877 F1: 0.8244 Train AUC: 0.9129 Val AUC: 0.9130 Time: 12.06\n",
      "Epoch: 41 Train Loss: 0.3411 Val Loss: 0.3652 Acc: 0.8170 Pre: 0.8631 Recall: 0.7774 F1: 0.8180 Train AUC: 0.9249 Val AUC: 0.9138 Time: 14.47\n",
      "Epoch: 42 Train Loss: 0.3586 Val Loss: 0.3658 Acc: 0.8116 Pre: 0.8588 Recall: 0.7705 F1: 0.8123 Train AUC: 0.9170 Val AUC: 0.9139 Time: 15.26\n",
      "Epoch: 43 Train Loss: 0.3533 Val Loss: 0.3666 Acc: 0.8152 Pre: 0.8626 Recall: 0.7740 F1: 0.8159 Train AUC: 0.9206 Val AUC: 0.9134 Time: 14.03\n",
      "Epoch: 44 Train Loss: 0.3538 Val Loss: 0.3671 Acc: 0.8188 Pre: 0.8636 Recall: 0.7808 F1: 0.8201 Train AUC: 0.9187 Val AUC: 0.9133 Time: 14.54\n",
      "Epoch: 45 Train Loss: 0.3438 Val Loss: 0.3654 Acc: 0.8188 Pre: 0.8582 Recall: 0.7877 F1: 0.8214 Train AUC: 0.9253 Val AUC: 0.9137 Time: 13.72\n",
      "Epoch: 46 Train Loss: 0.3445 Val Loss: 0.3627 Acc: 0.8207 Pre: 0.8587 Recall: 0.7911 F1: 0.8235 Train AUC: 0.9259 Val AUC: 0.9145 Time: 12.66\n",
      "Epoch: 47 Train Loss: 0.3379 Val Loss: 0.3605 Acc: 0.8207 Pre: 0.8535 Recall: 0.7979 F1: 0.8248 Train AUC: 0.9268 Val AUC: 0.9151 Time: 12.24\n",
      "Epoch: 48 Train Loss: 0.3578 Val Loss: 0.3570 Acc: 0.8279 Pre: 0.8556 Recall: 0.8116 F1: 0.8330 Train AUC: 0.9181 Val AUC: 0.9165 Time: 14.78\n",
      "Epoch: 49 Train Loss: 0.3576 Val Loss: 0.3544 Acc: 0.8333 Pre: 0.8571 Recall: 0.8219 F1: 0.8392 Train AUC: 0.9189 Val AUC: 0.9174 Time: 12.75\n",
      "Epoch: 50 Train Loss: 0.3353 Val Loss: 0.3526 Acc: 0.8333 Pre: 0.8597 Recall: 0.8185 F1: 0.8386 Train AUC: 0.9267 Val AUC: 0.9189 Time: 12.93\n",
      "Epoch: 51 Train Loss: 0.3357 Val Loss: 0.3524 Acc: 0.8315 Pre: 0.8699 Recall: 0.8014 F1: 0.8342 Train AUC: 0.9306 Val AUC: 0.9205 Time: 13.48\n",
      "Epoch: 52 Train Loss: 0.3465 Val Loss: 0.3518 Acc: 0.8388 Pre: 0.8859 Recall: 0.7979 F1: 0.8396 Train AUC: 0.9235 Val AUC: 0.9209 Time: 14.32\n",
      "Epoch: 53 Train Loss: 0.3362 Val Loss: 0.3522 Acc: 0.8388 Pre: 0.8919 Recall: 0.7911 F1: 0.8385 Train AUC: 0.9287 Val AUC: 0.9212 Time: 13.64\n",
      "Epoch: 54 Train Loss: 0.3398 Val Loss: 0.3519 Acc: 0.8370 Pre: 0.8885 Recall: 0.7911 F1: 0.8370 Train AUC: 0.9287 Val AUC: 0.9213 Time: 12.87\n",
      "Epoch: 55 Train Loss: 0.3334 Val Loss: 0.3507 Acc: 0.8351 Pre: 0.8821 Recall: 0.7945 F1: 0.8360 Train AUC: 0.9280 Val AUC: 0.9215 Time: 11.59\n",
      "Epoch: 56 Train Loss: 0.3295 Val Loss: 0.3486 Acc: 0.8370 Pre: 0.8797 Recall: 0.8014 F1: 0.8387 Train AUC: 0.9303 Val AUC: 0.9215 Time: 11.83\n",
      "Epoch: 57 Train Loss: 0.3401 Val Loss: 0.3474 Acc: 0.8351 Pre: 0.8681 Recall: 0.8116 F1: 0.8389 Train AUC: 0.9270 Val AUC: 0.9216 Time: 12.06\n",
      "Epoch: 58 Train Loss: 0.3387 Val Loss: 0.3471 Acc: 0.8388 Pre: 0.8638 Recall: 0.8253 F1: 0.8441 Train AUC: 0.9279 Val AUC: 0.9217 Time: 12.35\n",
      "Epoch: 59 Train Loss: 0.3371 Val Loss: 0.3468 Acc: 0.8424 Pre: 0.8596 Recall: 0.8390 F1: 0.8492 Train AUC: 0.9273 Val AUC: 0.9224 Time: 12.76\n",
      "Epoch: 60 Train Loss: 0.3341 Val Loss: 0.3459 Acc: 0.8424 Pre: 0.8674 Recall: 0.8288 F1: 0.8476 Train AUC: 0.9293 Val AUC: 0.9229 Time: 13.38\n",
      "Epoch: 61 Train Loss: 0.3314 Val Loss: 0.3443 Acc: 0.8388 Pre: 0.8691 Recall: 0.8185 F1: 0.8430 Train AUC: 0.9295 Val AUC: 0.9240 Time: 14.07\n",
      "Epoch: 62 Train Loss: 0.3272 Val Loss: 0.3439 Acc: 0.8460 Pre: 0.8819 Recall: 0.8185 F1: 0.8490 Train AUC: 0.9326 Val AUC: 0.9249 Time: 14.52\n",
      "Epoch: 63 Train Loss: 0.3236 Val Loss: 0.3455 Acc: 0.8460 Pre: 0.8966 Recall: 0.8014 F1: 0.8463 Train AUC: 0.9336 Val AUC: 0.9258 Time: 13.52\n",
      "Epoch: 64 Train Loss: 0.3341 Val Loss: 0.3456 Acc: 0.8496 Pre: 0.9035 Recall: 0.8014 F1: 0.8494 Train AUC: 0.9312 Val AUC: 0.9263 Time: 13.23\n",
      "Epoch: 65 Train Loss: 0.3186 Val Loss: 0.3440 Acc: 0.8496 Pre: 0.8973 Recall: 0.8082 F1: 0.8505 Train AUC: 0.9341 Val AUC: 0.9268 Time: 12.00\n",
      "Epoch: 66 Train Loss: 0.3285 Val Loss: 0.3416 Acc: 0.8533 Pre: 0.8951 Recall: 0.8185 F1: 0.8551 Train AUC: 0.9326 Val AUC: 0.9268 Time: 11.20\n",
      "Epoch: 67 Train Loss: 0.3262 Val Loss: 0.3398 Acc: 0.8533 Pre: 0.8922 Recall: 0.8219 F1: 0.8556 Train AUC: 0.9339 Val AUC: 0.9270 Time: 11.58\n",
      "Epoch: 68 Train Loss: 0.3234 Val Loss: 0.3381 Acc: 0.8514 Pre: 0.8832 Recall: 0.8288 F1: 0.8551 Train AUC: 0.9348 Val AUC: 0.9273 Time: 11.96\n",
      "Epoch: 69 Train Loss: 0.3308 Val Loss: 0.3373 Acc: 0.8514 Pre: 0.8832 Recall: 0.8288 F1: 0.8551 Train AUC: 0.9315 Val AUC: 0.9278 Time: 13.12\n",
      "Epoch: 70 Train Loss: 0.3141 Val Loss: 0.3373 Acc: 0.8496 Pre: 0.8828 Recall: 0.8253 F1: 0.8531 Train AUC: 0.9368 Val AUC: 0.9287 Time: 12.91\n",
      "Epoch: 71 Train Loss: 0.3065 Val Loss: 0.3370 Acc: 0.8478 Pre: 0.8796 Recall: 0.8253 F1: 0.8516 Train AUC: 0.9401 Val AUC: 0.9291 Time: 16.21\n",
      "Epoch: 72 Train Loss: 0.3105 Val Loss: 0.3359 Acc: 0.8533 Pre: 0.8809 Recall: 0.8356 F1: 0.8576 Train AUC: 0.9381 Val AUC: 0.9294 Time: 15.06\n",
      "Epoch: 73 Train Loss: 0.3175 Val Loss: 0.3352 Acc: 0.8587 Pre: 0.8905 Recall: 0.8356 F1: 0.8622 Train AUC: 0.9379 Val AUC: 0.9296 Time: 14.89\n",
      "Epoch: 74 Train Loss: 0.3091 Val Loss: 0.3347 Acc: 0.8605 Pre: 0.8938 Recall: 0.8356 F1: 0.8637 Train AUC: 0.9390 Val AUC: 0.9300 Time: 13.88\n",
      "Epoch: 75 Train Loss: 0.3097 Val Loss: 0.3344 Acc: 0.8587 Pre: 0.8993 Recall: 0.8253 F1: 0.8607 Train AUC: 0.9387 Val AUC: 0.9304 Time: 12.59\n",
      "Epoch: 76 Train Loss: 0.3070 Val Loss: 0.3355 Acc: 0.8605 Pre: 0.9057 Recall: 0.8219 F1: 0.8618 Train AUC: 0.9402 Val AUC: 0.9309 Time: 11.76\n",
      "Epoch: 77 Train Loss: 0.3046 Val Loss: 0.3352 Acc: 0.8605 Pre: 0.9057 Recall: 0.8219 F1: 0.8618 Train AUC: 0.9421 Val AUC: 0.9312 Time: 12.68\n",
      "Epoch: 78 Train Loss: 0.3103 Val Loss: 0.3335 Acc: 0.8587 Pre: 0.9023 Recall: 0.8219 F1: 0.8602 Train AUC: 0.9391 Val AUC: 0.9315 Time: 12.85\n",
      "Epoch: 79 Train Loss: 0.3149 Val Loss: 0.3318 Acc: 0.8587 Pre: 0.8993 Recall: 0.8253 F1: 0.8607 Train AUC: 0.9377 Val AUC: 0.9315 Time: 13.14\n",
      "Epoch: 80 Train Loss: 0.3086 Val Loss: 0.3299 Acc: 0.8623 Pre: 0.8971 Recall: 0.8356 F1: 0.8652 Train AUC: 0.9395 Val AUC: 0.9317 Time: 13.46\n",
      "Epoch: 81 Train Loss: 0.3171 Val Loss: 0.3287 Acc: 0.8659 Pre: 0.8949 Recall: 0.8459 F1: 0.8697 Train AUC: 0.9376 Val AUC: 0.9321 Time: 15.94\n",
      "Epoch: 82 Train Loss: 0.3004 Val Loss: 0.3281 Acc: 0.8659 Pre: 0.8949 Recall: 0.8459 F1: 0.8697 Train AUC: 0.9432 Val AUC: 0.9327 Time: 12.90\n",
      "Epoch: 83 Train Loss: 0.3227 Val Loss: 0.3284 Acc: 0.8605 Pre: 0.8938 Recall: 0.8356 F1: 0.8637 Train AUC: 0.9353 Val AUC: 0.9327 Time: 12.09\n",
      "Epoch: 84 Train Loss: 0.3063 Val Loss: 0.3302 Acc: 0.8551 Pre: 0.8926 Recall: 0.8253 F1: 0.8577 Train AUC: 0.9414 Val AUC: 0.9323 Time: 12.10\n",
      "Epoch: 85 Train Loss: 0.2989 Val Loss: 0.3317 Acc: 0.8569 Pre: 0.8959 Recall: 0.8253 F1: 0.8592 Train AUC: 0.9438 Val AUC: 0.9322 Time: 12.54\n",
      "Epoch: 86 Train Loss: 0.3007 Val Loss: 0.3319 Acc: 0.8569 Pre: 0.8959 Recall: 0.8253 F1: 0.8592 Train AUC: 0.9435 Val AUC: 0.9321 Time: 12.37\n",
      "Epoch: 87 Train Loss: 0.3054 Val Loss: 0.3306 Acc: 0.8569 Pre: 0.8959 Recall: 0.8253 F1: 0.8592 Train AUC: 0.9415 Val AUC: 0.9323 Time: 13.10\n",
      "Epoch: 88 Train Loss: 0.3030 Val Loss: 0.3286 Acc: 0.8678 Pre: 0.8982 Recall: 0.8459 F1: 0.8713 Train AUC: 0.9421 Val AUC: 0.9329 Time: 14.08\n",
      "Epoch: 89 Train Loss: 0.2978 Val Loss: 0.3252 Acc: 0.8696 Pre: 0.9015 Recall: 0.8459 F1: 0.8728 Train AUC: 0.9440 Val AUC: 0.9339 Time: 14.46\n",
      "Epoch: 90 Train Loss: 0.2922 Val Loss: 0.3233 Acc: 0.8678 Pre: 0.8953 Recall: 0.8493 F1: 0.8717 Train AUC: 0.9460 Val AUC: 0.9350 Time: 13.59\n",
      "Epoch: 91 Train Loss: 0.3029 Val Loss: 0.3234 Acc: 0.8623 Pre: 0.8885 Recall: 0.8459 F1: 0.8667 Train AUC: 0.9428 Val AUC: 0.9353 Time: 13.31\n",
      "Epoch: 92 Train Loss: 0.3033 Val Loss: 0.3243 Acc: 0.8623 Pre: 0.8942 Recall: 0.8390 F1: 0.8657 Train AUC: 0.9430 Val AUC: 0.9349 Time: 13.04\n",
      "Epoch: 93 Train Loss: 0.3041 Val Loss: 0.3236 Acc: 0.8714 Pre: 0.9108 Recall: 0.8390 F1: 0.8734 Train AUC: 0.9437 Val AUC: 0.9349 Time: 14.04\n",
      "Epoch: 94 Train Loss: 0.3031 Val Loss: 0.3230 Acc: 0.8714 Pre: 0.9108 Recall: 0.8390 F1: 0.8734 Train AUC: 0.9433 Val AUC: 0.9350 Time: 13.16\n",
      "Epoch: 95 Train Loss: 0.2947 Val Loss: 0.3230 Acc: 0.8714 Pre: 0.9139 Recall: 0.8356 F1: 0.8730 Train AUC: 0.9446 Val AUC: 0.9350 Time: 13.51\n",
      "Epoch: 96 Train Loss: 0.3044 Val Loss: 0.3229 Acc: 0.8732 Pre: 0.9142 Recall: 0.8390 F1: 0.8750 Train AUC: 0.9430 Val AUC: 0.9351 Time: 16.12\n",
      "Epoch: 97 Train Loss: 0.2958 Val Loss: 0.3219 Acc: 0.8768 Pre: 0.9148 Recall: 0.8459 F1: 0.8790 Train AUC: 0.9433 Val AUC: 0.9355 Time: 14.95\n",
      "Epoch: 98 Train Loss: 0.2923 Val Loss: 0.3216 Acc: 0.8750 Pre: 0.9145 Recall: 0.8425 F1: 0.8770 Train AUC: 0.9465 Val AUC: 0.9355 Time: 14.53\n",
      "Epoch: 99 Train Loss: 0.2969 Val Loss: 0.3202 Acc: 0.8732 Pre: 0.9111 Recall: 0.8425 F1: 0.8754 Train AUC: 0.9438 Val AUC: 0.9360 Time: 12.77\n",
      "Epoch: 100 Train Loss: 0.2922 Val Loss: 0.3193 Acc: 0.8641 Pre: 0.9094 Recall: 0.8253 F1: 0.8654 Train AUC: 0.9458 Val AUC: 0.9365 Time: 11.55\n",
      "Epoch: 101 Train Loss: 0.2865 Val Loss: 0.3185 Acc: 0.8641 Pre: 0.9064 Recall: 0.8288 F1: 0.8658 Train AUC: 0.9481 Val AUC: 0.9371 Time: 11.99\n",
      "Epoch: 102 Train Loss: 0.2847 Val Loss: 0.3181 Acc: 0.8696 Pre: 0.9044 Recall: 0.8425 F1: 0.8723 Train AUC: 0.9502 Val AUC: 0.9373 Time: 12.64\n",
      "Epoch: 103 Train Loss: 0.2874 Val Loss: 0.3174 Acc: 0.8678 Pre: 0.9041 Recall: 0.8390 F1: 0.8703 Train AUC: 0.9489 Val AUC: 0.9373 Time: 12.89\n",
      "Epoch: 104 Train Loss: 0.2926 Val Loss: 0.3164 Acc: 0.8714 Pre: 0.9077 Recall: 0.8425 F1: 0.8739 Train AUC: 0.9483 Val AUC: 0.9372 Time: 13.56\n",
      "Epoch: 105 Train Loss: 0.2805 Val Loss: 0.3163 Acc: 0.8714 Pre: 0.9077 Recall: 0.8425 F1: 0.8739 Train AUC: 0.9511 Val AUC: 0.9373 Time: 14.49\n",
      "Epoch: 106 Train Loss: 0.2860 Val Loss: 0.3158 Acc: 0.8732 Pre: 0.9081 Recall: 0.8459 F1: 0.8759 Train AUC: 0.9475 Val AUC: 0.9373 Time: 14.88\n",
      "Epoch: 107 Train Loss: 0.2895 Val Loss: 0.3156 Acc: 0.8768 Pre: 0.9118 Recall: 0.8493 F1: 0.8794 Train AUC: 0.9466 Val AUC: 0.9376 Time: 15.86\n",
      "Epoch: 108 Train Loss: 0.2812 Val Loss: 0.3152 Acc: 0.8750 Pre: 0.9084 Recall: 0.8493 F1: 0.8779 Train AUC: 0.9504 Val AUC: 0.9379 Time: 13.70\n",
      "Epoch: 109 Train Loss: 0.2897 Val Loss: 0.3162 Acc: 0.8732 Pre: 0.9111 Recall: 0.8425 F1: 0.8754 Train AUC: 0.9471 Val AUC: 0.9378 Time: 12.39\n",
      "Epoch: 110 Train Loss: 0.2847 Val Loss: 0.3170 Acc: 0.8696 Pre: 0.9135 Recall: 0.8322 F1: 0.8710 Train AUC: 0.9497 Val AUC: 0.9377 Time: 11.50\n",
      "Epoch: 111 Train Loss: 0.2811 Val Loss: 0.3175 Acc: 0.8659 Pre: 0.9129 Recall: 0.8253 F1: 0.8669 Train AUC: 0.9495 Val AUC: 0.9384 Time: 11.93\n",
      "Epoch: 112 Train Loss: 0.2915 Val Loss: 0.3156 Acc: 0.8714 Pre: 0.9108 Recall: 0.8390 F1: 0.8734 Train AUC: 0.9472 Val AUC: 0.9387 Time: 12.04\n",
      "Epoch: 113 Train Loss: 0.2859 Val Loss: 0.3129 Acc: 0.8714 Pre: 0.9048 Recall: 0.8459 F1: 0.8743 Train AUC: 0.9489 Val AUC: 0.9388 Time: 12.31\n",
      "Epoch: 114 Train Loss: 0.2802 Val Loss: 0.3119 Acc: 0.8696 Pre: 0.8986 Recall: 0.8493 F1: 0.8732 Train AUC: 0.9524 Val AUC: 0.9387 Time: 13.05\n",
      "Epoch: 115 Train Loss: 0.2872 Val Loss: 0.3111 Acc: 0.8678 Pre: 0.8953 Recall: 0.8493 F1: 0.8717 Train AUC: 0.9484 Val AUC: 0.9393 Time: 13.46\n",
      "Epoch: 116 Train Loss: 0.2781 Val Loss: 0.3102 Acc: 0.8696 Pre: 0.8986 Recall: 0.8493 F1: 0.8732 Train AUC: 0.9520 Val AUC: 0.9396 Time: 13.80\n",
      "Epoch: 117 Train Loss: 0.2981 Val Loss: 0.3124 Acc: 0.8732 Pre: 0.9142 Recall: 0.8390 F1: 0.8750 Train AUC: 0.9451 Val AUC: 0.9394 Time: 14.90\n",
      "Epoch: 118 Train Loss: 0.2845 Val Loss: 0.3153 Acc: 0.8750 Pre: 0.9176 Recall: 0.8390 F1: 0.8766 Train AUC: 0.9513 Val AUC: 0.9383 Time: 14.95\n",
      "Epoch: 119 Train Loss: 0.2808 Val Loss: 0.3149 Acc: 0.8750 Pre: 0.9145 Recall: 0.8425 F1: 0.8770 Train AUC: 0.9508 Val AUC: 0.9377 Time: 13.34\n",
      "Epoch: 120 Train Loss: 0.2823 Val Loss: 0.3140 Acc: 0.8641 Pre: 0.8917 Recall: 0.8459 F1: 0.8682 Train AUC: 0.9510 Val AUC: 0.9376 Time: 12.35\n",
      "Epoch: 121 Train Loss: 0.2855 Val Loss: 0.3127 Acc: 0.8641 Pre: 0.8917 Recall: 0.8459 F1: 0.8682 Train AUC: 0.9501 Val AUC: 0.9381 Time: 12.40\n",
      "Epoch: 122 Train Loss: 0.2897 Val Loss: 0.3104 Acc: 0.8696 Pre: 0.9015 Recall: 0.8459 F1: 0.8728 Train AUC: 0.9475 Val AUC: 0.9391 Time: 12.42\n",
      "Epoch: 123 Train Loss: 0.2787 Val Loss: 0.3080 Acc: 0.8641 Pre: 0.8889 Recall: 0.8493 F1: 0.8687 Train AUC: 0.9515 Val AUC: 0.9403 Time: 12.67\n",
      "Epoch: 124 Train Loss: 0.2741 Val Loss: 0.3074 Acc: 0.8659 Pre: 0.8921 Recall: 0.8493 F1: 0.8702 Train AUC: 0.9550 Val AUC: 0.9405 Time: 13.15\n",
      "Epoch: 125 Train Loss: 0.2898 Val Loss: 0.3079 Acc: 0.8696 Pre: 0.8986 Recall: 0.8493 F1: 0.8732 Train AUC: 0.9491 Val AUC: 0.9403 Time: 13.72\n",
      "Epoch: 126 Train Loss: 0.2798 Val Loss: 0.3104 Acc: 0.8732 Pre: 0.9051 Recall: 0.8493 F1: 0.8763 Train AUC: 0.9513 Val AUC: 0.9398 Time: 13.96\n",
      "Epoch: 127 Train Loss: 0.2767 Val Loss: 0.3118 Acc: 0.8750 Pre: 0.9084 Recall: 0.8493 F1: 0.8779 Train AUC: 0.9523 Val AUC: 0.9395 Time: 13.22\n",
      "Epoch: 128 Train Loss: 0.2775 Val Loss: 0.3116 Acc: 0.8732 Pre: 0.9051 Recall: 0.8493 F1: 0.8763 Train AUC: 0.9525 Val AUC: 0.9393 Time: 12.71\n",
      "Epoch: 129 Train Loss: 0.2712 Val Loss: 0.3093 Acc: 0.8659 Pre: 0.8921 Recall: 0.8493 F1: 0.8702 Train AUC: 0.9538 Val AUC: 0.9395 Time: 12.86\n",
      "Epoch: 130 Train Loss: 0.2729 Val Loss: 0.3071 Acc: 0.8696 Pre: 0.8986 Recall: 0.8493 F1: 0.8732 Train AUC: 0.9531 Val AUC: 0.9403 Time: 13.93\n",
      "Epoch: 131 Train Loss: 0.2722 Val Loss: 0.3069 Acc: 0.8696 Pre: 0.8986 Recall: 0.8493 F1: 0.8732 Train AUC: 0.9540 Val AUC: 0.9407 Time: 13.79\n",
      "Epoch: 132 Train Loss: 0.2632 Val Loss: 0.3074 Acc: 0.8678 Pre: 0.9041 Recall: 0.8390 F1: 0.8703 Train AUC: 0.9583 Val AUC: 0.9411 Time: 14.40\n",
      "Epoch: 133 Train Loss: 0.2725 Val Loss: 0.3054 Acc: 0.8696 Pre: 0.9015 Recall: 0.8459 F1: 0.8728 Train AUC: 0.9550 Val AUC: 0.9416 Time: 15.06\n",
      "Epoch: 134 Train Loss: 0.2766 Val Loss: 0.3029 Acc: 0.8678 Pre: 0.8982 Recall: 0.8459 F1: 0.8713 Train AUC: 0.9533 Val AUC: 0.9422 Time: 13.22\n",
      "Epoch: 135 Train Loss: 0.2638 Val Loss: 0.3019 Acc: 0.8696 Pre: 0.8986 Recall: 0.8493 F1: 0.8732 Train AUC: 0.9573 Val AUC: 0.9426 Time: 12.43\n",
      "Epoch: 136 Train Loss: 0.2573 Val Loss: 0.3015 Acc: 0.8678 Pre: 0.8982 Recall: 0.8459 F1: 0.8713 Train AUC: 0.9586 Val AUC: 0.9429 Time: 12.89\n",
      "Epoch: 137 Train Loss: 0.2655 Val Loss: 0.3017 Acc: 0.8678 Pre: 0.8982 Recall: 0.8459 F1: 0.8713 Train AUC: 0.9555 Val AUC: 0.9429 Time: 12.91\n",
      "Epoch: 138 Train Loss: 0.2568 Val Loss: 0.3017 Acc: 0.8678 Pre: 0.8982 Recall: 0.8459 F1: 0.8713 Train AUC: 0.9580 Val AUC: 0.9431 Time: 14.50\n",
      "Epoch: 139 Train Loss: 0.2642 Val Loss: 0.3009 Acc: 0.8696 Pre: 0.9015 Recall: 0.8459 F1: 0.8728 Train AUC: 0.9563 Val AUC: 0.9435 Time: 13.74\n",
      "Epoch: 140 Train Loss: 0.2647 Val Loss: 0.3001 Acc: 0.8714 Pre: 0.9018 Recall: 0.8493 F1: 0.8748 Train AUC: 0.9564 Val AUC: 0.9439 Time: 13.11\n",
      "Epoch: 141 Train Loss: 0.2731 Val Loss: 0.2989 Acc: 0.8696 Pre: 0.9015 Recall: 0.8459 F1: 0.8728 Train AUC: 0.9523 Val AUC: 0.9440 Time: 12.75\n",
      "Epoch: 142 Train Loss: 0.2920 Val Loss: 0.3005 Acc: 0.8714 Pre: 0.9077 Recall: 0.8425 F1: 0.8739 Train AUC: 0.9476 Val AUC: 0.9433 Time: 13.36\n",
      "Epoch: 143 Train Loss: 0.2653 Val Loss: 0.3050 Acc: 0.8678 Pre: 0.9071 Recall: 0.8356 F1: 0.8699 Train AUC: 0.9547 Val AUC: 0.9422 Time: 13.35\n",
      "Epoch: 144 Train Loss: 0.2754 Val Loss: 0.3048 Acc: 0.8678 Pre: 0.9101 Recall: 0.8322 F1: 0.8694 Train AUC: 0.9530 Val AUC: 0.9416 Time: 14.14\n",
      "Epoch: 145 Train Loss: 0.2685 Val Loss: 0.3009 Acc: 0.8732 Pre: 0.9142 Recall: 0.8390 F1: 0.8750 Train AUC: 0.9550 Val AUC: 0.9426 Time: 13.43\n",
      "Epoch: 146 Train Loss: 0.2675 Val Loss: 0.2968 Acc: 0.8714 Pre: 0.9048 Recall: 0.8459 F1: 0.8743 Train AUC: 0.9557 Val AUC: 0.9437 Time: 13.12\n",
      "Epoch: 147 Train Loss: 0.2649 Val Loss: 0.2967 Acc: 0.8659 Pre: 0.8978 Recall: 0.8425 F1: 0.8693 Train AUC: 0.9568 Val AUC: 0.9443 Time: 12.33\n",
      "Epoch: 148 Train Loss: 0.2592 Val Loss: 0.2996 Acc: 0.8678 Pre: 0.9041 Recall: 0.8390 F1: 0.8703 Train AUC: 0.9602 Val AUC: 0.9443 Time: 12.30\n",
      "Epoch: 149 Train Loss: 0.2639 Val Loss: 0.3024 Acc: 0.8623 Pre: 0.9060 Recall: 0.8253 F1: 0.8638 Train AUC: 0.9583 Val AUC: 0.9434 Time: 13.14\n",
      "Epoch: 150 Train Loss: 0.2728 Val Loss: 0.3039 Acc: 0.8623 Pre: 0.9060 Recall: 0.8253 F1: 0.8638 Train AUC: 0.9568 Val AUC: 0.9433 Time: 14.32\n",
      "Epoch: 151 Train Loss: 0.2634 Val Loss: 0.3020 Acc: 0.8623 Pre: 0.9030 Recall: 0.8288 F1: 0.8643 Train AUC: 0.9569 Val AUC: 0.9437 Time: 13.39\n",
      "Epoch: 152 Train Loss: 0.2632 Val Loss: 0.2988 Acc: 0.8678 Pre: 0.9041 Recall: 0.8390 F1: 0.8703 Train AUC: 0.9566 Val AUC: 0.9442 Time: 13.41\n",
      "Epoch: 153 Train Loss: 0.2650 Val Loss: 0.2961 Acc: 0.8714 Pre: 0.8989 Recall: 0.8527 F1: 0.8752 Train AUC: 0.9551 Val AUC: 0.9445 Time: 14.82\n",
      "Epoch: 154 Train Loss: 0.2576 Val Loss: 0.2954 Acc: 0.8623 Pre: 0.8803 Recall: 0.8562 F1: 0.8681 Train AUC: 0.9589 Val AUC: 0.9450 Time: 12.91\n",
      "Epoch: 155 Train Loss: 0.2633 Val Loss: 0.2933 Acc: 0.8696 Pre: 0.8929 Recall: 0.8562 F1: 0.8741 Train AUC: 0.9593 Val AUC: 0.9451 Time: 12.49\n",
      "Epoch: 156 Train Loss: 0.2525 Val Loss: 0.2958 Acc: 0.8750 Pre: 0.9176 Recall: 0.8390 F1: 0.8766 Train AUC: 0.9609 Val AUC: 0.9453 Time: 11.62\n",
      "Epoch: 157 Train Loss: 0.2529 Val Loss: 0.2977 Acc: 0.8714 Pre: 0.9202 Recall: 0.8288 F1: 0.8721 Train AUC: 0.9622 Val AUC: 0.9456 Time: 11.39\n",
      "Epoch: 158 Train Loss: 0.2577 Val Loss: 0.2961 Acc: 0.8659 Pre: 0.9067 Recall: 0.8322 F1: 0.8679 Train AUC: 0.9613 Val AUC: 0.9459 Time: 11.92\n",
      "Epoch: 159 Train Loss: 0.2650 Val Loss: 0.2952 Acc: 0.8659 Pre: 0.9007 Recall: 0.8390 F1: 0.8688 Train AUC: 0.9569 Val AUC: 0.9463 Time: 12.32\n",
      "Epoch: 160 Train Loss: 0.2485 Val Loss: 0.2947 Acc: 0.8696 Pre: 0.9015 Recall: 0.8459 F1: 0.8728 Train AUC: 0.9623 Val AUC: 0.9461 Time: 12.73\n",
      "Epoch: 161 Train Loss: 0.2492 Val Loss: 0.2938 Acc: 0.8768 Pre: 0.9058 Recall: 0.8562 F1: 0.8803 Train AUC: 0.9618 Val AUC: 0.9460 Time: 13.39\n",
      "Epoch: 162 Train Loss: 0.2536 Val Loss: 0.2942 Acc: 0.8768 Pre: 0.9058 Recall: 0.8562 F1: 0.8803 Train AUC: 0.9588 Val AUC: 0.9456 Time: 14.07\n",
      "Epoch: 163 Train Loss: 0.2373 Val Loss: 0.2947 Acc: 0.8768 Pre: 0.9058 Recall: 0.8562 F1: 0.8803 Train AUC: 0.9652 Val AUC: 0.9453 Time: 14.41\n",
      "Epoch: 164 Train Loss: 0.2563 Val Loss: 0.2936 Acc: 0.8750 Pre: 0.9025 Recall: 0.8562 F1: 0.8787 Train AUC: 0.9592 Val AUC: 0.9457 Time: 12.91\n",
      "Epoch: 165 Train Loss: 0.2538 Val Loss: 0.2924 Acc: 0.8714 Pre: 0.8961 Recall: 0.8562 F1: 0.8757 Train AUC: 0.9605 Val AUC: 0.9461 Time: 12.04\n",
      "Epoch: 166 Train Loss: 0.2497 Val Loss: 0.2924 Acc: 0.8678 Pre: 0.8953 Recall: 0.8493 F1: 0.8717 Train AUC: 0.9611 Val AUC: 0.9465 Time: 11.76\n",
      "Epoch: 167 Train Loss: 0.2427 Val Loss: 0.2927 Acc: 0.8659 Pre: 0.8921 Recall: 0.8493 F1: 0.8702 Train AUC: 0.9643 Val AUC: 0.9469 Time: 12.28\n",
      "Epoch: 168 Train Loss: 0.2536 Val Loss: 0.2925 Acc: 0.8732 Pre: 0.9051 Recall: 0.8493 F1: 0.8763 Train AUC: 0.9610 Val AUC: 0.9473 Time: 12.25\n",
      "Epoch: 169 Train Loss: 0.2443 Val Loss: 0.2928 Acc: 0.8641 Pre: 0.9064 Recall: 0.8288 F1: 0.8658 Train AUC: 0.9627 Val AUC: 0.9477 Time: 12.56\n",
      "Epoch: 170 Train Loss: 0.2504 Val Loss: 0.2925 Acc: 0.8659 Pre: 0.9098 Recall: 0.8288 F1: 0.8674 Train AUC: 0.9614 Val AUC: 0.9478 Time: 13.08\n",
      "Epoch: 171 Train Loss: 0.2521 Val Loss: 0.2901 Acc: 0.8768 Pre: 0.9118 Recall: 0.8493 F1: 0.8794 Train AUC: 0.9597 Val AUC: 0.9479 Time: 13.63\n",
      "Epoch: 172 Train Loss: 0.2431 Val Loss: 0.2888 Acc: 0.8750 Pre: 0.9025 Recall: 0.8562 F1: 0.8787 Train AUC: 0.9637 Val AUC: 0.9476 Time: 14.35\n",
      "Epoch: 173 Train Loss: 0.2451 Val Loss: 0.2898 Acc: 0.8696 Pre: 0.8929 Recall: 0.8562 F1: 0.8741 Train AUC: 0.9637 Val AUC: 0.9473 Time: 13.58\n",
      "Epoch: 174 Train Loss: 0.2469 Val Loss: 0.2884 Acc: 0.8714 Pre: 0.8961 Recall: 0.8562 F1: 0.8757 Train AUC: 0.9632 Val AUC: 0.9478 Time: 12.92\n",
      "Epoch: 175 Train Loss: 0.2439 Val Loss: 0.2877 Acc: 0.8696 Pre: 0.9015 Recall: 0.8459 F1: 0.8728 Train AUC: 0.9639 Val AUC: 0.9481 Time: 11.90\n",
      "Epoch: 176 Train Loss: 0.2458 Val Loss: 0.2911 Acc: 0.8732 Pre: 0.9173 Recall: 0.8356 F1: 0.8746 Train AUC: 0.9630 Val AUC: 0.9479 Time: 11.49\n",
      "Epoch: 177 Train Loss: 0.2470 Val Loss: 0.2912 Acc: 0.8696 Pre: 0.9104 Recall: 0.8356 F1: 0.8714 Train AUC: 0.9632 Val AUC: 0.9476 Time: 12.06\n",
      "Epoch: 178 Train Loss: 0.2448 Val Loss: 0.2897 Acc: 0.8696 Pre: 0.9044 Recall: 0.8425 F1: 0.8723 Train AUC: 0.9638 Val AUC: 0.9478 Time: 12.47\n",
      "Epoch: 179 Train Loss: 0.2373 Val Loss: 0.2877 Acc: 0.8678 Pre: 0.8953 Recall: 0.8493 F1: 0.8717 Train AUC: 0.9662 Val AUC: 0.9482 Time: 12.88\n",
      "Epoch: 180 Train Loss: 0.2360 Val Loss: 0.2873 Acc: 0.8714 Pre: 0.8989 Recall: 0.8527 F1: 0.8752 Train AUC: 0.9666 Val AUC: 0.9477 Time: 14.11\n",
      "Epoch: 181 Train Loss: 0.2435 Val Loss: 0.2890 Acc: 0.8714 Pre: 0.9018 Recall: 0.8493 F1: 0.8748 Train AUC: 0.9651 Val AUC: 0.9475 Time: 14.40\n",
      "Epoch: 182 Train Loss: 0.2395 Val Loss: 0.2892 Acc: 0.8678 Pre: 0.8925 Recall: 0.8527 F1: 0.8722 Train AUC: 0.9651 Val AUC: 0.9480 Time: 14.80\n",
      "Epoch: 183 Train Loss: 0.2460 Val Loss: 0.2889 Acc: 0.8623 Pre: 0.8803 Recall: 0.8562 F1: 0.8681 Train AUC: 0.9628 Val AUC: 0.9485 Time: 13.66\n",
      "Epoch: 184 Train Loss: 0.2358 Val Loss: 0.2877 Acc: 0.8623 Pre: 0.8857 Recall: 0.8493 F1: 0.8671 Train AUC: 0.9667 Val AUC: 0.9492 Time: 13.31\n",
      "Epoch: 185 Train Loss: 0.2362 Val Loss: 0.2883 Acc: 0.8678 Pre: 0.9011 Recall: 0.8425 F1: 0.8708 Train AUC: 0.9667 Val AUC: 0.9491 Time: 13.40\n",
      "Epoch: 186 Train Loss: 0.2273 Val Loss: 0.2897 Acc: 0.8732 Pre: 0.9111 Recall: 0.8425 F1: 0.8754 Train AUC: 0.9679 Val AUC: 0.9481 Time: 11.40\n",
      "Epoch: 187 Train Loss: 0.2328 Val Loss: 0.2881 Acc: 0.8714 Pre: 0.9077 Recall: 0.8425 F1: 0.8739 Train AUC: 0.9675 Val AUC: 0.9481 Time: 11.80\n",
      "Epoch: 188 Train Loss: 0.2360 Val Loss: 0.2853 Acc: 0.8678 Pre: 0.9011 Recall: 0.8425 F1: 0.8708 Train AUC: 0.9663 Val AUC: 0.9486 Time: 13.58\n",
      "Epoch: 189 Train Loss: 0.2325 Val Loss: 0.2862 Acc: 0.8678 Pre: 0.8897 Recall: 0.8562 F1: 0.8726 Train AUC: 0.9674 Val AUC: 0.9485 Time: 12.54\n",
      "Epoch: 190 Train Loss: 0.2375 Val Loss: 0.2889 Acc: 0.8732 Pre: 0.9081 Recall: 0.8459 F1: 0.8759 Train AUC: 0.9662 Val AUC: 0.9473 Time: 13.44\n",
      "Epoch: 191 Train Loss: 0.2295 Val Loss: 0.2894 Acc: 0.8732 Pre: 0.9111 Recall: 0.8425 F1: 0.8754 Train AUC: 0.9673 Val AUC: 0.9478 Time: 13.85\n",
      "Epoch: 192 Train Loss: 0.2401 Val Loss: 0.2852 Acc: 0.8714 Pre: 0.9018 Recall: 0.8493 F1: 0.8748 Train AUC: 0.9640 Val AUC: 0.9492 Time: 14.41\n",
      "Epoch: 193 Train Loss: 0.2365 Val Loss: 0.2852 Acc: 0.8605 Pre: 0.8881 Recall: 0.8425 F1: 0.8647 Train AUC: 0.9662 Val AUC: 0.9502 Time: 15.81\n",
      "Epoch: 194 Train Loss: 0.2410 Val Loss: 0.2865 Acc: 0.8696 Pre: 0.9044 Recall: 0.8425 F1: 0.8723 Train AUC: 0.9658 Val AUC: 0.9492 Time: 16.10\n",
      "Epoch: 195 Train Loss: 0.2349 Val Loss: 0.2877 Acc: 0.8714 Pre: 0.9077 Recall: 0.8425 F1: 0.8739 Train AUC: 0.9666 Val AUC: 0.9489 Time: 14.24\n",
      "Epoch: 196 Train Loss: 0.2343 Val Loss: 0.2846 Acc: 0.8696 Pre: 0.9044 Recall: 0.8425 F1: 0.8723 Train AUC: 0.9667 Val AUC: 0.9494 Time: 12.18\n",
      "Epoch: 197 Train Loss: 0.2371 Val Loss: 0.2823 Acc: 0.8678 Pre: 0.9011 Recall: 0.8425 F1: 0.8708 Train AUC: 0.9664 Val AUC: 0.9498 Time: 12.42\n",
      "Epoch: 198 Train Loss: 0.2222 Val Loss: 0.2832 Acc: 0.8659 Pre: 0.8921 Recall: 0.8493 F1: 0.8702 Train AUC: 0.9700 Val AUC: 0.9500 Time: 13.62\n",
      "Epoch: 199 Train Loss: 0.2342 Val Loss: 0.2838 Acc: 0.8659 Pre: 0.8949 Recall: 0.8459 F1: 0.8697 Train AUC: 0.9686 Val AUC: 0.9497 Time: 13.00\n",
      "Epoch: 200 Train Loss: 0.2301 Val Loss: 0.2864 Acc: 0.8732 Pre: 0.9051 Recall: 0.8493 F1: 0.8763 Train AUC: 0.9680 Val AUC: 0.9500 Time: 13.31\n",
      "Epoch: 201 Train Loss: 0.2259 Val Loss: 0.2910 Acc: 0.8750 Pre: 0.9084 Recall: 0.8493 F1: 0.8779 Train AUC: 0.9688 Val AUC: 0.9501 Time: 13.79\n",
      "Epoch: 202 Train Loss: 0.2277 Val Loss: 0.2893 Acc: 0.8768 Pre: 0.9148 Recall: 0.8459 F1: 0.8790 Train AUC: 0.9678 Val AUC: 0.9505 Time: 14.56\n",
      "Epoch: 203 Train Loss: 0.2314 Val Loss: 0.2846 Acc: 0.8714 Pre: 0.9077 Recall: 0.8425 F1: 0.8739 Train AUC: 0.9667 Val AUC: 0.9498 Time: 15.48\n",
      "Epoch: 204 Train Loss: 0.2335 Val Loss: 0.2855 Acc: 0.8587 Pre: 0.8821 Recall: 0.8459 F1: 0.8636 Train AUC: 0.9667 Val AUC: 0.9491 Time: 16.17\n",
      "Epoch: 205 Train Loss: 0.2240 Val Loss: 0.2854 Acc: 0.8623 Pre: 0.8803 Recall: 0.8562 F1: 0.8681 Train AUC: 0.9712 Val AUC: 0.9487 Time: 19.71\n",
      "Epoch: 206 Train Loss: 0.2223 Val Loss: 0.2842 Acc: 0.8659 Pre: 0.8949 Recall: 0.8459 F1: 0.8697 Train AUC: 0.9725 Val AUC: 0.9493 Time: 12.78\n",
      "Epoch: 207 Train Loss: 0.2278 Val Loss: 0.2909 Acc: 0.8786 Pre: 0.9213 Recall: 0.8425 F1: 0.8801 Train AUC: 0.9682 Val AUC: 0.9493 Time: 13.33\n",
      "Epoch: 208 Train Loss: 0.2271 Val Loss: 0.2861 Acc: 0.8714 Pre: 0.9018 Recall: 0.8493 F1: 0.8748 Train AUC: 0.9687 Val AUC: 0.9504 Time: 13.89\n",
      "Epoch: 209 Train Loss: 0.2308 Val Loss: 0.2860 Acc: 0.8623 Pre: 0.8699 Recall: 0.8699 F1: 0.8699 Train AUC: 0.9677 Val AUC: 0.9515 Time: 14.95\n",
      "Epoch: 210 Train Loss: 0.2310 Val Loss: 0.2833 Acc: 0.8641 Pre: 0.8754 Recall: 0.8664 F1: 0.8709 Train AUC: 0.9687 Val AUC: 0.9514 Time: 14.06\n",
      "Epoch: 211 Train Loss: 0.2235 Val Loss: 0.2826 Acc: 0.8659 Pre: 0.9007 Recall: 0.8390 F1: 0.8688 Train AUC: 0.9719 Val AUC: 0.9498 Time: 12.86\n",
      "Epoch: 212 Train Loss: 0.2235 Val Loss: 0.2944 Acc: 0.8696 Pre: 0.9198 Recall: 0.8253 F1: 0.8700 Train AUC: 0.9702 Val AUC: 0.9488 Time: 12.18\n",
      "Epoch: 213 Train Loss: 0.2361 Val Loss: 0.2865 Acc: 0.8623 Pre: 0.9000 Recall: 0.8322 F1: 0.8648 Train AUC: 0.9688 Val AUC: 0.9497 Time: 12.87\n",
      "Epoch: 214 Train Loss: 0.2302 Val Loss: 0.2810 Acc: 0.8623 Pre: 0.8885 Recall: 0.8459 F1: 0.8667 Train AUC: 0.9699 Val AUC: 0.9510 Time: 12.43\n",
      "Epoch: 215 Train Loss: 0.2218 Val Loss: 0.2801 Acc: 0.8605 Pre: 0.8853 Recall: 0.8459 F1: 0.8651 Train AUC: 0.9721 Val AUC: 0.9530 Time: 13.01\n",
      "Epoch: 216 Train Loss: 0.2278 Val Loss: 0.2776 Acc: 0.8696 Pre: 0.8986 Recall: 0.8493 F1: 0.8732 Train AUC: 0.9708 Val AUC: 0.9528 Time: 13.83\n",
      "Epoch: 217 Train Loss: 0.2273 Val Loss: 0.2870 Acc: 0.8804 Pre: 0.9248 Recall: 0.8425 F1: 0.8817 Train AUC: 0.9694 Val AUC: 0.9512 Time: 14.97\n",
      "Epoch: 218 Train Loss: 0.2247 Val Loss: 0.2866 Acc: 0.8786 Pre: 0.9213 Recall: 0.8425 F1: 0.8801 Train AUC: 0.9696 Val AUC: 0.9504 Time: 16.82\n",
      "Epoch: 219 Train Loss: 0.2244 Val Loss: 0.2791 Acc: 0.8714 Pre: 0.8961 Recall: 0.8562 F1: 0.8757 Train AUC: 0.9702 Val AUC: 0.9516 Time: 14.79\n",
      "Epoch: 220 Train Loss: 0.2150 Val Loss: 0.2793 Acc: 0.8714 Pre: 0.8877 Recall: 0.8664 F1: 0.8769 Train AUC: 0.9718 Val AUC: 0.9527 Time: 13.25\n",
      "Epoch: 221 Train Loss: 0.2276 Val Loss: 0.2770 Acc: 0.8623 Pre: 0.8913 Recall: 0.8425 F1: 0.8662 Train AUC: 0.9694 Val AUC: 0.9536 Time: 12.56\n",
      "Epoch: 222 Train Loss: 0.2216 Val Loss: 0.2818 Acc: 0.8659 Pre: 0.8978 Recall: 0.8425 F1: 0.8693 Train AUC: 0.9702 Val AUC: 0.9524 Time: 12.01\n",
      "Epoch: 223 Train Loss: 0.2123 Val Loss: 0.2853 Acc: 0.8641 Pre: 0.9004 Recall: 0.8356 F1: 0.8668 Train AUC: 0.9738 Val AUC: 0.9517 Time: 12.56\n",
      "Epoch: 224 Train Loss: 0.2215 Val Loss: 0.2824 Acc: 0.8659 Pre: 0.8978 Recall: 0.8425 F1: 0.8693 Train AUC: 0.9709 Val AUC: 0.9511 Time: 13.83\n",
      "Epoch: 225 Train Loss: 0.2155 Val Loss: 0.2789 Acc: 0.8696 Pre: 0.8957 Recall: 0.8527 F1: 0.8737 Train AUC: 0.9731 Val AUC: 0.9509 Time: 13.59\n",
      "Epoch: 226 Train Loss: 0.2286 Val Loss: 0.2797 Acc: 0.8714 Pre: 0.8824 Recall: 0.8733 F1: 0.8778 Train AUC: 0.9689 Val AUC: 0.9506 Time: 14.15\n",
      "Epoch: 227 Train Loss: 0.2235 Val Loss: 0.2805 Acc: 0.8714 Pre: 0.8877 Recall: 0.8664 F1: 0.8769 Train AUC: 0.9703 Val AUC: 0.9505 Time: 14.86\n",
      "Epoch: 228 Train Loss: 0.2222 Val Loss: 0.2822 Acc: 0.8750 Pre: 0.8968 Recall: 0.8630 F1: 0.8796 Train AUC: 0.9698 Val AUC: 0.9507 Time: 15.50\n",
      "Epoch: 229 Train Loss: 0.2144 Val Loss: 0.2832 Acc: 0.8768 Pre: 0.9088 Recall: 0.8527 F1: 0.8799 Train AUC: 0.9720 Val AUC: 0.9519 Time: 13.58\n",
      "Epoch: 230 Train Loss: 0.2154 Val Loss: 0.2805 Acc: 0.8750 Pre: 0.8996 Recall: 0.8596 F1: 0.8792 Train AUC: 0.9714 Val AUC: 0.9527 Time: 13.45\n",
      "Epoch: 231 Train Loss: 0.2222 Val Loss: 0.2785 Acc: 0.8678 Pre: 0.8789 Recall: 0.8699 F1: 0.8744 Train AUC: 0.9709 Val AUC: 0.9527 Time: 13.74\n",
      "Epoch: 232 Train Loss: 0.2124 Val Loss: 0.2785 Acc: 0.8696 Pre: 0.8819 Recall: 0.8699 F1: 0.8759 Train AUC: 0.9743 Val AUC: 0.9521 Time: 13.19\n",
      "Epoch: 233 Train Loss: 0.2069 Val Loss: 0.2798 Acc: 0.8569 Pre: 0.8845 Recall: 0.8390 F1: 0.8612 Train AUC: 0.9755 Val AUC: 0.9511 Time: 13.57\n",
      "Epoch: 234 Train Loss: 0.2164 Val Loss: 0.2832 Acc: 0.8659 Pre: 0.9037 Recall: 0.8356 F1: 0.8683 Train AUC: 0.9722 Val AUC: 0.9513 Time: 17.16\n",
      "Epoch: 235 Train Loss: 0.2226 Val Loss: 0.2788 Acc: 0.8750 Pre: 0.8968 Recall: 0.8630 F1: 0.8796 Train AUC: 0.9726 Val AUC: 0.9524 Time: 14.51\n",
      "Epoch: 236 Train Loss: 0.2134 Val Loss: 0.2785 Acc: 0.8696 Pre: 0.8819 Recall: 0.8699 F1: 0.8759 Train AUC: 0.9721 Val AUC: 0.9522 Time: 13.09\n",
      "Epoch: 237 Train Loss: 0.2185 Val Loss: 0.2783 Acc: 0.8714 Pre: 0.8824 Recall: 0.8733 F1: 0.8778 Train AUC: 0.9717 Val AUC: 0.9524 Time: 12.74\n",
      "Epoch: 238 Train Loss: 0.2163 Val Loss: 0.2766 Acc: 0.8732 Pre: 0.8936 Recall: 0.8630 F1: 0.8780 Train AUC: 0.9724 Val AUC: 0.9529 Time: 14.07\n",
      "Epoch: 239 Train Loss: 0.2075 Val Loss: 0.2771 Acc: 0.8714 Pre: 0.8989 Recall: 0.8527 F1: 0.8752 Train AUC: 0.9747 Val AUC: 0.9530 Time: 13.41\n",
      "Epoch: 240 Train Loss: 0.2095 Val Loss: 0.2760 Acc: 0.8623 Pre: 0.8913 Recall: 0.8425 F1: 0.8662 Train AUC: 0.9734 Val AUC: 0.9532 Time: 13.94\n",
      "Epoch: 241 Train Loss: 0.2132 Val Loss: 0.2754 Acc: 0.8659 Pre: 0.8921 Recall: 0.8493 F1: 0.8702 Train AUC: 0.9731 Val AUC: 0.9536 Time: 14.56\n",
      "Epoch: 242 Train Loss: 0.1999 Val Loss: 0.2756 Acc: 0.8714 Pre: 0.8905 Recall: 0.8630 F1: 0.8765 Train AUC: 0.9763 Val AUC: 0.9535 Time: 12.94\n",
      "Epoch: 243 Train Loss: 0.2076 Val Loss: 0.2758 Acc: 0.8750 Pre: 0.8968 Recall: 0.8630 F1: 0.8796 Train AUC: 0.9738 Val AUC: 0.9537 Time: 12.60\n",
      "Epoch: 244 Train Loss: 0.2038 Val Loss: 0.2768 Acc: 0.8714 Pre: 0.9018 Recall: 0.8493 F1: 0.8748 Train AUC: 0.9750 Val AUC: 0.9533 Time: 13.91\n",
      "Epoch: 245 Train Loss: 0.2113 Val Loss: 0.2759 Acc: 0.8678 Pre: 0.9011 Recall: 0.8425 F1: 0.8708 Train AUC: 0.9729 Val AUC: 0.9534 Time: 13.97\n",
      "Epoch: 246 Train Loss: 0.2071 Val Loss: 0.2726 Acc: 0.8696 Pre: 0.8901 Recall: 0.8596 F1: 0.8746 Train AUC: 0.9747 Val AUC: 0.9538 Time: 14.67\n",
      "Epoch: 247 Train Loss: 0.2105 Val Loss: 0.2713 Acc: 0.8732 Pre: 0.8908 Recall: 0.8664 F1: 0.8785 Train AUC: 0.9738 Val AUC: 0.9548 Time: 13.54\n",
      "Epoch: 248 Train Loss: 0.2075 Val Loss: 0.2727 Acc: 0.8714 Pre: 0.8905 Recall: 0.8630 F1: 0.8765 Train AUC: 0.9745 Val AUC: 0.9549 Time: 12.40\n",
      "Epoch: 249 Train Loss: 0.2057 Val Loss: 0.2748 Acc: 0.8750 Pre: 0.8968 Recall: 0.8630 F1: 0.8796 Train AUC: 0.9745 Val AUC: 0.9549 Time: 12.32\n",
      "Epoch: 250 Train Loss: 0.2035 Val Loss: 0.2748 Acc: 0.8750 Pre: 0.8968 Recall: 0.8630 F1: 0.8796 Train AUC: 0.9755 Val AUC: 0.9545 Time: 13.33\n",
      "Epoch: 251 Train Loss: 0.2021 Val Loss: 0.2749 Acc: 0.8750 Pre: 0.9025 Recall: 0.8562 F1: 0.8787 Train AUC: 0.9752 Val AUC: 0.9542 Time: 13.32\n",
      "Epoch: 252 Train Loss: 0.2024 Val Loss: 0.2758 Acc: 0.8750 Pre: 0.9025 Recall: 0.8562 F1: 0.8787 Train AUC: 0.9755 Val AUC: 0.9534 Time: 13.77\n",
      "Epoch: 253 Train Loss: 0.2104 Val Loss: 0.2769 Acc: 0.8786 Pre: 0.9032 Recall: 0.8630 F1: 0.8827 Train AUC: 0.9735 Val AUC: 0.9531 Time: 15.40\n",
      "Epoch: 254 Train Loss: 0.1966 Val Loss: 0.2766 Acc: 0.8714 Pre: 0.8824 Recall: 0.8733 F1: 0.8778 Train AUC: 0.9771 Val AUC: 0.9535 Time: 16.05\n",
      "Epoch: 255 Train Loss: 0.2033 Val Loss: 0.2749 Acc: 0.8732 Pre: 0.8854 Recall: 0.8733 F1: 0.8793 Train AUC: 0.9750 Val AUC: 0.9541 Time: 12.49\n",
      "Epoch: 256 Train Loss: 0.2039 Val Loss: 0.2731 Acc: 0.8750 Pre: 0.8912 Recall: 0.8699 F1: 0.8804 Train AUC: 0.9749 Val AUC: 0.9544 Time: 12.24\n",
      "Epoch: 257 Train Loss: 0.1911 Val Loss: 0.2739 Acc: 0.8696 Pre: 0.8901 Recall: 0.8596 F1: 0.8746 Train AUC: 0.9779 Val AUC: 0.9543 Time: 12.32\n",
      "Epoch: 258 Train Loss: 0.2012 Val Loss: 0.2757 Acc: 0.8641 Pre: 0.8889 Recall: 0.8493 F1: 0.8687 Train AUC: 0.9755 Val AUC: 0.9539 Time: 13.20\n",
      "Epoch: 259 Train Loss: 0.2001 Val Loss: 0.2722 Acc: 0.8678 Pre: 0.8869 Recall: 0.8596 F1: 0.8730 Train AUC: 0.9775 Val AUC: 0.9547 Time: 14.12\n",
      "Epoch: 260 Train Loss: 0.2019 Val Loss: 0.2707 Acc: 0.8659 Pre: 0.8838 Recall: 0.8596 F1: 0.8715 Train AUC: 0.9761 Val AUC: 0.9548 Time: 14.22\n",
      "Epoch: 261 Train Loss: 0.2017 Val Loss: 0.2715 Acc: 0.8750 Pre: 0.8940 Recall: 0.8664 F1: 0.8800 Train AUC: 0.9758 Val AUC: 0.9545 Time: 14.17\n",
      "Epoch: 262 Train Loss: 0.2016 Val Loss: 0.2731 Acc: 0.8768 Pre: 0.9000 Recall: 0.8630 F1: 0.8811 Train AUC: 0.9756 Val AUC: 0.9544 Time: 13.29\n",
      "Epoch: 263 Train Loss: 0.2052 Val Loss: 0.2711 Acc: 0.8732 Pre: 0.8881 Recall: 0.8699 F1: 0.8789 Train AUC: 0.9743 Val AUC: 0.9549 Time: 12.98\n",
      "Epoch: 264 Train Loss: 0.2065 Val Loss: 0.2701 Acc: 0.8678 Pre: 0.8815 Recall: 0.8664 F1: 0.8739 Train AUC: 0.9739 Val AUC: 0.9557 Time: 12.89\n",
      "Epoch: 265 Train Loss: 0.1993 Val Loss: 0.2720 Acc: 0.8696 Pre: 0.8846 Recall: 0.8664 F1: 0.8754 Train AUC: 0.9768 Val AUC: 0.9554 Time: 17.15\n",
      "Epoch: 266 Train Loss: 0.2011 Val Loss: 0.2739 Acc: 0.8696 Pre: 0.8901 Recall: 0.8596 F1: 0.8746 Train AUC: 0.9762 Val AUC: 0.9553 Time: 15.33\n",
      "Epoch: 267 Train Loss: 0.2005 Val Loss: 0.2723 Acc: 0.8678 Pre: 0.8869 Recall: 0.8596 F1: 0.8730 Train AUC: 0.9761 Val AUC: 0.9557 Time: 14.28\n",
      "Epoch: 268 Train Loss: 0.1939 Val Loss: 0.2717 Acc: 0.8714 Pre: 0.8850 Recall: 0.8699 F1: 0.8774 Train AUC: 0.9773 Val AUC: 0.9545 Time: 15.29\n",
      "Epoch: 269 Train Loss: 0.1991 Val Loss: 0.2712 Acc: 0.8768 Pre: 0.8889 Recall: 0.8767 F1: 0.8828 Train AUC: 0.9765 Val AUC: 0.9547 Time: 14.17\n",
      "Epoch: 270 Train Loss: 0.1970 Val Loss: 0.2705 Acc: 0.8786 Pre: 0.8975 Recall: 0.8699 F1: 0.8835 Train AUC: 0.9764 Val AUC: 0.9557 Time: 14.79\n",
      "Epoch: 271 Train Loss: 0.1930 Val Loss: 0.2718 Acc: 0.8768 Pre: 0.8972 Recall: 0.8664 F1: 0.8815 Train AUC: 0.9781 Val AUC: 0.9558 Time: 14.80\n",
      "Epoch: 272 Train Loss: 0.1941 Val Loss: 0.2722 Acc: 0.8786 Pre: 0.8975 Recall: 0.8699 F1: 0.8835 Train AUC: 0.9771 Val AUC: 0.9557 Time: 13.55\n",
      "Epoch: 273 Train Loss: 0.2014 Val Loss: 0.2709 Acc: 0.8786 Pre: 0.8975 Recall: 0.8699 F1: 0.8835 Train AUC: 0.9759 Val AUC: 0.9555 Time: 14.10\n",
      "Epoch: 274 Train Loss: 0.1955 Val Loss: 0.2697 Acc: 0.8786 Pre: 0.8947 Recall: 0.8733 F1: 0.8839 Train AUC: 0.9769 Val AUC: 0.9560 Time: 13.97\n",
      "Epoch: 275 Train Loss: 0.1936 Val Loss: 0.2696 Acc: 0.8750 Pre: 0.8912 Recall: 0.8699 F1: 0.8804 Train AUC: 0.9779 Val AUC: 0.9555 Time: 14.63\n",
      "Epoch: 276 Train Loss: 0.1960 Val Loss: 0.2683 Acc: 0.8750 Pre: 0.8885 Recall: 0.8733 F1: 0.8808 Train AUC: 0.9778 Val AUC: 0.9558 Time: 14.41\n",
      "Epoch: 277 Train Loss: 0.1962 Val Loss: 0.2677 Acc: 0.8714 Pre: 0.8877 Recall: 0.8664 F1: 0.8769 Train AUC: 0.9772 Val AUC: 0.9565 Time: 13.40\n",
      "Epoch: 278 Train Loss: 0.1956 Val Loss: 0.2714 Acc: 0.8804 Pre: 0.9007 Recall: 0.8699 F1: 0.8850 Train AUC: 0.9781 Val AUC: 0.9565 Time: 12.98\n",
      "Epoch: 279 Train Loss: 0.1894 Val Loss: 0.2752 Acc: 0.8804 Pre: 0.9007 Recall: 0.8699 F1: 0.8850 Train AUC: 0.9783 Val AUC: 0.9567 Time: 13.04\n",
      "Epoch: 280 Train Loss: 0.1963 Val Loss: 0.2700 Acc: 0.8786 Pre: 0.8975 Recall: 0.8699 F1: 0.8835 Train AUC: 0.9762 Val AUC: 0.9564 Time: 13.70\n",
      "Epoch: 281 Train Loss: 0.1960 Val Loss: 0.2681 Acc: 0.8859 Pre: 0.8855 Recall: 0.9007 F1: 0.8930 Train AUC: 0.9768 Val AUC: 0.9563 Time: 13.46\n",
      "Epoch: 282 Train Loss: 0.1956 Val Loss: 0.2707 Acc: 0.8750 Pre: 0.8858 Recall: 0.8767 F1: 0.8812 Train AUC: 0.9778 Val AUC: 0.9545 Time: 13.53\n",
      "Epoch: 283 Train Loss: 0.1875 Val Loss: 0.2769 Acc: 0.8569 Pre: 0.8845 Recall: 0.8390 F1: 0.8612 Train AUC: 0.9794 Val AUC: 0.9547 Time: 14.54\n",
      "Epoch: 284 Train Loss: 0.1973 Val Loss: 0.2721 Acc: 0.8659 Pre: 0.8811 Recall: 0.8630 F1: 0.8720 Train AUC: 0.9797 Val AUC: 0.9561 Time: 14.60\n",
      "Epoch: 285 Train Loss: 0.1864 Val Loss: 0.2720 Acc: 0.8659 Pre: 0.8759 Recall: 0.8699 F1: 0.8729 Train AUC: 0.9792 Val AUC: 0.9569 Time: 14.31\n",
      "Epoch: 286 Train Loss: 0.1906 Val Loss: 0.2725 Acc: 0.8641 Pre: 0.8678 Recall: 0.8767 F1: 0.8722 Train AUC: 0.9787 Val AUC: 0.9571 Time: 13.52\n",
      "Epoch: 287 Train Loss: 0.1890 Val Loss: 0.2704 Acc: 0.8696 Pre: 0.8819 Recall: 0.8699 F1: 0.8759 Train AUC: 0.9791 Val AUC: 0.9556 Time: 13.15\n",
      "Epoch: 288 Train Loss: 0.1820 Val Loss: 0.2700 Acc: 0.8750 Pre: 0.8940 Recall: 0.8664 F1: 0.8800 Train AUC: 0.9792 Val AUC: 0.9559 Time: 13.03\n",
      "Epoch: 289 Train Loss: 0.1918 Val Loss: 0.2676 Acc: 0.8714 Pre: 0.8850 Recall: 0.8699 F1: 0.8774 Train AUC: 0.9776 Val AUC: 0.9562 Time: 13.04\n",
      "Epoch: 290 Train Loss: 0.1887 Val Loss: 0.2667 Acc: 0.8750 Pre: 0.8858 Recall: 0.8767 F1: 0.8812 Train AUC: 0.9799 Val AUC: 0.9575 Time: 13.62\n",
      "Epoch: 291 Train Loss: 0.1963 Val Loss: 0.2704 Acc: 0.8732 Pre: 0.8881 Recall: 0.8699 F1: 0.8789 Train AUC: 0.9773 Val AUC: 0.9574 Time: 14.19\n",
      "Epoch: 292 Train Loss: 0.1897 Val Loss: 0.2718 Acc: 0.8750 Pre: 0.8912 Recall: 0.8699 F1: 0.8804 Train AUC: 0.9784 Val AUC: 0.9573 Time: 13.69\n",
      "Epoch: 293 Train Loss: 0.1926 Val Loss: 0.2693 Acc: 0.8732 Pre: 0.8854 Recall: 0.8733 F1: 0.8793 Train AUC: 0.9772 Val AUC: 0.9566 Time: 13.58\n",
      "Epoch: 294 Train Loss: 0.1894 Val Loss: 0.2716 Acc: 0.8750 Pre: 0.8805 Recall: 0.8836 F1: 0.8821 Train AUC: 0.9785 Val AUC: 0.9552 Time: 13.86\n",
      "Epoch: 295 Train Loss: 0.1790 Val Loss: 0.2723 Acc: 0.8804 Pre: 0.8818 Recall: 0.8938 F1: 0.8878 Train AUC: 0.9809 Val AUC: 0.9552 Time: 13.70\n",
      "Epoch: 296 Train Loss: 0.1802 Val Loss: 0.2688 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9811 Val AUC: 0.9563 Time: 13.02\n",
      "Epoch: 297 Train Loss: 0.1901 Val Loss: 0.2665 Acc: 0.8696 Pre: 0.8819 Recall: 0.8699 F1: 0.8759 Train AUC: 0.9792 Val AUC: 0.9580 Time: 12.44\n",
      "Epoch: 298 Train Loss: 0.1866 Val Loss: 0.2691 Acc: 0.8732 Pre: 0.8908 Recall: 0.8664 F1: 0.8785 Train AUC: 0.9787 Val AUC: 0.9579 Time: 12.58\n",
      "Epoch: 299 Train Loss: 0.1910 Val Loss: 0.2701 Acc: 0.8732 Pre: 0.8964 Recall: 0.8596 F1: 0.8776 Train AUC: 0.9776 Val AUC: 0.9579 Time: 13.71\n",
      "Epoch: 300 Train Loss: 0.1861 Val Loss: 0.2650 Acc: 0.8768 Pre: 0.8836 Recall: 0.8836 F1: 0.8836 Train AUC: 0.9798 Val AUC: 0.9586 Time: 13.65\n",
      "Epoch: 301 Train Loss: 0.1867 Val Loss: 0.2665 Acc: 0.8895 Pre: 0.8889 Recall: 0.9041 F1: 0.8964 Train AUC: 0.9796 Val AUC: 0.9579 Time: 14.25\n",
      "Epoch: 302 Train Loss: 0.1889 Val Loss: 0.2697 Acc: 0.8732 Pre: 0.8881 Recall: 0.8699 F1: 0.8789 Train AUC: 0.9786 Val AUC: 0.9558 Time: 14.46\n",
      "Epoch: 303 Train Loss: 0.1922 Val Loss: 0.2716 Acc: 0.8750 Pre: 0.8968 Recall: 0.8630 F1: 0.8796 Train AUC: 0.9779 Val AUC: 0.9556 Time: 13.57\n",
      "Epoch: 304 Train Loss: 0.1811 Val Loss: 0.2676 Acc: 0.8678 Pre: 0.8815 Recall: 0.8664 F1: 0.8739 Train AUC: 0.9801 Val AUC: 0.9565 Time: 13.29\n",
      "Epoch: 305 Train Loss: 0.1787 Val Loss: 0.2673 Acc: 0.8714 Pre: 0.8824 Recall: 0.8733 F1: 0.8778 Train AUC: 0.9814 Val AUC: 0.9570 Time: 13.52\n",
      "Epoch: 306 Train Loss: 0.1800 Val Loss: 0.2669 Acc: 0.8714 Pre: 0.8850 Recall: 0.8699 F1: 0.8774 Train AUC: 0.9825 Val AUC: 0.9577 Time: 13.84\n",
      "Epoch: 307 Train Loss: 0.1832 Val Loss: 0.2673 Acc: 0.8768 Pre: 0.8944 Recall: 0.8699 F1: 0.8819 Train AUC: 0.9805 Val AUC: 0.9584 Time: 13.14\n",
      "Epoch: 308 Train Loss: 0.1815 Val Loss: 0.2660 Acc: 0.8877 Pre: 0.9049 Recall: 0.8801 F1: 0.8924 Train AUC: 0.9802 Val AUC: 0.9587 Time: 13.97\n",
      "Epoch: 309 Train Loss: 0.1750 Val Loss: 0.2651 Acc: 0.8913 Pre: 0.9028 Recall: 0.8904 F1: 0.8966 Train AUC: 0.9818 Val AUC: 0.9584 Time: 15.77\n",
      "Epoch: 310 Train Loss: 0.1784 Val Loss: 0.2646 Acc: 0.8895 Pre: 0.8969 Recall: 0.8938 F1: 0.8954 Train AUC: 0.9806 Val AUC: 0.9582 Time: 13.63\n",
      "Epoch: 311 Train Loss: 0.1805 Val Loss: 0.2647 Acc: 0.8714 Pre: 0.8932 Recall: 0.8596 F1: 0.8761 Train AUC: 0.9803 Val AUC: 0.9575 Time: 12.74\n",
      "Epoch: 312 Train Loss: 0.1823 Val Loss: 0.2665 Acc: 0.8732 Pre: 0.8854 Recall: 0.8733 F1: 0.8793 Train AUC: 0.9806 Val AUC: 0.9578 Time: 11.75\n",
      "Epoch: 313 Train Loss: 0.1783 Val Loss: 0.2699 Acc: 0.8696 Pre: 0.8793 Recall: 0.8733 F1: 0.8763 Train AUC: 0.9812 Val AUC: 0.9574 Time: 12.08\n",
      "Epoch: 314 Train Loss: 0.1759 Val Loss: 0.2678 Acc: 0.8732 Pre: 0.8828 Recall: 0.8767 F1: 0.8797 Train AUC: 0.9825 Val AUC: 0.9575 Time: 12.63\n",
      "Epoch: 315 Train Loss: 0.1761 Val Loss: 0.2667 Acc: 0.8732 Pre: 0.8854 Recall: 0.8733 F1: 0.8793 Train AUC: 0.9810 Val AUC: 0.9571 Time: 13.00\n",
      "Epoch: 316 Train Loss: 0.1740 Val Loss: 0.2658 Acc: 0.8895 Pre: 0.8863 Recall: 0.9075 F1: 0.8968 Train AUC: 0.9826 Val AUC: 0.9572 Time: 13.54\n",
      "Epoch: 317 Train Loss: 0.1730 Val Loss: 0.2633 Acc: 0.8913 Pre: 0.8919 Recall: 0.9041 F1: 0.8980 Train AUC: 0.9824 Val AUC: 0.9587 Time: 14.28\n",
      "Epoch: 318 Train Loss: 0.1800 Val Loss: 0.2657 Acc: 0.8768 Pre: 0.9029 Recall: 0.8596 F1: 0.8807 Train AUC: 0.9810 Val AUC: 0.9596 Time: 14.19\n",
      "Epoch: 319 Train Loss: 0.1848 Val Loss: 0.2650 Acc: 0.8895 Pre: 0.9053 Recall: 0.8836 F1: 0.8943 Train AUC: 0.9794 Val AUC: 0.9598 Time: 13.20\n",
      "Epoch: 320 Train Loss: 0.1796 Val Loss: 0.2636 Acc: 0.8804 Pre: 0.8844 Recall: 0.8904 F1: 0.8874 Train AUC: 0.9793 Val AUC: 0.9595 Time: 12.31\n",
      "Epoch: 321 Train Loss: 0.1767 Val Loss: 0.2619 Acc: 0.8804 Pre: 0.8870 Recall: 0.8870 F1: 0.8870 Train AUC: 0.9814 Val AUC: 0.9589 Time: 12.06\n",
      "Epoch: 322 Train Loss: 0.1803 Val Loss: 0.2637 Acc: 0.8678 Pre: 0.8842 Recall: 0.8630 F1: 0.8735 Train AUC: 0.9803 Val AUC: 0.9579 Time: 13.19\n",
      "Epoch: 323 Train Loss: 0.1771 Val Loss: 0.2647 Acc: 0.8732 Pre: 0.8828 Recall: 0.8767 F1: 0.8797 Train AUC: 0.9818 Val AUC: 0.9573 Time: 14.64\n",
      "Epoch: 324 Train Loss: 0.1757 Val Loss: 0.2646 Acc: 0.8732 Pre: 0.8776 Recall: 0.8836 F1: 0.8805 Train AUC: 0.9818 Val AUC: 0.9580 Time: 13.90\n",
      "Epoch: 325 Train Loss: 0.1675 Val Loss: 0.2651 Acc: 0.8714 Pre: 0.8746 Recall: 0.8836 F1: 0.8790 Train AUC: 0.9840 Val AUC: 0.9587 Time: 14.63\n",
      "Epoch: 326 Train Loss: 0.1711 Val Loss: 0.2647 Acc: 0.8732 Pre: 0.8828 Recall: 0.8767 F1: 0.8797 Train AUC: 0.9827 Val AUC: 0.9589 Time: 17.64\n",
      "Epoch: 327 Train Loss: 0.1727 Val Loss: 0.2607 Acc: 0.8804 Pre: 0.8924 Recall: 0.8801 F1: 0.8862 Train AUC: 0.9817 Val AUC: 0.9599 Time: 17.33\n",
      "Epoch: 328 Train Loss: 0.1665 Val Loss: 0.2592 Acc: 0.8768 Pre: 0.8944 Recall: 0.8699 F1: 0.8819 Train AUC: 0.9835 Val AUC: 0.9596 Time: 12.79\n",
      "Epoch: 329 Train Loss: 0.1675 Val Loss: 0.2588 Acc: 0.8895 Pre: 0.8969 Recall: 0.8938 F1: 0.8954 Train AUC: 0.9836 Val AUC: 0.9602 Time: 14.44\n",
      "Epoch: 330 Train Loss: 0.1611 Val Loss: 0.2595 Acc: 0.8877 Pre: 0.8938 Recall: 0.8938 F1: 0.8938 Train AUC: 0.9851 Val AUC: 0.9599 Time: 14.85\n",
      "Epoch: 331 Train Loss: 0.1677 Val Loss: 0.2625 Acc: 0.8804 Pre: 0.8818 Recall: 0.8938 F1: 0.8878 Train AUC: 0.9846 Val AUC: 0.9599 Time: 16.25\n",
      "Epoch: 332 Train Loss: 0.1655 Val Loss: 0.2648 Acc: 0.8768 Pre: 0.8810 Recall: 0.8870 F1: 0.8840 Train AUC: 0.9841 Val AUC: 0.9594 Time: 14.85\n",
      "Epoch: 333 Train Loss: 0.1678 Val Loss: 0.2679 Acc: 0.8714 Pre: 0.8850 Recall: 0.8699 F1: 0.8774 Train AUC: 0.9833 Val AUC: 0.9594 Time: 17.44\n",
      "Epoch: 334 Train Loss: 0.1657 Val Loss: 0.2658 Acc: 0.8714 Pre: 0.8797 Recall: 0.8767 F1: 0.8782 Train AUC: 0.9834 Val AUC: 0.9586 Time: 16.65\n",
      "Epoch: 335 Train Loss: 0.1636 Val Loss: 0.2687 Acc: 0.8877 Pre: 0.8758 Recall: 0.9178 F1: 0.8963 Train AUC: 0.9837 Val AUC: 0.9581 Time: 13.27\n",
      "Epoch: 336 Train Loss: 0.1642 Val Loss: 0.2660 Acc: 0.8822 Pre: 0.8847 Recall: 0.8938 F1: 0.8893 Train AUC: 0.9847 Val AUC: 0.9579 Time: 13.19\n",
      "Epoch: 337 Train Loss: 0.1732 Val Loss: 0.2673 Acc: 0.8732 Pre: 0.8936 Recall: 0.8630 F1: 0.8780 Train AUC: 0.9824 Val AUC: 0.9587 Time: 13.67\n",
      "Epoch: 338 Train Loss: 0.1711 Val Loss: 0.2634 Acc: 0.8859 Pre: 0.8935 Recall: 0.8904 F1: 0.8919 Train AUC: 0.9840 Val AUC: 0.9601 Time: 13.83\n",
      "Epoch: 339 Train Loss: 0.1635 Val Loss: 0.2707 Acc: 0.8804 Pre: 0.8767 Recall: 0.9007 F1: 0.8885 Train AUC: 0.9842 Val AUC: 0.9602 Time: 14.40\n",
      "Epoch: 340 Train Loss: 0.1613 Val Loss: 0.2679 Acc: 0.8804 Pre: 0.8767 Recall: 0.9007 F1: 0.8885 Train AUC: 0.9847 Val AUC: 0.9601 Time: 16.35\n",
      "Epoch: 341 Train Loss: 0.1751 Val Loss: 0.2640 Acc: 0.8841 Pre: 0.8958 Recall: 0.8836 F1: 0.8897 Train AUC: 0.9814 Val AUC: 0.9593 Time: 17.29\n",
      "Epoch: 342 Train Loss: 0.1675 Val Loss: 0.2662 Acc: 0.8804 Pre: 0.8951 Recall: 0.8767 F1: 0.8858 Train AUC: 0.9851 Val AUC: 0.9582 Time: 16.10\n",
      "Epoch: 343 Train Loss: 0.1646 Val Loss: 0.2643 Acc: 0.8822 Pre: 0.8796 Recall: 0.9007 F1: 0.8900 Train AUC: 0.9847 Val AUC: 0.9580 Time: 18.54\n",
      "Epoch: 344 Train Loss: 0.1685 Val Loss: 0.2623 Acc: 0.8768 Pre: 0.8784 Recall: 0.8904 F1: 0.8844 Train AUC: 0.9841 Val AUC: 0.9599 Time: 15.24\n",
      "Epoch: 345 Train Loss: 0.1735 Val Loss: 0.2659 Acc: 0.8859 Pre: 0.8908 Recall: 0.8938 F1: 0.8923 Train AUC: 0.9836 Val AUC: 0.9610 Time: 13.85\n",
      "Epoch: 346 Train Loss: 0.1688 Val Loss: 0.2700 Acc: 0.8895 Pre: 0.8997 Recall: 0.8904 F1: 0.8950 Train AUC: 0.9828 Val AUC: 0.9602 Time: 13.32\n",
      "Epoch: 347 Train Loss: 0.1780 Val Loss: 0.2699 Acc: 0.8895 Pre: 0.8997 Recall: 0.8904 F1: 0.8950 Train AUC: 0.9804 Val AUC: 0.9599 Time: 16.95\n",
      "Epoch: 348 Train Loss: 0.1629 Val Loss: 0.2614 Acc: 0.8895 Pre: 0.8969 Recall: 0.8938 F1: 0.8954 Train AUC: 0.9839 Val AUC: 0.9608 Time: 13.56\n",
      "Epoch: 349 Train Loss: 0.1609 Val Loss: 0.2657 Acc: 0.8949 Pre: 0.8750 Recall: 0.9349 F1: 0.9040 Train AUC: 0.9848 Val AUC: 0.9597 Time: 13.48\n",
      "Epoch: 350 Train Loss: 0.1538 Val Loss: 0.2627 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9883 Val AUC: 0.9582 Time: 14.74\n",
      "Epoch: 351 Train Loss: 0.1559 Val Loss: 0.2698 Acc: 0.8732 Pre: 0.8881 Recall: 0.8699 F1: 0.8789 Train AUC: 0.9866 Val AUC: 0.9573 Time: 14.79\n",
      "Epoch: 352 Train Loss: 0.1637 Val Loss: 0.2733 Acc: 0.8750 Pre: 0.8912 Recall: 0.8699 F1: 0.8804 Train AUC: 0.9851 Val AUC: 0.9576 Time: 14.82\n",
      "Epoch: 353 Train Loss: 0.1665 Val Loss: 0.2681 Acc: 0.8841 Pre: 0.8775 Recall: 0.9075 F1: 0.8923 Train AUC: 0.9836 Val AUC: 0.9582 Time: 19.19\n",
      "Epoch: 354 Train Loss: 0.1637 Val Loss: 0.2830 Acc: 0.8768 Pre: 0.8500 Recall: 0.9315 F1: 0.8889 Train AUC: 0.9842 Val AUC: 0.9594 Time: 15.42\n",
      "Epoch: 355 Train Loss: 0.1757 Val Loss: 0.2613 Acc: 0.9022 Pre: 0.8940 Recall: 0.9247 F1: 0.9091 Train AUC: 0.9848 Val AUC: 0.9609 Time: 14.12\n",
      "Epoch: 356 Train Loss: 0.1584 Val Loss: 0.2657 Acc: 0.8786 Pre: 0.9032 Recall: 0.8630 F1: 0.8827 Train AUC: 0.9853 Val AUC: 0.9609 Time: 12.14\n",
      "Epoch: 357 Train Loss: 0.1577 Val Loss: 0.2627 Acc: 0.8895 Pre: 0.9024 Recall: 0.8870 F1: 0.8946 Train AUC: 0.9863 Val AUC: 0.9604 Time: 13.79\n",
      "Epoch: 358 Train Loss: 0.1659 Val Loss: 0.2695 Acc: 0.8931 Pre: 0.8795 Recall: 0.9247 F1: 0.9015 Train AUC: 0.9838 Val AUC: 0.9591 Time: 13.01\n",
      "Epoch: 359 Train Loss: 0.1631 Val Loss: 0.2696 Acc: 0.8913 Pre: 0.8766 Recall: 0.9247 F1: 0.9000 Train AUC: 0.9857 Val AUC: 0.9597 Time: 16.18\n",
      "Epoch: 360 Train Loss: 0.1566 Val Loss: 0.2683 Acc: 0.8877 Pre: 0.9021 Recall: 0.8836 F1: 0.8927 Train AUC: 0.9868 Val AUC: 0.9607 Time: 15.69\n",
      "Epoch: 361 Train Loss: 0.1715 Val Loss: 0.2719 Acc: 0.8895 Pre: 0.9081 Recall: 0.8801 F1: 0.8939 Train AUC: 0.9833 Val AUC: 0.9591 Time: 16.14\n",
      "Epoch: 362 Train Loss: 0.1635 Val Loss: 0.2713 Acc: 0.8949 Pre: 0.8774 Recall: 0.9315 F1: 0.9037 Train AUC: 0.9841 Val AUC: 0.9585 Time: 16.66\n",
      "Epoch: 363 Train Loss: 0.1584 Val Loss: 0.2790 Acc: 0.8822 Pre: 0.8580 Recall: 0.9315 F1: 0.8933 Train AUC: 0.9864 Val AUC: 0.9587 Time: 16.49\n",
      "Epoch: 364 Train Loss: 0.1561 Val Loss: 0.2641 Acc: 0.8967 Pre: 0.8930 Recall: 0.9144 F1: 0.9036 Train AUC: 0.9868 Val AUC: 0.9604 Time: 14.31\n",
      "Epoch: 365 Train Loss: 0.1561 Val Loss: 0.2663 Acc: 0.8913 Pre: 0.9085 Recall: 0.8836 F1: 0.8958 Train AUC: 0.9852 Val AUC: 0.9607 Time: 13.97\n",
      "Epoch: 366 Train Loss: 0.1554 Val Loss: 0.2617 Acc: 0.8913 Pre: 0.9000 Recall: 0.8938 F1: 0.8969 Train AUC: 0.9869 Val AUC: 0.9606 Time: 13.40\n",
      "Epoch: 367 Train Loss: 0.1560 Val Loss: 0.2662 Acc: 0.8931 Pre: 0.8820 Recall: 0.9212 F1: 0.9012 Train AUC: 0.9856 Val AUC: 0.9594 Time: 13.96\n",
      "Epoch: 368 Train Loss: 0.1547 Val Loss: 0.2670 Acc: 0.8931 Pre: 0.8820 Recall: 0.9212 F1: 0.9012 Train AUC: 0.9869 Val AUC: 0.9592 Time: 17.07\n",
      "Epoch: 369 Train Loss: 0.1584 Val Loss: 0.2635 Acc: 0.8877 Pre: 0.8912 Recall: 0.8973 F1: 0.8942 Train AUC: 0.9865 Val AUC: 0.9598 Time: 17.98\n",
      "Epoch: 370 Train Loss: 0.1589 Val Loss: 0.2692 Acc: 0.8822 Pre: 0.8927 Recall: 0.8836 F1: 0.8881 Train AUC: 0.9858 Val AUC: 0.9594 Time: 13.30\n",
      "Epoch: 371 Train Loss: 0.1635 Val Loss: 0.2696 Acc: 0.8841 Pre: 0.8775 Recall: 0.9075 F1: 0.8923 Train AUC: 0.9849 Val AUC: 0.9593 Time: 13.77\n",
      "Epoch: 372 Train Loss: 0.1509 Val Loss: 0.2792 Acc: 0.8895 Pre: 0.8690 Recall: 0.9315 F1: 0.8992 Train AUC: 0.9866 Val AUC: 0.9586 Time: 13.23\n",
      "Epoch: 373 Train Loss: 0.1608 Val Loss: 0.2677 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9858 Val AUC: 0.9593 Time: 17.74\n",
      "Epoch: 374 Train Loss: 0.1467 Val Loss: 0.2668 Acc: 0.8859 Pre: 0.8935 Recall: 0.8904 F1: 0.8919 Train AUC: 0.9871 Val AUC: 0.9594 Time: 14.32\n",
      "Epoch: 375 Train Loss: 0.1495 Val Loss: 0.2712 Acc: 0.8822 Pre: 0.8955 Recall: 0.8801 F1: 0.8877 Train AUC: 0.9870 Val AUC: 0.9597 Time: 16.84\n",
      "Epoch: 376 Train Loss: 0.1641 Val Loss: 0.2694 Acc: 0.8913 Pre: 0.8893 Recall: 0.9075 F1: 0.8983 Train AUC: 0.9855 Val AUC: 0.9595 Time: 13.57\n",
      "Epoch: 377 Train Loss: 0.1395 Val Loss: 0.2776 Acc: 0.8931 Pre: 0.8746 Recall: 0.9315 F1: 0.9022 Train AUC: 0.9886 Val AUC: 0.9589 Time: 13.94\n",
      "Epoch: 378 Train Loss: 0.1533 Val Loss: 0.2689 Acc: 0.8877 Pre: 0.8859 Recall: 0.9041 F1: 0.8949 Train AUC: 0.9866 Val AUC: 0.9599 Time: 18.04\n",
      "Epoch: 379 Train Loss: 0.1473 Val Loss: 0.2721 Acc: 0.8804 Pre: 0.8897 Recall: 0.8836 F1: 0.8866 Train AUC: 0.9874 Val AUC: 0.9599 Time: 16.13\n",
      "Epoch: 380 Train Loss: 0.1489 Val Loss: 0.2704 Acc: 0.8768 Pre: 0.8836 Recall: 0.8836 F1: 0.8836 Train AUC: 0.9880 Val AUC: 0.9587 Time: 12.96\n",
      "Epoch: 381 Train Loss: 0.1554 Val Loss: 0.2736 Acc: 0.8877 Pre: 0.8734 Recall: 0.9212 F1: 0.8967 Train AUC: 0.9866 Val AUC: 0.9575 Time: 12.72\n",
      "Epoch: 382 Train Loss: 0.1462 Val Loss: 0.2811 Acc: 0.8859 Pre: 0.8635 Recall: 0.9315 F1: 0.8962 Train AUC: 0.9885 Val AUC: 0.9576 Time: 12.80\n",
      "Epoch: 383 Train Loss: 0.1557 Val Loss: 0.2679 Acc: 0.9004 Pre: 0.8963 Recall: 0.9178 F1: 0.9069 Train AUC: 0.9877 Val AUC: 0.9602 Time: 16.71\n",
      "Epoch: 384 Train Loss: 0.1404 Val Loss: 0.2758 Acc: 0.8841 Pre: 0.8986 Recall: 0.8801 F1: 0.8893 Train AUC: 0.9883 Val AUC: 0.9605 Time: 15.35\n",
      "Epoch: 385 Train Loss: 0.1549 Val Loss: 0.2711 Acc: 0.8931 Pre: 0.9003 Recall: 0.8973 F1: 0.8988 Train AUC: 0.9860 Val AUC: 0.9607 Time: 15.63\n",
      "Epoch: 386 Train Loss: 0.1422 Val Loss: 0.2726 Acc: 0.8967 Pre: 0.8803 Recall: 0.9315 F1: 0.9052 Train AUC: 0.9877 Val AUC: 0.9602 Time: 15.94\n",
      "Epoch: 387 Train Loss: 0.1377 Val Loss: 0.2730 Acc: 0.8859 Pre: 0.8635 Recall: 0.9315 F1: 0.8962 Train AUC: 0.9894 Val AUC: 0.9599 Time: 14.14\n",
      "Epoch: 388 Train Loss: 0.1567 Val Loss: 0.2648 Acc: 0.8913 Pre: 0.8919 Recall: 0.9041 F1: 0.8980 Train AUC: 0.9868 Val AUC: 0.9598 Time: 11.66\n",
      "Epoch: 389 Train Loss: 0.1505 Val Loss: 0.2705 Acc: 0.8877 Pre: 0.8912 Recall: 0.8973 F1: 0.8942 Train AUC: 0.9873 Val AUC: 0.9606 Time: 13.62\n",
      "Epoch: 390 Train Loss: 0.1534 Val Loss: 0.2709 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9857 Val AUC: 0.9602 Time: 14.79\n",
      "Epoch: 391 Train Loss: 0.1484 Val Loss: 0.2746 Acc: 0.8895 Pre: 0.8738 Recall: 0.9247 F1: 0.8985 Train AUC: 0.9867 Val AUC: 0.9601 Time: 13.66\n",
      "Epoch: 392 Train Loss: 0.1458 Val Loss: 0.2747 Acc: 0.8895 Pre: 0.8690 Recall: 0.9315 F1: 0.8992 Train AUC: 0.9883 Val AUC: 0.9597 Time: 14.68\n",
      "Epoch: 393 Train Loss: 0.1507 Val Loss: 0.2649 Acc: 0.8967 Pre: 0.8878 Recall: 0.9212 F1: 0.9042 Train AUC: 0.9870 Val AUC: 0.9602 Time: 19.41\n",
      "Epoch: 394 Train Loss: 0.1413 Val Loss: 0.2639 Acc: 0.8913 Pre: 0.8946 Recall: 0.9007 F1: 0.8976 Train AUC: 0.9889 Val AUC: 0.9601 Time: 18.38\n",
      "Epoch: 395 Train Loss: 0.1437 Val Loss: 0.2661 Acc: 0.8877 Pre: 0.8859 Recall: 0.9041 F1: 0.8949 Train AUC: 0.9879 Val AUC: 0.9604 Time: 14.61\n",
      "Epoch: 396 Train Loss: 0.1370 Val Loss: 0.2703 Acc: 0.8913 Pre: 0.8841 Recall: 0.9144 F1: 0.8990 Train AUC: 0.9894 Val AUC: 0.9597 Time: 15.85\n",
      "Epoch: 397 Train Loss: 0.1471 Val Loss: 0.2703 Acc: 0.8841 Pre: 0.8878 Recall: 0.8938 F1: 0.8908 Train AUC: 0.9876 Val AUC: 0.9590 Time: 12.95\n",
      "Epoch: 398 Train Loss: 0.1365 Val Loss: 0.2728 Acc: 0.8841 Pre: 0.8851 Recall: 0.8973 F1: 0.8912 Train AUC: 0.9892 Val AUC: 0.9586 Time: 13.79\n",
      "Epoch: 399 Train Loss: 0.1485 Val Loss: 0.2772 Acc: 0.8877 Pre: 0.8885 Recall: 0.9007 F1: 0.8946 Train AUC: 0.9869 Val AUC: 0.9591 Time: 13.13\n",
      "Epoch: 400 Train Loss: 0.1476 Val Loss: 0.2864 Acc: 0.8895 Pre: 0.8690 Recall: 0.9315 F1: 0.8992 Train AUC: 0.9873 Val AUC: 0.9575 Time: 13.40\n",
      "Epoch: 401 Train Loss: 0.1390 Val Loss: 0.2833 Acc: 0.8895 Pre: 0.8690 Recall: 0.9315 F1: 0.8992 Train AUC: 0.9897 Val AUC: 0.9581 Time: 14.16\n",
      "Epoch: 402 Train Loss: 0.1398 Val Loss: 0.2695 Acc: 0.8967 Pre: 0.8930 Recall: 0.9144 F1: 0.9036 Train AUC: 0.9893 Val AUC: 0.9594 Time: 17.74\n",
      "Epoch: 403 Train Loss: 0.1430 Val Loss: 0.2712 Acc: 0.8841 Pre: 0.8931 Recall: 0.8870 F1: 0.8900 Train AUC: 0.9881 Val AUC: 0.9582 Time: 19.38\n",
      "Epoch: 404 Train Loss: 0.1530 Val Loss: 0.2697 Acc: 0.8804 Pre: 0.8870 Recall: 0.8870 F1: 0.8870 Train AUC: 0.9877 Val AUC: 0.9583 Time: 14.22\n",
      "Epoch: 405 Train Loss: 0.1348 Val Loss: 0.2734 Acc: 0.8877 Pre: 0.8833 Recall: 0.9075 F1: 0.8953 Train AUC: 0.9894 Val AUC: 0.9589 Time: 13.02\n",
      "Epoch: 406 Train Loss: 0.1397 Val Loss: 0.2737 Acc: 0.8895 Pre: 0.8889 Recall: 0.9041 F1: 0.8964 Train AUC: 0.9887 Val AUC: 0.9591 Time: 12.51\n",
      "Epoch: 407 Train Loss: 0.1323 Val Loss: 0.2733 Acc: 0.8931 Pre: 0.8949 Recall: 0.9041 F1: 0.8995 Train AUC: 0.9899 Val AUC: 0.9595 Time: 12.59\n",
      "Epoch: 408 Train Loss: 0.1445 Val Loss: 0.2781 Acc: 0.9022 Pre: 0.8940 Recall: 0.9247 F1: 0.9091 Train AUC: 0.9878 Val AUC: 0.9595 Time: 14.52\n",
      "Epoch: 409 Train Loss: 0.1439 Val Loss: 0.2752 Acc: 0.8986 Pre: 0.8933 Recall: 0.9178 F1: 0.9054 Train AUC: 0.9874 Val AUC: 0.9595 Time: 15.43\n",
      "Epoch: 410 Train Loss: 0.1390 Val Loss: 0.2733 Acc: 0.8931 Pre: 0.8896 Recall: 0.9110 F1: 0.9002 Train AUC: 0.9882 Val AUC: 0.9595 Time: 14.22\n",
      "Epoch: 411 Train Loss: 0.1338 Val Loss: 0.2716 Acc: 0.8804 Pre: 0.8818 Recall: 0.8938 F1: 0.8878 Train AUC: 0.9896 Val AUC: 0.9582 Time: 15.78\n",
      "Epoch: 412 Train Loss: 0.1366 Val Loss: 0.2726 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9890 Val AUC: 0.9572 Time: 14.75\n",
      "Epoch: 413 Train Loss: 0.1393 Val Loss: 0.2742 Acc: 0.8877 Pre: 0.8833 Recall: 0.9075 F1: 0.8953 Train AUC: 0.9892 Val AUC: 0.9580 Time: 13.54\n",
      "Epoch: 414 Train Loss: 0.1349 Val Loss: 0.2704 Acc: 0.8859 Pre: 0.8855 Recall: 0.9007 F1: 0.8930 Train AUC: 0.9900 Val AUC: 0.9593 Time: 12.20\n",
      "Epoch: 415 Train Loss: 0.1337 Val Loss: 0.2702 Acc: 0.8913 Pre: 0.8946 Recall: 0.9007 F1: 0.8976 Train AUC: 0.9894 Val AUC: 0.9600 Time: 11.93\n",
      "Epoch: 416 Train Loss: 0.1332 Val Loss: 0.2718 Acc: 0.8949 Pre: 0.8824 Recall: 0.9247 F1: 0.9030 Train AUC: 0.9899 Val AUC: 0.9594 Time: 12.39\n",
      "Epoch: 417 Train Loss: 0.1304 Val Loss: 0.2758 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9903 Val AUC: 0.9584 Time: 12.80\n",
      "Epoch: 418 Train Loss: 0.1345 Val Loss: 0.2765 Acc: 0.8895 Pre: 0.8738 Recall: 0.9247 F1: 0.8985 Train AUC: 0.9904 Val AUC: 0.9594 Time: 13.47\n",
      "Epoch: 419 Train Loss: 0.1354 Val Loss: 0.2727 Acc: 0.8986 Pre: 0.8933 Recall: 0.9178 F1: 0.9054 Train AUC: 0.9895 Val AUC: 0.9599 Time: 14.24\n",
      "Epoch: 420 Train Loss: 0.1331 Val Loss: 0.2704 Acc: 0.8986 Pre: 0.8960 Recall: 0.9144 F1: 0.9051 Train AUC: 0.9894 Val AUC: 0.9599 Time: 14.37\n",
      "Epoch: 421 Train Loss: 0.1298 Val Loss: 0.2694 Acc: 0.8913 Pre: 0.8841 Recall: 0.9144 F1: 0.8990 Train AUC: 0.9901 Val AUC: 0.9592 Time: 13.29\n",
      "Epoch: 422 Train Loss: 0.1357 Val Loss: 0.2715 Acc: 0.8913 Pre: 0.8841 Recall: 0.9144 F1: 0.8990 Train AUC: 0.9898 Val AUC: 0.9590 Time: 12.74\n",
      "Epoch: 423 Train Loss: 0.1384 Val Loss: 0.2698 Acc: 0.8822 Pre: 0.8874 Recall: 0.8904 F1: 0.8889 Train AUC: 0.9891 Val AUC: 0.9593 Time: 13.66\n",
      "Epoch: 424 Train Loss: 0.1292 Val Loss: 0.2715 Acc: 0.8841 Pre: 0.8878 Recall: 0.8938 F1: 0.8908 Train AUC: 0.9909 Val AUC: 0.9592 Time: 16.87\n",
      "Epoch: 425 Train Loss: 0.1288 Val Loss: 0.2748 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9910 Val AUC: 0.9589 Time: 16.22\n",
      "Epoch: 426 Train Loss: 0.1229 Val Loss: 0.2862 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9912 Val AUC: 0.9581 Time: 17.00\n",
      "Epoch: 427 Train Loss: 0.1330 Val Loss: 0.2774 Acc: 0.8859 Pre: 0.8730 Recall: 0.9178 F1: 0.8948 Train AUC: 0.9913 Val AUC: 0.9580 Time: 13.95\n",
      "Epoch: 428 Train Loss: 0.1333 Val Loss: 0.2739 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9903 Val AUC: 0.9585 Time: 14.58\n",
      "Epoch: 429 Train Loss: 0.1277 Val Loss: 0.2768 Acc: 0.8913 Pre: 0.8791 Recall: 0.9212 F1: 0.8997 Train AUC: 0.9916 Val AUC: 0.9600 Time: 16.70\n",
      "Epoch: 430 Train Loss: 0.1311 Val Loss: 0.2802 Acc: 0.8949 Pre: 0.8849 Recall: 0.9212 F1: 0.9027 Train AUC: 0.9903 Val AUC: 0.9604 Time: 15.35\n",
      "Epoch: 431 Train Loss: 0.1291 Val Loss: 0.2766 Acc: 0.8913 Pre: 0.8893 Recall: 0.9075 F1: 0.8983 Train AUC: 0.9898 Val AUC: 0.9601 Time: 14.28\n",
      "Epoch: 432 Train Loss: 0.1259 Val Loss: 0.2757 Acc: 0.8859 Pre: 0.8935 Recall: 0.8904 F1: 0.8919 Train AUC: 0.9907 Val AUC: 0.9599 Time: 13.58\n",
      "Epoch: 433 Train Loss: 0.1308 Val Loss: 0.2791 Acc: 0.8804 Pre: 0.8818 Recall: 0.8938 F1: 0.8878 Train AUC: 0.9903 Val AUC: 0.9584 Time: 15.54\n",
      "Epoch: 434 Train Loss: 0.1334 Val Loss: 0.2836 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9913 Val AUC: 0.9582 Time: 13.86\n",
      "Epoch: 435 Train Loss: 0.1309 Val Loss: 0.2835 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9898 Val AUC: 0.9584 Time: 15.36\n",
      "Epoch: 436 Train Loss: 0.1300 Val Loss: 0.2785 Acc: 0.8967 Pre: 0.8930 Recall: 0.9144 F1: 0.9036 Train AUC: 0.9909 Val AUC: 0.9591 Time: 14.26\n",
      "Epoch: 437 Train Loss: 0.1262 Val Loss: 0.2823 Acc: 0.8949 Pre: 0.8953 Recall: 0.9075 F1: 0.9014 Train AUC: 0.9906 Val AUC: 0.9574 Time: 13.57\n",
      "Epoch: 438 Train Loss: 0.1376 Val Loss: 0.2804 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9893 Val AUC: 0.9584 Time: 13.14\n",
      "Epoch: 439 Train Loss: 0.1244 Val Loss: 0.2901 Acc: 0.8841 Pre: 0.8775 Recall: 0.9075 F1: 0.8923 Train AUC: 0.9909 Val AUC: 0.9580 Time: 13.10\n",
      "Epoch: 440 Train Loss: 0.1236 Val Loss: 0.2920 Acc: 0.8841 Pre: 0.8750 Recall: 0.9110 F1: 0.8926 Train AUC: 0.9904 Val AUC: 0.9572 Time: 13.32\n",
      "Epoch: 441 Train Loss: 0.1298 Val Loss: 0.2807 Acc: 0.8786 Pre: 0.8763 Recall: 0.8973 F1: 0.8866 Train AUC: 0.9906 Val AUC: 0.9561 Time: 13.85\n",
      "Epoch: 442 Train Loss: 0.1329 Val Loss: 0.2818 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9904 Val AUC: 0.9557 Time: 13.71\n",
      "Epoch: 443 Train Loss: 0.1201 Val Loss: 0.2896 Acc: 0.8841 Pre: 0.8654 Recall: 0.9247 F1: 0.8940 Train AUC: 0.9922 Val AUC: 0.9566 Time: 13.33\n",
      "Epoch: 444 Train Loss: 0.1313 Val Loss: 0.2819 Acc: 0.8949 Pre: 0.8900 Recall: 0.9144 F1: 0.9020 Train AUC: 0.9903 Val AUC: 0.9598 Time: 13.14\n",
      "Epoch: 445 Train Loss: 0.1217 Val Loss: 0.2831 Acc: 0.8913 Pre: 0.9000 Recall: 0.8938 F1: 0.8969 Train AUC: 0.9916 Val AUC: 0.9606 Time: 13.71\n",
      "Epoch: 446 Train Loss: 0.1295 Val Loss: 0.2824 Acc: 0.8931 Pre: 0.9003 Recall: 0.8973 F1: 0.8988 Train AUC: 0.9904 Val AUC: 0.9599 Time: 13.74\n",
      "Epoch: 447 Train Loss: 0.1247 Val Loss: 0.2782 Acc: 0.8859 Pre: 0.8804 Recall: 0.9075 F1: 0.8938 Train AUC: 0.9905 Val AUC: 0.9589 Time: 13.64\n",
      "Epoch: 448 Train Loss: 0.1239 Val Loss: 0.2828 Acc: 0.8768 Pre: 0.8636 Recall: 0.9110 F1: 0.8867 Train AUC: 0.9910 Val AUC: 0.9555 Time: 13.53\n",
      "Epoch: 449 Train Loss: 0.1279 Val Loss: 0.2787 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9920 Val AUC: 0.9572 Time: 13.27\n",
      "Epoch: 450 Train Loss: 0.1282 Val Loss: 0.2805 Acc: 0.8931 Pre: 0.8820 Recall: 0.9212 F1: 0.9012 Train AUC: 0.9913 Val AUC: 0.9581 Time: 12.34\n",
      "Epoch: 451 Train Loss: 0.1141 Val Loss: 0.2887 Acc: 0.8913 Pre: 0.8791 Recall: 0.9212 F1: 0.8997 Train AUC: 0.9926 Val AUC: 0.9582 Time: 13.25\n",
      "Epoch: 452 Train Loss: 0.1294 Val Loss: 0.2798 Acc: 0.8931 Pre: 0.8820 Recall: 0.9212 F1: 0.9012 Train AUC: 0.9903 Val AUC: 0.9593 Time: 13.46\n",
      "Epoch: 453 Train Loss: 0.1244 Val Loss: 0.2752 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9908 Val AUC: 0.9583 Time: 13.88\n",
      "Epoch: 454 Train Loss: 0.1161 Val Loss: 0.2814 Acc: 0.8804 Pre: 0.8818 Recall: 0.8938 F1: 0.8878 Train AUC: 0.9933 Val AUC: 0.9556 Time: 14.43\n",
      "Epoch: 455 Train Loss: 0.1257 Val Loss: 0.2823 Acc: 0.8750 Pre: 0.8754 Recall: 0.8904 F1: 0.8829 Train AUC: 0.9923 Val AUC: 0.9578 Time: 14.36\n",
      "Epoch: 456 Train Loss: 0.1255 Val Loss: 0.2891 Acc: 0.8804 Pre: 0.8792 Recall: 0.8973 F1: 0.8881 Train AUC: 0.9912 Val AUC: 0.9602 Time: 14.24\n",
      "Epoch: 457 Train Loss: 0.1236 Val Loss: 0.2879 Acc: 0.8895 Pre: 0.8863 Recall: 0.9075 F1: 0.8968 Train AUC: 0.9908 Val AUC: 0.9608 Time: 13.02\n",
      "Epoch: 458 Train Loss: 0.1338 Val Loss: 0.2880 Acc: 0.8895 Pre: 0.8762 Recall: 0.9212 F1: 0.8982 Train AUC: 0.9896 Val AUC: 0.9595 Time: 12.96\n",
      "Epoch: 459 Train Loss: 0.1301 Val Loss: 0.2913 Acc: 0.8841 Pre: 0.8654 Recall: 0.9247 F1: 0.8940 Train AUC: 0.9896 Val AUC: 0.9567 Time: 13.07\n",
      "Epoch: 460 Train Loss: 0.1194 Val Loss: 0.2921 Acc: 0.8804 Pre: 0.8645 Recall: 0.9178 F1: 0.8904 Train AUC: 0.9919 Val AUC: 0.9557 Time: 13.28\n",
      "Epoch: 461 Train Loss: 0.1257 Val Loss: 0.2898 Acc: 0.8786 Pre: 0.8763 Recall: 0.8973 F1: 0.8866 Train AUC: 0.9907 Val AUC: 0.9570 Time: 13.87\n",
      "Epoch: 462 Train Loss: 0.1152 Val Loss: 0.2890 Acc: 0.8732 Pre: 0.8776 Recall: 0.8836 F1: 0.8805 Train AUC: 0.9927 Val AUC: 0.9575 Time: 14.13\n",
      "Epoch: 463 Train Loss: 0.1355 Val Loss: 0.2883 Acc: 0.8877 Pre: 0.8808 Recall: 0.9110 F1: 0.8956 Train AUC: 0.9899 Val AUC: 0.9575 Time: 13.89\n",
      "Epoch: 464 Train Loss: 0.1119 Val Loss: 0.2973 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9932 Val AUC: 0.9588 Time: 12.94\n",
      "Epoch: 465 Train Loss: 0.1244 Val Loss: 0.2848 Acc: 0.8949 Pre: 0.8874 Recall: 0.9178 F1: 0.9024 Train AUC: 0.9913 Val AUC: 0.9595 Time: 12.71\n",
      "Epoch: 466 Train Loss: 0.1186 Val Loss: 0.2810 Acc: 0.8877 Pre: 0.8885 Recall: 0.9007 F1: 0.8946 Train AUC: 0.9914 Val AUC: 0.9592 Time: 13.35\n",
      "Epoch: 467 Train Loss: 0.1213 Val Loss: 0.2824 Acc: 0.8804 Pre: 0.8767 Recall: 0.9007 F1: 0.8885 Train AUC: 0.9912 Val AUC: 0.9567 Time: 13.52\n",
      "Epoch: 468 Train Loss: 0.1174 Val Loss: 0.2926 Acc: 0.8822 Pre: 0.8650 Recall: 0.9212 F1: 0.8922 Train AUC: 0.9926 Val AUC: 0.9566 Time: 14.06\n",
      "Epoch: 469 Train Loss: 0.1295 Val Loss: 0.2832 Acc: 0.8786 Pre: 0.8713 Recall: 0.9041 F1: 0.8874 Train AUC: 0.9920 Val AUC: 0.9579 Time: 14.87\n",
      "Epoch: 470 Train Loss: 0.1182 Val Loss: 0.2805 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9922 Val AUC: 0.9599 Time: 13.64\n",
      "Epoch: 471 Train Loss: 0.1190 Val Loss: 0.2868 Acc: 0.8877 Pre: 0.8833 Recall: 0.9075 F1: 0.8953 Train AUC: 0.9919 Val AUC: 0.9585 Time: 12.53\n",
      "Epoch: 472 Train Loss: 0.1224 Val Loss: 0.2927 Acc: 0.8895 Pre: 0.8738 Recall: 0.9247 F1: 0.8985 Train AUC: 0.9909 Val AUC: 0.9580 Time: 12.02\n",
      "Epoch: 473 Train Loss: 0.1224 Val Loss: 0.2854 Acc: 0.8877 Pre: 0.8734 Recall: 0.9212 F1: 0.8967 Train AUC: 0.9914 Val AUC: 0.9585 Time: 12.51\n",
      "Epoch: 474 Train Loss: 0.1220 Val Loss: 0.2812 Acc: 0.8822 Pre: 0.8796 Recall: 0.9007 F1: 0.8900 Train AUC: 0.9915 Val AUC: 0.9577 Time: 13.03\n",
      "Epoch: 475 Train Loss: 0.1199 Val Loss: 0.2827 Acc: 0.8786 Pre: 0.8763 Recall: 0.8973 F1: 0.8866 Train AUC: 0.9921 Val AUC: 0.9560 Time: 13.54\n",
      "Epoch: 476 Train Loss: 0.1209 Val Loss: 0.2835 Acc: 0.8768 Pre: 0.8709 Recall: 0.9007 F1: 0.8855 Train AUC: 0.9921 Val AUC: 0.9572 Time: 14.44\n",
      "Epoch: 477 Train Loss: 0.1145 Val Loss: 0.2868 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9937 Val AUC: 0.9590 Time: 15.24\n",
      "Epoch: 478 Train Loss: 0.1195 Val Loss: 0.2843 Acc: 0.8913 Pre: 0.8893 Recall: 0.9075 F1: 0.8983 Train AUC: 0.9922 Val AUC: 0.9589 Time: 14.04\n",
      "Epoch: 479 Train Loss: 0.1169 Val Loss: 0.2872 Acc: 0.8949 Pre: 0.8980 Recall: 0.9041 F1: 0.9010 Train AUC: 0.9920 Val AUC: 0.9594 Time: 14.87\n",
      "Epoch: 480 Train Loss: 0.1261 Val Loss: 0.2867 Acc: 0.8931 Pre: 0.8896 Recall: 0.9110 F1: 0.9002 Train AUC: 0.9914 Val AUC: 0.9594 Time: 15.43\n",
      "Epoch: 481 Train Loss: 0.1094 Val Loss: 0.2936 Acc: 0.8913 Pre: 0.8766 Recall: 0.9247 F1: 0.9000 Train AUC: 0.9929 Val AUC: 0.9589 Time: 15.45\n",
      "Epoch: 482 Train Loss: 0.1035 Val Loss: 0.3043 Acc: 0.8804 Pre: 0.8599 Recall: 0.9247 F1: 0.8911 Train AUC: 0.9940 Val AUC: 0.9567 Time: 15.54\n",
      "Epoch: 483 Train Loss: 0.1196 Val Loss: 0.2921 Acc: 0.8768 Pre: 0.8684 Recall: 0.9041 F1: 0.8859 Train AUC: 0.9926 Val AUC: 0.9573 Time: 16.12\n",
      "Epoch: 484 Train Loss: 0.1129 Val Loss: 0.2869 Acc: 0.8841 Pre: 0.8851 Recall: 0.8973 F1: 0.8912 Train AUC: 0.9931 Val AUC: 0.9583 Time: 16.66\n",
      "Epoch: 485 Train Loss: 0.1141 Val Loss: 0.2868 Acc: 0.8913 Pre: 0.8867 Recall: 0.9110 F1: 0.8986 Train AUC: 0.9928 Val AUC: 0.9599 Time: 14.73\n",
      "Epoch: 486 Train Loss: 0.1165 Val Loss: 0.2956 Acc: 0.8949 Pre: 0.8824 Recall: 0.9247 F1: 0.9030 Train AUC: 0.9921 Val AUC: 0.9600 Time: 13.21\n",
      "Epoch: 487 Train Loss: 0.1209 Val Loss: 0.2927 Acc: 0.8913 Pre: 0.8816 Recall: 0.9178 F1: 0.8993 Train AUC: 0.9912 Val AUC: 0.9596 Time: 12.27\n",
      "Epoch: 488 Train Loss: 0.1207 Val Loss: 0.2826 Acc: 0.8931 Pre: 0.8896 Recall: 0.9110 F1: 0.9002 Train AUC: 0.9910 Val AUC: 0.9579 Time: 13.57\n",
      "Epoch: 489 Train Loss: 0.1314 Val Loss: 0.2845 Acc: 0.8822 Pre: 0.8721 Recall: 0.9110 F1: 0.8911 Train AUC: 0.9908 Val AUC: 0.9573 Time: 13.91\n",
      "Epoch: 490 Train Loss: 0.1242 Val Loss: 0.2842 Acc: 0.8841 Pre: 0.8750 Recall: 0.9110 F1: 0.8926 Train AUC: 0.9918 Val AUC: 0.9572 Time: 14.39\n",
      "Epoch: 491 Train Loss: 0.1144 Val Loss: 0.2831 Acc: 0.8768 Pre: 0.8758 Recall: 0.8938 F1: 0.8847 Train AUC: 0.9934 Val AUC: 0.9580 Time: 15.39\n",
      "Epoch: 492 Train Loss: 0.1146 Val Loss: 0.2838 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9929 Val AUC: 0.9596 Time: 15.86\n",
      "Epoch: 493 Train Loss: 0.1153 Val Loss: 0.3005 Acc: 0.8967 Pre: 0.8852 Recall: 0.9247 F1: 0.9045 Train AUC: 0.9922 Val AUC: 0.9606 Time: 16.82\n",
      "Epoch: 494 Train Loss: 0.1147 Val Loss: 0.2961 Acc: 0.8949 Pre: 0.8874 Recall: 0.9178 F1: 0.9024 Train AUC: 0.9925 Val AUC: 0.9605 Time: 14.90\n",
      "Epoch: 495 Train Loss: 0.1192 Val Loss: 0.2857 Acc: 0.8841 Pre: 0.8851 Recall: 0.8973 F1: 0.8912 Train AUC: 0.9914 Val AUC: 0.9602 Time: 14.05\n",
      "Epoch: 496 Train Loss: 0.1215 Val Loss: 0.2878 Acc: 0.8786 Pre: 0.8763 Recall: 0.8973 F1: 0.8866 Train AUC: 0.9921 Val AUC: 0.9580 Time: 13.24\n",
      "Epoch: 497 Train Loss: 0.1130 Val Loss: 0.2923 Acc: 0.8768 Pre: 0.8684 Recall: 0.9041 F1: 0.8859 Train AUC: 0.9934 Val AUC: 0.9577 Time: 13.51\n",
      "Epoch: 498 Train Loss: 0.1142 Val Loss: 0.2898 Acc: 0.8859 Pre: 0.8779 Recall: 0.9110 F1: 0.8941 Train AUC: 0.9931 Val AUC: 0.9575 Time: 14.37\n",
      "Epoch: 499 Train Loss: 0.1120 Val Loss: 0.2876 Acc: 0.8877 Pre: 0.8885 Recall: 0.9007 F1: 0.8946 Train AUC: 0.9934 Val AUC: 0.9572 Time: 16.05\n",
      "Epoch: 500 Train Loss: 0.1154 Val Loss: 0.2931 Acc: 0.8841 Pre: 0.8878 Recall: 0.8938 F1: 0.8908 Train AUC: 0.9926 Val AUC: 0.9572 Time: 16.84\n",
      "Epoch: 501 Train Loss: 0.1177 Val Loss: 0.3043 Acc: 0.8859 Pre: 0.8682 Recall: 0.9247 F1: 0.8955 Train AUC: 0.9926 Val AUC: 0.9562 Time: 15.09\n",
      "Epoch: 502 Train Loss: 0.1199 Val Loss: 0.3003 Acc: 0.8913 Pre: 0.8766 Recall: 0.9247 F1: 0.9000 Train AUC: 0.9918 Val AUC: 0.9574 Time: 15.30\n",
      "Epoch: 503 Train Loss: 0.1046 Val Loss: 0.2968 Acc: 0.8786 Pre: 0.8763 Recall: 0.8973 F1: 0.8866 Train AUC: 0.9940 Val AUC: 0.9566 Time: 14.09\n",
      "Epoch: 504 Train Loss: 0.1163 Val Loss: 0.2980 Acc: 0.8732 Pre: 0.8700 Recall: 0.8938 F1: 0.8818 Train AUC: 0.9926 Val AUC: 0.9574 Time: 12.98\n",
      "Epoch: 505 Train Loss: 0.1152 Val Loss: 0.3107 Acc: 0.8822 Pre: 0.8580 Recall: 0.9315 F1: 0.8933 Train AUC: 0.9925 Val AUC: 0.9575 Time: 13.77\n",
      "Epoch: 506 Train Loss: 0.1145 Val Loss: 0.3026 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9939 Val AUC: 0.9591 Time: 14.27\n",
      "Epoch: 507 Train Loss: 0.1170 Val Loss: 0.2976 Acc: 0.8949 Pre: 0.9062 Recall: 0.8938 F1: 0.9000 Train AUC: 0.9920 Val AUC: 0.9593 Time: 14.03\n",
      "Epoch: 508 Train Loss: 0.1194 Val Loss: 0.2925 Acc: 0.8967 Pre: 0.9038 Recall: 0.9007 F1: 0.9022 Train AUC: 0.9916 Val AUC: 0.9587 Time: 15.21\n",
      "Epoch: 509 Train Loss: 0.1144 Val Loss: 0.2999 Acc: 0.8804 Pre: 0.8645 Recall: 0.9178 F1: 0.8904 Train AUC: 0.9937 Val AUC: 0.9566 Time: 16.15\n",
      "Epoch: 510 Train Loss: 0.1059 Val Loss: 0.3066 Acc: 0.8768 Pre: 0.8590 Recall: 0.9178 F1: 0.8874 Train AUC: 0.9945 Val AUC: 0.9551 Time: 13.98\n",
      "Epoch: 511 Train Loss: 0.1074 Val Loss: 0.2976 Acc: 0.8768 Pre: 0.8709 Recall: 0.9007 F1: 0.8855 Train AUC: 0.9946 Val AUC: 0.9548 Time: 12.60\n",
      "Epoch: 512 Train Loss: 0.1132 Val Loss: 0.2953 Acc: 0.8786 Pre: 0.8814 Recall: 0.8904 F1: 0.8859 Train AUC: 0.9932 Val AUC: 0.9564 Time: 12.20\n",
      "Epoch: 513 Train Loss: 0.1096 Val Loss: 0.3037 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9935 Val AUC: 0.9586 Time: 12.69\n",
      "Epoch: 514 Train Loss: 0.1048 Val Loss: 0.3117 Acc: 0.8913 Pre: 0.8816 Recall: 0.9178 F1: 0.8993 Train AUC: 0.9940 Val AUC: 0.9584 Time: 13.30\n",
      "Epoch: 515 Train Loss: 0.1120 Val Loss: 0.3012 Acc: 0.8949 Pre: 0.8900 Recall: 0.9144 F1: 0.9020 Train AUC: 0.9932 Val AUC: 0.9584 Time: 13.60\n",
      "Epoch: 516 Train Loss: 0.1093 Val Loss: 0.2956 Acc: 0.8949 Pre: 0.8926 Recall: 0.9110 F1: 0.9017 Train AUC: 0.9934 Val AUC: 0.9570 Time: 14.30\n",
      "Epoch: 517 Train Loss: 0.1181 Val Loss: 0.3025 Acc: 0.8804 Pre: 0.8742 Recall: 0.9041 F1: 0.8889 Train AUC: 0.9927 Val AUC: 0.9581 Time: 15.19\n",
      "Epoch: 518 Train Loss: 0.1088 Val Loss: 0.3134 Acc: 0.8859 Pre: 0.8754 Recall: 0.9144 F1: 0.8945 Train AUC: 0.9934 Val AUC: 0.9554 Time: 17.05\n",
      "Epoch: 519 Train Loss: 0.1221 Val Loss: 0.2975 Acc: 0.8804 Pre: 0.8792 Recall: 0.8973 F1: 0.8881 Train AUC: 0.9917 Val AUC: 0.9561 Time: 15.09\n",
      "Epoch: 520 Train Loss: 0.1122 Val Loss: 0.2911 Acc: 0.8931 Pre: 0.8949 Recall: 0.9041 F1: 0.8995 Train AUC: 0.9934 Val AUC: 0.9581 Time: 13.95\n",
      "Epoch: 521 Train Loss: 0.1100 Val Loss: 0.3035 Acc: 0.8949 Pre: 0.8926 Recall: 0.9110 F1: 0.9017 Train AUC: 0.9936 Val AUC: 0.9584 Time: 13.40\n",
      "Epoch: 522 Train Loss: 0.1211 Val Loss: 0.3142 Acc: 0.8967 Pre: 0.8852 Recall: 0.9247 F1: 0.9045 Train AUC: 0.9913 Val AUC: 0.9597 Time: 13.74\n",
      "Epoch: 523 Train Loss: 0.1174 Val Loss: 0.2995 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9920 Val AUC: 0.9599 Time: 13.79\n",
      "Epoch: 524 Train Loss: 0.1075 Val Loss: 0.2922 Acc: 0.8804 Pre: 0.8844 Recall: 0.8904 F1: 0.8874 Train AUC: 0.9931 Val AUC: 0.9585 Time: 14.43\n",
      "Epoch: 525 Train Loss: 0.1128 Val Loss: 0.2964 Acc: 0.8678 Pre: 0.8567 Recall: 0.9007 F1: 0.8781 Train AUC: 0.9930 Val AUC: 0.9548 Time: 14.85\n",
      "Epoch: 526 Train Loss: 0.1102 Val Loss: 0.3037 Acc: 0.8768 Pre: 0.8544 Recall: 0.9247 F1: 0.8882 Train AUC: 0.9945 Val AUC: 0.9552 Time: 14.43\n",
      "Epoch: 527 Train Loss: 0.1115 Val Loss: 0.2997 Acc: 0.8895 Pre: 0.8787 Recall: 0.9178 F1: 0.8978 Train AUC: 0.9943 Val AUC: 0.9596 Time: 13.19\n",
      "Epoch: 528 Train Loss: 0.1115 Val Loss: 0.3004 Acc: 0.8931 Pre: 0.8976 Recall: 0.9007 F1: 0.8991 Train AUC: 0.9929 Val AUC: 0.9602 Time: 13.32\n",
      "Epoch: 529 Train Loss: 0.1116 Val Loss: 0.3004 Acc: 0.8895 Pre: 0.8997 Recall: 0.8904 F1: 0.8950 Train AUC: 0.9926 Val AUC: 0.9607 Time: 14.53\n",
      "Epoch: 530 Train Loss: 0.1138 Val Loss: 0.2978 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9933 Val AUC: 0.9604 Time: 14.52\n",
      "Epoch: 531 Train Loss: 0.1073 Val Loss: 0.3070 Acc: 0.8841 Pre: 0.8631 Recall: 0.9281 F1: 0.8944 Train AUC: 0.9935 Val AUC: 0.9583 Time: 15.37\n",
      "Epoch: 532 Train Loss: 0.1085 Val Loss: 0.3008 Acc: 0.8804 Pre: 0.8742 Recall: 0.9041 F1: 0.8889 Train AUC: 0.9942 Val AUC: 0.9557 Time: 14.23\n",
      "Epoch: 533 Train Loss: 0.1079 Val Loss: 0.3021 Acc: 0.8822 Pre: 0.8771 Recall: 0.9041 F1: 0.8904 Train AUC: 0.9937 Val AUC: 0.9541 Time: 13.09\n",
      "Epoch: 534 Train Loss: 0.1173 Val Loss: 0.2966 Acc: 0.8804 Pre: 0.8669 Recall: 0.9144 F1: 0.8900 Train AUC: 0.9929 Val AUC: 0.9562 Time: 12.50\n",
      "Epoch: 535 Train Loss: 0.1011 Val Loss: 0.2977 Acc: 0.8841 Pre: 0.8725 Recall: 0.9144 F1: 0.8930 Train AUC: 0.9945 Val AUC: 0.9577 Time: 12.90\n",
      "Epoch: 536 Train Loss: 0.1056 Val Loss: 0.3017 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9936 Val AUC: 0.9576 Time: 13.55\n",
      "Epoch: 537 Train Loss: 0.1072 Val Loss: 0.2967 Acc: 0.8931 Pre: 0.8896 Recall: 0.9110 F1: 0.9002 Train AUC: 0.9937 Val AUC: 0.9584 Time: 14.10\n",
      "Epoch: 538 Train Loss: 0.1052 Val Loss: 0.2947 Acc: 0.8841 Pre: 0.8826 Recall: 0.9007 F1: 0.8915 Train AUC: 0.9937 Val AUC: 0.9582 Time: 14.77\n",
      "Epoch: 539 Train Loss: 0.1074 Val Loss: 0.3018 Acc: 0.8786 Pre: 0.8713 Recall: 0.9041 F1: 0.8874 Train AUC: 0.9938 Val AUC: 0.9564 Time: 14.78\n",
      "Epoch: 540 Train Loss: 0.1015 Val Loss: 0.3076 Acc: 0.8768 Pre: 0.8684 Recall: 0.9041 F1: 0.8859 Train AUC: 0.9948 Val AUC: 0.9560 Time: 14.26\n",
      "Epoch: 541 Train Loss: 0.1031 Val Loss: 0.3029 Acc: 0.8804 Pre: 0.8717 Recall: 0.9075 F1: 0.8893 Train AUC: 0.9942 Val AUC: 0.9579 Time: 13.15\n",
      "Epoch: 542 Train Loss: 0.1051 Val Loss: 0.3008 Acc: 0.8931 Pre: 0.8896 Recall: 0.9110 F1: 0.9002 Train AUC: 0.9939 Val AUC: 0.9581 Time: 13.20\n",
      "Epoch: 543 Train Loss: 0.0991 Val Loss: 0.3015 Acc: 0.8931 Pre: 0.8923 Recall: 0.9075 F1: 0.8998 Train AUC: 0.9946 Val AUC: 0.9577 Time: 13.68\n",
      "Epoch: 544 Train Loss: 0.1151 Val Loss: 0.3045 Acc: 0.8895 Pre: 0.8787 Recall: 0.9178 F1: 0.8978 Train AUC: 0.9924 Val AUC: 0.9579 Time: 13.87\n",
      "Epoch: 545 Train Loss: 0.1125 Val Loss: 0.3116 Acc: 0.8804 Pre: 0.8645 Recall: 0.9178 F1: 0.8904 Train AUC: 0.9929 Val AUC: 0.9568 Time: 14.36\n",
      "Epoch: 546 Train Loss: 0.1097 Val Loss: 0.3049 Acc: 0.8859 Pre: 0.8804 Recall: 0.9075 F1: 0.8938 Train AUC: 0.9937 Val AUC: 0.9556 Time: 15.10\n",
      "Epoch: 547 Train Loss: 0.1069 Val Loss: 0.2995 Acc: 0.8822 Pre: 0.8874 Recall: 0.8904 F1: 0.8889 Train AUC: 0.9939 Val AUC: 0.9560 Time: 13.78\n",
      "Epoch: 548 Train Loss: 0.1036 Val Loss: 0.3030 Acc: 0.8895 Pre: 0.8837 Recall: 0.9110 F1: 0.8971 Train AUC: 0.9949 Val AUC: 0.9586 Time: 12.70\n",
      "Epoch: 549 Train Loss: 0.1040 Val Loss: 0.3091 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9938 Val AUC: 0.9589 Time: 12.01\n",
      "Epoch: 550 Train Loss: 0.1004 Val Loss: 0.3030 Acc: 0.8895 Pre: 0.8787 Recall: 0.9178 F1: 0.8978 Train AUC: 0.9952 Val AUC: 0.9580 Time: 12.51\n",
      "Epoch: 551 Train Loss: 0.1021 Val Loss: 0.2996 Acc: 0.8877 Pre: 0.8859 Recall: 0.9041 F1: 0.8949 Train AUC: 0.9945 Val AUC: 0.9580 Time: 12.99\n",
      "Epoch: 552 Train Loss: 0.1053 Val Loss: 0.2990 Acc: 0.8949 Pre: 0.8900 Recall: 0.9144 F1: 0.9020 Train AUC: 0.9944 Val AUC: 0.9589 Time: 13.21\n",
      "Epoch: 553 Train Loss: 0.1045 Val Loss: 0.3123 Acc: 0.8877 Pre: 0.8662 Recall: 0.9315 F1: 0.8977 Train AUC: 0.9941 Val AUC: 0.9583 Time: 13.82\n",
      "Epoch: 554 Train Loss: 0.1057 Val Loss: 0.3092 Acc: 0.8895 Pre: 0.8738 Recall: 0.9247 F1: 0.8985 Train AUC: 0.9945 Val AUC: 0.9580 Time: 14.40\n",
      "Epoch: 555 Train Loss: 0.0948 Val Loss: 0.3034 Acc: 0.8859 Pre: 0.8935 Recall: 0.8904 F1: 0.8919 Train AUC: 0.9958 Val AUC: 0.9569 Time: 15.61\n",
      "Epoch: 556 Train Loss: 0.1034 Val Loss: 0.3042 Acc: 0.8804 Pre: 0.8924 Recall: 0.8801 F1: 0.8862 Train AUC: 0.9942 Val AUC: 0.9565 Time: 15.47\n",
      "Epoch: 557 Train Loss: 0.1083 Val Loss: 0.3194 Acc: 0.8786 Pre: 0.8571 Recall: 0.9247 F1: 0.8896 Train AUC: 0.9948 Val AUC: 0.9564 Time: 14.09\n",
      "Epoch: 558 Train Loss: 0.1040 Val Loss: 0.3343 Acc: 0.8732 Pre: 0.8405 Recall: 0.9384 F1: 0.8867 Train AUC: 0.9941 Val AUC: 0.9570 Time: 13.40\n",
      "Epoch: 559 Train Loss: 0.1076 Val Loss: 0.3043 Acc: 0.8841 Pre: 0.8750 Recall: 0.9110 F1: 0.8926 Train AUC: 0.9952 Val AUC: 0.9578 Time: 13.39\n",
      "Epoch: 560 Train Loss: 0.0992 Val Loss: 0.3105 Acc: 0.8786 Pre: 0.8947 Recall: 0.8733 F1: 0.8839 Train AUC: 0.9950 Val AUC: 0.9586 Time: 12.99\n",
      "Epoch: 561 Train Loss: 0.1109 Val Loss: 0.3073 Acc: 0.8841 Pre: 0.8851 Recall: 0.8973 F1: 0.8912 Train AUC: 0.9939 Val AUC: 0.9585 Time: 12.87\n",
      "Epoch: 562 Train Loss: 0.1041 Val Loss: 0.3360 Acc: 0.8768 Pre: 0.8500 Recall: 0.9315 F1: 0.8889 Train AUC: 0.9945 Val AUC: 0.9582 Time: 13.36\n",
      "Epoch: 563 Train Loss: 0.1172 Val Loss: 0.3160 Acc: 0.8822 Pre: 0.8650 Recall: 0.9212 F1: 0.8922 Train AUC: 0.9941 Val AUC: 0.9576 Time: 14.08\n",
      "Epoch: 564 Train Loss: 0.0974 Val Loss: 0.3054 Acc: 0.8841 Pre: 0.8878 Recall: 0.8938 F1: 0.8908 Train AUC: 0.9950 Val AUC: 0.9574 Time: 14.95\n",
      "Epoch: 565 Train Loss: 0.1009 Val Loss: 0.3101 Acc: 0.8804 Pre: 0.8924 Recall: 0.8801 F1: 0.8862 Train AUC: 0.9946 Val AUC: 0.9569 Time: 14.91\n",
      "Epoch: 566 Train Loss: 0.1069 Val Loss: 0.3174 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9944 Val AUC: 0.9577 Time: 14.51\n",
      "Epoch: 567 Train Loss: 0.1111 Val Loss: 0.3205 Acc: 0.8768 Pre: 0.8567 Recall: 0.9212 F1: 0.8878 Train AUC: 0.9924 Val AUC: 0.9565 Time: 13.37\n",
      "Epoch: 568 Train Loss: 0.1091 Val Loss: 0.3027 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9940 Val AUC: 0.9556 Time: 13.28\n",
      "Epoch: 569 Train Loss: 0.1009 Val Loss: 0.2962 Acc: 0.8895 Pre: 0.8889 Recall: 0.9041 F1: 0.8964 Train AUC: 0.9950 Val AUC: 0.9572 Time: 12.68\n",
      "Epoch: 570 Train Loss: 0.1156 Val Loss: 0.3051 Acc: 0.8986 Pre: 0.8986 Recall: 0.9110 F1: 0.9048 Train AUC: 0.9943 Val AUC: 0.9601 Time: 13.04\n",
      "Epoch: 571 Train Loss: 0.1074 Val Loss: 0.3221 Acc: 0.8877 Pre: 0.8758 Recall: 0.9178 F1: 0.8963 Train AUC: 0.9934 Val AUC: 0.9583 Time: 13.54\n",
      "Epoch: 572 Train Loss: 0.1087 Val Loss: 0.3106 Acc: 0.8913 Pre: 0.8816 Recall: 0.9178 F1: 0.8993 Train AUC: 0.9939 Val AUC: 0.9590 Time: 15.23\n",
      "Epoch: 573 Train Loss: 0.1048 Val Loss: 0.2999 Acc: 0.8895 Pre: 0.8863 Recall: 0.9075 F1: 0.8968 Train AUC: 0.9943 Val AUC: 0.9569 Time: 17.89\n",
      "Epoch: 574 Train Loss: 0.1034 Val Loss: 0.3108 Acc: 0.8750 Pre: 0.8968 Recall: 0.8630 F1: 0.8796 Train AUC: 0.9939 Val AUC: 0.9527 Time: 15.16\n",
      "Epoch: 575 Train Loss: 0.1256 Val Loss: 0.3124 Acc: 0.8822 Pre: 0.8673 Recall: 0.9178 F1: 0.8918 Train AUC: 0.9930 Val AUC: 0.9548 Time: 14.20\n",
      "Epoch: 576 Train Loss: 0.1024 Val Loss: 0.3280 Acc: 0.8841 Pre: 0.8631 Recall: 0.9281 F1: 0.8944 Train AUC: 0.9941 Val AUC: 0.9566 Time: 14.17\n",
      "Epoch: 577 Train Loss: 0.1030 Val Loss: 0.3136 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9944 Val AUC: 0.9581 Time: 14.25\n",
      "Epoch: 578 Train Loss: 0.1029 Val Loss: 0.3053 Acc: 0.8949 Pre: 0.8900 Recall: 0.9144 F1: 0.9020 Train AUC: 0.9944 Val AUC: 0.9595 Time: 14.87\n",
      "Epoch: 579 Train Loss: 0.0928 Val Loss: 0.3096 Acc: 0.8931 Pre: 0.8896 Recall: 0.9110 F1: 0.9002 Train AUC: 0.9957 Val AUC: 0.9598 Time: 16.14\n",
      "Epoch: 580 Train Loss: 0.0986 Val Loss: 0.3224 Acc: 0.8949 Pre: 0.8774 Recall: 0.9315 F1: 0.9037 Train AUC: 0.9952 Val AUC: 0.9589 Time: 14.81\n",
      "Epoch: 581 Train Loss: 0.1054 Val Loss: 0.3240 Acc: 0.8913 Pre: 0.8766 Recall: 0.9247 F1: 0.9000 Train AUC: 0.9942 Val AUC: 0.9584 Time: 15.15\n",
      "Epoch: 582 Train Loss: 0.1013 Val Loss: 0.3147 Acc: 0.8822 Pre: 0.8771 Recall: 0.9041 F1: 0.8904 Train AUC: 0.9943 Val AUC: 0.9579 Time: 13.81\n",
      "Epoch: 583 Train Loss: 0.1004 Val Loss: 0.3109 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9943 Val AUC: 0.9572 Time: 12.61\n",
      "Epoch: 584 Train Loss: 0.1030 Val Loss: 0.3122 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9944 Val AUC: 0.9561 Time: 13.05\n",
      "Epoch: 585 Train Loss: 0.1010 Val Loss: 0.3212 Acc: 0.8768 Pre: 0.8567 Recall: 0.9212 F1: 0.8878 Train AUC: 0.9941 Val AUC: 0.9539 Time: 13.48\n",
      "Epoch: 586 Train Loss: 0.0974 Val Loss: 0.3190 Acc: 0.8750 Pre: 0.8562 Recall: 0.9178 F1: 0.8860 Train AUC: 0.9954 Val AUC: 0.9549 Time: 14.11\n",
      "Epoch: 587 Train Loss: 0.0972 Val Loss: 0.3146 Acc: 0.8804 Pre: 0.8767 Recall: 0.9007 F1: 0.8885 Train AUC: 0.9950 Val AUC: 0.9565 Time: 14.81\n",
      "Epoch: 588 Train Loss: 0.0948 Val Loss: 0.3205 Acc: 0.8786 Pre: 0.8763 Recall: 0.8973 F1: 0.8866 Train AUC: 0.9957 Val AUC: 0.9579 Time: 15.25\n",
      "Epoch: 589 Train Loss: 0.1044 Val Loss: 0.3278 Acc: 0.8804 Pre: 0.8693 Recall: 0.9110 F1: 0.8896 Train AUC: 0.9939 Val AUC: 0.9579 Time: 15.94\n",
      "Epoch: 590 Train Loss: 0.0988 Val Loss: 0.3311 Acc: 0.8877 Pre: 0.8662 Recall: 0.9315 F1: 0.8977 Train AUC: 0.9946 Val AUC: 0.9572 Time: 14.66\n",
      "Epoch: 591 Train Loss: 0.1011 Val Loss: 0.3242 Acc: 0.8804 Pre: 0.8645 Recall: 0.9178 F1: 0.8904 Train AUC: 0.9951 Val AUC: 0.9549 Time: 12.92\n",
      "Epoch: 592 Train Loss: 0.0982 Val Loss: 0.3184 Acc: 0.8859 Pre: 0.8804 Recall: 0.9075 F1: 0.8938 Train AUC: 0.9953 Val AUC: 0.9552 Time: 12.46\n",
      "Epoch: 593 Train Loss: 0.0946 Val Loss: 0.3207 Acc: 0.8931 Pre: 0.8870 Recall: 0.9144 F1: 0.9005 Train AUC: 0.9954 Val AUC: 0.9560 Time: 12.66\n",
      "Epoch: 594 Train Loss: 0.1014 Val Loss: 0.3409 Acc: 0.8859 Pre: 0.8635 Recall: 0.9315 F1: 0.8962 Train AUC: 0.9940 Val AUC: 0.9567 Time: 13.53\n",
      "Epoch: 595 Train Loss: 0.1043 Val Loss: 0.3253 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9954 Val AUC: 0.9566 Time: 13.96\n",
      "Epoch: 596 Train Loss: 0.0933 Val Loss: 0.3137 Acc: 0.8895 Pre: 0.8889 Recall: 0.9041 F1: 0.8964 Train AUC: 0.9955 Val AUC: 0.9551 Time: 15.19\n",
      "Epoch: 597 Train Loss: 0.1037 Val Loss: 0.3208 Acc: 0.8768 Pre: 0.8613 Recall: 0.9144 F1: 0.8870 Train AUC: 0.9952 Val AUC: 0.9550 Time: 19.27\n",
      "Epoch: 598 Train Loss: 0.0948 Val Loss: 0.3194 Acc: 0.8841 Pre: 0.8677 Recall: 0.9212 F1: 0.8937 Train AUC: 0.9957 Val AUC: 0.9559 Time: 15.76\n",
      "Epoch: 599 Train Loss: 0.0991 Val Loss: 0.3156 Acc: 0.8895 Pre: 0.8812 Recall: 0.9144 F1: 0.8975 Train AUC: 0.9952 Val AUC: 0.9572 Time: 13.81\n",
      "Epoch: 600 Train Loss: 0.1002 Val Loss: 0.3200 Acc: 0.8804 Pre: 0.8792 Recall: 0.8973 F1: 0.8881 Train AUC: 0.9943 Val AUC: 0.9570 Time: 13.15\n",
      "Epoch: 601 Train Loss: 0.1020 Val Loss: 0.3221 Acc: 0.8786 Pre: 0.8713 Recall: 0.9041 F1: 0.8874 Train AUC: 0.9942 Val AUC: 0.9568 Time: 12.90\n",
      "Epoch: 602 Train Loss: 0.0992 Val Loss: 0.3246 Acc: 0.8696 Pre: 0.8503 Recall: 0.9144 F1: 0.8812 Train AUC: 0.9944 Val AUC: 0.9544 Time: 13.53\n",
      "Epoch: 603 Train Loss: 0.0900 Val Loss: 0.3305 Acc: 0.8804 Pre: 0.8531 Recall: 0.9349 F1: 0.8922 Train AUC: 0.9963 Val AUC: 0.9543 Time: 14.17\n",
      "Epoch: 604 Train Loss: 0.1004 Val Loss: 0.3159 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9947 Val AUC: 0.9572 Time: 14.40\n",
      "Epoch: 605 Train Loss: 0.0970 Val Loss: 0.3179 Acc: 0.8841 Pre: 0.8826 Recall: 0.9007 F1: 0.8915 Train AUC: 0.9950 Val AUC: 0.9576 Time: 13.45\n",
      "Epoch: 606 Train Loss: 0.1003 Val Loss: 0.3274 Acc: 0.8841 Pre: 0.8725 Recall: 0.9144 F1: 0.8930 Train AUC: 0.9943 Val AUC: 0.9573 Time: 13.42\n",
      "Epoch: 607 Train Loss: 0.0966 Val Loss: 0.3262 Acc: 0.8768 Pre: 0.8590 Recall: 0.9178 F1: 0.8874 Train AUC: 0.9950 Val AUC: 0.9551 Time: 13.84\n",
      "Epoch: 608 Train Loss: 0.0858 Val Loss: 0.3356 Acc: 0.8678 Pre: 0.8476 Recall: 0.9144 F1: 0.8797 Train AUC: 0.9964 Val AUC: 0.9513 Time: 13.66\n",
      "Epoch: 609 Train Loss: 0.1001 Val Loss: 0.3188 Acc: 0.8750 Pre: 0.8680 Recall: 0.9007 F1: 0.8840 Train AUC: 0.9947 Val AUC: 0.9549 Time: 14.22\n",
      "Epoch: 610 Train Loss: 0.0990 Val Loss: 0.3155 Acc: 0.8895 Pre: 0.8969 Recall: 0.8938 F1: 0.8954 Train AUC: 0.9946 Val AUC: 0.9585 Time: 14.37\n",
      "Epoch: 611 Train Loss: 0.1086 Val Loss: 0.3282 Acc: 0.8877 Pre: 0.8808 Recall: 0.9110 F1: 0.8956 Train AUC: 0.9941 Val AUC: 0.9593 Time: 14.26\n",
      "Epoch: 612 Train Loss: 0.1011 Val Loss: 0.3357 Acc: 0.8877 Pre: 0.8686 Recall: 0.9281 F1: 0.8974 Train AUC: 0.9937 Val AUC: 0.9590 Time: 13.86\n",
      "Epoch: 613 Train Loss: 0.1048 Val Loss: 0.3163 Acc: 0.8768 Pre: 0.8544 Recall: 0.9247 F1: 0.8882 Train AUC: 0.9946 Val AUC: 0.9576 Time: 13.41\n",
      "Epoch: 614 Train Loss: 0.0961 Val Loss: 0.3101 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9951 Val AUC: 0.9552 Time: 13.74\n",
      "Epoch: 615 Train Loss: 0.0931 Val Loss: 0.3134 Acc: 0.8786 Pre: 0.8893 Recall: 0.8801 F1: 0.8847 Train AUC: 0.9958 Val AUC: 0.9546 Time: 14.42\n",
      "Epoch: 616 Train Loss: 0.1025 Val Loss: 0.3358 Acc: 0.8877 Pre: 0.8710 Recall: 0.9247 F1: 0.8970 Train AUC: 0.9957 Val AUC: 0.9555 Time: 15.12\n",
      "Epoch: 617 Train Loss: 0.1089 Val Loss: 0.3440 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9939 Val AUC: 0.9565 Time: 14.91\n",
      "Epoch: 618 Train Loss: 0.1057 Val Loss: 0.3116 Acc: 0.8841 Pre: 0.8958 Recall: 0.8836 F1: 0.8897 Train AUC: 0.9949 Val AUC: 0.9563 Time: 14.46\n",
      "Epoch: 619 Train Loss: 0.0963 Val Loss: 0.3140 Acc: 0.8714 Pre: 0.8850 Recall: 0.8699 F1: 0.8774 Train AUC: 0.9953 Val AUC: 0.9555 Time: 13.26\n",
      "Epoch: 620 Train Loss: 0.1192 Val Loss: 0.3205 Acc: 0.8841 Pre: 0.8631 Recall: 0.9281 F1: 0.8944 Train AUC: 0.9932 Val AUC: 0.9566 Time: 12.80\n",
      "Epoch: 621 Train Loss: 0.1054 Val Loss: 0.3523 Acc: 0.8786 Pre: 0.8483 Recall: 0.9384 F1: 0.8911 Train AUC: 0.9940 Val AUC: 0.9580 Time: 13.31\n",
      "Epoch: 622 Train Loss: 0.1209 Val Loss: 0.3242 Acc: 0.8841 Pre: 0.8725 Recall: 0.9144 F1: 0.8930 Train AUC: 0.9947 Val AUC: 0.9585 Time: 13.89\n",
      "Epoch: 623 Train Loss: 0.0993 Val Loss: 0.3133 Acc: 0.8822 Pre: 0.8874 Recall: 0.8904 F1: 0.8889 Train AUC: 0.9947 Val AUC: 0.9577 Time: 14.43\n",
      "Epoch: 624 Train Loss: 0.1008 Val Loss: 0.3103 Acc: 0.8895 Pre: 0.8942 Recall: 0.8973 F1: 0.8957 Train AUC: 0.9951 Val AUC: 0.9563 Time: 14.49\n",
      "Epoch: 625 Train Loss: 0.1007 Val Loss: 0.3354 Acc: 0.8841 Pre: 0.8585 Recall: 0.9349 F1: 0.8951 Train AUC: 0.9957 Val AUC: 0.9563 Time: 14.20\n",
      "Epoch: 626 Train Loss: 0.1047 Val Loss: 0.3576 Acc: 0.8732 Pre: 0.8405 Recall: 0.9384 F1: 0.8867 Train AUC: 0.9951 Val AUC: 0.9573 Time: 14.09\n",
      "Epoch: 627 Train Loss: 0.1208 Val Loss: 0.3194 Acc: 0.8877 Pre: 0.8808 Recall: 0.9110 F1: 0.8956 Train AUC: 0.9937 Val AUC: 0.9572 Time: 12.65\n",
      "Epoch: 628 Train Loss: 0.0928 Val Loss: 0.3110 Acc: 0.8768 Pre: 0.8784 Recall: 0.8904 F1: 0.8844 Train AUC: 0.9949 Val AUC: 0.9565 Time: 13.02\n",
      "Epoch: 629 Train Loss: 0.1093 Val Loss: 0.3096 Acc: 0.8696 Pre: 0.8667 Recall: 0.8904 F1: 0.8784 Train AUC: 0.9944 Val AUC: 0.9555 Time: 13.83\n",
      "Epoch: 630 Train Loss: 0.1051 Val Loss: 0.3288 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9945 Val AUC: 0.9548 Time: 14.75\n",
      "Epoch: 631 Train Loss: 0.0947 Val Loss: 0.3395 Acc: 0.8877 Pre: 0.8662 Recall: 0.9315 F1: 0.8977 Train AUC: 0.9958 Val AUC: 0.9551 Time: 14.93\n",
      "Epoch: 632 Train Loss: 0.0988 Val Loss: 0.3191 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9956 Val AUC: 0.9570 Time: 15.91\n",
      "Epoch: 633 Train Loss: 0.0932 Val Loss: 0.3149 Acc: 0.8895 Pre: 0.8942 Recall: 0.8973 F1: 0.8957 Train AUC: 0.9954 Val AUC: 0.9563 Time: 16.41\n",
      "Epoch: 634 Train Loss: 0.0996 Val Loss: 0.3179 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9948 Val AUC: 0.9546 Time: 15.58\n",
      "Epoch: 635 Train Loss: 0.0912 Val Loss: 0.3382 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9958 Val AUC: 0.9505 Time: 14.27\n",
      "Epoch: 636 Train Loss: 0.0998 Val Loss: 0.3293 Acc: 0.8786 Pre: 0.8549 Recall: 0.9281 F1: 0.8900 Train AUC: 0.9956 Val AUC: 0.9548 Time: 15.51\n",
      "Epoch: 637 Train Loss: 0.1029 Val Loss: 0.3250 Acc: 0.8768 Pre: 0.8684 Recall: 0.9041 F1: 0.8859 Train AUC: 0.9942 Val AUC: 0.9574 Time: 14.92\n",
      "Epoch: 638 Train Loss: 0.0956 Val Loss: 0.3295 Acc: 0.8804 Pre: 0.8792 Recall: 0.8973 F1: 0.8881 Train AUC: 0.9948 Val AUC: 0.9583 Time: 15.07\n",
      "Epoch: 639 Train Loss: 0.0956 Val Loss: 0.3198 Acc: 0.8895 Pre: 0.8889 Recall: 0.9041 F1: 0.8964 Train AUC: 0.9945 Val AUC: 0.9578 Time: 14.68\n",
      "Epoch: 640 Train Loss: 0.0901 Val Loss: 0.3263 Acc: 0.8696 Pre: 0.8595 Recall: 0.9007 F1: 0.8796 Train AUC: 0.9959 Val AUC: 0.9534 Time: 14.92\n",
      "Epoch: 641 Train Loss: 0.1040 Val Loss: 0.3213 Acc: 0.8822 Pre: 0.8746 Recall: 0.9075 F1: 0.8908 Train AUC: 0.9945 Val AUC: 0.9562 Time: 13.57\n",
      "Epoch: 642 Train Loss: 0.0953 Val Loss: 0.3193 Acc: 0.8895 Pre: 0.8863 Recall: 0.9075 F1: 0.8968 Train AUC: 0.9954 Val AUC: 0.9571 Time: 12.70\n",
      "Epoch: 643 Train Loss: 0.0927 Val Loss: 0.3200 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9950 Val AUC: 0.9566 Time: 13.11\n",
      "Epoch: 644 Train Loss: 0.0933 Val Loss: 0.3198 Acc: 0.8768 Pre: 0.8684 Recall: 0.9041 F1: 0.8859 Train AUC: 0.9947 Val AUC: 0.9535 Time: 16.19\n",
      "Epoch: 645 Train Loss: 0.0914 Val Loss: 0.3292 Acc: 0.8696 Pre: 0.8526 Recall: 0.9110 F1: 0.8808 Train AUC: 0.9961 Val AUC: 0.9507 Time: 16.17\n",
      "Epoch: 646 Train Loss: 0.0935 Val Loss: 0.3228 Acc: 0.8913 Pre: 0.8816 Recall: 0.9178 F1: 0.8993 Train AUC: 0.9963 Val AUC: 0.9557 Time: 17.64\n",
      "Epoch: 647 Train Loss: 0.0889 Val Loss: 0.3292 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9968 Val AUC: 0.9583 Time: 16.98\n",
      "Epoch: 648 Train Loss: 0.1012 Val Loss: 0.3341 Acc: 0.8859 Pre: 0.8881 Recall: 0.8973 F1: 0.8927 Train AUC: 0.9939 Val AUC: 0.9577 Time: 17.72\n",
      "Epoch: 649 Train Loss: 0.1000 Val Loss: 0.3275 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9944 Val AUC: 0.9569 Time: 16.16\n",
      "Epoch: 650 Train Loss: 0.0972 Val Loss: 0.3307 Acc: 0.8786 Pre: 0.8617 Recall: 0.9178 F1: 0.8889 Train AUC: 0.9948 Val AUC: 0.9549 Time: 13.96\n",
      "Epoch: 651 Train Loss: 0.1024 Val Loss: 0.3452 Acc: 0.8678 Pre: 0.8454 Recall: 0.9178 F1: 0.8801 Train AUC: 0.9944 Val AUC: 0.9508 Time: 13.42\n",
      "Epoch: 652 Train Loss: 0.1007 Val Loss: 0.3282 Acc: 0.8822 Pre: 0.8796 Recall: 0.9007 F1: 0.8900 Train AUC: 0.9951 Val AUC: 0.9521 Time: 14.64\n",
      "Epoch: 653 Train Loss: 0.0907 Val Loss: 0.3347 Acc: 0.8714 Pre: 0.8797 Recall: 0.8767 F1: 0.8782 Train AUC: 0.9959 Val AUC: 0.9546 Time: 15.31\n",
      "Epoch: 654 Train Loss: 0.0999 Val Loss: 0.3396 Acc: 0.8768 Pre: 0.8733 Recall: 0.8973 F1: 0.8851 Train AUC: 0.9945 Val AUC: 0.9552 Time: 14.97\n",
      "Epoch: 655 Train Loss: 0.0994 Val Loss: 0.3319 Acc: 0.8895 Pre: 0.8812 Recall: 0.9144 F1: 0.8975 Train AUC: 0.9941 Val AUC: 0.9567 Time: 14.74\n",
      "Epoch: 656 Train Loss: 0.1033 Val Loss: 0.3272 Acc: 0.8822 Pre: 0.8721 Recall: 0.9110 F1: 0.8911 Train AUC: 0.9938 Val AUC: 0.9553 Time: 15.57\n",
      "Epoch: 657 Train Loss: 0.0888 Val Loss: 0.3385 Acc: 0.8750 Pre: 0.8562 Recall: 0.9178 F1: 0.8860 Train AUC: 0.9964 Val AUC: 0.9534 Time: 16.17\n",
      "Epoch: 658 Train Loss: 0.1008 Val Loss: 0.3262 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9951 Val AUC: 0.9566 Time: 13.23\n",
      "Epoch: 659 Train Loss: 0.0979 Val Loss: 0.3314 Acc: 0.8804 Pre: 0.8717 Recall: 0.9075 F1: 0.8893 Train AUC: 0.9949 Val AUC: 0.9576 Time: 12.91\n",
      "Epoch: 660 Train Loss: 0.1015 Val Loss: 0.3314 Acc: 0.8804 Pre: 0.8792 Recall: 0.8973 F1: 0.8881 Train AUC: 0.9937 Val AUC: 0.9578 Time: 13.32\n",
      "Epoch: 661 Train Loss: 0.0943 Val Loss: 0.3284 Acc: 0.8877 Pre: 0.8808 Recall: 0.9110 F1: 0.8956 Train AUC: 0.9945 Val AUC: 0.9565 Time: 13.56\n",
      "Epoch: 662 Train Loss: 0.0915 Val Loss: 0.3430 Acc: 0.8768 Pre: 0.8613 Recall: 0.9144 F1: 0.8870 Train AUC: 0.9951 Val AUC: 0.9527 Time: 14.04\n",
      "Epoch: 663 Train Loss: 0.0928 Val Loss: 0.3571 Acc: 0.8714 Pre: 0.8553 Recall: 0.9110 F1: 0.8823 Train AUC: 0.9956 Val AUC: 0.9470 Time: 14.83\n",
      "Epoch: 664 Train Loss: 0.0947 Val Loss: 0.3384 Acc: 0.8786 Pre: 0.8664 Recall: 0.9110 F1: 0.8881 Train AUC: 0.9952 Val AUC: 0.9529 Time: 15.85\n",
      "Epoch: 665 Train Loss: 0.0910 Val Loss: 0.3267 Acc: 0.8768 Pre: 0.8784 Recall: 0.8904 F1: 0.8844 Train AUC: 0.9962 Val AUC: 0.9558 Time: 14.36\n",
      "Epoch: 666 Train Loss: 0.0929 Val Loss: 0.3292 Acc: 0.8841 Pre: 0.8750 Recall: 0.9110 F1: 0.8926 Train AUC: 0.9955 Val AUC: 0.9565 Time: 12.79\n",
      "Epoch: 667 Train Loss: 0.0951 Val Loss: 0.3339 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9946 Val AUC: 0.9569 Time: 12.65\n",
      "Epoch: 668 Train Loss: 0.1025 Val Loss: 0.3361 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9945 Val AUC: 0.9563 Time: 13.72\n",
      "Epoch: 669 Train Loss: 0.0965 Val Loss: 0.3193 Acc: 0.8877 Pre: 0.8808 Recall: 0.9110 F1: 0.8956 Train AUC: 0.9955 Val AUC: 0.9562 Time: 13.89\n",
      "Epoch: 670 Train Loss: 0.0861 Val Loss: 0.3169 Acc: 0.8822 Pre: 0.8847 Recall: 0.8938 F1: 0.8893 Train AUC: 0.9963 Val AUC: 0.9561 Time: 14.41\n",
      "Epoch: 671 Train Loss: 0.0960 Val Loss: 0.3269 Acc: 0.8750 Pre: 0.8680 Recall: 0.9007 F1: 0.8840 Train AUC: 0.9953 Val AUC: 0.9562 Time: 15.34\n",
      "Epoch: 672 Train Loss: 0.0925 Val Loss: 0.3365 Acc: 0.8913 Pre: 0.8791 Recall: 0.9212 F1: 0.8997 Train AUC: 0.9953 Val AUC: 0.9553 Time: 14.91\n",
      "Epoch: 673 Train Loss: 0.0933 Val Loss: 0.3336 Acc: 0.8895 Pre: 0.8738 Recall: 0.9247 F1: 0.8985 Train AUC: 0.9955 Val AUC: 0.9563 Time: 13.40\n",
      "Epoch: 674 Train Loss: 0.0879 Val Loss: 0.3218 Acc: 0.8913 Pre: 0.8867 Recall: 0.9110 F1: 0.8986 Train AUC: 0.9960 Val AUC: 0.9563 Time: 12.75\n",
      "Epoch: 675 Train Loss: 0.0913 Val Loss: 0.3170 Acc: 0.8877 Pre: 0.8859 Recall: 0.9041 F1: 0.8949 Train AUC: 0.9959 Val AUC: 0.9576 Time: 12.88\n",
      "Epoch: 676 Train Loss: 0.0929 Val Loss: 0.3262 Acc: 0.8895 Pre: 0.8762 Recall: 0.9212 F1: 0.8982 Train AUC: 0.9959 Val AUC: 0.9582 Time: 13.48\n",
      "Epoch: 677 Train Loss: 0.0911 Val Loss: 0.3296 Acc: 0.8895 Pre: 0.8690 Recall: 0.9315 F1: 0.8992 Train AUC: 0.9956 Val AUC: 0.9578 Time: 14.12\n",
      "Epoch: 678 Train Loss: 0.0881 Val Loss: 0.3203 Acc: 0.8913 Pre: 0.8791 Recall: 0.9212 F1: 0.8997 Train AUC: 0.9962 Val AUC: 0.9563 Time: 14.19\n",
      "Epoch: 679 Train Loss: 0.0891 Val Loss: 0.3154 Acc: 0.8768 Pre: 0.8660 Recall: 0.9075 F1: 0.8863 Train AUC: 0.9963 Val AUC: 0.9545 Time: 14.73\n",
      "Epoch: 680 Train Loss: 0.0959 Val Loss: 0.3154 Acc: 0.8822 Pre: 0.8721 Recall: 0.9110 F1: 0.8911 Train AUC: 0.9956 Val AUC: 0.9554 Time: 14.99\n",
      "Epoch: 681 Train Loss: 0.0907 Val Loss: 0.3233 Acc: 0.8967 Pre: 0.8852 Recall: 0.9247 F1: 0.9045 Train AUC: 0.9964 Val AUC: 0.9581 Time: 13.69\n",
      "Epoch: 682 Train Loss: 0.0892 Val Loss: 0.3306 Acc: 0.8877 Pre: 0.8758 Recall: 0.9178 F1: 0.8963 Train AUC: 0.9957 Val AUC: 0.9586 Time: 13.47\n",
      "Epoch: 683 Train Loss: 0.0960 Val Loss: 0.3251 Acc: 0.8895 Pre: 0.8812 Recall: 0.9144 F1: 0.8975 Train AUC: 0.9946 Val AUC: 0.9578 Time: 13.30\n",
      "Epoch: 684 Train Loss: 0.0941 Val Loss: 0.3209 Acc: 0.8786 Pre: 0.8738 Recall: 0.9007 F1: 0.8870 Train AUC: 0.9954 Val AUC: 0.9545 Time: 13.08\n",
      "Epoch: 685 Train Loss: 0.0937 Val Loss: 0.3256 Acc: 0.8804 Pre: 0.8669 Recall: 0.9144 F1: 0.8900 Train AUC: 0.9962 Val AUC: 0.9534 Time: 14.12\n",
      "Epoch: 686 Train Loss: 0.0955 Val Loss: 0.3212 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9950 Val AUC: 0.9562 Time: 14.37\n",
      "Epoch: 687 Train Loss: 0.0911 Val Loss: 0.3241 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9956 Val AUC: 0.9582 Time: 14.97\n",
      "Epoch: 688 Train Loss: 0.0912 Val Loss: 0.3258 Acc: 0.8859 Pre: 0.8779 Recall: 0.9110 F1: 0.8941 Train AUC: 0.9952 Val AUC: 0.9581 Time: 13.66\n",
      "Epoch: 689 Train Loss: 0.0923 Val Loss: 0.3240 Acc: 0.8877 Pre: 0.8758 Recall: 0.9178 F1: 0.8963 Train AUC: 0.9953 Val AUC: 0.9572 Time: 13.50\n",
      "Epoch: 690 Train Loss: 0.0855 Val Loss: 0.3265 Acc: 0.8786 Pre: 0.8617 Recall: 0.9178 F1: 0.8889 Train AUC: 0.9961 Val AUC: 0.9556 Time: 13.39\n",
      "Epoch: 691 Train Loss: 0.0904 Val Loss: 0.3163 Acc: 0.8822 Pre: 0.8721 Recall: 0.9110 F1: 0.8911 Train AUC: 0.9961 Val AUC: 0.9556 Time: 13.78\n",
      "Epoch: 692 Train Loss: 0.0849 Val Loss: 0.3155 Acc: 0.8877 Pre: 0.8859 Recall: 0.9041 F1: 0.8949 Train AUC: 0.9969 Val AUC: 0.9561 Time: 13.99\n",
      "Epoch: 693 Train Loss: 0.0819 Val Loss: 0.3187 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9972 Val AUC: 0.9561 Time: 14.67\n",
      "Epoch: 694 Train Loss: 0.0857 Val Loss: 0.3227 Acc: 0.8841 Pre: 0.8775 Recall: 0.9075 F1: 0.8923 Train AUC: 0.9968 Val AUC: 0.9570 Time: 14.18\n",
      "Epoch: 695 Train Loss: 0.0907 Val Loss: 0.3397 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9956 Val AUC: 0.9569 Time: 13.49\n",
      "Epoch: 696 Train Loss: 0.0970 Val Loss: 0.3355 Acc: 0.8786 Pre: 0.8527 Recall: 0.9315 F1: 0.8903 Train AUC: 0.9952 Val AUC: 0.9565 Time: 13.14\n",
      "Epoch: 697 Train Loss: 0.0937 Val Loss: 0.3217 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9953 Val AUC: 0.9553 Time: 13.39\n",
      "Epoch: 698 Train Loss: 0.0871 Val Loss: 0.3222 Acc: 0.8804 Pre: 0.8818 Recall: 0.8938 F1: 0.8878 Train AUC: 0.9962 Val AUC: 0.9552 Time: 13.66\n",
      "Epoch: 699 Train Loss: 0.0913 Val Loss: 0.3415 Acc: 0.8768 Pre: 0.8500 Recall: 0.9315 F1: 0.8889 Train AUC: 0.9962 Val AUC: 0.9556 Time: 14.50\n",
      "Epoch: 700 Train Loss: 0.1003 Val Loss: 0.3412 Acc: 0.8804 Pre: 0.8622 Recall: 0.9212 F1: 0.8907 Train AUC: 0.9951 Val AUC: 0.9554 Time: 14.85\n",
      "Epoch: 701 Train Loss: 0.0955 Val Loss: 0.3282 Acc: 0.8822 Pre: 0.8796 Recall: 0.9007 F1: 0.8900 Train AUC: 0.9952 Val AUC: 0.9559 Time: 14.04\n",
      "Epoch: 702 Train Loss: 0.0910 Val Loss: 0.3239 Acc: 0.8786 Pre: 0.8893 Recall: 0.8801 F1: 0.8847 Train AUC: 0.9956 Val AUC: 0.9557 Time: 13.04\n",
      "Epoch: 703 Train Loss: 0.0949 Val Loss: 0.3215 Acc: 0.8822 Pre: 0.8955 Recall: 0.8801 F1: 0.8877 Train AUC: 0.9954 Val AUC: 0.9570 Time: 12.93\n",
      "Epoch: 704 Train Loss: 0.0903 Val Loss: 0.3510 Acc: 0.8822 Pre: 0.8580 Recall: 0.9315 F1: 0.8933 Train AUC: 0.9966 Val AUC: 0.9555 Time: 13.23\n",
      "Epoch: 705 Train Loss: 0.1042 Val Loss: 0.3385 Acc: 0.8822 Pre: 0.8650 Recall: 0.9212 F1: 0.8922 Train AUC: 0.9952 Val AUC: 0.9558 Time: 13.98\n",
      "Epoch: 706 Train Loss: 0.0931 Val Loss: 0.3212 Acc: 0.8768 Pre: 0.8810 Recall: 0.8870 F1: 0.8840 Train AUC: 0.9963 Val AUC: 0.9562 Time: 14.76\n",
      "Epoch: 707 Train Loss: 0.0944 Val Loss: 0.3236 Acc: 0.8877 Pre: 0.8885 Recall: 0.9007 F1: 0.8946 Train AUC: 0.9954 Val AUC: 0.9566 Time: 15.49\n",
      "Epoch: 708 Train Loss: 0.1068 Val Loss: 0.3353 Acc: 0.8750 Pre: 0.8585 Recall: 0.9144 F1: 0.8856 Train AUC: 0.9933 Val AUC: 0.9550 Time: 14.28\n",
      "Epoch: 709 Train Loss: 0.0909 Val Loss: 0.3393 Acc: 0.8768 Pre: 0.8567 Recall: 0.9212 F1: 0.8878 Train AUC: 0.9962 Val AUC: 0.9519 Time: 13.06\n",
      "Epoch: 710 Train Loss: 0.0931 Val Loss: 0.3308 Acc: 0.8859 Pre: 0.8754 Recall: 0.9144 F1: 0.8945 Train AUC: 0.9957 Val AUC: 0.9529 Time: 12.15\n",
      "Epoch: 711 Train Loss: 0.0910 Val Loss: 0.3397 Acc: 0.8768 Pre: 0.8709 Recall: 0.9007 F1: 0.8855 Train AUC: 0.9962 Val AUC: 0.9548 Time: 12.48\n",
      "Epoch: 712 Train Loss: 0.0887 Val Loss: 0.3297 Acc: 0.8768 Pre: 0.8733 Recall: 0.8973 F1: 0.8851 Train AUC: 0.9958 Val AUC: 0.9566 Time: 12.97\n",
      "Epoch: 713 Train Loss: 0.0904 Val Loss: 0.3302 Acc: 0.8804 Pre: 0.8622 Recall: 0.9212 F1: 0.8907 Train AUC: 0.9956 Val AUC: 0.9562 Time: 13.55\n",
      "Epoch: 714 Train Loss: 0.0911 Val Loss: 0.3401 Acc: 0.8659 Pre: 0.8562 Recall: 0.8973 F1: 0.8763 Train AUC: 0.9951 Val AUC: 0.9543 Time: 13.97\n",
      "Epoch: 715 Train Loss: 0.0886 Val Loss: 0.3371 Acc: 0.8641 Pre: 0.8581 Recall: 0.8904 F1: 0.8739 Train AUC: 0.9958 Val AUC: 0.9536 Time: 14.56\n",
      "Epoch: 716 Train Loss: 0.0930 Val Loss: 0.3357 Acc: 0.8895 Pre: 0.8738 Recall: 0.9247 F1: 0.8985 Train AUC: 0.9954 Val AUC: 0.9553 Time: 14.81\n",
      "Epoch: 717 Train Loss: 0.0842 Val Loss: 0.3391 Acc: 0.8895 Pre: 0.8762 Recall: 0.9212 F1: 0.8982 Train AUC: 0.9961 Val AUC: 0.9550 Time: 14.89\n",
      "Epoch: 718 Train Loss: 0.0911 Val Loss: 0.3271 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9955 Val AUC: 0.9538 Time: 14.07\n",
      "Epoch: 719 Train Loss: 0.0862 Val Loss: 0.3187 Acc: 0.8877 Pre: 0.8833 Recall: 0.9075 F1: 0.8953 Train AUC: 0.9961 Val AUC: 0.9560 Time: 13.10\n",
      "Epoch: 720 Train Loss: 0.0891 Val Loss: 0.3213 Acc: 0.8841 Pre: 0.8775 Recall: 0.9075 F1: 0.8923 Train AUC: 0.9957 Val AUC: 0.9568 Time: 13.16\n",
      "Epoch: 721 Train Loss: 0.0938 Val Loss: 0.3256 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9956 Val AUC: 0.9579 Time: 13.66\n",
      "Epoch: 722 Train Loss: 0.0918 Val Loss: 0.3289 Acc: 0.8931 Pre: 0.8795 Recall: 0.9247 F1: 0.9015 Train AUC: 0.9956 Val AUC: 0.9582 Time: 14.12\n",
      "Epoch: 723 Train Loss: 0.0910 Val Loss: 0.3271 Acc: 0.8895 Pre: 0.8714 Recall: 0.9281 F1: 0.8988 Train AUC: 0.9956 Val AUC: 0.9570 Time: 14.47\n",
      "Epoch: 724 Train Loss: 0.0902 Val Loss: 0.3249 Acc: 0.8859 Pre: 0.8682 Recall: 0.9247 F1: 0.8955 Train AUC: 0.9965 Val AUC: 0.9542 Time: 14.28\n",
      "Epoch: 725 Train Loss: 0.0933 Val Loss: 0.3259 Acc: 0.8841 Pre: 0.8654 Recall: 0.9247 F1: 0.8940 Train AUC: 0.9954 Val AUC: 0.9546 Time: 13.97\n",
      "Epoch: 726 Train Loss: 0.0895 Val Loss: 0.3274 Acc: 0.8804 Pre: 0.8599 Recall: 0.9247 F1: 0.8911 Train AUC: 0.9958 Val AUC: 0.9565 Time: 13.53\n",
      "Epoch: 727 Train Loss: 0.0843 Val Loss: 0.3198 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9966 Val AUC: 0.9579 Time: 13.43\n",
      "Epoch: 728 Train Loss: 0.0869 Val Loss: 0.3225 Acc: 0.8931 Pre: 0.8795 Recall: 0.9247 F1: 0.9015 Train AUC: 0.9962 Val AUC: 0.9581 Time: 14.06\n",
      "Epoch: 729 Train Loss: 0.0819 Val Loss: 0.3221 Acc: 0.8931 Pre: 0.8795 Recall: 0.9247 F1: 0.9015 Train AUC: 0.9966 Val AUC: 0.9575 Time: 13.89\n",
      "Epoch: 730 Train Loss: 0.0789 Val Loss: 0.3159 Acc: 0.8931 Pre: 0.8870 Recall: 0.9144 F1: 0.9005 Train AUC: 0.9973 Val AUC: 0.9572 Time: 13.87\n",
      "Epoch: 731 Train Loss: 0.0802 Val Loss: 0.3149 Acc: 0.8859 Pre: 0.8779 Recall: 0.9110 F1: 0.8941 Train AUC: 0.9972 Val AUC: 0.9558 Time: 14.50\n",
      "Epoch: 732 Train Loss: 0.0836 Val Loss: 0.3210 Acc: 0.8768 Pre: 0.8590 Recall: 0.9178 F1: 0.8874 Train AUC: 0.9969 Val AUC: 0.9570 Time: 13.66\n",
      "Epoch: 733 Train Loss: 0.0833 Val Loss: 0.3292 Acc: 0.8841 Pre: 0.8654 Recall: 0.9247 F1: 0.8940 Train AUC: 0.9970 Val AUC: 0.9582 Time: 13.31\n",
      "Epoch: 734 Train Loss: 0.0820 Val Loss: 0.3326 Acc: 0.8895 Pre: 0.8690 Recall: 0.9315 F1: 0.8992 Train AUC: 0.9965 Val AUC: 0.9583 Time: 13.76\n",
      "Epoch: 735 Train Loss: 0.0879 Val Loss: 0.3335 Acc: 0.8822 Pre: 0.8626 Recall: 0.9247 F1: 0.8926 Train AUC: 0.9955 Val AUC: 0.9577 Time: 14.27\n",
      "Epoch: 736 Train Loss: 0.0810 Val Loss: 0.3306 Acc: 0.8859 Pre: 0.8682 Recall: 0.9247 F1: 0.8955 Train AUC: 0.9967 Val AUC: 0.9554 Time: 14.01\n",
      "Epoch: 737 Train Loss: 0.0798 Val Loss: 0.3292 Acc: 0.8822 Pre: 0.8697 Recall: 0.9144 F1: 0.8915 Train AUC: 0.9970 Val AUC: 0.9536 Time: 13.41\n",
      "Epoch: 738 Train Loss: 0.0966 Val Loss: 0.3447 Acc: 0.8786 Pre: 0.8571 Recall: 0.9247 F1: 0.8896 Train AUC: 0.9963 Val AUC: 0.9562 Time: 13.56\n",
      "Epoch: 739 Train Loss: 0.0944 Val Loss: 0.3516 Acc: 0.8768 Pre: 0.8500 Recall: 0.9315 F1: 0.8889 Train AUC: 0.9950 Val AUC: 0.9581 Time: 14.18\n",
      "Epoch: 740 Train Loss: 0.0948 Val Loss: 0.3294 Acc: 0.8804 Pre: 0.8576 Recall: 0.9281 F1: 0.8914 Train AUC: 0.9959 Val AUC: 0.9578 Time: 14.36\n",
      "Epoch: 741 Train Loss: 0.0794 Val Loss: 0.3270 Acc: 0.8714 Pre: 0.8623 Recall: 0.9007 F1: 0.8811 Train AUC: 0.9971 Val AUC: 0.9562 Time: 13.72\n",
      "Epoch: 742 Train Loss: 0.1070 Val Loss: 0.3217 Acc: 0.8841 Pre: 0.8851 Recall: 0.8973 F1: 0.8912 Train AUC: 0.9938 Val AUC: 0.9570 Time: 13.31\n",
      "Epoch: 743 Train Loss: 0.0870 Val Loss: 0.3452 Acc: 0.8859 Pre: 0.8682 Recall: 0.9247 F1: 0.8955 Train AUC: 0.9967 Val AUC: 0.9572 Time: 13.43\n",
      "Epoch: 744 Train Loss: 0.0942 Val Loss: 0.3409 Acc: 0.8822 Pre: 0.8697 Recall: 0.9144 F1: 0.8915 Train AUC: 0.9954 Val AUC: 0.9550 Time: 13.88\n",
      "Epoch: 745 Train Loss: 0.0892 Val Loss: 0.3306 Acc: 0.8786 Pre: 0.8866 Recall: 0.8836 F1: 0.8851 Train AUC: 0.9960 Val AUC: 0.9519 Time: 14.58\n",
      "Epoch: 746 Train Loss: 0.0890 Val Loss: 0.3262 Acc: 0.8750 Pre: 0.8780 Recall: 0.8870 F1: 0.8825 Train AUC: 0.9962 Val AUC: 0.9535 Time: 15.67\n",
      "Epoch: 747 Train Loss: 0.0826 Val Loss: 0.3377 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9970 Val AUC: 0.9553 Time: 14.52\n",
      "Epoch: 748 Train Loss: 0.0858 Val Loss: 0.3463 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9963 Val AUC: 0.9576 Time: 13.04\n",
      "Epoch: 749 Train Loss: 0.0999 Val Loss: 0.3370 Acc: 0.8822 Pre: 0.8650 Recall: 0.9212 F1: 0.8922 Train AUC: 0.9948 Val AUC: 0.9566 Time: 12.88\n",
      "Epoch: 750 Train Loss: 0.0866 Val Loss: 0.3341 Acc: 0.8768 Pre: 0.8684 Recall: 0.9041 F1: 0.8859 Train AUC: 0.9959 Val AUC: 0.9550 Time: 12.86\n",
      "Epoch: 751 Train Loss: 0.0867 Val Loss: 0.3405 Acc: 0.8750 Pre: 0.8632 Recall: 0.9075 F1: 0.8848 Train AUC: 0.9962 Val AUC: 0.9527 Time: 13.08\n",
      "Epoch: 752 Train Loss: 0.0855 Val Loss: 0.3477 Acc: 0.8786 Pre: 0.8571 Recall: 0.9247 F1: 0.8896 Train AUC: 0.9962 Val AUC: 0.9540 Time: 13.42\n",
      "Epoch: 753 Train Loss: 0.0842 Val Loss: 0.3624 Acc: 0.8804 Pre: 0.8645 Recall: 0.9178 F1: 0.8904 Train AUC: 0.9964 Val AUC: 0.9536 Time: 14.36\n",
      "Epoch: 754 Train Loss: 0.0899 Val Loss: 0.3446 Acc: 0.8841 Pre: 0.8750 Recall: 0.9110 F1: 0.8926 Train AUC: 0.9960 Val AUC: 0.9559 Time: 14.87\n",
      "Epoch: 755 Train Loss: 0.0846 Val Loss: 0.3294 Acc: 0.8768 Pre: 0.8889 Recall: 0.8767 F1: 0.8828 Train AUC: 0.9962 Val AUC: 0.9568 Time: 15.71\n",
      "Epoch: 756 Train Loss: 0.0854 Val Loss: 0.3284 Acc: 0.8732 Pre: 0.8675 Recall: 0.8973 F1: 0.8822 Train AUC: 0.9967 Val AUC: 0.9562 Time: 14.85\n",
      "Epoch: 757 Train Loss: 0.0969 Val Loss: 0.3505 Acc: 0.8822 Pre: 0.8558 Recall: 0.9349 F1: 0.8936 Train AUC: 0.9955 Val AUC: 0.9540 Time: 13.52\n",
      "Epoch: 758 Train Loss: 0.0850 Val Loss: 0.3523 Acc: 0.8750 Pre: 0.8474 Recall: 0.9315 F1: 0.8874 Train AUC: 0.9970 Val AUC: 0.9556 Time: 13.43\n",
      "Epoch: 759 Train Loss: 0.0907 Val Loss: 0.3399 Acc: 0.8859 Pre: 0.8804 Recall: 0.9075 F1: 0.8938 Train AUC: 0.9969 Val AUC: 0.9562 Time: 13.28\n",
      "Epoch: 760 Train Loss: 0.0965 Val Loss: 0.3340 Acc: 0.8678 Pre: 0.8842 Recall: 0.8630 F1: 0.8735 Train AUC: 0.9953 Val AUC: 0.9545 Time: 13.27\n",
      "Epoch: 761 Train Loss: 0.1014 Val Loss: 0.3294 Acc: 0.8732 Pre: 0.8750 Recall: 0.8870 F1: 0.8810 Train AUC: 0.9954 Val AUC: 0.9517 Time: 13.74\n",
      "Epoch: 762 Train Loss: 0.0984 Val Loss: 0.3656 Acc: 0.8659 Pre: 0.8364 Recall: 0.9281 F1: 0.8799 Train AUC: 0.9958 Val AUC: 0.9481 Time: 14.33\n",
      "Epoch: 763 Train Loss: 0.0954 Val Loss: 0.3606 Acc: 0.8877 Pre: 0.8662 Recall: 0.9315 F1: 0.8977 Train AUC: 0.9962 Val AUC: 0.9574 Time: 14.41\n",
      "Epoch: 764 Train Loss: 0.0984 Val Loss: 0.3427 Acc: 0.8967 Pre: 0.8930 Recall: 0.9144 F1: 0.9036 Train AUC: 0.9955 Val AUC: 0.9586 Time: 13.99\n",
      "Epoch: 765 Train Loss: 0.0897 Val Loss: 0.3409 Acc: 0.8678 Pre: 0.8815 Recall: 0.8664 F1: 0.8739 Train AUC: 0.9953 Val AUC: 0.9580 Time: 13.35\n",
      "Epoch: 766 Train Loss: 0.1091 Val Loss: 0.3340 Acc: 0.8859 Pre: 0.8804 Recall: 0.9075 F1: 0.8938 Train AUC: 0.9945 Val AUC: 0.9558 Time: 13.55\n",
      "Epoch: 767 Train Loss: 0.0929 Val Loss: 0.3878 Acc: 0.8750 Pre: 0.8431 Recall: 0.9384 F1: 0.8882 Train AUC: 0.9952 Val AUC: 0.9479 Time: 14.22\n",
      "Epoch: 768 Train Loss: 0.1063 Val Loss: 0.3557 Acc: 0.8768 Pre: 0.8500 Recall: 0.9315 F1: 0.8889 Train AUC: 0.9953 Val AUC: 0.9538 Time: 14.47\n",
      "Epoch: 769 Train Loss: 0.0837 Val Loss: 0.3301 Acc: 0.8859 Pre: 0.8881 Recall: 0.8973 F1: 0.8927 Train AUC: 0.9971 Val AUC: 0.9570 Time: 13.41\n",
      "Epoch: 770 Train Loss: 0.0901 Val Loss: 0.3335 Acc: 0.8768 Pre: 0.8916 Recall: 0.8733 F1: 0.8824 Train AUC: 0.9954 Val AUC: 0.9568 Time: 13.27\n",
      "Epoch: 771 Train Loss: 0.0979 Val Loss: 0.3275 Acc: 0.8913 Pre: 0.8893 Recall: 0.9075 F1: 0.8983 Train AUC: 0.9948 Val AUC: 0.9555 Time: 13.86\n",
      "Epoch: 772 Train Loss: 0.0840 Val Loss: 0.3511 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9964 Val AUC: 0.9519 Time: 14.62\n",
      "Epoch: 773 Train Loss: 0.0934 Val Loss: 0.3529 Acc: 0.8822 Pre: 0.8558 Recall: 0.9349 F1: 0.8936 Train AUC: 0.9963 Val AUC: 0.9506 Time: 13.85\n",
      "Epoch: 774 Train Loss: 0.0899 Val Loss: 0.3319 Acc: 0.8895 Pre: 0.8762 Recall: 0.9212 F1: 0.8982 Train AUC: 0.9972 Val AUC: 0.9550 Time: 13.72\n",
      "Epoch: 775 Train Loss: 0.0847 Val Loss: 0.3318 Acc: 0.8822 Pre: 0.8927 Recall: 0.8836 F1: 0.8881 Train AUC: 0.9964 Val AUC: 0.9567 Time: 14.29\n",
      "Epoch: 776 Train Loss: 0.0935 Val Loss: 0.3362 Acc: 0.8986 Pre: 0.8933 Recall: 0.9178 F1: 0.9054 Train AUC: 0.9957 Val AUC: 0.9573 Time: 13.50\n",
      "Epoch: 777 Train Loss: 0.0831 Val Loss: 0.3482 Acc: 0.8931 Pre: 0.8746 Recall: 0.9315 F1: 0.9022 Train AUC: 0.9962 Val AUC: 0.9564 Time: 13.06\n",
      "Epoch: 778 Train Loss: 0.0865 Val Loss: 0.3504 Acc: 0.8822 Pre: 0.8580 Recall: 0.9315 F1: 0.8933 Train AUC: 0.9962 Val AUC: 0.9540 Time: 13.50\n",
      "Epoch: 779 Train Loss: 0.0879 Val Loss: 0.3367 Acc: 0.8822 Pre: 0.8746 Recall: 0.9075 F1: 0.8908 Train AUC: 0.9964 Val AUC: 0.9515 Time: 14.25\n",
      "Epoch: 780 Train Loss: 0.0850 Val Loss: 0.3367 Acc: 0.8732 Pre: 0.8750 Recall: 0.8870 F1: 0.8810 Train AUC: 0.9964 Val AUC: 0.9498 Time: 14.80\n",
      "Epoch: 781 Train Loss: 0.0843 Val Loss: 0.3345 Acc: 0.8696 Pre: 0.8642 Recall: 0.8938 F1: 0.8788 Train AUC: 0.9972 Val AUC: 0.9515 Time: 14.47\n",
      "Epoch: 782 Train Loss: 0.0868 Val Loss: 0.3418 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9963 Val AUC: 0.9544 Time: 13.72\n",
      "Epoch: 783 Train Loss: 0.0910 Val Loss: 0.3552 Acc: 0.8877 Pre: 0.8662 Recall: 0.9315 F1: 0.8977 Train AUC: 0.9950 Val AUC: 0.9562 Time: 13.36\n",
      "Epoch: 784 Train Loss: 0.0930 Val Loss: 0.3381 Acc: 0.8859 Pre: 0.8730 Recall: 0.9178 F1: 0.8948 Train AUC: 0.9958 Val AUC: 0.9567 Time: 13.19\n",
      "Epoch: 785 Train Loss: 0.0772 Val Loss: 0.3325 Acc: 0.8768 Pre: 0.8862 Recall: 0.8801 F1: 0.8832 Train AUC: 0.9971 Val AUC: 0.9560 Time: 13.23\n",
      "Epoch: 786 Train Loss: 0.0992 Val Loss: 0.3339 Acc: 0.8786 Pre: 0.8814 Recall: 0.8904 F1: 0.8859 Train AUC: 0.9949 Val AUC: 0.9559 Time: 13.83\n",
      "Epoch: 787 Train Loss: 0.0753 Val Loss: 0.3433 Acc: 0.8750 Pre: 0.8517 Recall: 0.9247 F1: 0.8867 Train AUC: 0.9974 Val AUC: 0.9551 Time: 14.34\n",
      "Epoch: 788 Train Loss: 0.0853 Val Loss: 0.3511 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9965 Val AUC: 0.9548 Time: 14.34\n",
      "Epoch: 789 Train Loss: 0.0870 Val Loss: 0.3457 Acc: 0.8913 Pre: 0.8718 Recall: 0.9315 F1: 0.9007 Train AUC: 0.9963 Val AUC: 0.9555 Time: 13.80\n",
      "Epoch: 790 Train Loss: 0.0775 Val Loss: 0.3443 Acc: 0.8841 Pre: 0.8775 Recall: 0.9075 F1: 0.8923 Train AUC: 0.9970 Val AUC: 0.9553 Time: 13.59\n",
      "Epoch: 791 Train Loss: 0.0914 Val Loss: 0.3384 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9953 Val AUC: 0.9546 Time: 13.39\n",
      "Epoch: 792 Train Loss: 0.0851 Val Loss: 0.3524 Acc: 0.8750 Pre: 0.8585 Recall: 0.9144 F1: 0.8856 Train AUC: 0.9964 Val AUC: 0.9498 Time: 13.37\n",
      "Epoch: 793 Train Loss: 0.0908 Val Loss: 0.3436 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9962 Val AUC: 0.9554 Time: 13.44\n",
      "Epoch: 794 Train Loss: 0.0866 Val Loss: 0.3397 Acc: 0.8913 Pre: 0.8791 Recall: 0.9212 F1: 0.8997 Train AUC: 0.9960 Val AUC: 0.9585 Time: 14.03\n",
      "Epoch: 795 Train Loss: 0.0920 Val Loss: 0.3409 Acc: 0.8804 Pre: 0.8742 Recall: 0.9041 F1: 0.8889 Train AUC: 0.9953 Val AUC: 0.9589 Time: 14.69\n",
      "Epoch: 796 Train Loss: 0.0906 Val Loss: 0.3289 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9955 Val AUC: 0.9575 Time: 15.11\n",
      "Epoch: 797 Train Loss: 0.0837 Val Loss: 0.3316 Acc: 0.8859 Pre: 0.8658 Recall: 0.9281 F1: 0.8959 Train AUC: 0.9965 Val AUC: 0.9549 Time: 13.49\n",
      "Epoch: 798 Train Loss: 0.0839 Val Loss: 0.3350 Acc: 0.8750 Pre: 0.8562 Recall: 0.9178 F1: 0.8860 Train AUC: 0.9971 Val AUC: 0.9530 Time: 12.81\n",
      "Epoch: 799 Train Loss: 0.0883 Val Loss: 0.3305 Acc: 0.8822 Pre: 0.8822 Recall: 0.8973 F1: 0.8896 Train AUC: 0.9966 Val AUC: 0.9536 Time: 13.21\n",
      "Epoch: 800 Train Loss: 0.0824 Val Loss: 0.3355 Acc: 0.8877 Pre: 0.8833 Recall: 0.9075 F1: 0.8953 Train AUC: 0.9966 Val AUC: 0.9545 Time: 13.67\n",
      "Epoch: 801 Train Loss: 0.0917 Val Loss: 0.3420 Acc: 0.8895 Pre: 0.8787 Recall: 0.9178 F1: 0.8978 Train AUC: 0.9955 Val AUC: 0.9549 Time: 14.28\n",
      "Epoch: 802 Train Loss: 0.0884 Val Loss: 0.3369 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9961 Val AUC: 0.9565 Time: 14.76\n",
      "Epoch: 803 Train Loss: 0.0840 Val Loss: 0.3332 Acc: 0.8804 Pre: 0.8645 Recall: 0.9178 F1: 0.8904 Train AUC: 0.9964 Val AUC: 0.9558 Time: 13.73\n",
      "Epoch: 804 Train Loss: 0.0787 Val Loss: 0.3338 Acc: 0.8768 Pre: 0.8613 Recall: 0.9144 F1: 0.8870 Train AUC: 0.9970 Val AUC: 0.9552 Time: 13.01\n",
      "Epoch: 805 Train Loss: 0.0878 Val Loss: 0.3402 Acc: 0.8822 Pre: 0.8603 Recall: 0.9281 F1: 0.8929 Train AUC: 0.9966 Val AUC: 0.9560 Time: 12.86\n",
      "Epoch: 806 Train Loss: 0.0861 Val Loss: 0.3424 Acc: 0.8895 Pre: 0.8762 Recall: 0.9212 F1: 0.8982 Train AUC: 0.9962 Val AUC: 0.9570 Time: 13.40\n",
      "Epoch: 807 Train Loss: 0.0814 Val Loss: 0.3353 Acc: 0.8895 Pre: 0.8863 Recall: 0.9075 F1: 0.8968 Train AUC: 0.9966 Val AUC: 0.9566 Time: 14.01\n",
      "Epoch: 808 Train Loss: 0.0793 Val Loss: 0.3334 Acc: 0.8714 Pre: 0.8671 Recall: 0.8938 F1: 0.8803 Train AUC: 0.9967 Val AUC: 0.9544 Time: 14.56\n",
      "Epoch: 809 Train Loss: 0.0814 Val Loss: 0.3457 Acc: 0.8714 Pre: 0.8553 Recall: 0.9110 F1: 0.8823 Train AUC: 0.9970 Val AUC: 0.9508 Time: 15.56\n",
      "Epoch: 810 Train Loss: 0.0802 Val Loss: 0.3478 Acc: 0.8841 Pre: 0.8631 Recall: 0.9281 F1: 0.8944 Train AUC: 0.9971 Val AUC: 0.9507 Time: 14.32\n",
      "Epoch: 811 Train Loss: 0.0845 Val Loss: 0.3436 Acc: 0.8768 Pre: 0.8636 Recall: 0.9110 F1: 0.8867 Train AUC: 0.9963 Val AUC: 0.9527 Time: 13.08\n",
      "Epoch: 812 Train Loss: 0.0838 Val Loss: 0.3459 Acc: 0.8804 Pre: 0.8742 Recall: 0.9041 F1: 0.8889 Train AUC: 0.9963 Val AUC: 0.9541 Time: 12.46\n",
      "Epoch: 813 Train Loss: 0.0799 Val Loss: 0.3452 Acc: 0.8895 Pre: 0.8787 Recall: 0.9178 F1: 0.8978 Train AUC: 0.9968 Val AUC: 0.9562 Time: 13.17\n",
      "Epoch: 814 Train Loss: 0.0893 Val Loss: 0.3463 Acc: 0.8804 Pre: 0.8576 Recall: 0.9281 F1: 0.8914 Train AUC: 0.9957 Val AUC: 0.9571 Time: 13.70\n",
      "Epoch: 815 Train Loss: 0.0843 Val Loss: 0.3415 Acc: 0.8804 Pre: 0.8693 Recall: 0.9110 F1: 0.8896 Train AUC: 0.9964 Val AUC: 0.9581 Time: 14.29\n",
      "Epoch: 816 Train Loss: 0.0891 Val Loss: 0.3328 Acc: 0.8913 Pre: 0.8946 Recall: 0.9007 F1: 0.8976 Train AUC: 0.9959 Val AUC: 0.9571 Time: 15.01\n",
      "Epoch: 817 Train Loss: 0.0884 Val Loss: 0.3371 Acc: 0.8841 Pre: 0.8851 Recall: 0.8973 F1: 0.8912 Train AUC: 0.9962 Val AUC: 0.9549 Time: 14.78\n",
      "Epoch: 818 Train Loss: 0.0820 Val Loss: 0.3519 Acc: 0.8714 Pre: 0.8599 Recall: 0.9041 F1: 0.8815 Train AUC: 0.9964 Val AUC: 0.9479 Time: 14.35\n",
      "Epoch: 819 Train Loss: 0.0826 Val Loss: 0.3545 Acc: 0.8732 Pre: 0.8581 Recall: 0.9110 F1: 0.8837 Train AUC: 0.9970 Val AUC: 0.9475 Time: 13.29\n",
      "Epoch: 820 Train Loss: 0.0805 Val Loss: 0.3516 Acc: 0.8822 Pre: 0.8650 Recall: 0.9212 F1: 0.8922 Train AUC: 0.9977 Val AUC: 0.9538 Time: 12.62\n",
      "Epoch: 821 Train Loss: 0.0864 Val Loss: 0.3399 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9964 Val AUC: 0.9580 Time: 12.70\n",
      "Epoch: 822 Train Loss: 0.0864 Val Loss: 0.3289 Acc: 0.8895 Pre: 0.8915 Recall: 0.9007 F1: 0.8961 Train AUC: 0.9957 Val AUC: 0.9582 Time: 13.52\n",
      "Epoch: 823 Train Loss: 0.0844 Val Loss: 0.3334 Acc: 0.8804 Pre: 0.8792 Recall: 0.8973 F1: 0.8881 Train AUC: 0.9967 Val AUC: 0.9579 Time: 13.86\n",
      "Epoch: 824 Train Loss: 0.0879 Val Loss: 0.3463 Acc: 0.8877 Pre: 0.8734 Recall: 0.9212 F1: 0.8967 Train AUC: 0.9957 Val AUC: 0.9572 Time: 14.40\n",
      "Epoch: 825 Train Loss: 0.0895 Val Loss: 0.3414 Acc: 0.8822 Pre: 0.8603 Recall: 0.9281 F1: 0.8929 Train AUC: 0.9962 Val AUC: 0.9569 Time: 15.33\n",
      "Epoch: 826 Train Loss: 0.0806 Val Loss: 0.3348 Acc: 0.8768 Pre: 0.8660 Recall: 0.9075 F1: 0.8863 Train AUC: 0.9973 Val AUC: 0.9538 Time: 16.01\n",
      "Epoch: 827 Train Loss: 0.0787 Val Loss: 0.3427 Acc: 0.8804 Pre: 0.8742 Recall: 0.9041 F1: 0.8889 Train AUC: 0.9970 Val AUC: 0.9513 Time: 13.84\n",
      "Epoch: 828 Train Loss: 0.0820 Val Loss: 0.3488 Acc: 0.8841 Pre: 0.8725 Recall: 0.9144 F1: 0.8930 Train AUC: 0.9965 Val AUC: 0.9497 Time: 12.91\n",
      "Epoch: 829 Train Loss: 0.0910 Val Loss: 0.3478 Acc: 0.8804 Pre: 0.8645 Recall: 0.9178 F1: 0.8904 Train AUC: 0.9955 Val AUC: 0.9518 Time: 11.96\n",
      "Epoch: 830 Train Loss: 0.0837 Val Loss: 0.3481 Acc: 0.8786 Pre: 0.8571 Recall: 0.9247 F1: 0.8896 Train AUC: 0.9963 Val AUC: 0.9551 Time: 11.78\n",
      "Epoch: 831 Train Loss: 0.0876 Val Loss: 0.3378 Acc: 0.8859 Pre: 0.8706 Recall: 0.9212 F1: 0.8952 Train AUC: 0.9961 Val AUC: 0.9573 Time: 12.28\n",
      "Epoch: 832 Train Loss: 0.0845 Val Loss: 0.3374 Acc: 0.8859 Pre: 0.8682 Recall: 0.9247 F1: 0.8955 Train AUC: 0.9961 Val AUC: 0.9573 Time: 12.69\n",
      "Epoch: 833 Train Loss: 0.0849 Val Loss: 0.3414 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9959 Val AUC: 0.9570 Time: 13.43\n",
      "Epoch: 834 Train Loss: 0.0869 Val Loss: 0.3350 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9961 Val AUC: 0.9575 Time: 13.73\n",
      "Epoch: 835 Train Loss: 0.0882 Val Loss: 0.3371 Acc: 0.8913 Pre: 0.8893 Recall: 0.9075 F1: 0.8983 Train AUC: 0.9958 Val AUC: 0.9563 Time: 14.33\n",
      "Epoch: 836 Train Loss: 0.0867 Val Loss: 0.3555 Acc: 0.8877 Pre: 0.8734 Recall: 0.9212 F1: 0.8967 Train AUC: 0.9962 Val AUC: 0.9528 Time: 15.27\n",
      "Epoch: 837 Train Loss: 0.0839 Val Loss: 0.3636 Acc: 0.8732 Pre: 0.8558 Recall: 0.9144 F1: 0.8841 Train AUC: 0.9963 Val AUC: 0.9503 Time: 16.07\n",
      "Epoch: 838 Train Loss: 0.0915 Val Loss: 0.3447 Acc: 0.8678 Pre: 0.8567 Recall: 0.9007 F1: 0.8781 Train AUC: 0.9961 Val AUC: 0.9534 Time: 14.75\n",
      "Epoch: 839 Train Loss: 0.0882 Val Loss: 0.3322 Acc: 0.8714 Pre: 0.8647 Recall: 0.8973 F1: 0.8807 Train AUC: 0.9958 Val AUC: 0.9549 Time: 13.45\n",
      "Epoch: 840 Train Loss: 0.0836 Val Loss: 0.3391 Acc: 0.8804 Pre: 0.8669 Recall: 0.9144 F1: 0.8900 Train AUC: 0.9971 Val AUC: 0.9550 Time: 12.90\n",
      "Epoch: 841 Train Loss: 0.0793 Val Loss: 0.3473 Acc: 0.8786 Pre: 0.8571 Recall: 0.9247 F1: 0.8896 Train AUC: 0.9975 Val AUC: 0.9553 Time: 13.49\n",
      "Epoch: 842 Train Loss: 0.0852 Val Loss: 0.3349 Acc: 0.8841 Pre: 0.8701 Recall: 0.9178 F1: 0.8933 Train AUC: 0.9968 Val AUC: 0.9582 Time: 14.23\n",
      "Epoch: 843 Train Loss: 0.0747 Val Loss: 0.3394 Acc: 0.8786 Pre: 0.8814 Recall: 0.8904 F1: 0.8859 Train AUC: 0.9977 Val AUC: 0.9585 Time: 14.13\n",
      "Epoch: 844 Train Loss: 0.0877 Val Loss: 0.3380 Acc: 0.8786 Pre: 0.8713 Recall: 0.9041 F1: 0.8874 Train AUC: 0.9960 Val AUC: 0.9574 Time: 14.54\n",
      "Epoch: 845 Train Loss: 0.0750 Val Loss: 0.3455 Acc: 0.8768 Pre: 0.8544 Recall: 0.9247 F1: 0.8882 Train AUC: 0.9968 Val AUC: 0.9533 Time: 14.55\n",
      "Epoch: 846 Train Loss: 0.0803 Val Loss: 0.3583 Acc: 0.8804 Pre: 0.8599 Recall: 0.9247 F1: 0.8911 Train AUC: 0.9969 Val AUC: 0.9487 Time: 13.59\n",
      "Epoch: 847 Train Loss: 0.0810 Val Loss: 0.3498 Acc: 0.8859 Pre: 0.8635 Recall: 0.9315 F1: 0.8962 Train AUC: 0.9974 Val AUC: 0.9527 Time: 13.04\n",
      "Epoch: 848 Train Loss: 0.0801 Val Loss: 0.3417 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9972 Val AUC: 0.9570 Time: 12.60\n",
      "Epoch: 849 Train Loss: 0.0830 Val Loss: 0.3483 Acc: 0.8931 Pre: 0.8845 Recall: 0.9178 F1: 0.9008 Train AUC: 0.9961 Val AUC: 0.9580 Time: 13.34\n",
      "Epoch: 850 Train Loss: 0.0819 Val Loss: 0.3444 Acc: 0.8913 Pre: 0.8718 Recall: 0.9315 F1: 0.9007 Train AUC: 0.9961 Val AUC: 0.9579 Time: 13.69\n",
      "Epoch: 851 Train Loss: 0.0827 Val Loss: 0.3370 Acc: 0.8768 Pre: 0.8613 Recall: 0.9144 F1: 0.8870 Train AUC: 0.9965 Val AUC: 0.9526 Time: 14.51\n",
      "Epoch: 852 Train Loss: 0.0789 Val Loss: 0.3379 Acc: 0.8750 Pre: 0.8680 Recall: 0.9007 F1: 0.8840 Train AUC: 0.9975 Val AUC: 0.9500 Time: 14.94\n",
      "Epoch: 853 Train Loss: 0.0873 Val Loss: 0.3381 Acc: 0.8895 Pre: 0.8812 Recall: 0.9144 F1: 0.8975 Train AUC: 0.9966 Val AUC: 0.9547 Time: 14.57\n",
      "Epoch: 854 Train Loss: 0.0802 Val Loss: 0.3448 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9968 Val AUC: 0.9553 Time: 13.53\n",
      "Epoch: 855 Train Loss: 0.0861 Val Loss: 0.3359 Acc: 0.8804 Pre: 0.8767 Recall: 0.9007 F1: 0.8885 Train AUC: 0.9960 Val AUC: 0.9550 Time: 12.87\n",
      "Epoch: 856 Train Loss: 0.0863 Val Loss: 0.3444 Acc: 0.8696 Pre: 0.8642 Recall: 0.8938 F1: 0.8788 Train AUC: 0.9955 Val AUC: 0.9495 Time: 12.88\n",
      "Epoch: 857 Train Loss: 0.0810 Val Loss: 0.3540 Acc: 0.8623 Pre: 0.8600 Recall: 0.8836 F1: 0.8716 Train AUC: 0.9970 Val AUC: 0.9456 Time: 13.35\n",
      "Epoch: 858 Train Loss: 0.0965 Val Loss: 0.3347 Acc: 0.8841 Pre: 0.8654 Recall: 0.9247 F1: 0.8940 Train AUC: 0.9960 Val AUC: 0.9568 Time: 13.80\n",
      "Epoch: 859 Train Loss: 0.0739 Val Loss: 0.3629 Acc: 0.8877 Pre: 0.8758 Recall: 0.9178 F1: 0.8963 Train AUC: 0.9977 Val AUC: 0.9573 Time: 14.70\n",
      "Epoch: 860 Train Loss: 0.0944 Val Loss: 0.3627 Acc: 0.8913 Pre: 0.8766 Recall: 0.9247 F1: 0.9000 Train AUC: 0.9952 Val AUC: 0.9576 Time: 15.61\n",
      "Epoch: 861 Train Loss: 0.0960 Val Loss: 0.3381 Acc: 0.8859 Pre: 0.8804 Recall: 0.9075 F1: 0.8938 Train AUC: 0.9954 Val AUC: 0.9570 Time: 14.54\n",
      "Epoch: 862 Train Loss: 0.0870 Val Loss: 0.3536 Acc: 0.8678 Pre: 0.8567 Recall: 0.9007 F1: 0.8781 Train AUC: 0.9959 Val AUC: 0.9523 Time: 13.32\n",
      "Epoch: 863 Train Loss: 0.0897 Val Loss: 0.3526 Acc: 0.8696 Pre: 0.8571 Recall: 0.9041 F1: 0.8800 Train AUC: 0.9959 Val AUC: 0.9523 Time: 12.92\n",
      "Epoch: 864 Train Loss: 0.0876 Val Loss: 0.3479 Acc: 0.8877 Pre: 0.8783 Recall: 0.9144 F1: 0.8960 Train AUC: 0.9962 Val AUC: 0.9539 Time: 13.08\n",
      "Epoch: 865 Train Loss: 0.0798 Val Loss: 0.3545 Acc: 0.8786 Pre: 0.8788 Recall: 0.8938 F1: 0.8862 Train AUC: 0.9965 Val AUC: 0.9536 Time: 13.66\n",
      "Epoch: 866 Train Loss: 0.0851 Val Loss: 0.3449 Acc: 0.8859 Pre: 0.8829 Recall: 0.9041 F1: 0.8934 Train AUC: 0.9959 Val AUC: 0.9535 Time: 14.29\n",
      "Epoch: 867 Train Loss: 0.0827 Val Loss: 0.3422 Acc: 0.8732 Pre: 0.8627 Recall: 0.9041 F1: 0.8829 Train AUC: 0.9963 Val AUC: 0.9518 Time: 14.88\n",
      "Epoch: 868 Train Loss: 0.0801 Val Loss: 0.3482 Acc: 0.8696 Pre: 0.8642 Recall: 0.8938 F1: 0.8788 Train AUC: 0.9972 Val AUC: 0.9501 Time: 14.70\n",
      "Epoch: 869 Train Loss: 0.0891 Val Loss: 0.3332 Acc: 0.8678 Pre: 0.8614 Recall: 0.8938 F1: 0.8773 Train AUC: 0.9963 Val AUC: 0.9542 Time: 13.33\n",
      "Epoch: 870 Train Loss: 0.0855 Val Loss: 0.3390 Acc: 0.8913 Pre: 0.8816 Recall: 0.9178 F1: 0.8993 Train AUC: 0.9969 Val AUC: 0.9567 Time: 12.68\n",
      "Epoch: 871 Train Loss: 0.0801 Val Loss: 0.3512 Acc: 0.8859 Pre: 0.8730 Recall: 0.9178 F1: 0.8948 Train AUC: 0.9966 Val AUC: 0.9569 Time: 13.10\n",
      "Epoch: 872 Train Loss: 0.0890 Val Loss: 0.3435 Acc: 0.8931 Pre: 0.8746 Recall: 0.9315 F1: 0.9022 Train AUC: 0.9956 Val AUC: 0.9567 Time: 13.20\n",
      "Epoch: 873 Train Loss: 0.0849 Val Loss: 0.3418 Acc: 0.8641 Pre: 0.8581 Recall: 0.8904 F1: 0.8739 Train AUC: 0.9960 Val AUC: 0.9532 Time: 13.85\n",
      "Epoch: 874 Train Loss: 0.0905 Val Loss: 0.3510 Acc: 0.8714 Pre: 0.8553 Recall: 0.9110 F1: 0.8823 Train AUC: 0.9966 Val AUC: 0.9515 Time: 14.43\n",
      "Epoch: 875 Train Loss: 0.0842 Val Loss: 0.3520 Acc: 0.8822 Pre: 0.8536 Recall: 0.9384 F1: 0.8940 Train AUC: 0.9966 Val AUC: 0.9530 Time: 15.04\n",
      "Epoch: 876 Train Loss: 0.0800 Val Loss: 0.3523 Acc: 0.8913 Pre: 0.8718 Recall: 0.9315 F1: 0.9007 Train AUC: 0.9976 Val AUC: 0.9552 Time: 14.95\n",
      "Epoch: 877 Train Loss: 0.0803 Val Loss: 0.3457 Acc: 0.8931 Pre: 0.8870 Recall: 0.9144 F1: 0.9005 Train AUC: 0.9969 Val AUC: 0.9565 Time: 13.37\n",
      "Epoch: 878 Train Loss: 0.0876 Val Loss: 0.3312 Acc: 0.8804 Pre: 0.8844 Recall: 0.8904 F1: 0.8874 Train AUC: 0.9958 Val AUC: 0.9552 Time: 12.46\n",
      "Epoch: 879 Train Loss: 0.0838 Val Loss: 0.3397 Acc: 0.8696 Pre: 0.8618 Recall: 0.8973 F1: 0.8792 Train AUC: 0.9966 Val AUC: 0.9518 Time: 13.06\n",
      "Epoch: 880 Train Loss: 0.0833 Val Loss: 0.3502 Acc: 0.8732 Pre: 0.8581 Recall: 0.9110 F1: 0.8837 Train AUC: 0.9970 Val AUC: 0.9519 Time: 13.35\n",
      "Epoch: 881 Train Loss: 0.0776 Val Loss: 0.3463 Acc: 0.8804 Pre: 0.8599 Recall: 0.9247 F1: 0.8911 Train AUC: 0.9974 Val AUC: 0.9551 Time: 14.44\n",
      "Epoch: 882 Train Loss: 0.0764 Val Loss: 0.3460 Acc: 0.8768 Pre: 0.8544 Recall: 0.9247 F1: 0.8882 Train AUC: 0.9972 Val AUC: 0.9548 Time: 14.58\n",
      "Epoch: 883 Train Loss: 0.0807 Val Loss: 0.3490 Acc: 0.8732 Pre: 0.8491 Recall: 0.9247 F1: 0.8852 Train AUC: 0.9963 Val AUC: 0.9523 Time: 14.72\n",
      "Epoch: 884 Train Loss: 0.0807 Val Loss: 0.3480 Acc: 0.8732 Pre: 0.8651 Recall: 0.9007 F1: 0.8826 Train AUC: 0.9970 Val AUC: 0.9499 Time: 14.12\n",
      "Epoch: 885 Train Loss: 0.0878 Val Loss: 0.3388 Acc: 0.8822 Pre: 0.8746 Recall: 0.9075 F1: 0.8908 Train AUC: 0.9958 Val AUC: 0.9535 Time: 13.57\n",
      "Epoch: 886 Train Loss: 0.0810 Val Loss: 0.3541 Acc: 0.8786 Pre: 0.8549 Recall: 0.9281 F1: 0.8900 Train AUC: 0.9969 Val AUC: 0.9565 Time: 13.11\n",
      "Epoch: 887 Train Loss: 0.0828 Val Loss: 0.3685 Acc: 0.8822 Pre: 0.8626 Recall: 0.9247 F1: 0.8926 Train AUC: 0.9968 Val AUC: 0.9560 Time: 13.17\n",
      "Epoch: 888 Train Loss: 0.0998 Val Loss: 0.3393 Acc: 0.8931 Pre: 0.9031 Recall: 0.8938 F1: 0.8985 Train AUC: 0.9946 Val AUC: 0.9581 Time: 13.67\n",
      "Epoch: 889 Train Loss: 0.0974 Val Loss: 0.3343 Acc: 0.8714 Pre: 0.8850 Recall: 0.8699 F1: 0.8774 Train AUC: 0.9954 Val AUC: 0.9569 Time: 14.21\n",
      "Epoch: 890 Train Loss: 0.0968 Val Loss: 0.3533 Acc: 0.8822 Pre: 0.8580 Recall: 0.9315 F1: 0.8933 Train AUC: 0.9960 Val AUC: 0.9526 Time: 14.21\n",
      "Epoch: 891 Train Loss: 0.0923 Val Loss: 0.3957 Acc: 0.8678 Pre: 0.8328 Recall: 0.9384 F1: 0.8824 Train AUC: 0.9956 Val AUC: 0.9473 Time: 14.77\n",
      "Epoch: 892 Train Loss: 0.1044 Val Loss: 0.3485 Acc: 0.8786 Pre: 0.8549 Recall: 0.9281 F1: 0.8900 Train AUC: 0.9970 Val AUC: 0.9514 Time: 13.81\n",
      "Epoch: 893 Train Loss: 0.0855 Val Loss: 0.3293 Acc: 0.8786 Pre: 0.8947 Recall: 0.8733 F1: 0.8839 Train AUC: 0.9969 Val AUC: 0.9567 Time: 12.79\n",
      "Epoch: 894 Train Loss: 0.0966 Val Loss: 0.3318 Acc: 0.8931 Pre: 0.9059 Recall: 0.8904 F1: 0.8981 Train AUC: 0.9963 Val AUC: 0.9595 Time: 12.85\n",
      "Epoch: 895 Train Loss: 0.0916 Val Loss: 0.3400 Acc: 0.8931 Pre: 0.8820 Recall: 0.9212 F1: 0.9012 Train AUC: 0.9961 Val AUC: 0.9596 Time: 13.25\n",
      "Epoch: 896 Train Loss: 0.0918 Val Loss: 0.3641 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9957 Val AUC: 0.9564 Time: 13.90\n",
      "Epoch: 897 Train Loss: 0.0947 Val Loss: 0.3521 Acc: 0.8822 Pre: 0.8558 Recall: 0.9349 F1: 0.8936 Train AUC: 0.9964 Val AUC: 0.9537 Time: 14.36\n",
      "Epoch: 898 Train Loss: 0.0960 Val Loss: 0.3385 Acc: 0.8714 Pre: 0.8721 Recall: 0.8870 F1: 0.8795 Train AUC: 0.9963 Val AUC: 0.9480 Time: 14.57\n",
      "Epoch: 899 Train Loss: 0.0873 Val Loss: 0.3524 Acc: 0.8659 Pre: 0.8682 Recall: 0.8801 F1: 0.8741 Train AUC: 0.9969 Val AUC: 0.9435 Time: 15.16\n",
      "Epoch: 900 Train Loss: 0.1042 Val Loss: 0.3570 Acc: 0.8786 Pre: 0.8641 Recall: 0.9144 F1: 0.8885 Train AUC: 0.9951 Val AUC: 0.9520 Time: 13.86\n",
      "Epoch: 901 Train Loss: 0.0921 Val Loss: 0.3592 Acc: 0.8841 Pre: 0.8654 Recall: 0.9247 F1: 0.8940 Train AUC: 0.9956 Val AUC: 0.9555 Time: 12.67\n",
      "Epoch: 902 Train Loss: 0.0966 Val Loss: 0.3382 Acc: 0.8913 Pre: 0.8841 Recall: 0.9144 F1: 0.8990 Train AUC: 0.9949 Val AUC: 0.9580 Time: 12.30\n",
      "Epoch: 903 Train Loss: 0.0893 Val Loss: 0.3401 Acc: 0.8623 Pre: 0.8576 Recall: 0.8870 F1: 0.8721 Train AUC: 0.9953 Val AUC: 0.9537 Time: 12.47\n",
      "Epoch: 904 Train Loss: 0.0986 Val Loss: 0.3552 Acc: 0.8641 Pre: 0.8557 Recall: 0.8938 F1: 0.8744 Train AUC: 0.9951 Val AUC: 0.9490 Time: 12.77\n",
      "Epoch: 905 Train Loss: 0.0917 Val Loss: 0.3523 Acc: 0.8768 Pre: 0.8590 Recall: 0.9178 F1: 0.8874 Train AUC: 0.9954 Val AUC: 0.9536 Time: 13.37\n",
      "Epoch: 906 Train Loss: 0.0853 Val Loss: 0.3531 Acc: 0.8913 Pre: 0.8841 Recall: 0.9144 F1: 0.8990 Train AUC: 0.9963 Val AUC: 0.9564 Time: 13.99\n",
      "Epoch: 907 Train Loss: 0.0862 Val Loss: 0.3514 Acc: 0.8877 Pre: 0.8912 Recall: 0.8973 F1: 0.8942 Train AUC: 0.9953 Val AUC: 0.9561 Time: 14.62\n",
      "Epoch: 908 Train Loss: 0.0861 Val Loss: 0.3444 Acc: 0.8877 Pre: 0.8734 Recall: 0.9212 F1: 0.8967 Train AUC: 0.9952 Val AUC: 0.9557 Time: 15.67\n",
      "Epoch: 909 Train Loss: 0.0818 Val Loss: 0.3399 Acc: 0.8786 Pre: 0.8594 Recall: 0.9212 F1: 0.8893 Train AUC: 0.9959 Val AUC: 0.9518 Time: 14.81\n",
      "Epoch: 910 Train Loss: 0.0857 Val Loss: 0.3407 Acc: 0.8786 Pre: 0.8641 Recall: 0.9144 F1: 0.8885 Train AUC: 0.9965 Val AUC: 0.9484 Time: 13.18\n",
      "Epoch: 911 Train Loss: 0.0815 Val Loss: 0.3411 Acc: 0.8750 Pre: 0.8608 Recall: 0.9110 F1: 0.8852 Train AUC: 0.9975 Val AUC: 0.9505 Time: 13.12\n",
      "Epoch: 912 Train Loss: 0.0853 Val Loss: 0.3336 Acc: 0.8967 Pre: 0.8878 Recall: 0.9212 F1: 0.9042 Train AUC: 0.9963 Val AUC: 0.9556 Time: 13.59\n",
      "Epoch: 913 Train Loss: 0.0820 Val Loss: 0.3350 Acc: 0.8931 Pre: 0.8820 Recall: 0.9212 F1: 0.9012 Train AUC: 0.9967 Val AUC: 0.9561 Time: 14.32\n",
      "Epoch: 914 Train Loss: 0.0854 Val Loss: 0.3287 Acc: 0.8913 Pre: 0.8867 Recall: 0.9110 F1: 0.8986 Train AUC: 0.9963 Val AUC: 0.9568 Time: 14.81\n",
      "Epoch: 915 Train Loss: 0.0823 Val Loss: 0.3260 Acc: 0.8895 Pre: 0.8812 Recall: 0.9144 F1: 0.8975 Train AUC: 0.9968 Val AUC: 0.9568 Time: 13.69\n",
      "Epoch: 916 Train Loss: 0.0782 Val Loss: 0.3286 Acc: 0.8895 Pre: 0.8738 Recall: 0.9247 F1: 0.8985 Train AUC: 0.9971 Val AUC: 0.9558 Time: 13.46\n",
      "Epoch: 917 Train Loss: 0.0748 Val Loss: 0.3370 Acc: 0.8804 Pre: 0.8669 Recall: 0.9144 F1: 0.8900 Train AUC: 0.9973 Val AUC: 0.9542 Time: 13.30\n",
      "Epoch: 918 Train Loss: 0.0824 Val Loss: 0.3472 Acc: 0.8768 Pre: 0.8613 Recall: 0.9144 F1: 0.8870 Train AUC: 0.9965 Val AUC: 0.9521 Time: 14.15\n",
      "Epoch: 919 Train Loss: 0.0793 Val Loss: 0.3493 Acc: 0.8786 Pre: 0.8594 Recall: 0.9212 F1: 0.8893 Train AUC: 0.9970 Val AUC: 0.9532 Time: 14.68\n",
      "Epoch: 920 Train Loss: 0.0839 Val Loss: 0.3341 Acc: 0.8895 Pre: 0.8762 Recall: 0.9212 F1: 0.8982 Train AUC: 0.9966 Val AUC: 0.9555 Time: 14.61\n",
      "Epoch: 921 Train Loss: 0.0777 Val Loss: 0.3338 Acc: 0.8750 Pre: 0.8704 Recall: 0.8973 F1: 0.8836 Train AUC: 0.9968 Val AUC: 0.9552 Time: 13.49\n",
      "Epoch: 922 Train Loss: 0.0765 Val Loss: 0.3353 Acc: 0.8714 Pre: 0.8623 Recall: 0.9007 F1: 0.8811 Train AUC: 0.9970 Val AUC: 0.9549 Time: 12.60\n",
      "Epoch: 923 Train Loss: 0.0804 Val Loss: 0.3315 Acc: 0.8841 Pre: 0.8800 Recall: 0.9041 F1: 0.8919 Train AUC: 0.9967 Val AUC: 0.9562 Time: 12.73\n",
      "Epoch: 924 Train Loss: 0.0845 Val Loss: 0.3464 Acc: 0.8895 Pre: 0.8714 Recall: 0.9281 F1: 0.8988 Train AUC: 0.9966 Val AUC: 0.9550 Time: 13.10\n",
      "Epoch: 925 Train Loss: 0.0868 Val Loss: 0.3438 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9963 Val AUC: 0.9534 Time: 13.65\n",
      "Epoch: 926 Train Loss: 0.0803 Val Loss: 0.3360 Acc: 0.8732 Pre: 0.8558 Recall: 0.9144 F1: 0.8841 Train AUC: 0.9971 Val AUC: 0.9513 Time: 14.37\n",
      "Epoch: 927 Train Loss: 0.0890 Val Loss: 0.3319 Acc: 0.8822 Pre: 0.8697 Recall: 0.9144 F1: 0.8915 Train AUC: 0.9965 Val AUC: 0.9533 Time: 14.84\n",
      "Epoch: 928 Train Loss: 0.0795 Val Loss: 0.3379 Acc: 0.8841 Pre: 0.8725 Recall: 0.9144 F1: 0.8930 Train AUC: 0.9968 Val AUC: 0.9560 Time: 14.55\n",
      "Epoch: 929 Train Loss: 0.0793 Val Loss: 0.3378 Acc: 0.8895 Pre: 0.8714 Recall: 0.9281 F1: 0.8988 Train AUC: 0.9968 Val AUC: 0.9568 Time: 13.82\n",
      "Epoch: 930 Train Loss: 0.0891 Val Loss: 0.3268 Acc: 0.8804 Pre: 0.8844 Recall: 0.8904 F1: 0.8874 Train AUC: 0.9965 Val AUC: 0.9579 Time: 12.68\n",
      "Epoch: 931 Train Loss: 0.0785 Val Loss: 0.3271 Acc: 0.8768 Pre: 0.8784 Recall: 0.8904 F1: 0.8844 Train AUC: 0.9968 Val AUC: 0.9576 Time: 12.73\n",
      "Epoch: 932 Train Loss: 0.0744 Val Loss: 0.3307 Acc: 0.8859 Pre: 0.8706 Recall: 0.9212 F1: 0.8952 Train AUC: 0.9977 Val AUC: 0.9562 Time: 13.32\n",
      "Epoch: 933 Train Loss: 0.0816 Val Loss: 0.3492 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9969 Val AUC: 0.9527 Time: 13.97\n",
      "Epoch: 934 Train Loss: 0.0821 Val Loss: 0.3401 Acc: 0.8895 Pre: 0.8690 Recall: 0.9315 F1: 0.8992 Train AUC: 0.9974 Val AUC: 0.9555 Time: 14.54\n",
      "Epoch: 935 Train Loss: 0.0796 Val Loss: 0.3350 Acc: 0.8786 Pre: 0.8840 Recall: 0.8870 F1: 0.8855 Train AUC: 0.9973 Val AUC: 0.9567 Time: 15.00\n",
      "Epoch: 936 Train Loss: 0.0810 Val Loss: 0.3363 Acc: 0.8768 Pre: 0.8836 Recall: 0.8836 F1: 0.8836 Train AUC: 0.9959 Val AUC: 0.9546 Time: 14.82\n",
      "Epoch: 937 Train Loss: 0.0861 Val Loss: 0.3437 Acc: 0.8786 Pre: 0.8594 Recall: 0.9212 F1: 0.8893 Train AUC: 0.9962 Val AUC: 0.9534 Time: 13.33\n",
      "Epoch: 938 Train Loss: 0.0790 Val Loss: 0.3452 Acc: 0.8804 Pre: 0.8599 Recall: 0.9247 F1: 0.8911 Train AUC: 0.9975 Val AUC: 0.9539 Time: 12.89\n",
      "Epoch: 939 Train Loss: 0.0723 Val Loss: 0.3373 Acc: 0.8714 Pre: 0.8553 Recall: 0.9110 F1: 0.8823 Train AUC: 0.9979 Val AUC: 0.9533 Time: 13.48\n",
      "Epoch: 940 Train Loss: 0.0748 Val Loss: 0.3311 Acc: 0.8678 Pre: 0.8614 Recall: 0.8938 F1: 0.8773 Train AUC: 0.9974 Val AUC: 0.9539 Time: 13.44\n",
      "Epoch: 941 Train Loss: 0.0832 Val Loss: 0.3323 Acc: 0.8786 Pre: 0.8664 Recall: 0.9110 F1: 0.8881 Train AUC: 0.9968 Val AUC: 0.9561 Time: 14.05\n",
      "Epoch: 942 Train Loss: 0.0750 Val Loss: 0.3410 Acc: 0.8822 Pre: 0.8626 Recall: 0.9247 F1: 0.8926 Train AUC: 0.9974 Val AUC: 0.9564 Time: 14.78\n",
      "Epoch: 943 Train Loss: 0.0794 Val Loss: 0.3458 Acc: 0.8841 Pre: 0.8631 Recall: 0.9281 F1: 0.8944 Train AUC: 0.9970 Val AUC: 0.9552 Time: 14.92\n",
      "Epoch: 944 Train Loss: 0.0732 Val Loss: 0.3401 Acc: 0.8786 Pre: 0.8641 Recall: 0.9144 F1: 0.8885 Train AUC: 0.9978 Val AUC: 0.9536 Time: 13.31\n",
      "Epoch: 945 Train Loss: 0.0827 Val Loss: 0.3384 Acc: 0.8714 Pre: 0.8553 Recall: 0.9110 F1: 0.8823 Train AUC: 0.9968 Val AUC: 0.9531 Time: 12.45\n",
      "Epoch: 946 Train Loss: 0.0796 Val Loss: 0.3399 Acc: 0.8732 Pre: 0.8581 Recall: 0.9110 F1: 0.8837 Train AUC: 0.9971 Val AUC: 0.9535 Time: 13.00\n",
      "Epoch: 947 Train Loss: 0.0804 Val Loss: 0.3357 Acc: 0.8750 Pre: 0.8680 Recall: 0.9007 F1: 0.8840 Train AUC: 0.9972 Val AUC: 0.9557 Time: 13.14\n",
      "Epoch: 948 Train Loss: 0.0819 Val Loss: 0.3348 Acc: 0.8822 Pre: 0.8796 Recall: 0.9007 F1: 0.8900 Train AUC: 0.9972 Val AUC: 0.9574 Time: 13.73\n",
      "Epoch: 949 Train Loss: 0.0719 Val Loss: 0.3378 Acc: 0.8877 Pre: 0.8859 Recall: 0.9041 F1: 0.8949 Train AUC: 0.9976 Val AUC: 0.9576 Time: 14.56\n",
      "Epoch: 950 Train Loss: 0.0857 Val Loss: 0.3410 Acc: 0.8967 Pre: 0.8803 Recall: 0.9315 F1: 0.9052 Train AUC: 0.9961 Val AUC: 0.9570 Time: 15.30\n",
      "Epoch: 951 Train Loss: 0.0713 Val Loss: 0.3521 Acc: 0.8750 Pre: 0.8585 Recall: 0.9144 F1: 0.8856 Train AUC: 0.9977 Val AUC: 0.9518 Time: 15.62\n",
      "Epoch: 952 Train Loss: 0.0812 Val Loss: 0.3468 Acc: 0.8714 Pre: 0.8576 Recall: 0.9075 F1: 0.8819 Train AUC: 0.9975 Val AUC: 0.9515 Time: 13.47\n",
      "Epoch: 953 Train Loss: 0.0767 Val Loss: 0.3373 Acc: 0.8822 Pre: 0.8796 Recall: 0.9007 F1: 0.8900 Train AUC: 0.9975 Val AUC: 0.9538 Time: 12.82\n",
      "Epoch: 954 Train Loss: 0.0760 Val Loss: 0.3363 Acc: 0.8804 Pre: 0.8792 Recall: 0.8973 F1: 0.8881 Train AUC: 0.9973 Val AUC: 0.9559 Time: 13.08\n",
      "Epoch: 955 Train Loss: 0.0839 Val Loss: 0.3340 Acc: 0.8877 Pre: 0.8808 Recall: 0.9110 F1: 0.8956 Train AUC: 0.9963 Val AUC: 0.9567 Time: 13.35\n",
      "Epoch: 956 Train Loss: 0.0776 Val Loss: 0.3397 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9968 Val AUC: 0.9546 Time: 13.95\n",
      "Epoch: 957 Train Loss: 0.0754 Val Loss: 0.3481 Acc: 0.8822 Pre: 0.8603 Recall: 0.9281 F1: 0.8929 Train AUC: 0.9973 Val AUC: 0.9524 Time: 13.80\n",
      "Epoch: 958 Train Loss: 0.0897 Val Loss: 0.3344 Acc: 0.8786 Pre: 0.8594 Recall: 0.9212 F1: 0.8893 Train AUC: 0.9965 Val AUC: 0.9548 Time: 14.69\n",
      "Epoch: 959 Train Loss: 0.0729 Val Loss: 0.3334 Acc: 0.8822 Pre: 0.8771 Recall: 0.9041 F1: 0.8904 Train AUC: 0.9977 Val AUC: 0.9565 Time: 14.05\n",
      "Epoch: 960 Train Loss: 0.0790 Val Loss: 0.3388 Acc: 0.8859 Pre: 0.8754 Recall: 0.9144 F1: 0.8945 Train AUC: 0.9965 Val AUC: 0.9558 Time: 13.18\n",
      "Epoch: 961 Train Loss: 0.0757 Val Loss: 0.3511 Acc: 0.8768 Pre: 0.8522 Recall: 0.9281 F1: 0.8885 Train AUC: 0.9970 Val AUC: 0.9551 Time: 13.07\n",
      "Epoch: 962 Train Loss: 0.0801 Val Loss: 0.3526 Acc: 0.8786 Pre: 0.8571 Recall: 0.9247 F1: 0.8896 Train AUC: 0.9971 Val AUC: 0.9532 Time: 13.83\n",
      "Epoch: 963 Train Loss: 0.0800 Val Loss: 0.3371 Acc: 0.8732 Pre: 0.8627 Recall: 0.9041 F1: 0.8829 Train AUC: 0.9973 Val AUC: 0.9544 Time: 14.60\n",
      "Epoch: 964 Train Loss: 0.0801 Val Loss: 0.3294 Acc: 0.8768 Pre: 0.8810 Recall: 0.8870 F1: 0.8840 Train AUC: 0.9969 Val AUC: 0.9564 Time: 14.98\n",
      "Epoch: 965 Train Loss: 0.0788 Val Loss: 0.3313 Acc: 0.8804 Pre: 0.8844 Recall: 0.8904 F1: 0.8874 Train AUC: 0.9970 Val AUC: 0.9557 Time: 15.48\n",
      "Epoch: 966 Train Loss: 0.0789 Val Loss: 0.3504 Acc: 0.8822 Pre: 0.8580 Recall: 0.9315 F1: 0.8933 Train AUC: 0.9972 Val AUC: 0.9540 Time: 13.72\n",
      "Epoch: 967 Train Loss: 0.0752 Val Loss: 0.3627 Acc: 0.8750 Pre: 0.8495 Recall: 0.9281 F1: 0.8871 Train AUC: 0.9976 Val AUC: 0.9507 Time: 12.51\n",
      "Epoch: 968 Train Loss: 0.0833 Val Loss: 0.3351 Acc: 0.8786 Pre: 0.8617 Recall: 0.9178 F1: 0.8889 Train AUC: 0.9980 Val AUC: 0.9537 Time: 12.24\n",
      "Epoch: 969 Train Loss: 0.0775 Val Loss: 0.3294 Acc: 0.8768 Pre: 0.8836 Recall: 0.8836 F1: 0.8836 Train AUC: 0.9975 Val AUC: 0.9571 Time: 12.83\n",
      "Epoch: 970 Train Loss: 0.0844 Val Loss: 0.3378 Acc: 0.8931 Pre: 0.8820 Recall: 0.9212 F1: 0.9012 Train AUC: 0.9972 Val AUC: 0.9575 Time: 13.35\n",
      "Epoch: 971 Train Loss: 0.0719 Val Loss: 0.3610 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9978 Val AUC: 0.9574 Time: 13.85\n",
      "Epoch: 972 Train Loss: 0.0767 Val Loss: 0.3641 Acc: 0.8804 Pre: 0.8509 Recall: 0.9384 F1: 0.8925 Train AUC: 0.9975 Val AUC: 0.9542 Time: 14.46\n",
      "Epoch: 973 Train Loss: 0.0841 Val Loss: 0.3403 Acc: 0.8750 Pre: 0.8608 Recall: 0.9110 F1: 0.8852 Train AUC: 0.9971 Val AUC: 0.9539 Time: 15.11\n",
      "Epoch: 974 Train Loss: 0.0767 Val Loss: 0.3344 Acc: 0.8659 Pre: 0.8707 Recall: 0.8767 F1: 0.8737 Train AUC: 0.9973 Val AUC: 0.9554 Time: 14.78\n",
      "Epoch: 975 Train Loss: 0.0843 Val Loss: 0.3440 Acc: 0.8913 Pre: 0.8718 Recall: 0.9315 F1: 0.9007 Train AUC: 0.9976 Val AUC: 0.9566 Time: 13.46\n",
      "Epoch: 976 Train Loss: 0.0823 Val Loss: 0.3617 Acc: 0.8768 Pre: 0.8500 Recall: 0.9315 F1: 0.8889 Train AUC: 0.9960 Val AUC: 0.9541 Time: 12.73\n",
      "Epoch: 977 Train Loss: 0.0846 Val Loss: 0.3415 Acc: 0.8786 Pre: 0.8617 Recall: 0.9178 F1: 0.8889 Train AUC: 0.9967 Val AUC: 0.9541 Time: 13.04\n",
      "Epoch: 978 Train Loss: 0.0758 Val Loss: 0.3328 Acc: 0.8750 Pre: 0.8832 Recall: 0.8801 F1: 0.8816 Train AUC: 0.9973 Val AUC: 0.9553 Time: 13.42\n",
      "Epoch: 979 Train Loss: 0.0821 Val Loss: 0.3341 Acc: 0.8768 Pre: 0.8836 Recall: 0.8836 F1: 0.8836 Train AUC: 0.9970 Val AUC: 0.9548 Time: 14.05\n",
      "Epoch: 980 Train Loss: 0.0721 Val Loss: 0.3416 Acc: 0.8750 Pre: 0.8656 Recall: 0.9041 F1: 0.8844 Train AUC: 0.9980 Val AUC: 0.9536 Time: 14.73\n",
      "Epoch: 981 Train Loss: 0.0784 Val Loss: 0.3439 Acc: 0.8804 Pre: 0.8622 Recall: 0.9212 F1: 0.8907 Train AUC: 0.9968 Val AUC: 0.9536 Time: 15.14\n",
      "Epoch: 982 Train Loss: 0.0821 Val Loss: 0.3410 Acc: 0.8768 Pre: 0.8613 Recall: 0.9144 F1: 0.8870 Train AUC: 0.9969 Val AUC: 0.9534 Time: 14.92\n",
      "Epoch: 983 Train Loss: 0.0768 Val Loss: 0.3422 Acc: 0.8895 Pre: 0.8714 Recall: 0.9281 F1: 0.8988 Train AUC: 0.9978 Val AUC: 0.9560 Time: 13.53\n",
      "Epoch: 984 Train Loss: 0.0752 Val Loss: 0.3443 Acc: 0.8913 Pre: 0.8742 Recall: 0.9281 F1: 0.9003 Train AUC: 0.9973 Val AUC: 0.9572 Time: 13.19\n",
      "Epoch: 985 Train Loss: 0.0724 Val Loss: 0.3520 Acc: 0.8841 Pre: 0.8654 Recall: 0.9247 F1: 0.8940 Train AUC: 0.9978 Val AUC: 0.9560 Time: 13.96\n",
      "Epoch: 986 Train Loss: 0.0824 Val Loss: 0.3476 Acc: 0.8841 Pre: 0.8677 Recall: 0.9212 F1: 0.8937 Train AUC: 0.9966 Val AUC: 0.9552 Time: 14.20\n",
      "Epoch: 987 Train Loss: 0.0862 Val Loss: 0.3413 Acc: 0.8714 Pre: 0.8671 Recall: 0.8938 F1: 0.8803 Train AUC: 0.9963 Val AUC: 0.9513 Time: 12.76\n",
      "Epoch: 988 Train Loss: 0.0798 Val Loss: 0.3443 Acc: 0.8714 Pre: 0.8746 Recall: 0.8836 F1: 0.8790 Train AUC: 0.9968 Val AUC: 0.9492 Time: 12.45\n",
      "Epoch: 989 Train Loss: 0.0781 Val Loss: 0.3477 Acc: 0.8786 Pre: 0.8617 Recall: 0.9178 F1: 0.8889 Train AUC: 0.9977 Val AUC: 0.9514 Time: 13.02\n",
      "Epoch: 990 Train Loss: 0.0755 Val Loss: 0.3549 Acc: 0.8841 Pre: 0.8608 Recall: 0.9315 F1: 0.8947 Train AUC: 0.9974 Val AUC: 0.9550 Time: 13.39\n",
      "Epoch: 991 Train Loss: 0.0851 Val Loss: 0.3361 Acc: 0.8841 Pre: 0.8775 Recall: 0.9075 F1: 0.8923 Train AUC: 0.9973 Val AUC: 0.9571 Time: 14.05\n",
      "Epoch: 992 Train Loss: 0.0790 Val Loss: 0.3319 Acc: 0.8804 Pre: 0.8818 Recall: 0.8938 F1: 0.8878 Train AUC: 0.9970 Val AUC: 0.9564 Time: 14.79\n",
      "Epoch: 993 Train Loss: 0.0898 Val Loss: 0.3326 Acc: 0.8768 Pre: 0.8684 Recall: 0.9041 F1: 0.8859 Train AUC: 0.9956 Val AUC: 0.9551 Time: 15.90\n",
      "Epoch: 994 Train Loss: 0.0720 Val Loss: 0.3495 Acc: 0.8768 Pre: 0.8567 Recall: 0.9212 F1: 0.8878 Train AUC: 0.9977 Val AUC: 0.9523 Time: 14.13\n",
      "Epoch: 995 Train Loss: 0.0772 Val Loss: 0.3620 Acc: 0.8822 Pre: 0.8580 Recall: 0.9315 F1: 0.8933 Train AUC: 0.9974 Val AUC: 0.9524 Time: 12.88\n",
      "Epoch: 996 Train Loss: 0.0808 Val Loss: 0.3441 Acc: 0.8895 Pre: 0.8837 Recall: 0.9110 F1: 0.8971 Train AUC: 0.9970 Val AUC: 0.9548 Time: 12.05\n",
      "Epoch: 997 Train Loss: 0.0703 Val Loss: 0.3368 Acc: 0.8768 Pre: 0.8836 Recall: 0.8836 F1: 0.8836 Train AUC: 0.9978 Val AUC: 0.9560 Time: 12.05\n",
      "Epoch: 998 Train Loss: 0.0884 Val Loss: 0.3475 Acc: 0.8804 Pre: 0.8576 Recall: 0.9281 F1: 0.8914 Train AUC: 0.9965 Val AUC: 0.9542 Time: 12.58\n",
      "Epoch: 999 Train Loss: 0.0787 Val Loss: 0.3651 Acc: 0.8804 Pre: 0.8509 Recall: 0.9384 F1: 0.8925 Train AUC: 0.9969 Val AUC: 0.9551 Time: 13.05\n",
      "Epoch: 1000 Train Loss: 0.0796 Val Loss: 0.3539 Acc: 0.8804 Pre: 0.8553 Recall: 0.9315 F1: 0.8918 Train AUC: 0.9972 Val AUC: 0.9567 Time: 13.42\n",
      "Fold: 2 Best Epoch: 345 Test acc: 0.8859 Test Pre: 0.8908 Test Recall: 0.8938 Test F1: 0.8923 Test PRC: 0.9678 Test AUC: 0.9610\n",
      "Training for Fold 3\n",
      "## Training edges: 2208\n",
      "## Testing edges: 552\n",
      "Epoch: 1 Train Loss: 0.8958 Val Loss: 0.8164 Acc: 0.6413 Pre: 0.6150 Recall: 0.8483 F1: 0.7130 Train AUC: 0.5057 Val AUC: 0.7078 Time: 14.43\n",
      "Epoch: 2 Train Loss: 1.0223 Val Loss: 1.8294 Acc: 0.6087 Pre: 0.6814 Recall: 0.4793 F1: 0.5628 Train AUC: 0.7007 Val AUC: 0.6700 Time: 15.25\n",
      "Epoch: 3 Train Loss: 1.8375 Val Loss: 0.5815 Acc: 0.6703 Pre: 0.8553 Recall: 0.4483 F1: 0.5882 Train AUC: 0.6077 Val AUC: 0.8372 Time: 16.49\n",
      "Epoch: 4 Train Loss: 0.5678 Val Loss: 0.4943 Acc: 0.7518 Pre: 0.7297 Recall: 0.8379 F1: 0.7801 Train AUC: 0.8226 Val AUC: 0.8487 Time: 14.75\n",
      "Epoch: 5 Train Loss: 0.6024 Val Loss: 0.5085 Acc: 0.7464 Pre: 0.7219 Recall: 0.8414 F1: 0.7771 Train AUC: 0.7988 Val AUC: 0.8443 Time: 13.40\n",
      "Epoch: 6 Train Loss: 0.5828 Val Loss: 0.4294 Acc: 0.7862 Pre: 0.8282 Recall: 0.7483 F1: 0.7862 Train AUC: 0.8204 Val AUC: 0.8771 Time: 13.07\n",
      "Epoch: 7 Train Loss: 0.5267 Val Loss: 0.5026 Acc: 0.7808 Pre: 0.8824 Recall: 0.6724 F1: 0.7632 Train AUC: 0.8327 Val AUC: 0.8677 Time: 13.52\n",
      "Epoch: 8 Train Loss: 0.5205 Val Loss: 0.5569 Acc: 0.7699 Pre: 0.8655 Recall: 0.6655 F1: 0.7524 Train AUC: 0.8575 Val AUC: 0.8531 Time: 13.95\n",
      "Epoch: 9 Train Loss: 0.5979 Val Loss: 0.5209 Acc: 0.7754 Pre: 0.8578 Recall: 0.6862 F1: 0.7625 Train AUC: 0.8528 Val AUC: 0.8642 Time: 14.02\n",
      "Epoch: 10 Train Loss: 0.5757 Val Loss: 0.4752 Acc: 0.7971 Pre: 0.8589 Recall: 0.7345 F1: 0.7918 Train AUC: 0.8533 Val AUC: 0.8762 Time: 14.82\n",
      "Epoch: 11 Train Loss: 0.4973 Val Loss: 0.4758 Acc: 0.7899 Pre: 0.8398 Recall: 0.7414 F1: 0.7875 Train AUC: 0.8674 Val AUC: 0.8757 Time: 14.93\n",
      "Epoch: 12 Train Loss: 0.5318 Val Loss: 0.4765 Acc: 0.7862 Pre: 0.8209 Recall: 0.7586 F1: 0.7885 Train AUC: 0.8575 Val AUC: 0.8747 Time: 14.58\n",
      "Epoch: 13 Train Loss: 0.4949 Val Loss: 0.4618 Acc: 0.7808 Pre: 0.8189 Recall: 0.7483 F1: 0.7820 Train AUC: 0.8748 Val AUC: 0.8783 Time: 13.48\n",
      "Epoch: 14 Train Loss: 0.4662 Val Loss: 0.4284 Acc: 0.7953 Pre: 0.8444 Recall: 0.7483 F1: 0.7934 Train AUC: 0.8767 Val AUC: 0.8848 Time: 13.14\n",
      "Epoch: 15 Train Loss: 0.4508 Val Loss: 0.4005 Acc: 0.8062 Pre: 0.8617 Recall: 0.7517 F1: 0.8029 Train AUC: 0.8769 Val AUC: 0.8958 Time: 13.25\n",
      "Epoch: 16 Train Loss: 0.4116 Val Loss: 0.3965 Acc: 0.8152 Pre: 0.8917 Recall: 0.7379 F1: 0.8075 Train AUC: 0.8938 Val AUC: 0.9039 Time: 13.71\n",
      "Epoch: 17 Train Loss: 0.4243 Val Loss: 0.4093 Acc: 0.8188 Pre: 0.9167 Recall: 0.7207 F1: 0.8069 Train AUC: 0.8828 Val AUC: 0.9035 Time: 14.34\n",
      "Epoch: 18 Train Loss: 0.4150 Val Loss: 0.4167 Acc: 0.8279 Pre: 0.9535 Recall: 0.7069 F1: 0.8119 Train AUC: 0.8894 Val AUC: 0.9040 Time: 14.13\n",
      "Epoch: 19 Train Loss: 0.4132 Val Loss: 0.4064 Acc: 0.8388 Pre: 0.9507 Recall: 0.7310 F1: 0.8265 Train AUC: 0.8899 Val AUC: 0.9050 Time: 13.99\n",
      "Epoch: 20 Train Loss: 0.4047 Val Loss: 0.3997 Acc: 0.8170 Pre: 0.8954 Recall: 0.7379 F1: 0.8091 Train AUC: 0.8965 Val AUC: 0.9029 Time: 13.46\n",
      "Epoch: 21 Train Loss: 0.4436 Val Loss: 0.4032 Acc: 0.8043 Pre: 0.8611 Recall: 0.7483 F1: 0.8007 Train AUC: 0.8854 Val AUC: 0.8990 Time: 13.68\n",
      "Epoch: 22 Train Loss: 0.3910 Val Loss: 0.4142 Acc: 0.7971 Pre: 0.8346 Recall: 0.7655 F1: 0.7986 Train AUC: 0.9093 Val AUC: 0.8966 Time: 14.00\n",
      "Epoch: 23 Train Loss: 0.3985 Val Loss: 0.4198 Acc: 0.7971 Pre: 0.8321 Recall: 0.7690 F1: 0.7993 Train AUC: 0.9076 Val AUC: 0.8963 Time: 14.86\n",
      "Epoch: 24 Train Loss: 0.4033 Val Loss: 0.4190 Acc: 0.8025 Pre: 0.8467 Recall: 0.7621 F1: 0.8022 Train AUC: 0.9108 Val AUC: 0.8966 Time: 14.74\n",
      "Epoch: 25 Train Loss: 0.3845 Val Loss: 0.4119 Acc: 0.8116 Pre: 0.8750 Recall: 0.7483 F1: 0.8067 Train AUC: 0.9128 Val AUC: 0.8982 Time: 13.22\n",
      "Epoch: 26 Train Loss: 0.4062 Val Loss: 0.4030 Acc: 0.8188 Pre: 0.8926 Recall: 0.7448 F1: 0.8120 Train AUC: 0.9038 Val AUC: 0.9009 Time: 13.05\n",
      "Epoch: 27 Train Loss: 0.4068 Val Loss: 0.3946 Acc: 0.8225 Pre: 0.9000 Recall: 0.7448 F1: 0.8151 Train AUC: 0.8971 Val AUC: 0.9043 Time: 13.12\n",
      "Epoch: 28 Train Loss: 0.3869 Val Loss: 0.3939 Acc: 0.8333 Pre: 0.9231 Recall: 0.7448 F1: 0.8244 Train AUC: 0.9032 Val AUC: 0.9050 Time: 13.85\n",
      "Epoch: 29 Train Loss: 0.3872 Val Loss: 0.3901 Acc: 0.8351 Pre: 0.9270 Recall: 0.7448 F1: 0.8260 Train AUC: 0.9023 Val AUC: 0.9055 Time: 14.50\n",
      "Epoch: 30 Train Loss: 0.3834 Val Loss: 0.3857 Acc: 0.8279 Pre: 0.9114 Recall: 0.7448 F1: 0.8197 Train AUC: 0.9046 Val AUC: 0.9054 Time: 14.96\n",
      "Epoch: 31 Train Loss: 0.3756 Val Loss: 0.3837 Acc: 0.8134 Pre: 0.8816 Recall: 0.7448 F1: 0.8075 Train AUC: 0.9109 Val AUC: 0.9060 Time: 14.62\n",
      "Epoch: 32 Train Loss: 0.3557 Val Loss: 0.3844 Acc: 0.8134 Pre: 0.8785 Recall: 0.7483 F1: 0.8082 Train AUC: 0.9184 Val AUC: 0.9063 Time: 13.94\n",
      "Epoch: 33 Train Loss: 0.3611 Val Loss: 0.3860 Acc: 0.8098 Pre: 0.8656 Recall: 0.7552 F1: 0.8066 Train AUC: 0.9196 Val AUC: 0.9065 Time: 12.88\n",
      "Epoch: 34 Train Loss: 0.3485 Val Loss: 0.3855 Acc: 0.8098 Pre: 0.8571 Recall: 0.7655 F1: 0.8087 Train AUC: 0.9223 Val AUC: 0.9070 Time: 13.10\n",
      "Epoch: 35 Train Loss: 0.3536 Val Loss: 0.3816 Acc: 0.8116 Pre: 0.8550 Recall: 0.7724 F1: 0.8116 Train AUC: 0.9226 Val AUC: 0.9087 Time: 13.52\n",
      "Epoch: 36 Train Loss: 0.3671 Val Loss: 0.3669 Acc: 0.8134 Pre: 0.8555 Recall: 0.7759 F1: 0.8137 Train AUC: 0.9187 Val AUC: 0.9123 Time: 13.97\n",
      "Epoch: 37 Train Loss: 0.3514 Val Loss: 0.3550 Acc: 0.8315 Pre: 0.8662 Recall: 0.8034 F1: 0.8336 Train AUC: 0.9226 Val AUC: 0.9179 Time: 14.73\n",
      "Epoch: 38 Train Loss: 0.3555 Val Loss: 0.3501 Acc: 0.8351 Pre: 0.8592 Recall: 0.8207 F1: 0.8395 Train AUC: 0.9205 Val AUC: 0.9215 Time: 14.92\n",
      "Epoch: 39 Train Loss: 0.3586 Val Loss: 0.3494 Acc: 0.8406 Pre: 0.8713 Recall: 0.8172 F1: 0.8434 Train AUC: 0.9210 Val AUC: 0.9228 Time: 13.31\n",
      "Epoch: 40 Train Loss: 0.3441 Val Loss: 0.3551 Acc: 0.8514 Pre: 0.9094 Recall: 0.7966 F1: 0.8493 Train AUC: 0.9255 Val AUC: 0.9227 Time: 12.99\n",
      "Epoch: 41 Train Loss: 0.3216 Val Loss: 0.3672 Acc: 0.8496 Pre: 0.9295 Recall: 0.7724 F1: 0.8437 Train AUC: 0.9335 Val AUC: 0.9219 Time: 13.25\n",
      "Epoch: 42 Train Loss: 0.3386 Val Loss: 0.3730 Acc: 0.8406 Pre: 0.9316 Recall: 0.7517 F1: 0.8321 Train AUC: 0.9292 Val AUC: 0.9212 Time: 13.67\n",
      "Epoch: 43 Train Loss: 0.3397 Val Loss: 0.3647 Acc: 0.8496 Pre: 0.9259 Recall: 0.7759 F1: 0.8443 Train AUC: 0.9316 Val AUC: 0.9217 Time: 14.41\n",
      "Epoch: 44 Train Loss: 0.3252 Val Loss: 0.3550 Acc: 0.8514 Pre: 0.9000 Recall: 0.8069 F1: 0.8509 Train AUC: 0.9324 Val AUC: 0.9221 Time: 15.06\n",
      "Epoch: 45 Train Loss: 0.3246 Val Loss: 0.3533 Acc: 0.8351 Pre: 0.8672 Recall: 0.8103 F1: 0.8378 Train AUC: 0.9336 Val AUC: 0.9210 Time: 15.86\n",
      "Epoch: 46 Train Loss: 0.3362 Val Loss: 0.3574 Acc: 0.8279 Pre: 0.8545 Recall: 0.8103 F1: 0.8319 Train AUC: 0.9296 Val AUC: 0.9184 Time: 13.79\n",
      "Epoch: 47 Train Loss: 0.3257 Val Loss: 0.3627 Acc: 0.8261 Pre: 0.8540 Recall: 0.8069 F1: 0.8298 Train AUC: 0.9338 Val AUC: 0.9168 Time: 12.82\n",
      "Epoch: 48 Train Loss: 0.3190 Val Loss: 0.3651 Acc: 0.8279 Pre: 0.8571 Recall: 0.8069 F1: 0.8313 Train AUC: 0.9350 Val AUC: 0.9163 Time: 12.61\n",
      "Epoch: 49 Train Loss: 0.3326 Val Loss: 0.3637 Acc: 0.8333 Pre: 0.8640 Recall: 0.8103 F1: 0.8363 Train AUC: 0.9314 Val AUC: 0.9167 Time: 12.93\n",
      "Epoch: 50 Train Loss: 0.3264 Val Loss: 0.3614 Acc: 0.8370 Pre: 0.8676 Recall: 0.8138 F1: 0.8399 Train AUC: 0.9325 Val AUC: 0.9180 Time: 13.44\n",
      "Epoch: 51 Train Loss: 0.3455 Val Loss: 0.3604 Acc: 0.8351 Pre: 0.8645 Recall: 0.8138 F1: 0.8384 Train AUC: 0.9271 Val AUC: 0.9179 Time: 14.10\n",
      "Epoch: 52 Train Loss: 0.3245 Val Loss: 0.3583 Acc: 0.8333 Pre: 0.8561 Recall: 0.8207 F1: 0.8380 Train AUC: 0.9342 Val AUC: 0.9186 Time: 14.57\n",
      "Epoch: 53 Train Loss: 0.3150 Val Loss: 0.3563 Acc: 0.8315 Pre: 0.8505 Recall: 0.8241 F1: 0.8371 Train AUC: 0.9366 Val AUC: 0.9201 Time: 15.55\n",
      "Epoch: 54 Train Loss: 0.3171 Val Loss: 0.3612 Acc: 0.8406 Pre: 0.8826 Recall: 0.8034 F1: 0.8412 Train AUC: 0.9385 Val AUC: 0.9204 Time: 15.28\n",
      "Epoch: 55 Train Loss: 0.3042 Val Loss: 0.3679 Acc: 0.8496 Pre: 0.9091 Recall: 0.7931 F1: 0.8471 Train AUC: 0.9410 Val AUC: 0.9209 Time: 13.41\n",
      "Epoch: 56 Train Loss: 0.3331 Val Loss: 0.3642 Acc: 0.8478 Pre: 0.9023 Recall: 0.7966 F1: 0.8462 Train AUC: 0.9361 Val AUC: 0.9208 Time: 12.91\n",
      "Epoch: 57 Train Loss: 0.3066 Val Loss: 0.3611 Acc: 0.8442 Pre: 0.8893 Recall: 0.8034 F1: 0.8442 Train AUC: 0.9403 Val AUC: 0.9212 Time: 13.03\n",
      "Epoch: 58 Train Loss: 0.3054 Val Loss: 0.3572 Acc: 0.8514 Pre: 0.8910 Recall: 0.8172 F1: 0.8525 Train AUC: 0.9414 Val AUC: 0.9217 Time: 13.00\n",
      "Epoch: 59 Train Loss: 0.3119 Val Loss: 0.3548 Acc: 0.8478 Pre: 0.8843 Recall: 0.8172 F1: 0.8495 Train AUC: 0.9381 Val AUC: 0.9226 Time: 13.57\n",
      "Epoch: 60 Train Loss: 0.3038 Val Loss: 0.3496 Acc: 0.8442 Pre: 0.8723 Recall: 0.8241 F1: 0.8475 Train AUC: 0.9432 Val AUC: 0.9243 Time: 14.32\n",
      "Epoch: 61 Train Loss: 0.3170 Val Loss: 0.3478 Acc: 0.8442 Pre: 0.8723 Recall: 0.8241 F1: 0.8475 Train AUC: 0.9369 Val AUC: 0.9248 Time: 14.93\n",
      "Epoch: 62 Train Loss: 0.3098 Val Loss: 0.3514 Acc: 0.8478 Pre: 0.8843 Recall: 0.8172 F1: 0.8495 Train AUC: 0.9408 Val AUC: 0.9243 Time: 15.87\n",
      "Epoch: 63 Train Loss: 0.3079 Val Loss: 0.3588 Acc: 0.8496 Pre: 0.8935 Recall: 0.8103 F1: 0.8499 Train AUC: 0.9409 Val AUC: 0.9228 Time: 15.12\n",
      "Epoch: 64 Train Loss: 0.3224 Val Loss: 0.3611 Acc: 0.8514 Pre: 0.8969 Recall: 0.8103 F1: 0.8514 Train AUC: 0.9351 Val AUC: 0.9226 Time: 13.53\n",
      "Epoch: 65 Train Loss: 0.3062 Val Loss: 0.3530 Acc: 0.8478 Pre: 0.8872 Recall: 0.8138 F1: 0.8489 Train AUC: 0.9410 Val AUC: 0.9242 Time: 12.71\n",
      "Epoch: 66 Train Loss: 0.3000 Val Loss: 0.3442 Acc: 0.8406 Pre: 0.8633 Recall: 0.8276 F1: 0.8451 Train AUC: 0.9433 Val AUC: 0.9267 Time: 12.70\n",
      "Epoch: 67 Train Loss: 0.3004 Val Loss: 0.3451 Acc: 0.8496 Pre: 0.8791 Recall: 0.8276 F1: 0.8526 Train AUC: 0.9444 Val AUC: 0.9271 Time: 13.29\n",
      "Epoch: 68 Train Loss: 0.3119 Val Loss: 0.3491 Acc: 0.8460 Pre: 0.8782 Recall: 0.8207 F1: 0.8485 Train AUC: 0.9409 Val AUC: 0.9256 Time: 13.84\n",
      "Epoch: 69 Train Loss: 0.3112 Val Loss: 0.3533 Acc: 0.8460 Pre: 0.8810 Recall: 0.8172 F1: 0.8479 Train AUC: 0.9426 Val AUC: 0.9235 Time: 13.69\n",
      "Epoch: 70 Train Loss: 0.2972 Val Loss: 0.3590 Acc: 0.8442 Pre: 0.8778 Recall: 0.8172 F1: 0.8464 Train AUC: 0.9441 Val AUC: 0.9216 Time: 14.35\n",
      "Epoch: 71 Train Loss: 0.3115 Val Loss: 0.3601 Acc: 0.8333 Pre: 0.8561 Recall: 0.8207 F1: 0.8380 Train AUC: 0.9397 Val AUC: 0.9207 Time: 14.74\n",
      "Epoch: 72 Train Loss: 0.3043 Val Loss: 0.3577 Acc: 0.8297 Pre: 0.8500 Recall: 0.8207 F1: 0.8351 Train AUC: 0.9423 Val AUC: 0.9213 Time: 14.32\n",
      "Epoch: 73 Train Loss: 0.2903 Val Loss: 0.3551 Acc: 0.8279 Pre: 0.8421 Recall: 0.8276 F1: 0.8348 Train AUC: 0.9474 Val AUC: 0.9222 Time: 13.58\n",
      "Epoch: 74 Train Loss: 0.2985 Val Loss: 0.3561 Acc: 0.8333 Pre: 0.8561 Recall: 0.8207 F1: 0.8380 Train AUC: 0.9447 Val AUC: 0.9221 Time: 13.36\n",
      "Epoch: 75 Train Loss: 0.2880 Val Loss: 0.3599 Acc: 0.8424 Pre: 0.8801 Recall: 0.8103 F1: 0.8438 Train AUC: 0.9468 Val AUC: 0.9226 Time: 13.73\n",
      "Epoch: 76 Train Loss: 0.2901 Val Loss: 0.3582 Acc: 0.8406 Pre: 0.8769 Recall: 0.8103 F1: 0.8423 Train AUC: 0.9475 Val AUC: 0.9240 Time: 14.33\n",
      "Epoch: 77 Train Loss: 0.2843 Val Loss: 0.3534 Acc: 0.8424 Pre: 0.8773 Recall: 0.8138 F1: 0.8444 Train AUC: 0.9507 Val AUC: 0.9258 Time: 13.97\n",
      "Epoch: 78 Train Loss: 0.3074 Val Loss: 0.3495 Acc: 0.8388 Pre: 0.8628 Recall: 0.8241 F1: 0.8430 Train AUC: 0.9431 Val AUC: 0.9255 Time: 14.74\n",
      "Epoch: 79 Train Loss: 0.3038 Val Loss: 0.3496 Acc: 0.8333 Pre: 0.8462 Recall: 0.8345 F1: 0.8403 Train AUC: 0.9431 Val AUC: 0.9245 Time: 13.86\n",
      "Epoch: 80 Train Loss: 0.2970 Val Loss: 0.3584 Acc: 0.8460 Pre: 0.8782 Recall: 0.8207 F1: 0.8485 Train AUC: 0.9466 Val AUC: 0.9225 Time: 13.24\n",
      "Epoch: 81 Train Loss: 0.2917 Val Loss: 0.3699 Acc: 0.8478 Pre: 0.9087 Recall: 0.7897 F1: 0.8450 Train AUC: 0.9467 Val AUC: 0.9219 Time: 13.34\n",
      "Epoch: 82 Train Loss: 0.2958 Val Loss: 0.3587 Acc: 0.8569 Pre: 0.9042 Recall: 0.8138 F1: 0.8566 Train AUC: 0.9466 Val AUC: 0.9242 Time: 13.71\n",
      "Epoch: 83 Train Loss: 0.2953 Val Loss: 0.3443 Acc: 0.8424 Pre: 0.8691 Recall: 0.8241 F1: 0.8460 Train AUC: 0.9474 Val AUC: 0.9292 Time: 14.40\n",
      "Epoch: 84 Train Loss: 0.2864 Val Loss: 0.3473 Acc: 0.8478 Pre: 0.8705 Recall: 0.8345 F1: 0.8521 Train AUC: 0.9496 Val AUC: 0.9292 Time: 15.05\n",
      "Epoch: 85 Train Loss: 0.2910 Val Loss: 0.3547 Acc: 0.8478 Pre: 0.8872 Recall: 0.8138 F1: 0.8489 Train AUC: 0.9498 Val AUC: 0.9295 Time: 13.81\n",
      "Epoch: 86 Train Loss: 0.2981 Val Loss: 0.3472 Acc: 0.8569 Pre: 0.8951 Recall: 0.8241 F1: 0.8582 Train AUC: 0.9487 Val AUC: 0.9290 Time: 13.65\n",
      "Epoch: 87 Train Loss: 0.2955 Val Loss: 0.3544 Acc: 0.8442 Pre: 0.8669 Recall: 0.8310 F1: 0.8486 Train AUC: 0.9475 Val AUC: 0.9233 Time: 12.92\n",
      "Epoch: 88 Train Loss: 0.2948 Val Loss: 0.3657 Acc: 0.8315 Pre: 0.8505 Recall: 0.8241 F1: 0.8371 Train AUC: 0.9469 Val AUC: 0.9203 Time: 13.49\n",
      "Epoch: 89 Train Loss: 0.2958 Val Loss: 0.3722 Acc: 0.8370 Pre: 0.8704 Recall: 0.8103 F1: 0.8393 Train AUC: 0.9456 Val AUC: 0.9192 Time: 14.17\n",
      "Epoch: 90 Train Loss: 0.2863 Val Loss: 0.3652 Acc: 0.8424 Pre: 0.8801 Recall: 0.8103 F1: 0.8438 Train AUC: 0.9496 Val AUC: 0.9206 Time: 14.75\n",
      "Epoch: 91 Train Loss: 0.2952 Val Loss: 0.3582 Acc: 0.8388 Pre: 0.8736 Recall: 0.8103 F1: 0.8408 Train AUC: 0.9450 Val AUC: 0.9225 Time: 14.31\n",
      "Epoch: 92 Train Loss: 0.2875 Val Loss: 0.3538 Acc: 0.8315 Pre: 0.8505 Recall: 0.8241 F1: 0.8371 Train AUC: 0.9501 Val AUC: 0.9243 Time: 13.40\n",
      "Epoch: 93 Train Loss: 0.2768 Val Loss: 0.3554 Acc: 0.8315 Pre: 0.8635 Recall: 0.8069 F1: 0.8342 Train AUC: 0.9538 Val AUC: 0.9251 Time: 13.30\n",
      "Epoch: 94 Train Loss: 0.2804 Val Loss: 0.3632 Acc: 0.8478 Pre: 0.8962 Recall: 0.8034 F1: 0.8473 Train AUC: 0.9529 Val AUC: 0.9247 Time: 14.01\n",
      "Epoch: 95 Train Loss: 0.2874 Val Loss: 0.3614 Acc: 0.8478 Pre: 0.8962 Recall: 0.8034 F1: 0.8473 Train AUC: 0.9506 Val AUC: 0.9233 Time: 14.28\n",
      "Epoch: 96 Train Loss: 0.2855 Val Loss: 0.3587 Acc: 0.8388 Pre: 0.8526 Recall: 0.8379 F1: 0.8452 Train AUC: 0.9521 Val AUC: 0.9221 Time: 13.68\n",
      "Epoch: 97 Train Loss: 0.2941 Val Loss: 0.3597 Acc: 0.8351 Pre: 0.8491 Recall: 0.8345 F1: 0.8417 Train AUC: 0.9475 Val AUC: 0.9220 Time: 13.58\n",
      "Epoch: 98 Train Loss: 0.2919 Val Loss: 0.3605 Acc: 0.8460 Pre: 0.8897 Recall: 0.8069 F1: 0.8463 Train AUC: 0.9485 Val AUC: 0.9236 Time: 13.71\n",
      "Epoch: 99 Train Loss: 0.2761 Val Loss: 0.3559 Acc: 0.8496 Pre: 0.8966 Recall: 0.8069 F1: 0.8494 Train AUC: 0.9527 Val AUC: 0.9263 Time: 14.13\n",
      "Epoch: 100 Train Loss: 0.2732 Val Loss: 0.3462 Acc: 0.8388 Pre: 0.8681 Recall: 0.8172 F1: 0.8419 Train AUC: 0.9570 Val AUC: 0.9294 Time: 13.96\n",
      "Epoch: 101 Train Loss: 0.2756 Val Loss: 0.3416 Acc: 0.8388 Pre: 0.8577 Recall: 0.8310 F1: 0.8441 Train AUC: 0.9562 Val AUC: 0.9303 Time: 14.39\n",
      "Epoch: 102 Train Loss: 0.2688 Val Loss: 0.3430 Acc: 0.8424 Pre: 0.8691 Recall: 0.8241 F1: 0.8460 Train AUC: 0.9559 Val AUC: 0.9299 Time: 14.14\n",
      "Epoch: 103 Train Loss: 0.2717 Val Loss: 0.3549 Acc: 0.8533 Pre: 0.9130 Recall: 0.7966 F1: 0.8508 Train AUC: 0.9545 Val AUC: 0.9288 Time: 13.84\n",
      "Epoch: 104 Train Loss: 0.2797 Val Loss: 0.3491 Acc: 0.8533 Pre: 0.8943 Recall: 0.8172 F1: 0.8541 Train AUC: 0.9537 Val AUC: 0.9283 Time: 13.17\n",
      "Epoch: 105 Train Loss: 0.2775 Val Loss: 0.3432 Acc: 0.8514 Pre: 0.8796 Recall: 0.8310 F1: 0.8546 Train AUC: 0.9521 Val AUC: 0.9288 Time: 13.26\n",
      "Epoch: 106 Train Loss: 0.2763 Val Loss: 0.3464 Acc: 0.8496 Pre: 0.8848 Recall: 0.8207 F1: 0.8515 Train AUC: 0.9534 Val AUC: 0.9280 Time: 13.93\n",
      "Epoch: 107 Train Loss: 0.2664 Val Loss: 0.3468 Acc: 0.8533 Pre: 0.8943 Recall: 0.8172 F1: 0.8541 Train AUC: 0.9559 Val AUC: 0.9282 Time: 13.84\n",
      "Epoch: 108 Train Loss: 0.2705 Val Loss: 0.3508 Acc: 0.8587 Pre: 0.9046 Recall: 0.8172 F1: 0.8587 Train AUC: 0.9543 Val AUC: 0.9278 Time: 14.22\n",
      "Epoch: 109 Train Loss: 0.2722 Val Loss: 0.3464 Acc: 0.8569 Pre: 0.8981 Recall: 0.8207 F1: 0.8577 Train AUC: 0.9531 Val AUC: 0.9286 Time: 13.79\n",
      "Epoch: 110 Train Loss: 0.2749 Val Loss: 0.3444 Acc: 0.8442 Pre: 0.8696 Recall: 0.8276 F1: 0.8481 Train AUC: 0.9530 Val AUC: 0.9285 Time: 14.22\n",
      "Epoch: 111 Train Loss: 0.2737 Val Loss: 0.3477 Acc: 0.8388 Pre: 0.8577 Recall: 0.8310 F1: 0.8441 Train AUC: 0.9563 Val AUC: 0.9260 Time: 13.94\n",
      "Epoch: 112 Train Loss: 0.2695 Val Loss: 0.3639 Acc: 0.8424 Pre: 0.8919 Recall: 0.7966 F1: 0.8415 Train AUC: 0.9557 Val AUC: 0.9218 Time: 13.37\n",
      "Epoch: 113 Train Loss: 0.2716 Val Loss: 0.3664 Acc: 0.8388 Pre: 0.8851 Recall: 0.7966 F1: 0.8385 Train AUC: 0.9540 Val AUC: 0.9208 Time: 13.73\n",
      "Epoch: 114 Train Loss: 0.2703 Val Loss: 0.3559 Acc: 0.8406 Pre: 0.8659 Recall: 0.8241 F1: 0.8445 Train AUC: 0.9554 Val AUC: 0.9222 Time: 14.31\n",
      "Epoch: 115 Train Loss: 0.2688 Val Loss: 0.3504 Acc: 0.8388 Pre: 0.8551 Recall: 0.8345 F1: 0.8447 Train AUC: 0.9567 Val AUC: 0.9239 Time: 14.77\n",
      "Epoch: 116 Train Loss: 0.2636 Val Loss: 0.3547 Acc: 0.8514 Pre: 0.9000 Recall: 0.8069 F1: 0.8509 Train AUC: 0.9585 Val AUC: 0.9251 Time: 14.47\n",
      "Epoch: 117 Train Loss: 0.2607 Val Loss: 0.3602 Acc: 0.8533 Pre: 0.9163 Recall: 0.7931 F1: 0.8503 Train AUC: 0.9594 Val AUC: 0.9268 Time: 13.34\n",
      "Epoch: 118 Train Loss: 0.2650 Val Loss: 0.3511 Acc: 0.8569 Pre: 0.9137 Recall: 0.8034 F1: 0.8550 Train AUC: 0.9568 Val AUC: 0.9292 Time: 12.78\n",
      "Epoch: 119 Train Loss: 0.2688 Val Loss: 0.3344 Acc: 0.8424 Pre: 0.8664 Recall: 0.8276 F1: 0.8466 Train AUC: 0.9579 Val AUC: 0.9314 Time: 13.27\n",
      "Epoch: 120 Train Loss: 0.2744 Val Loss: 0.3339 Acc: 0.8424 Pre: 0.8561 Recall: 0.8414 F1: 0.8487 Train AUC: 0.9532 Val AUC: 0.9314 Time: 13.86\n",
      "Epoch: 121 Train Loss: 0.2671 Val Loss: 0.3420 Acc: 0.8442 Pre: 0.8723 Recall: 0.8241 F1: 0.8475 Train AUC: 0.9576 Val AUC: 0.9292 Time: 14.49\n",
      "Epoch: 122 Train Loss: 0.2620 Val Loss: 0.3613 Acc: 0.8533 Pre: 0.9163 Recall: 0.7931 F1: 0.8503 Train AUC: 0.9576 Val AUC: 0.9274 Time: 15.26\n",
      "Epoch: 123 Train Loss: 0.2652 Val Loss: 0.3637 Acc: 0.8533 Pre: 0.9163 Recall: 0.7931 F1: 0.8503 Train AUC: 0.9573 Val AUC: 0.9274 Time: 14.44\n",
      "Epoch: 124 Train Loss: 0.2615 Val Loss: 0.3427 Acc: 0.8424 Pre: 0.8801 Recall: 0.8103 F1: 0.8438 Train AUC: 0.9585 Val AUC: 0.9300 Time: 13.08\n",
      "Epoch: 125 Train Loss: 0.2675 Val Loss: 0.3362 Acc: 0.8478 Pre: 0.8552 Recall: 0.8552 F1: 0.8552 Train AUC: 0.9571 Val AUC: 0.9317 Time: 12.49\n",
      "Epoch: 126 Train Loss: 0.2643 Val Loss: 0.3382 Acc: 0.8496 Pre: 0.8581 Recall: 0.8552 F1: 0.8566 Train AUC: 0.9583 Val AUC: 0.9309 Time: 12.39\n",
      "Epoch: 127 Train Loss: 0.2635 Val Loss: 0.3580 Acc: 0.8424 Pre: 0.8773 Recall: 0.8138 F1: 0.8444 Train AUC: 0.9593 Val AUC: 0.9258 Time: 13.00\n",
      "Epoch: 128 Train Loss: 0.2510 Val Loss: 0.3823 Acc: 0.8496 Pre: 0.9124 Recall: 0.7897 F1: 0.8466 Train AUC: 0.9610 Val AUC: 0.9236 Time: 13.68\n",
      "Epoch: 129 Train Loss: 0.2524 Val Loss: 0.3629 Acc: 0.8460 Pre: 0.8782 Recall: 0.8207 F1: 0.8485 Train AUC: 0.9621 Val AUC: 0.9259 Time: 14.01\n",
      "Epoch: 130 Train Loss: 0.2606 Val Loss: 0.3416 Acc: 0.8496 Pre: 0.8632 Recall: 0.8483 F1: 0.8557 Train AUC: 0.9586 Val AUC: 0.9298 Time: 14.63\n",
      "Epoch: 131 Train Loss: 0.2674 Val Loss: 0.3351 Acc: 0.8496 Pre: 0.8683 Recall: 0.8414 F1: 0.8546 Train AUC: 0.9570 Val AUC: 0.9326 Time: 15.31\n",
      "Epoch: 132 Train Loss: 0.2586 Val Loss: 0.3412 Acc: 0.8514 Pre: 0.8939 Recall: 0.8138 F1: 0.8520 Train AUC: 0.9610 Val AUC: 0.9324 Time: 14.88\n",
      "Epoch: 133 Train Loss: 0.2789 Val Loss: 0.3445 Acc: 0.8514 Pre: 0.8881 Recall: 0.8207 F1: 0.8530 Train AUC: 0.9554 Val AUC: 0.9300 Time: 13.36\n",
      "Epoch: 134 Train Loss: 0.2514 Val Loss: 0.3538 Acc: 0.8406 Pre: 0.8659 Recall: 0.8241 F1: 0.8445 Train AUC: 0.9616 Val AUC: 0.9268 Time: 12.81\n",
      "Epoch: 135 Train Loss: 0.2565 Val Loss: 0.3625 Acc: 0.8424 Pre: 0.8718 Recall: 0.8207 F1: 0.8455 Train AUC: 0.9603 Val AUC: 0.9248 Time: 13.03\n",
      "Epoch: 136 Train Loss: 0.2509 Val Loss: 0.3566 Acc: 0.8424 Pre: 0.8691 Recall: 0.8241 F1: 0.8460 Train AUC: 0.9615 Val AUC: 0.9263 Time: 13.60\n",
      "Epoch: 137 Train Loss: 0.2458 Val Loss: 0.3477 Acc: 0.8514 Pre: 0.8852 Recall: 0.8241 F1: 0.8536 Train AUC: 0.9630 Val AUC: 0.9292 Time: 13.74\n",
      "Epoch: 138 Train Loss: 0.2460 Val Loss: 0.3435 Acc: 0.8514 Pre: 0.8969 Recall: 0.8103 F1: 0.8514 Train AUC: 0.9634 Val AUC: 0.9311 Time: 14.17\n",
      "Epoch: 139 Train Loss: 0.2572 Val Loss: 0.3429 Acc: 0.8569 Pre: 0.8951 Recall: 0.8241 F1: 0.8582 Train AUC: 0.9609 Val AUC: 0.9309 Time: 14.91\n",
      "Epoch: 140 Train Loss: 0.2450 Val Loss: 0.3427 Acc: 0.8514 Pre: 0.8824 Recall: 0.8276 F1: 0.8541 Train AUC: 0.9633 Val AUC: 0.9307 Time: 14.44\n",
      "Epoch: 141 Train Loss: 0.2430 Val Loss: 0.3458 Acc: 0.8514 Pre: 0.8852 Recall: 0.8241 F1: 0.8536 Train AUC: 0.9639 Val AUC: 0.9303 Time: 13.41\n",
      "Epoch: 142 Train Loss: 0.2453 Val Loss: 0.3510 Acc: 0.8514 Pre: 0.8881 Recall: 0.8207 F1: 0.8530 Train AUC: 0.9637 Val AUC: 0.9289 Time: 12.91\n",
      "Epoch: 143 Train Loss: 0.2475 Val Loss: 0.3456 Acc: 0.8514 Pre: 0.8796 Recall: 0.8310 F1: 0.8546 Train AUC: 0.9629 Val AUC: 0.9299 Time: 13.46\n",
      "Epoch: 144 Train Loss: 0.2475 Val Loss: 0.3385 Acc: 0.8569 Pre: 0.8809 Recall: 0.8414 F1: 0.8607 Train AUC: 0.9622 Val AUC: 0.9321 Time: 13.81\n",
      "Epoch: 145 Train Loss: 0.2426 Val Loss: 0.3410 Acc: 0.8514 Pre: 0.8824 Recall: 0.8276 F1: 0.8541 Train AUC: 0.9643 Val AUC: 0.9321 Time: 14.61\n",
      "Epoch: 146 Train Loss: 0.2462 Val Loss: 0.3425 Acc: 0.8478 Pre: 0.8843 Recall: 0.8172 F1: 0.8495 Train AUC: 0.9634 Val AUC: 0.9323 Time: 15.40\n",
      "Epoch: 147 Train Loss: 0.2507 Val Loss: 0.3373 Acc: 0.8478 Pre: 0.8652 Recall: 0.8414 F1: 0.8531 Train AUC: 0.9620 Val AUC: 0.9326 Time: 14.85\n",
      "Epoch: 148 Train Loss: 0.2428 Val Loss: 0.3403 Acc: 0.8460 Pre: 0.8727 Recall: 0.8276 F1: 0.8496 Train AUC: 0.9643 Val AUC: 0.9318 Time: 13.58\n",
      "Epoch: 149 Train Loss: 0.2479 Val Loss: 0.3576 Acc: 0.8460 Pre: 0.8988 Recall: 0.7966 F1: 0.8446 Train AUC: 0.9638 Val AUC: 0.9290 Time: 12.70\n",
      "Epoch: 150 Train Loss: 0.2477 Val Loss: 0.3430 Acc: 0.8496 Pre: 0.8819 Recall: 0.8241 F1: 0.8520 Train AUC: 0.9639 Val AUC: 0.9308 Time: 12.55\n",
      "Epoch: 151 Train Loss: 0.2393 Val Loss: 0.3290 Acc: 0.8478 Pre: 0.8527 Recall: 0.8586 F1: 0.8557 Train AUC: 0.9653 Val AUC: 0.9338 Time: 12.99\n",
      "Epoch: 152 Train Loss: 0.2401 Val Loss: 0.3319 Acc: 0.8587 Pre: 0.8985 Recall: 0.8241 F1: 0.8597 Train AUC: 0.9672 Val AUC: 0.9345 Time: 13.60\n",
      "Epoch: 153 Train Loss: 0.2397 Val Loss: 0.3425 Acc: 0.8551 Pre: 0.9167 Recall: 0.7966 F1: 0.8524 Train AUC: 0.9648 Val AUC: 0.9345 Time: 14.36\n",
      "Epoch: 154 Train Loss: 0.2461 Val Loss: 0.3232 Acc: 0.8569 Pre: 0.8836 Recall: 0.8379 F1: 0.8602 Train AUC: 0.9662 Val AUC: 0.9365 Time: 14.91\n",
      "Epoch: 155 Train Loss: 0.2396 Val Loss: 0.3258 Acc: 0.8514 Pre: 0.8662 Recall: 0.8483 F1: 0.8571 Train AUC: 0.9657 Val AUC: 0.9362 Time: 15.39\n",
      "Epoch: 156 Train Loss: 0.2451 Val Loss: 0.3469 Acc: 0.8587 Pre: 0.9173 Recall: 0.8034 F1: 0.8566 Train AUC: 0.9661 Val AUC: 0.9324 Time: 13.78\n",
      "Epoch: 157 Train Loss: 0.2416 Val Loss: 0.3724 Acc: 0.8514 Pre: 0.9333 Recall: 0.7724 F1: 0.8453 Train AUC: 0.9635 Val AUC: 0.9298 Time: 12.92\n",
      "Epoch: 158 Train Loss: 0.2398 Val Loss: 0.3462 Acc: 0.8460 Pre: 0.8897 Recall: 0.8069 F1: 0.8463 Train AUC: 0.9661 Val AUC: 0.9296 Time: 12.76\n",
      "Epoch: 159 Train Loss: 0.2391 Val Loss: 0.3323 Acc: 0.8442 Pre: 0.8517 Recall: 0.8517 F1: 0.8517 Train AUC: 0.9652 Val AUC: 0.9313 Time: 13.38\n",
      "Epoch: 160 Train Loss: 0.2345 Val Loss: 0.3302 Acc: 0.8514 Pre: 0.8741 Recall: 0.8379 F1: 0.8556 Train AUC: 0.9689 Val AUC: 0.9331 Time: 13.69\n",
      "Epoch: 161 Train Loss: 0.2481 Val Loss: 0.3489 Acc: 0.8587 Pre: 0.9344 Recall: 0.7862 F1: 0.8539 Train AUC: 0.9640 Val AUC: 0.9340 Time: 14.33\n",
      "Epoch: 162 Train Loss: 0.2384 Val Loss: 0.3453 Acc: 0.8605 Pre: 0.9209 Recall: 0.8034 F1: 0.8582 Train AUC: 0.9675 Val AUC: 0.9354 Time: 15.17\n",
      "Epoch: 163 Train Loss: 0.2469 Val Loss: 0.3345 Acc: 0.8551 Pre: 0.8832 Recall: 0.8345 F1: 0.8582 Train AUC: 0.9630 Val AUC: 0.9351 Time: 13.86\n",
      "Epoch: 164 Train Loss: 0.2274 Val Loss: 0.3424 Acc: 0.8533 Pre: 0.8719 Recall: 0.8448 F1: 0.8581 Train AUC: 0.9692 Val AUC: 0.9323 Time: 13.34\n",
      "Epoch: 165 Train Loss: 0.2371 Val Loss: 0.3617 Acc: 0.8442 Pre: 0.8984 Recall: 0.7931 F1: 0.8425 Train AUC: 0.9665 Val AUC: 0.9281 Time: 13.02\n",
      "Epoch: 166 Train Loss: 0.2361 Val Loss: 0.3683 Acc: 0.8496 Pre: 0.9124 Recall: 0.7897 F1: 0.8466 Train AUC: 0.9661 Val AUC: 0.9285 Time: 13.45\n",
      "Epoch: 167 Train Loss: 0.2350 Val Loss: 0.3450 Acc: 0.8605 Pre: 0.9080 Recall: 0.8172 F1: 0.8603 Train AUC: 0.9679 Val AUC: 0.9331 Time: 14.08\n",
      "Epoch: 168 Train Loss: 0.2357 Val Loss: 0.3283 Acc: 0.8496 Pre: 0.8485 Recall: 0.8690 F1: 0.8586 Train AUC: 0.9680 Val AUC: 0.9373 Time: 14.79\n",
      "Epoch: 169 Train Loss: 0.2383 Val Loss: 0.3327 Acc: 0.8659 Pre: 0.8971 Recall: 0.8414 F1: 0.8683 Train AUC: 0.9685 Val AUC: 0.9372 Time: 15.35\n",
      "Epoch: 170 Train Loss: 0.2422 Val Loss: 0.3535 Acc: 0.8551 Pre: 0.9268 Recall: 0.7862 F1: 0.8507 Train AUC: 0.9645 Val AUC: 0.9379 Time: 13.99\n",
      "Epoch: 171 Train Loss: 0.2420 Val Loss: 0.3318 Acc: 0.8641 Pre: 0.9151 Recall: 0.8172 F1: 0.8634 Train AUC: 0.9678 Val AUC: 0.9386 Time: 12.86\n",
      "Epoch: 172 Train Loss: 0.2212 Val Loss: 0.3217 Acc: 0.8478 Pre: 0.8503 Recall: 0.8621 F1: 0.8562 Train AUC: 0.9700 Val AUC: 0.9377 Time: 12.45\n",
      "Epoch: 173 Train Loss: 0.2283 Val Loss: 0.3239 Acc: 0.8533 Pre: 0.8591 Recall: 0.8621 F1: 0.8606 Train AUC: 0.9711 Val AUC: 0.9369 Time: 12.84\n",
      "Epoch: 174 Train Loss: 0.2297 Val Loss: 0.3474 Acc: 0.8623 Pre: 0.9280 Recall: 0.8000 F1: 0.8593 Train AUC: 0.9705 Val AUC: 0.9343 Time: 13.10\n",
      "Epoch: 175 Train Loss: 0.2319 Val Loss: 0.3654 Acc: 0.8551 Pre: 0.9339 Recall: 0.7793 F1: 0.8496 Train AUC: 0.9676 Val AUC: 0.9342 Time: 13.59\n",
      "Epoch: 176 Train Loss: 0.2293 Val Loss: 0.3433 Acc: 0.8659 Pre: 0.9219 Recall: 0.8138 F1: 0.8645 Train AUC: 0.9682 Val AUC: 0.9355 Time: 14.16\n",
      "Epoch: 177 Train Loss: 0.2267 Val Loss: 0.3214 Acc: 0.8623 Pre: 0.8821 Recall: 0.8517 F1: 0.8667 Train AUC: 0.9688 Val AUC: 0.9370 Time: 14.87\n",
      "Epoch: 178 Train Loss: 0.2199 Val Loss: 0.3155 Acc: 0.8641 Pre: 0.8826 Recall: 0.8552 F1: 0.8687 Train AUC: 0.9733 Val AUC: 0.9387 Time: 14.82\n",
      "Epoch: 179 Train Loss: 0.2366 Val Loss: 0.3349 Acc: 0.8605 Pre: 0.9243 Recall: 0.8000 F1: 0.8577 Train AUC: 0.9693 Val AUC: 0.9384 Time: 15.37\n",
      "Epoch: 180 Train Loss: 0.2304 Val Loss: 0.3501 Acc: 0.8587 Pre: 0.9344 Recall: 0.7862 F1: 0.8539 Train AUC: 0.9678 Val AUC: 0.9369 Time: 13.70\n",
      "Epoch: 181 Train Loss: 0.2345 Val Loss: 0.3412 Acc: 0.8696 Pre: 0.9192 Recall: 0.8241 F1: 0.8691 Train AUC: 0.9671 Val AUC: 0.9349 Time: 12.85\n",
      "Epoch: 182 Train Loss: 0.2270 Val Loss: 0.3357 Acc: 0.8478 Pre: 0.8552 Recall: 0.8552 F1: 0.8552 Train AUC: 0.9686 Val AUC: 0.9335 Time: 13.02\n",
      "Epoch: 183 Train Loss: 0.2279 Val Loss: 0.3389 Acc: 0.8496 Pre: 0.8632 Recall: 0.8483 F1: 0.8557 Train AUC: 0.9703 Val AUC: 0.9335 Time: 13.28\n",
      "Epoch: 184 Train Loss: 0.2201 Val Loss: 0.3445 Acc: 0.8605 Pre: 0.9019 Recall: 0.8241 F1: 0.8613 Train AUC: 0.9708 Val AUC: 0.9347 Time: 13.82\n",
      "Epoch: 185 Train Loss: 0.2185 Val Loss: 0.3476 Acc: 0.8605 Pre: 0.9144 Recall: 0.8103 F1: 0.8592 Train AUC: 0.9709 Val AUC: 0.9368 Time: 14.53\n",
      "Epoch: 186 Train Loss: 0.2151 Val Loss: 0.3312 Acc: 0.8605 Pre: 0.9080 Recall: 0.8172 F1: 0.8603 Train AUC: 0.9723 Val AUC: 0.9397 Time: 15.15\n",
      "Epoch: 187 Train Loss: 0.2153 Val Loss: 0.3225 Acc: 0.8623 Pre: 0.8905 Recall: 0.8414 F1: 0.8652 Train AUC: 0.9721 Val AUC: 0.9402 Time: 14.62\n",
      "Epoch: 188 Train Loss: 0.2257 Val Loss: 0.3255 Acc: 0.8478 Pre: 0.8552 Recall: 0.8552 F1: 0.8552 Train AUC: 0.9700 Val AUC: 0.9377 Time: 13.33\n",
      "Epoch: 189 Train Loss: 0.2181 Val Loss: 0.3419 Acc: 0.8587 Pre: 0.9046 Recall: 0.8172 F1: 0.8587 Train AUC: 0.9729 Val AUC: 0.9362 Time: 12.76\n",
      "Epoch: 190 Train Loss: 0.2198 Val Loss: 0.3400 Acc: 0.8551 Pre: 0.8860 Recall: 0.8310 F1: 0.8577 Train AUC: 0.9722 Val AUC: 0.9356 Time: 13.00\n",
      "Epoch: 191 Train Loss: 0.2077 Val Loss: 0.3376 Acc: 0.8623 Pre: 0.8905 Recall: 0.8414 F1: 0.8652 Train AUC: 0.9741 Val AUC: 0.9371 Time: 13.48\n",
      "Epoch: 192 Train Loss: 0.2131 Val Loss: 0.3252 Acc: 0.8605 Pre: 0.8763 Recall: 0.8552 F1: 0.8656 Train AUC: 0.9724 Val AUC: 0.9393 Time: 14.10\n",
      "Epoch: 193 Train Loss: 0.2082 Val Loss: 0.3230 Acc: 0.8678 Pre: 0.8917 Recall: 0.8517 F1: 0.8713 Train AUC: 0.9745 Val AUC: 0.9402 Time: 14.78\n",
      "Epoch: 194 Train Loss: 0.2176 Val Loss: 0.3301 Acc: 0.8623 Pre: 0.9180 Recall: 0.8103 F1: 0.8608 Train AUC: 0.9719 Val AUC: 0.9407 Time: 14.49\n",
      "Epoch: 195 Train Loss: 0.2231 Val Loss: 0.3229 Acc: 0.8605 Pre: 0.9049 Recall: 0.8207 F1: 0.8608 Train AUC: 0.9704 Val AUC: 0.9404 Time: 13.48\n",
      "Epoch: 196 Train Loss: 0.2075 Val Loss: 0.3193 Acc: 0.8587 Pre: 0.8841 Recall: 0.8414 F1: 0.8622 Train AUC: 0.9747 Val AUC: 0.9397 Time: 13.39\n",
      "Epoch: 197 Train Loss: 0.2138 Val Loss: 0.3312 Acc: 0.8641 Pre: 0.9057 Recall: 0.8276 F1: 0.8649 Train AUC: 0.9732 Val AUC: 0.9384 Time: 13.49\n",
      "Epoch: 198 Train Loss: 0.2158 Val Loss: 0.3480 Acc: 0.8587 Pre: 0.9141 Recall: 0.8069 F1: 0.8571 Train AUC: 0.9720 Val AUC: 0.9369 Time: 13.71\n",
      "Epoch: 199 Train Loss: 0.2164 Val Loss: 0.3527 Acc: 0.8569 Pre: 0.9170 Recall: 0.8000 F1: 0.8545 Train AUC: 0.9715 Val AUC: 0.9353 Time: 14.22\n",
      "Epoch: 200 Train Loss: 0.2146 Val Loss: 0.3310 Acc: 0.8659 Pre: 0.8971 Recall: 0.8414 F1: 0.8683 Train AUC: 0.9719 Val AUC: 0.9361 Time: 14.14\n",
      "Epoch: 201 Train Loss: 0.2122 Val Loss: 0.3189 Acc: 0.8569 Pre: 0.8625 Recall: 0.8655 F1: 0.8640 Train AUC: 0.9729 Val AUC: 0.9378 Time: 14.02\n",
      "Epoch: 202 Train Loss: 0.2103 Val Loss: 0.3147 Acc: 0.8569 Pre: 0.8981 Recall: 0.8207 F1: 0.8577 Train AUC: 0.9753 Val AUC: 0.9410 Time: 13.56\n",
      "Epoch: 203 Train Loss: 0.2102 Val Loss: 0.3268 Acc: 0.8587 Pre: 0.9141 Recall: 0.8069 F1: 0.8571 Train AUC: 0.9757 Val AUC: 0.9421 Time: 13.61\n",
      "Epoch: 204 Train Loss: 0.2102 Val Loss: 0.3306 Acc: 0.8569 Pre: 0.9105 Recall: 0.8069 F1: 0.8556 Train AUC: 0.9735 Val AUC: 0.9412 Time: 13.41\n",
      "Epoch: 205 Train Loss: 0.2087 Val Loss: 0.3293 Acc: 0.8732 Pre: 0.9015 Recall: 0.8517 F1: 0.8759 Train AUC: 0.9738 Val AUC: 0.9387 Time: 13.96\n",
      "Epoch: 206 Train Loss: 0.2011 Val Loss: 0.3386 Acc: 0.8605 Pre: 0.8737 Recall: 0.8586 F1: 0.8661 Train AUC: 0.9771 Val AUC: 0.9358 Time: 13.95\n",
      "Epoch: 207 Train Loss: 0.2110 Val Loss: 0.3435 Acc: 0.8696 Pre: 0.9007 Recall: 0.8448 F1: 0.8719 Train AUC: 0.9744 Val AUC: 0.9370 Time: 13.98\n",
      "Epoch: 208 Train Loss: 0.2032 Val Loss: 0.3461 Acc: 0.8659 Pre: 0.9219 Recall: 0.8138 F1: 0.8645 Train AUC: 0.9748 Val AUC: 0.9385 Time: 14.51\n",
      "Epoch: 209 Train Loss: 0.2022 Val Loss: 0.3212 Acc: 0.8768 Pre: 0.9081 Recall: 0.8517 F1: 0.8790 Train AUC: 0.9762 Val AUC: 0.9418 Time: 14.04\n",
      "Epoch: 210 Train Loss: 0.2073 Val Loss: 0.3081 Acc: 0.8804 Pre: 0.9118 Recall: 0.8552 F1: 0.8826 Train AUC: 0.9753 Val AUC: 0.9454 Time: 13.36\n",
      "Epoch: 211 Train Loss: 0.2032 Val Loss: 0.3160 Acc: 0.8750 Pre: 0.9139 Recall: 0.8414 F1: 0.8761 Train AUC: 0.9763 Val AUC: 0.9462 Time: 12.89\n",
      "Epoch: 212 Train Loss: 0.2099 Val Loss: 0.3243 Acc: 0.8732 Pre: 0.9135 Recall: 0.8379 F1: 0.8741 Train AUC: 0.9741 Val AUC: 0.9426 Time: 13.16\n",
      "Epoch: 213 Train Loss: 0.2040 Val Loss: 0.3352 Acc: 0.8659 Pre: 0.8857 Recall: 0.8552 F1: 0.8702 Train AUC: 0.9745 Val AUC: 0.9375 Time: 13.58\n",
      "Epoch: 214 Train Loss: 0.1980 Val Loss: 0.3489 Acc: 0.8659 Pre: 0.9060 Recall: 0.8310 F1: 0.8669 Train AUC: 0.9767 Val AUC: 0.9353 Time: 14.25\n",
      "Epoch: 215 Train Loss: 0.2053 Val Loss: 0.3484 Acc: 0.8641 Pre: 0.9183 Recall: 0.8138 F1: 0.8629 Train AUC: 0.9740 Val AUC: 0.9376 Time: 15.14\n",
      "Epoch: 216 Train Loss: 0.2084 Val Loss: 0.3210 Acc: 0.8659 Pre: 0.9122 Recall: 0.8241 F1: 0.8659 Train AUC: 0.9735 Val AUC: 0.9430 Time: 14.33\n",
      "Epoch: 217 Train Loss: 0.2038 Val Loss: 0.3091 Acc: 0.8732 Pre: 0.8986 Recall: 0.8552 F1: 0.8763 Train AUC: 0.9759 Val AUC: 0.9452 Time: 13.76\n",
      "Epoch: 218 Train Loss: 0.2019 Val Loss: 0.3109 Acc: 0.8732 Pre: 0.8986 Recall: 0.8552 F1: 0.8763 Train AUC: 0.9764 Val AUC: 0.9450 Time: 13.54\n",
      "Epoch: 219 Train Loss: 0.2022 Val Loss: 0.3346 Acc: 0.8641 Pre: 0.8996 Recall: 0.8345 F1: 0.8658 Train AUC: 0.9766 Val AUC: 0.9410 Time: 13.98\n",
      "Epoch: 220 Train Loss: 0.2004 Val Loss: 0.3544 Acc: 0.8569 Pre: 0.9073 Recall: 0.8103 F1: 0.8561 Train AUC: 0.9758 Val AUC: 0.9375 Time: 14.43\n",
      "Epoch: 221 Train Loss: 0.1982 Val Loss: 0.3518 Acc: 0.8605 Pre: 0.9049 Recall: 0.8207 F1: 0.8608 Train AUC: 0.9763 Val AUC: 0.9347 Time: 14.54\n",
      "Epoch: 222 Train Loss: 0.1980 Val Loss: 0.3308 Acc: 0.8514 Pre: 0.8586 Recall: 0.8586 F1: 0.8586 Train AUC: 0.9760 Val AUC: 0.9362 Time: 13.46\n",
      "Epoch: 223 Train Loss: 0.2013 Val Loss: 0.3140 Acc: 0.8623 Pre: 0.8905 Recall: 0.8414 F1: 0.8652 Train AUC: 0.9767 Val AUC: 0.9434 Time: 13.02\n",
      "Epoch: 224 Train Loss: 0.2018 Val Loss: 0.3238 Acc: 0.8641 Pre: 0.8996 Recall: 0.8345 F1: 0.8658 Train AUC: 0.9778 Val AUC: 0.9440 Time: 12.63\n",
      "Epoch: 225 Train Loss: 0.2060 Val Loss: 0.3333 Acc: 0.8678 Pre: 0.9004 Recall: 0.8414 F1: 0.8699 Train AUC: 0.9743 Val AUC: 0.9416 Time: 13.25\n",
      "Epoch: 226 Train Loss: 0.2044 Val Loss: 0.3368 Acc: 0.8768 Pre: 0.9051 Recall: 0.8552 F1: 0.8794 Train AUC: 0.9744 Val AUC: 0.9384 Time: 13.55\n",
      "Epoch: 227 Train Loss: 0.2013 Val Loss: 0.3439 Acc: 0.8641 Pre: 0.8996 Recall: 0.8345 F1: 0.8658 Train AUC: 0.9757 Val AUC: 0.9347 Time: 14.30\n",
      "Epoch: 228 Train Loss: 0.1941 Val Loss: 0.3504 Acc: 0.8696 Pre: 0.9291 Recall: 0.8138 F1: 0.8676 Train AUC: 0.9779 Val AUC: 0.9360 Time: 14.93\n",
      "Epoch: 229 Train Loss: 0.2047 Val Loss: 0.3175 Acc: 0.8732 Pre: 0.9167 Recall: 0.8345 F1: 0.8736 Train AUC: 0.9769 Val AUC: 0.9424 Time: 15.20\n",
      "Epoch: 230 Train Loss: 0.1933 Val Loss: 0.3025 Acc: 0.8750 Pre: 0.9018 Recall: 0.8552 F1: 0.8779 Train AUC: 0.9790 Val AUC: 0.9466 Time: 13.68\n",
      "Epoch: 231 Train Loss: 0.2002 Val Loss: 0.3178 Acc: 0.8659 Pre: 0.8971 Recall: 0.8414 F1: 0.8683 Train AUC: 0.9770 Val AUC: 0.9452 Time: 13.17\n",
      "Epoch: 232 Train Loss: 0.2020 Val Loss: 0.3428 Acc: 0.8659 Pre: 0.9091 Recall: 0.8276 F1: 0.8664 Train AUC: 0.9750 Val AUC: 0.9409 Time: 12.80\n",
      "Epoch: 233 Train Loss: 0.2038 Val Loss: 0.3432 Acc: 0.8804 Pre: 0.9148 Recall: 0.8517 F1: 0.8821 Train AUC: 0.9745 Val AUC: 0.9374 Time: 13.54\n",
      "Epoch: 234 Train Loss: 0.1909 Val Loss: 0.3405 Acc: 0.8623 Pre: 0.8821 Recall: 0.8517 F1: 0.8667 Train AUC: 0.9783 Val AUC: 0.9352 Time: 13.85\n",
      "Epoch: 235 Train Loss: 0.1918 Val Loss: 0.3418 Acc: 0.8696 Pre: 0.9129 Recall: 0.8310 F1: 0.8700 Train AUC: 0.9791 Val AUC: 0.9385 Time: 14.69\n",
      "Epoch: 236 Train Loss: 0.1939 Val Loss: 0.3411 Acc: 0.8659 Pre: 0.9252 Recall: 0.8103 F1: 0.8640 Train AUC: 0.9782 Val AUC: 0.9428 Time: 15.15\n",
      "Epoch: 237 Train Loss: 0.1956 Val Loss: 0.3078 Acc: 0.8750 Pre: 0.8961 Recall: 0.8621 F1: 0.8787 Train AUC: 0.9791 Val AUC: 0.9466 Time: 13.65\n",
      "Epoch: 238 Train Loss: 0.1906 Val Loss: 0.3064 Acc: 0.8696 Pre: 0.8865 Recall: 0.8621 F1: 0.8741 Train AUC: 0.9789 Val AUC: 0.9469 Time: 12.75\n",
      "Epoch: 239 Train Loss: 0.2037 Val Loss: 0.3290 Acc: 0.8659 Pre: 0.9219 Recall: 0.8138 F1: 0.8645 Train AUC: 0.9768 Val AUC: 0.9447 Time: 12.62\n",
      "Epoch: 240 Train Loss: 0.1958 Val Loss: 0.3322 Acc: 0.8659 Pre: 0.9091 Recall: 0.8276 F1: 0.8664 Train AUC: 0.9775 Val AUC: 0.9389 Time: 12.96\n",
      "Epoch: 241 Train Loss: 0.1908 Val Loss: 0.3343 Acc: 0.8605 Pre: 0.8763 Recall: 0.8552 F1: 0.8656 Train AUC: 0.9782 Val AUC: 0.9347 Time: 13.53\n",
      "Epoch: 242 Train Loss: 0.1989 Val Loss: 0.3405 Acc: 0.8659 Pre: 0.9154 Recall: 0.8207 F1: 0.8655 Train AUC: 0.9786 Val AUC: 0.9398 Time: 14.10\n",
      "Epoch: 243 Train Loss: 0.1898 Val Loss: 0.3413 Acc: 0.8696 Pre: 0.9258 Recall: 0.8172 F1: 0.8681 Train AUC: 0.9791 Val AUC: 0.9434 Time: 14.78\n",
      "Epoch: 244 Train Loss: 0.1992 Val Loss: 0.3109 Acc: 0.8696 Pre: 0.8978 Recall: 0.8483 F1: 0.8723 Train AUC: 0.9762 Val AUC: 0.9471 Time: 14.78\n",
      "Epoch: 245 Train Loss: 0.1886 Val Loss: 0.2994 Acc: 0.8750 Pre: 0.8850 Recall: 0.8759 F1: 0.8804 Train AUC: 0.9789 Val AUC: 0.9486 Time: 13.57\n",
      "Epoch: 246 Train Loss: 0.2013 Val Loss: 0.3141 Acc: 0.8786 Pre: 0.9240 Recall: 0.8379 F1: 0.8788 Train AUC: 0.9783 Val AUC: 0.9473 Time: 13.39\n",
      "Epoch: 247 Train Loss: 0.1963 Val Loss: 0.3343 Acc: 0.8732 Pre: 0.9167 Recall: 0.8345 F1: 0.8736 Train AUC: 0.9783 Val AUC: 0.9421 Time: 13.17\n",
      "Epoch: 248 Train Loss: 0.1846 Val Loss: 0.3546 Acc: 0.8714 Pre: 0.8925 Recall: 0.8586 F1: 0.8752 Train AUC: 0.9807 Val AUC: 0.9347 Time: 13.89\n",
      "Epoch: 249 Train Loss: 0.1922 Val Loss: 0.3588 Acc: 0.8696 Pre: 0.8893 Recall: 0.8586 F1: 0.8737 Train AUC: 0.9777 Val AUC: 0.9325 Time: 14.37\n",
      "Epoch: 250 Train Loss: 0.2028 Val Loss: 0.3452 Acc: 0.8750 Pre: 0.9234 Recall: 0.8310 F1: 0.8748 Train AUC: 0.9754 Val AUC: 0.9365 Time: 14.27\n",
      "Epoch: 251 Train Loss: 0.1943 Val Loss: 0.3209 Acc: 0.8768 Pre: 0.9336 Recall: 0.8241 F1: 0.8755 Train AUC: 0.9768 Val AUC: 0.9436 Time: 14.24\n",
      "Epoch: 252 Train Loss: 0.1824 Val Loss: 0.3014 Acc: 0.8623 Pre: 0.8993 Recall: 0.8310 F1: 0.8638 Train AUC: 0.9821 Val AUC: 0.9463 Time: 13.98\n",
      "Epoch: 253 Train Loss: 0.2097 Val Loss: 0.3052 Acc: 0.8732 Pre: 0.9044 Recall: 0.8483 F1: 0.8754 Train AUC: 0.9779 Val AUC: 0.9477 Time: 13.00\n",
      "Epoch: 254 Train Loss: 0.1901 Val Loss: 0.3370 Acc: 0.8678 Pre: 0.8974 Recall: 0.8448 F1: 0.8703 Train AUC: 0.9794 Val AUC: 0.9427 Time: 12.92\n",
      "Epoch: 255 Train Loss: 0.1928 Val Loss: 0.3585 Acc: 0.8678 Pre: 0.8917 Recall: 0.8517 F1: 0.8713 Train AUC: 0.9772 Val AUC: 0.9390 Time: 13.46\n",
      "Epoch: 256 Train Loss: 0.1881 Val Loss: 0.3668 Acc: 0.8786 Pre: 0.9145 Recall: 0.8483 F1: 0.8801 Train AUC: 0.9788 Val AUC: 0.9382 Time: 14.14\n",
      "Epoch: 257 Train Loss: 0.1929 Val Loss: 0.3507 Acc: 0.8822 Pre: 0.9245 Recall: 0.8448 F1: 0.8829 Train AUC: 0.9769 Val AUC: 0.9390 Time: 14.66\n",
      "Epoch: 258 Train Loss: 0.1840 Val Loss: 0.3256 Acc: 0.8714 Pre: 0.8925 Recall: 0.8586 F1: 0.8752 Train AUC: 0.9792 Val AUC: 0.9399 Time: 14.99\n",
      "Epoch: 259 Train Loss: 0.1999 Val Loss: 0.3110 Acc: 0.8696 Pre: 0.8978 Recall: 0.8483 F1: 0.8723 Train AUC: 0.9779 Val AUC: 0.9457 Time: 13.47\n",
      "Epoch: 260 Train Loss: 0.1845 Val Loss: 0.3105 Acc: 0.8732 Pre: 0.9104 Recall: 0.8414 F1: 0.8746 Train AUC: 0.9807 Val AUC: 0.9482 Time: 12.89\n",
      "Epoch: 261 Train Loss: 0.1841 Val Loss: 0.3084 Acc: 0.8714 Pre: 0.9041 Recall: 0.8448 F1: 0.8734 Train AUC: 0.9797 Val AUC: 0.9472 Time: 13.15\n",
      "Epoch: 262 Train Loss: 0.1823 Val Loss: 0.3224 Acc: 0.8678 Pre: 0.9033 Recall: 0.8379 F1: 0.8694 Train AUC: 0.9812 Val AUC: 0.9442 Time: 13.71\n",
      "Epoch: 263 Train Loss: 0.1846 Val Loss: 0.3265 Acc: 0.8714 Pre: 0.8925 Recall: 0.8586 F1: 0.8752 Train AUC: 0.9798 Val AUC: 0.9413 Time: 14.32\n",
      "Epoch: 264 Train Loss: 0.1900 Val Loss: 0.3480 Acc: 0.8605 Pre: 0.9112 Recall: 0.8138 F1: 0.8597 Train AUC: 0.9797 Val AUC: 0.9381 Time: 15.02\n",
      "Epoch: 265 Train Loss: 0.1803 Val Loss: 0.3503 Acc: 0.8659 Pre: 0.9154 Recall: 0.8207 F1: 0.8655 Train AUC: 0.9811 Val AUC: 0.9375 Time: 14.21\n",
      "Epoch: 266 Train Loss: 0.1775 Val Loss: 0.3273 Acc: 0.8732 Pre: 0.8929 Recall: 0.8621 F1: 0.8772 Train AUC: 0.9814 Val AUC: 0.9412 Time: 13.01\n",
      "Epoch: 267 Train Loss: 0.1878 Val Loss: 0.3227 Acc: 0.8822 Pre: 0.9121 Recall: 0.8586 F1: 0.8845 Train AUC: 0.9799 Val AUC: 0.9467 Time: 12.91\n",
      "Epoch: 268 Train Loss: 0.1770 Val Loss: 0.3235 Acc: 0.8732 Pre: 0.9135 Recall: 0.8379 F1: 0.8741 Train AUC: 0.9815 Val AUC: 0.9491 Time: 13.36\n",
      "Epoch: 269 Train Loss: 0.1806 Val Loss: 0.3169 Acc: 0.8732 Pre: 0.8986 Recall: 0.8552 F1: 0.8763 Train AUC: 0.9801 Val AUC: 0.9490 Time: 14.02\n",
      "Epoch: 270 Train Loss: 0.1788 Val Loss: 0.3141 Acc: 0.8659 Pre: 0.8803 Recall: 0.8621 F1: 0.8711 Train AUC: 0.9808 Val AUC: 0.9456 Time: 14.56\n",
      "Epoch: 271 Train Loss: 0.1790 Val Loss: 0.3233 Acc: 0.8786 Pre: 0.9176 Recall: 0.8448 F1: 0.8797 Train AUC: 0.9816 Val AUC: 0.9431 Time: 14.97\n",
      "Epoch: 272 Train Loss: 0.1757 Val Loss: 0.3429 Acc: 0.8732 Pre: 0.9297 Recall: 0.8207 F1: 0.8718 Train AUC: 0.9818 Val AUC: 0.9411 Time: 13.83\n",
      "Epoch: 273 Train Loss: 0.1727 Val Loss: 0.3343 Acc: 0.8750 Pre: 0.9266 Recall: 0.8276 F1: 0.8743 Train AUC: 0.9838 Val AUC: 0.9413 Time: 13.33\n",
      "Epoch: 274 Train Loss: 0.1840 Val Loss: 0.3113 Acc: 0.8804 Pre: 0.8916 Recall: 0.8793 F1: 0.8854 Train AUC: 0.9821 Val AUC: 0.9426 Time: 14.04\n",
      "Epoch: 275 Train Loss: 0.1801 Val Loss: 0.3127 Acc: 0.8786 Pre: 0.8885 Recall: 0.8793 F1: 0.8839 Train AUC: 0.9830 Val AUC: 0.9444 Time: 14.58\n",
      "Epoch: 276 Train Loss: 0.1876 Val Loss: 0.3297 Acc: 0.8641 Pre: 0.9087 Recall: 0.8241 F1: 0.8644 Train AUC: 0.9829 Val AUC: 0.9467 Time: 14.66\n",
      "Epoch: 277 Train Loss: 0.1790 Val Loss: 0.3349 Acc: 0.8732 Pre: 0.9400 Recall: 0.8103 F1: 0.8704 Train AUC: 0.9809 Val AUC: 0.9492 Time: 13.26\n",
      "Epoch: 278 Train Loss: 0.1901 Val Loss: 0.3003 Acc: 0.8768 Pre: 0.8936 Recall: 0.8690 F1: 0.8811 Train AUC: 0.9808 Val AUC: 0.9474 Time: 12.61\n",
      "Epoch: 279 Train Loss: 0.1737 Val Loss: 0.3099 Acc: 0.8804 Pre: 0.8889 Recall: 0.8828 F1: 0.8858 Train AUC: 0.9838 Val AUC: 0.9435 Time: 12.92\n",
      "Epoch: 280 Train Loss: 0.1823 Val Loss: 0.3450 Acc: 0.8822 Pre: 0.9245 Recall: 0.8448 F1: 0.8829 Train AUC: 0.9825 Val AUC: 0.9414 Time: 13.41\n",
      "Epoch: 281 Train Loss: 0.1800 Val Loss: 0.3627 Acc: 0.8786 Pre: 0.9272 Recall: 0.8345 F1: 0.8784 Train AUC: 0.9804 Val AUC: 0.9392 Time: 14.22\n",
      "Epoch: 282 Train Loss: 0.1721 Val Loss: 0.3365 Acc: 0.8841 Pre: 0.9185 Recall: 0.8552 F1: 0.8857 Train AUC: 0.9819 Val AUC: 0.9413 Time: 14.90\n",
      "Epoch: 283 Train Loss: 0.1665 Val Loss: 0.3043 Acc: 0.8822 Pre: 0.8947 Recall: 0.8793 F1: 0.8870 Train AUC: 0.9838 Val AUC: 0.9456 Time: 15.36\n",
      "Epoch: 284 Train Loss: 0.1771 Val Loss: 0.2958 Acc: 0.8768 Pre: 0.9081 Recall: 0.8517 F1: 0.8790 Train AUC: 0.9841 Val AUC: 0.9502 Time: 13.99\n",
      "Epoch: 285 Train Loss: 0.1758 Val Loss: 0.3045 Acc: 0.8804 Pre: 0.9242 Recall: 0.8414 F1: 0.8809 Train AUC: 0.9831 Val AUC: 0.9510 Time: 12.87\n",
      "Epoch: 286 Train Loss: 0.1716 Val Loss: 0.3083 Acc: 0.8822 Pre: 0.9121 Recall: 0.8586 F1: 0.8845 Train AUC: 0.9830 Val AUC: 0.9501 Time: 12.12\n",
      "Epoch: 287 Train Loss: 0.1756 Val Loss: 0.3137 Acc: 0.8786 Pre: 0.8996 Recall: 0.8655 F1: 0.8822 Train AUC: 0.9815 Val AUC: 0.9468 Time: 12.67\n",
      "Epoch: 288 Train Loss: 0.1604 Val Loss: 0.3284 Acc: 0.8786 Pre: 0.9055 Recall: 0.8586 F1: 0.8814 Train AUC: 0.9855 Val AUC: 0.9429 Time: 13.08\n",
      "Epoch: 289 Train Loss: 0.1659 Val Loss: 0.3436 Acc: 0.8659 Pre: 0.9060 Recall: 0.8310 F1: 0.8669 Train AUC: 0.9838 Val AUC: 0.9401 Time: 13.53\n",
      "Epoch: 290 Train Loss: 0.1748 Val Loss: 0.3458 Acc: 0.8659 Pre: 0.9091 Recall: 0.8276 F1: 0.8664 Train AUC: 0.9822 Val AUC: 0.9408 Time: 14.22\n",
      "Epoch: 291 Train Loss: 0.1778 Val Loss: 0.3228 Acc: 0.8804 Pre: 0.9088 Recall: 0.8586 F1: 0.8830 Train AUC: 0.9809 Val AUC: 0.9439 Time: 14.81\n",
      "Epoch: 292 Train Loss: 0.1667 Val Loss: 0.3179 Acc: 0.8841 Pre: 0.9248 Recall: 0.8483 F1: 0.8849 Train AUC: 0.9840 Val AUC: 0.9475 Time: 15.84\n",
      "Epoch: 293 Train Loss: 0.1643 Val Loss: 0.3192 Acc: 0.8841 Pre: 0.9346 Recall: 0.8379 F1: 0.8836 Train AUC: 0.9844 Val AUC: 0.9490 Time: 14.57\n",
      "Epoch: 294 Train Loss: 0.1689 Val Loss: 0.3011 Acc: 0.8786 Pre: 0.8968 Recall: 0.8690 F1: 0.8827 Train AUC: 0.9845 Val AUC: 0.9492 Time: 13.18\n",
      "Epoch: 295 Train Loss: 0.1718 Val Loss: 0.3150 Acc: 0.8841 Pre: 0.9124 Recall: 0.8621 F1: 0.8865 Train AUC: 0.9839 Val AUC: 0.9464 Time: 12.32\n",
      "Epoch: 296 Train Loss: 0.1597 Val Loss: 0.3374 Acc: 0.8750 Pre: 0.9234 Recall: 0.8310 F1: 0.8748 Train AUC: 0.9851 Val AUC: 0.9441 Time: 12.78\n",
      "Epoch: 297 Train Loss: 0.1682 Val Loss: 0.3387 Acc: 0.8750 Pre: 0.9234 Recall: 0.8310 F1: 0.8748 Train AUC: 0.9836 Val AUC: 0.9426 Time: 13.28\n",
      "Epoch: 298 Train Loss: 0.1617 Val Loss: 0.3267 Acc: 0.8841 Pre: 0.9094 Recall: 0.8655 F1: 0.8869 Train AUC: 0.9851 Val AUC: 0.9430 Time: 13.64\n",
      "Epoch: 299 Train Loss: 0.1705 Val Loss: 0.3152 Acc: 0.8841 Pre: 0.9065 Recall: 0.8690 F1: 0.8873 Train AUC: 0.9831 Val AUC: 0.9461 Time: 14.39\n",
      "Epoch: 300 Train Loss: 0.1683 Val Loss: 0.3139 Acc: 0.8841 Pre: 0.9346 Recall: 0.8379 F1: 0.8836 Train AUC: 0.9842 Val AUC: 0.9507 Time: 14.74\n",
      "Epoch: 301 Train Loss: 0.1660 Val Loss: 0.2999 Acc: 0.8877 Pre: 0.9385 Recall: 0.8414 F1: 0.8873 Train AUC: 0.9837 Val AUC: 0.9522 Time: 14.66\n",
      "Epoch: 302 Train Loss: 0.1681 Val Loss: 0.2923 Acc: 0.8841 Pre: 0.9124 Recall: 0.8621 F1: 0.8865 Train AUC: 0.9846 Val AUC: 0.9507 Time: 13.93\n",
      "Epoch: 303 Train Loss: 0.1735 Val Loss: 0.3042 Acc: 0.8768 Pre: 0.9081 Recall: 0.8517 F1: 0.8790 Train AUC: 0.9833 Val AUC: 0.9476 Time: 12.96\n",
      "Epoch: 304 Train Loss: 0.1676 Val Loss: 0.3343 Acc: 0.8841 Pre: 0.9313 Recall: 0.8414 F1: 0.8841 Train AUC: 0.9847 Val AUC: 0.9446 Time: 12.81\n",
      "Epoch: 305 Train Loss: 0.1615 Val Loss: 0.3349 Acc: 0.8750 Pre: 0.9077 Recall: 0.8483 F1: 0.8770 Train AUC: 0.9851 Val AUC: 0.9439 Time: 13.39\n",
      "Epoch: 306 Train Loss: 0.1573 Val Loss: 0.3244 Acc: 0.8859 Pre: 0.9127 Recall: 0.8655 F1: 0.8885 Train AUC: 0.9854 Val AUC: 0.9454 Time: 14.04\n",
      "Epoch: 307 Train Loss: 0.1623 Val Loss: 0.3281 Acc: 0.8895 Pre: 0.9387 Recall: 0.8448 F1: 0.8893 Train AUC: 0.9847 Val AUC: 0.9481 Time: 14.61\n",
      "Epoch: 308 Train Loss: 0.1620 Val Loss: 0.3170 Acc: 0.8931 Pre: 0.9392 Recall: 0.8517 F1: 0.8933 Train AUC: 0.9849 Val AUC: 0.9495 Time: 15.20\n",
      "Epoch: 309 Train Loss: 0.1513 Val Loss: 0.2948 Acc: 0.8822 Pre: 0.9032 Recall: 0.8690 F1: 0.8858 Train AUC: 0.9872 Val AUC: 0.9502 Time: 14.33\n",
      "Epoch: 310 Train Loss: 0.1674 Val Loss: 0.3039 Acc: 0.8859 Pre: 0.9158 Recall: 0.8621 F1: 0.8881 Train AUC: 0.9853 Val AUC: 0.9509 Time: 13.38\n",
      "Epoch: 311 Train Loss: 0.1620 Val Loss: 0.3332 Acc: 0.8732 Pre: 0.9231 Recall: 0.8276 F1: 0.8727 Train AUC: 0.9850 Val AUC: 0.9480 Time: 12.71\n",
      "Epoch: 312 Train Loss: 0.1718 Val Loss: 0.3245 Acc: 0.8822 Pre: 0.9121 Recall: 0.8586 F1: 0.8845 Train AUC: 0.9824 Val AUC: 0.9460 Time: 12.83\n",
      "Epoch: 313 Train Loss: 0.1588 Val Loss: 0.3156 Acc: 0.8859 Pre: 0.9251 Recall: 0.8517 F1: 0.8869 Train AUC: 0.9855 Val AUC: 0.9467 Time: 13.01\n",
      "Epoch: 314 Train Loss: 0.1585 Val Loss: 0.3027 Acc: 0.8895 Pre: 0.9164 Recall: 0.8690 F1: 0.8920 Train AUC: 0.9851 Val AUC: 0.9480 Time: 13.59\n",
      "Epoch: 315 Train Loss: 0.1517 Val Loss: 0.3046 Acc: 0.8913 Pre: 0.9291 Recall: 0.8586 F1: 0.8925 Train AUC: 0.9876 Val AUC: 0.9497 Time: 14.17\n",
      "Epoch: 316 Train Loss: 0.1673 Val Loss: 0.3201 Acc: 0.8877 Pre: 0.9286 Recall: 0.8517 F1: 0.8885 Train AUC: 0.9845 Val AUC: 0.9494 Time: 14.78\n",
      "Epoch: 317 Train Loss: 0.1594 Val Loss: 0.3197 Acc: 0.8859 Pre: 0.9158 Recall: 0.8621 F1: 0.8881 Train AUC: 0.9852 Val AUC: 0.9482 Time: 15.76\n",
      "Epoch: 318 Train Loss: 0.1588 Val Loss: 0.3182 Acc: 0.8841 Pre: 0.9154 Recall: 0.8586 F1: 0.8861 Train AUC: 0.9851 Val AUC: 0.9470 Time: 14.61\n",
      "Epoch: 319 Train Loss: 0.1694 Val Loss: 0.3169 Acc: 0.8768 Pre: 0.9081 Recall: 0.8517 F1: 0.8790 Train AUC: 0.9828 Val AUC: 0.9456 Time: 13.14\n",
      "Epoch: 320 Train Loss: 0.1536 Val Loss: 0.3241 Acc: 0.8750 Pre: 0.9139 Recall: 0.8414 F1: 0.8761 Train AUC: 0.9864 Val AUC: 0.9460 Time: 12.26\n",
      "Epoch: 321 Train Loss: 0.1513 Val Loss: 0.3359 Acc: 0.8768 Pre: 0.9405 Recall: 0.8172 F1: 0.8745 Train AUC: 0.9867 Val AUC: 0.9473 Time: 12.13\n",
      "Epoch: 322 Train Loss: 0.1666 Val Loss: 0.3057 Acc: 0.8913 Pre: 0.9228 Recall: 0.8655 F1: 0.8932 Train AUC: 0.9854 Val AUC: 0.9494 Time: 12.58\n",
      "Epoch: 323 Train Loss: 0.1536 Val Loss: 0.3056 Acc: 0.8786 Pre: 0.8885 Recall: 0.8793 F1: 0.8839 Train AUC: 0.9868 Val AUC: 0.9494 Time: 13.13\n",
      "Epoch: 324 Train Loss: 0.1569 Val Loss: 0.3287 Acc: 0.8877 Pre: 0.9286 Recall: 0.8517 F1: 0.8885 Train AUC: 0.9872 Val AUC: 0.9499 Time: 13.63\n",
      "Epoch: 325 Train Loss: 0.1571 Val Loss: 0.3215 Acc: 0.8859 Pre: 0.9349 Recall: 0.8414 F1: 0.8857 Train AUC: 0.9857 Val AUC: 0.9505 Time: 14.18\n",
      "Epoch: 326 Train Loss: 0.1530 Val Loss: 0.2939 Acc: 0.8859 Pre: 0.9097 Recall: 0.8690 F1: 0.8889 Train AUC: 0.9873 Val AUC: 0.9503 Time: 14.86\n",
      "Epoch: 327 Train Loss: 0.1505 Val Loss: 0.2895 Acc: 0.8841 Pre: 0.9036 Recall: 0.8724 F1: 0.8877 Train AUC: 0.9876 Val AUC: 0.9508 Time: 15.88\n",
      "Epoch: 328 Train Loss: 0.1551 Val Loss: 0.3175 Acc: 0.8877 Pre: 0.9385 Recall: 0.8414 F1: 0.8873 Train AUC: 0.9882 Val AUC: 0.9521 Time: 15.10\n",
      "Epoch: 329 Train Loss: 0.1619 Val Loss: 0.3113 Acc: 0.8877 Pre: 0.9130 Recall: 0.8690 F1: 0.8905 Train AUC: 0.9861 Val AUC: 0.9506 Time: 13.56\n",
      "Epoch: 330 Train Loss: 0.1547 Val Loss: 0.3105 Acc: 0.8768 Pre: 0.8828 Recall: 0.8828 F1: 0.8828 Train AUC: 0.9856 Val AUC: 0.9477 Time: 12.72\n",
      "Epoch: 331 Train Loss: 0.1581 Val Loss: 0.3223 Acc: 0.8877 Pre: 0.9254 Recall: 0.8552 F1: 0.8889 Train AUC: 0.9869 Val AUC: 0.9484 Time: 12.32\n",
      "Epoch: 332 Train Loss: 0.1407 Val Loss: 0.3495 Acc: 0.8822 Pre: 0.9482 Recall: 0.8207 F1: 0.8799 Train AUC: 0.9886 Val AUC: 0.9498 Time: 12.68\n",
      "Epoch: 333 Train Loss: 0.1639 Val Loss: 0.3006 Acc: 0.8877 Pre: 0.9385 Recall: 0.8414 F1: 0.8873 Train AUC: 0.9871 Val AUC: 0.9529 Time: 13.25\n",
      "Epoch: 334 Train Loss: 0.1466 Val Loss: 0.2834 Acc: 0.8859 Pre: 0.8822 Recall: 0.9034 F1: 0.8927 Train AUC: 0.9880 Val AUC: 0.9534 Time: 13.71\n",
      "Epoch: 335 Train Loss: 0.1720 Val Loss: 0.3146 Acc: 0.8841 Pre: 0.9124 Recall: 0.8621 F1: 0.8865 Train AUC: 0.9871 Val AUC: 0.9500 Time: 14.38\n",
      "Epoch: 336 Train Loss: 0.1467 Val Loss: 0.3611 Acc: 0.8714 Pre: 0.9195 Recall: 0.8276 F1: 0.8711 Train AUC: 0.9874 Val AUC: 0.9466 Time: 15.02\n",
      "Epoch: 337 Train Loss: 0.1559 Val Loss: 0.3467 Acc: 0.8822 Pre: 0.9213 Recall: 0.8483 F1: 0.8833 Train AUC: 0.9857 Val AUC: 0.9449 Time: 16.84\n",
      "Epoch: 338 Train Loss: 0.1512 Val Loss: 0.3269 Acc: 0.8786 Pre: 0.8968 Recall: 0.8690 F1: 0.8827 Train AUC: 0.9869 Val AUC: 0.9437 Time: 14.83\n",
      "Epoch: 339 Train Loss: 0.1540 Val Loss: 0.3231 Acc: 0.8895 Pre: 0.9354 Recall: 0.8483 F1: 0.8897 Train AUC: 0.9873 Val AUC: 0.9488 Time: 13.26\n",
      "Epoch: 340 Train Loss: 0.1503 Val Loss: 0.3072 Acc: 0.8877 Pre: 0.9254 Recall: 0.8552 F1: 0.8889 Train AUC: 0.9876 Val AUC: 0.9514 Time: 12.39\n",
      "Epoch: 341 Train Loss: 0.1540 Val Loss: 0.3057 Acc: 0.8877 Pre: 0.9318 Recall: 0.8483 F1: 0.8881 Train AUC: 0.9865 Val AUC: 0.9513 Time: 12.42\n",
      "Epoch: 342 Train Loss: 0.1571 Val Loss: 0.3109 Acc: 0.8877 Pre: 0.9254 Recall: 0.8552 F1: 0.8889 Train AUC: 0.9857 Val AUC: 0.9498 Time: 12.76\n",
      "Epoch: 343 Train Loss: 0.1457 Val Loss: 0.3191 Acc: 0.8822 Pre: 0.9121 Recall: 0.8586 F1: 0.8845 Train AUC: 0.9882 Val AUC: 0.9479 Time: 13.23\n",
      "Epoch: 344 Train Loss: 0.1462 Val Loss: 0.3320 Acc: 0.8841 Pre: 0.9280 Recall: 0.8448 F1: 0.8845 Train AUC: 0.9885 Val AUC: 0.9483 Time: 13.96\n",
      "Epoch: 345 Train Loss: 0.1494 Val Loss: 0.3064 Acc: 0.8841 Pre: 0.9094 Recall: 0.8655 F1: 0.8869 Train AUC: 0.9876 Val AUC: 0.9502 Time: 14.47\n",
      "Epoch: 346 Train Loss: 0.1392 Val Loss: 0.2931 Acc: 0.8949 Pre: 0.9085 Recall: 0.8897 F1: 0.8990 Train AUC: 0.9896 Val AUC: 0.9525 Time: 15.28\n",
      "Epoch: 347 Train Loss: 0.1459 Val Loss: 0.3079 Acc: 0.8895 Pre: 0.9257 Recall: 0.8586 F1: 0.8909 Train AUC: 0.9892 Val AUC: 0.9532 Time: 14.63\n",
      "Epoch: 348 Train Loss: 0.1532 Val Loss: 0.3053 Acc: 0.8913 Pre: 0.9457 Recall: 0.8414 F1: 0.8905 Train AUC: 0.9860 Val AUC: 0.9551 Time: 13.69\n",
      "Epoch: 349 Train Loss: 0.1436 Val Loss: 0.2865 Acc: 0.8895 Pre: 0.9194 Recall: 0.8655 F1: 0.8917 Train AUC: 0.9884 Val AUC: 0.9547 Time: 13.41\n",
      "Epoch: 350 Train Loss: 0.1437 Val Loss: 0.2877 Acc: 0.8949 Pre: 0.9085 Recall: 0.8897 F1: 0.8990 Train AUC: 0.9890 Val AUC: 0.9531 Time: 13.01\n",
      "Epoch: 351 Train Loss: 0.1464 Val Loss: 0.3121 Acc: 0.8841 Pre: 0.9124 Recall: 0.8621 F1: 0.8865 Train AUC: 0.9891 Val AUC: 0.9504 Time: 13.64\n",
      "Epoch: 352 Train Loss: 0.1409 Val Loss: 0.3308 Acc: 0.8877 Pre: 0.9161 Recall: 0.8655 F1: 0.8901 Train AUC: 0.9886 Val AUC: 0.9482 Time: 14.17\n",
      "Epoch: 353 Train Loss: 0.1488 Val Loss: 0.3346 Acc: 0.8877 Pre: 0.9191 Recall: 0.8621 F1: 0.8897 Train AUC: 0.9867 Val AUC: 0.9474 Time: 14.90\n",
      "Epoch: 354 Train Loss: 0.1498 Val Loss: 0.3091 Acc: 0.8895 Pre: 0.9164 Recall: 0.8690 F1: 0.8920 Train AUC: 0.9867 Val AUC: 0.9498 Time: 14.47\n",
      "Epoch: 355 Train Loss: 0.1407 Val Loss: 0.2901 Acc: 0.8895 Pre: 0.9288 Recall: 0.8552 F1: 0.8905 Train AUC: 0.9889 Val AUC: 0.9535 Time: 13.66\n",
      "Epoch: 356 Train Loss: 0.1389 Val Loss: 0.2874 Acc: 0.8931 Pre: 0.9358 Recall: 0.8552 F1: 0.8937 Train AUC: 0.9899 Val AUC: 0.9562 Time: 13.11\n",
      "Epoch: 357 Train Loss: 0.1386 Val Loss: 0.2960 Acc: 0.8913 Pre: 0.9389 Recall: 0.8483 F1: 0.8913 Train AUC: 0.9901 Val AUC: 0.9568 Time: 13.27\n",
      "Epoch: 358 Train Loss: 0.1431 Val Loss: 0.2912 Acc: 0.8895 Pre: 0.9134 Recall: 0.8724 F1: 0.8924 Train AUC: 0.9901 Val AUC: 0.9549 Time: 13.55\n",
      "Epoch: 359 Train Loss: 0.1440 Val Loss: 0.3053 Acc: 0.8859 Pre: 0.8982 Recall: 0.8828 F1: 0.8904 Train AUC: 0.9883 Val AUC: 0.9514 Time: 13.80\n",
      "Epoch: 360 Train Loss: 0.1448 Val Loss: 0.3301 Acc: 0.8895 Pre: 0.9225 Recall: 0.8621 F1: 0.8913 Train AUC: 0.9888 Val AUC: 0.9481 Time: 14.50\n",
      "Epoch: 361 Train Loss: 0.1409 Val Loss: 0.3594 Acc: 0.8841 Pre: 0.9313 Recall: 0.8414 F1: 0.8841 Train AUC: 0.9883 Val AUC: 0.9463 Time: 14.99\n",
      "Epoch: 362 Train Loss: 0.1501 Val Loss: 0.3216 Acc: 0.8841 Pre: 0.9185 Recall: 0.8552 F1: 0.8857 Train AUC: 0.9869 Val AUC: 0.9480 Time: 14.65\n",
      "Epoch: 363 Train Loss: 0.1456 Val Loss: 0.2879 Acc: 0.8841 Pre: 0.8818 Recall: 0.9000 F1: 0.8908 Train AUC: 0.9887 Val AUC: 0.9521 Time: 13.75\n",
      "Epoch: 364 Train Loss: 0.1649 Val Loss: 0.3018 Acc: 0.8949 Pre: 0.9394 Recall: 0.8552 F1: 0.8953 Train AUC: 0.9878 Val AUC: 0.9553 Time: 12.96\n",
      "Epoch: 365 Train Loss: 0.1390 Val Loss: 0.3447 Acc: 0.8822 Pre: 0.9412 Recall: 0.8276 F1: 0.8807 Train AUC: 0.9891 Val AUC: 0.9546 Time: 12.46\n",
      "Epoch: 366 Train Loss: 0.1544 Val Loss: 0.3024 Acc: 0.8895 Pre: 0.9104 Recall: 0.8759 F1: 0.8928 Train AUC: 0.9874 Val AUC: 0.9540 Time: 12.91\n",
      "Epoch: 367 Train Loss: 0.1487 Val Loss: 0.2876 Acc: 0.8877 Pre: 0.8851 Recall: 0.9034 F1: 0.8942 Train AUC: 0.9870 Val AUC: 0.9534 Time: 13.47\n",
      "Epoch: 368 Train Loss: 0.1598 Val Loss: 0.3245 Acc: 0.8841 Pre: 0.9593 Recall: 0.8138 F1: 0.8806 Train AUC: 0.9900 Val AUC: 0.9553 Time: 14.00\n",
      "Epoch: 369 Train Loss: 0.1531 Val Loss: 0.3122 Acc: 0.8859 Pre: 0.9558 Recall: 0.8207 F1: 0.8831 Train AUC: 0.9896 Val AUC: 0.9552 Time: 14.64\n",
      "Epoch: 370 Train Loss: 0.1442 Val Loss: 0.2714 Acc: 0.8949 Pre: 0.8919 Recall: 0.9103 F1: 0.9010 Train AUC: 0.9905 Val AUC: 0.9558 Time: 15.30\n",
      "Epoch: 371 Train Loss: 0.1439 Val Loss: 0.2851 Acc: 0.8877 Pre: 0.8931 Recall: 0.8931 F1: 0.8931 Train AUC: 0.9922 Val AUC: 0.9531 Time: 14.27\n",
      "Epoch: 372 Train Loss: 0.1509 Val Loss: 0.3186 Acc: 0.8786 Pre: 0.9145 Recall: 0.8483 F1: 0.8801 Train AUC: 0.9889 Val AUC: 0.9510 Time: 12.96\n",
      "Epoch: 373 Train Loss: 0.1448 Val Loss: 0.3205 Acc: 0.8877 Pre: 0.9419 Recall: 0.8379 F1: 0.8869 Train AUC: 0.9877 Val AUC: 0.9541 Time: 13.11\n",
      "Epoch: 374 Train Loss: 0.1449 Val Loss: 0.2826 Acc: 0.8986 Pre: 0.9301 Recall: 0.8724 F1: 0.9004 Train AUC: 0.9883 Val AUC: 0.9571 Time: 13.80\n",
      "Epoch: 375 Train Loss: 0.1310 Val Loss: 0.2809 Acc: 0.9058 Pre: 0.9312 Recall: 0.8862 F1: 0.9081 Train AUC: 0.9910 Val AUC: 0.9567 Time: 14.30\n",
      "Epoch: 376 Train Loss: 0.1519 Val Loss: 0.3032 Acc: 0.8967 Pre: 0.9363 Recall: 0.8621 F1: 0.8977 Train AUC: 0.9878 Val AUC: 0.9554 Time: 14.19\n",
      "Epoch: 377 Train Loss: 0.1287 Val Loss: 0.3376 Acc: 0.8949 Pre: 0.9394 Recall: 0.8552 F1: 0.8953 Train AUC: 0.9911 Val AUC: 0.9513 Time: 13.60\n",
      "Epoch: 378 Train Loss: 0.1342 Val Loss: 0.3276 Acc: 0.8895 Pre: 0.9194 Recall: 0.8655 F1: 0.8917 Train AUC: 0.9895 Val AUC: 0.9495 Time: 13.41\n",
      "Epoch: 379 Train Loss: 0.1423 Val Loss: 0.3069 Acc: 0.8859 Pre: 0.9068 Recall: 0.8724 F1: 0.8893 Train AUC: 0.9881 Val AUC: 0.9504 Time: 14.03\n",
      "Epoch: 380 Train Loss: 0.1382 Val Loss: 0.2991 Acc: 0.8986 Pre: 0.9301 Recall: 0.8724 F1: 0.9004 Train AUC: 0.9898 Val AUC: 0.9516 Time: 13.95\n",
      "Epoch: 381 Train Loss: 0.1333 Val Loss: 0.3089 Acc: 0.8841 Pre: 0.9313 Recall: 0.8414 F1: 0.8841 Train AUC: 0.9907 Val AUC: 0.9542 Time: 14.32\n",
      "Epoch: 382 Train Loss: 0.1422 Val Loss: 0.2974 Acc: 0.8859 Pre: 0.9316 Recall: 0.8448 F1: 0.8861 Train AUC: 0.9893 Val AUC: 0.9566 Time: 13.29\n",
      "Epoch: 383 Train Loss: 0.1326 Val Loss: 0.2931 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9907 Val AUC: 0.9573 Time: 12.99\n",
      "Epoch: 384 Train Loss: 0.1291 Val Loss: 0.3145 Acc: 0.8931 Pre: 0.9231 Recall: 0.8690 F1: 0.8952 Train AUC: 0.9913 Val AUC: 0.9542 Time: 12.98\n",
      "Epoch: 385 Train Loss: 0.1407 Val Loss: 0.3313 Acc: 0.8913 Pre: 0.9259 Recall: 0.8621 F1: 0.8929 Train AUC: 0.9880 Val AUC: 0.9513 Time: 13.19\n",
      "Epoch: 386 Train Loss: 0.1446 Val Loss: 0.3120 Acc: 0.8895 Pre: 0.9134 Recall: 0.8724 F1: 0.8924 Train AUC: 0.9871 Val AUC: 0.9527 Time: 13.70\n",
      "Epoch: 387 Train Loss: 0.1343 Val Loss: 0.3019 Acc: 0.8931 Pre: 0.9200 Recall: 0.8724 F1: 0.8956 Train AUC: 0.9893 Val AUC: 0.9546 Time: 14.24\n",
      "Epoch: 388 Train Loss: 0.1265 Val Loss: 0.3145 Acc: 0.8895 Pre: 0.9490 Recall: 0.8345 F1: 0.8881 Train AUC: 0.9908 Val AUC: 0.9547 Time: 15.03\n",
      "Epoch: 389 Train Loss: 0.1434 Val Loss: 0.2975 Acc: 0.8877 Pre: 0.9385 Recall: 0.8414 F1: 0.8873 Train AUC: 0.9895 Val AUC: 0.9564 Time: 15.40\n",
      "Epoch: 390 Train Loss: 0.1405 Val Loss: 0.2753 Acc: 0.8949 Pre: 0.9113 Recall: 0.8862 F1: 0.8986 Train AUC: 0.9896 Val AUC: 0.9588 Time: 13.43\n",
      "Epoch: 391 Train Loss: 0.1420 Val Loss: 0.2934 Acc: 0.8804 Pre: 0.8916 Recall: 0.8793 F1: 0.8854 Train AUC: 0.9887 Val AUC: 0.9566 Time: 12.51\n",
      "Epoch: 392 Train Loss: 0.1387 Val Loss: 0.3254 Acc: 0.8913 Pre: 0.9259 Recall: 0.8621 F1: 0.8929 Train AUC: 0.9896 Val AUC: 0.9533 Time: 12.50\n",
      "Epoch: 393 Train Loss: 0.1278 Val Loss: 0.3507 Acc: 0.8859 Pre: 0.9316 Recall: 0.8448 F1: 0.8861 Train AUC: 0.9904 Val AUC: 0.9503 Time: 12.76\n",
      "Epoch: 394 Train Loss: 0.1361 Val Loss: 0.3303 Acc: 0.8859 Pre: 0.9251 Recall: 0.8517 F1: 0.8869 Train AUC: 0.9896 Val AUC: 0.9498 Time: 13.23\n",
      "Epoch: 395 Train Loss: 0.1351 Val Loss: 0.2978 Acc: 0.8986 Pre: 0.9270 Recall: 0.8759 F1: 0.9007 Train AUC: 0.9897 Val AUC: 0.9525 Time: 13.71\n",
      "Epoch: 396 Train Loss: 0.1313 Val Loss: 0.2828 Acc: 0.8949 Pre: 0.9203 Recall: 0.8759 F1: 0.8975 Train AUC: 0.9909 Val AUC: 0.9552 Time: 14.47\n",
      "Epoch: 397 Train Loss: 0.1357 Val Loss: 0.3031 Acc: 0.8859 Pre: 0.9283 Recall: 0.8483 F1: 0.8865 Train AUC: 0.9907 Val AUC: 0.9557 Time: 15.19\n",
      "Epoch: 398 Train Loss: 0.1338 Val Loss: 0.3167 Acc: 0.8841 Pre: 0.9313 Recall: 0.8414 F1: 0.8841 Train AUC: 0.9894 Val AUC: 0.9562 Time: 16.42\n",
      "Epoch: 399 Train Loss: 0.1388 Val Loss: 0.2938 Acc: 0.8986 Pre: 0.9398 Recall: 0.8621 F1: 0.8993 Train AUC: 0.9889 Val AUC: 0.9563 Time: 14.59\n",
      "Epoch: 400 Train Loss: 0.1247 Val Loss: 0.2884 Acc: 0.8931 Pre: 0.9053 Recall: 0.8897 F1: 0.8974 Train AUC: 0.9915 Val AUC: 0.9551 Time: 13.26\n",
      "Epoch: 401 Train Loss: 0.1404 Val Loss: 0.3035 Acc: 0.8986 Pre: 0.9432 Recall: 0.8586 F1: 0.8989 Train AUC: 0.9896 Val AUC: 0.9557 Time: 12.33\n",
      "Epoch: 402 Train Loss: 0.1242 Val Loss: 0.3120 Acc: 0.9004 Pre: 0.9537 Recall: 0.8517 F1: 0.8998 Train AUC: 0.9915 Val AUC: 0.9560 Time: 12.56\n",
      "Epoch: 403 Train Loss: 0.1320 Val Loss: 0.2904 Acc: 0.8967 Pre: 0.9396 Recall: 0.8586 F1: 0.8973 Train AUC: 0.9906 Val AUC: 0.9574 Time: 12.92\n",
      "Epoch: 404 Train Loss: 0.1230 Val Loss: 0.2795 Acc: 0.8967 Pre: 0.9236 Recall: 0.8759 F1: 0.8991 Train AUC: 0.9913 Val AUC: 0.9578 Time: 13.75\n",
      "Epoch: 405 Train Loss: 0.1337 Val Loss: 0.2977 Acc: 0.8986 Pre: 0.9432 Recall: 0.8586 F1: 0.8989 Train AUC: 0.9903 Val AUC: 0.9562 Time: 14.32\n",
      "Epoch: 406 Train Loss: 0.1349 Val Loss: 0.2960 Acc: 0.8986 Pre: 0.9432 Recall: 0.8586 F1: 0.8989 Train AUC: 0.9897 Val AUC: 0.9560 Time: 14.47\n",
      "Epoch: 407 Train Loss: 0.1341 Val Loss: 0.2969 Acc: 0.9022 Pre: 0.9436 Recall: 0.8655 F1: 0.9029 Train AUC: 0.9893 Val AUC: 0.9547 Time: 14.55\n",
      "Epoch: 408 Train Loss: 0.1303 Val Loss: 0.2978 Acc: 0.8967 Pre: 0.9299 Recall: 0.8690 F1: 0.8984 Train AUC: 0.9911 Val AUC: 0.9553 Time: 15.03\n",
      "Epoch: 409 Train Loss: 0.1183 Val Loss: 0.3011 Acc: 0.8931 Pre: 0.9294 Recall: 0.8621 F1: 0.8945 Train AUC: 0.9928 Val AUC: 0.9559 Time: 14.09\n",
      "Epoch: 410 Train Loss: 0.1241 Val Loss: 0.2989 Acc: 0.9022 Pre: 0.9436 Recall: 0.8655 F1: 0.9029 Train AUC: 0.9911 Val AUC: 0.9573 Time: 13.10\n",
      "Epoch: 411 Train Loss: 0.1310 Val Loss: 0.2833 Acc: 0.9004 Pre: 0.9401 Recall: 0.8655 F1: 0.9013 Train AUC: 0.9901 Val AUC: 0.9593 Time: 12.53\n",
      "Epoch: 412 Train Loss: 0.1140 Val Loss: 0.2753 Acc: 0.9004 Pre: 0.9434 Recall: 0.8621 F1: 0.9009 Train AUC: 0.9931 Val AUC: 0.9606 Time: 12.48\n",
      "Epoch: 413 Train Loss: 0.1327 Val Loss: 0.2675 Acc: 0.9004 Pre: 0.9304 Recall: 0.8759 F1: 0.9023 Train AUC: 0.9904 Val AUC: 0.9604 Time: 13.04\n",
      "Epoch: 414 Train Loss: 0.1252 Val Loss: 0.2681 Acc: 0.9004 Pre: 0.9242 Recall: 0.8828 F1: 0.9030 Train AUC: 0.9911 Val AUC: 0.9590 Time: 13.58\n",
      "Epoch: 415 Train Loss: 0.1257 Val Loss: 0.2925 Acc: 0.9004 Pre: 0.9401 Recall: 0.8655 F1: 0.9013 Train AUC: 0.9929 Val AUC: 0.9557 Time: 13.99\n",
      "Epoch: 416 Train Loss: 0.1194 Val Loss: 0.3185 Acc: 0.8949 Pre: 0.9531 Recall: 0.8414 F1: 0.8938 Train AUC: 0.9922 Val AUC: 0.9540 Time: 14.91\n",
      "Epoch: 417 Train Loss: 0.1303 Val Loss: 0.2838 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9907 Val AUC: 0.9570 Time: 15.42\n",
      "Epoch: 418 Train Loss: 0.1152 Val Loss: 0.2639 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9933 Val AUC: 0.9598 Time: 14.02\n",
      "Epoch: 419 Train Loss: 0.1228 Val Loss: 0.2793 Acc: 0.9022 Pre: 0.9436 Recall: 0.8655 F1: 0.9029 Train AUC: 0.9937 Val AUC: 0.9609 Time: 13.24\n",
      "Epoch: 420 Train Loss: 0.1205 Val Loss: 0.3039 Acc: 0.8949 Pre: 0.9462 Recall: 0.8483 F1: 0.8945 Train AUC: 0.9922 Val AUC: 0.9589 Time: 13.17\n",
      "Epoch: 421 Train Loss: 0.1282 Val Loss: 0.2911 Acc: 0.8913 Pre: 0.9228 Recall: 0.8655 F1: 0.8932 Train AUC: 0.9907 Val AUC: 0.9573 Time: 13.75\n",
      "Epoch: 422 Train Loss: 0.1310 Val Loss: 0.2728 Acc: 0.9076 Pre: 0.9164 Recall: 0.9069 F1: 0.9116 Train AUC: 0.9899 Val AUC: 0.9580 Time: 14.44\n",
      "Epoch: 423 Train Loss: 0.1272 Val Loss: 0.2891 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9935 Val AUC: 0.9569 Time: 15.15\n",
      "Epoch: 424 Train Loss: 0.1257 Val Loss: 0.3205 Acc: 0.9058 Pre: 0.9648 Recall: 0.8517 F1: 0.9048 Train AUC: 0.9919 Val AUC: 0.9553 Time: 13.99\n",
      "Epoch: 425 Train Loss: 0.1187 Val Loss: 0.3102 Acc: 0.9094 Pre: 0.9580 Recall: 0.8655 F1: 0.9094 Train AUC: 0.9929 Val AUC: 0.9550 Time: 13.26\n",
      "Epoch: 426 Train Loss: 0.1375 Val Loss: 0.2870 Acc: 0.9004 Pre: 0.9242 Recall: 0.8828 F1: 0.9030 Train AUC: 0.9917 Val AUC: 0.9546 Time: 13.00\n",
      "Epoch: 427 Train Loss: 0.1280 Val Loss: 0.2879 Acc: 0.9004 Pre: 0.9181 Recall: 0.8897 F1: 0.9037 Train AUC: 0.9918 Val AUC: 0.9557 Time: 13.55\n",
      "Epoch: 428 Train Loss: 0.1261 Val Loss: 0.3117 Acc: 0.8967 Pre: 0.9396 Recall: 0.8586 F1: 0.8973 Train AUC: 0.9923 Val AUC: 0.9554 Time: 14.05\n",
      "Epoch: 429 Train Loss: 0.1246 Val Loss: 0.3155 Acc: 0.8931 Pre: 0.9425 Recall: 0.8483 F1: 0.8929 Train AUC: 0.9908 Val AUC: 0.9579 Time: 14.50\n",
      "Epoch: 430 Train Loss: 0.1191 Val Loss: 0.2743 Acc: 0.9022 Pre: 0.9370 Recall: 0.8724 F1: 0.9036 Train AUC: 0.9929 Val AUC: 0.9601 Time: 13.26\n",
      "Epoch: 431 Train Loss: 0.1168 Val Loss: 0.2715 Acc: 0.8986 Pre: 0.9239 Recall: 0.8793 F1: 0.9011 Train AUC: 0.9940 Val AUC: 0.9591 Time: 13.39\n",
      "Epoch: 432 Train Loss: 0.1136 Val Loss: 0.3054 Acc: 0.9022 Pre: 0.9436 Recall: 0.8655 F1: 0.9029 Train AUC: 0.9944 Val AUC: 0.9558 Time: 13.89\n",
      "Epoch: 433 Train Loss: 0.1201 Val Loss: 0.3260 Acc: 0.9004 Pre: 0.9537 Recall: 0.8517 F1: 0.8998 Train AUC: 0.9919 Val AUC: 0.9543 Time: 14.58\n",
      "Epoch: 434 Train Loss: 0.1193 Val Loss: 0.2992 Acc: 0.9058 Pre: 0.9407 Recall: 0.8759 F1: 0.9071 Train AUC: 0.9925 Val AUC: 0.9561 Time: 14.25\n",
      "Epoch: 435 Train Loss: 0.1235 Val Loss: 0.2776 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9911 Val AUC: 0.9587 Time: 13.37\n",
      "Epoch: 436 Train Loss: 0.1171 Val Loss: 0.2752 Acc: 0.9004 Pre: 0.9368 Recall: 0.8690 F1: 0.9016 Train AUC: 0.9925 Val AUC: 0.9612 Time: 13.71\n",
      "Epoch: 437 Train Loss: 0.1103 Val Loss: 0.2893 Acc: 0.8986 Pre: 0.9466 Recall: 0.8552 F1: 0.8986 Train AUC: 0.9935 Val AUC: 0.9618 Time: 13.54\n",
      "Epoch: 438 Train Loss: 0.1243 Val Loss: 0.2857 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9919 Val AUC: 0.9585 Time: 13.48\n",
      "Epoch: 439 Train Loss: 0.1173 Val Loss: 0.2985 Acc: 0.9040 Pre: 0.9187 Recall: 0.8966 F1: 0.9075 Train AUC: 0.9928 Val AUC: 0.9541 Time: 14.16\n",
      "Epoch: 440 Train Loss: 0.1248 Val Loss: 0.3087 Acc: 0.8967 Pre: 0.9146 Recall: 0.8862 F1: 0.9002 Train AUC: 0.9913 Val AUC: 0.9519 Time: 14.92\n",
      "Epoch: 441 Train Loss: 0.1230 Val Loss: 0.3160 Acc: 0.9076 Pre: 0.9509 Recall: 0.8690 F1: 0.9081 Train AUC: 0.9920 Val AUC: 0.9540 Time: 13.68\n",
      "Epoch: 442 Train Loss: 0.1172 Val Loss: 0.3134 Acc: 0.9004 Pre: 0.9537 Recall: 0.8517 F1: 0.8998 Train AUC: 0.9924 Val AUC: 0.9574 Time: 13.14\n",
      "Epoch: 443 Train Loss: 0.1229 Val Loss: 0.2750 Acc: 0.9004 Pre: 0.9336 Recall: 0.8724 F1: 0.9020 Train AUC: 0.9924 Val AUC: 0.9606 Time: 13.15\n",
      "Epoch: 444 Train Loss: 0.1142 Val Loss: 0.2776 Acc: 0.9058 Pre: 0.9407 Recall: 0.8759 F1: 0.9071 Train AUC: 0.9936 Val AUC: 0.9608 Time: 13.39\n",
      "Epoch: 445 Train Loss: 0.1118 Val Loss: 0.3056 Acc: 0.9004 Pre: 0.9434 Recall: 0.8621 F1: 0.9009 Train AUC: 0.9937 Val AUC: 0.9589 Time: 13.84\n",
      "Epoch: 446 Train Loss: 0.1115 Val Loss: 0.3136 Acc: 0.8986 Pre: 0.9432 Recall: 0.8586 F1: 0.8989 Train AUC: 0.9927 Val AUC: 0.9579 Time: 14.51\n",
      "Epoch: 447 Train Loss: 0.1184 Val Loss: 0.2979 Acc: 0.9058 Pre: 0.9343 Recall: 0.8828 F1: 0.9078 Train AUC: 0.9923 Val AUC: 0.9560 Time: 15.06\n",
      "Epoch: 448 Train Loss: 0.1179 Val Loss: 0.3029 Acc: 0.8986 Pre: 0.9366 Recall: 0.8655 F1: 0.8996 Train AUC: 0.9930 Val AUC: 0.9555 Time: 13.77\n",
      "Epoch: 449 Train Loss: 0.1114 Val Loss: 0.3112 Acc: 0.9094 Pre: 0.9580 Recall: 0.8655 F1: 0.9094 Train AUC: 0.9935 Val AUC: 0.9561 Time: 12.79\n",
      "Epoch: 450 Train Loss: 0.1084 Val Loss: 0.3130 Acc: 0.9112 Pre: 0.9725 Recall: 0.8552 F1: 0.9101 Train AUC: 0.9939 Val AUC: 0.9584 Time: 12.46\n",
      "Epoch: 451 Train Loss: 0.1139 Val Loss: 0.2786 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9933 Val AUC: 0.9605 Time: 12.91\n",
      "Epoch: 452 Train Loss: 0.1070 Val Loss: 0.2639 Acc: 0.9058 Pre: 0.9220 Recall: 0.8966 F1: 0.9091 Train AUC: 0.9946 Val AUC: 0.9609 Time: 13.50\n",
      "Epoch: 453 Train Loss: 0.1202 Val Loss: 0.2980 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9936 Val AUC: 0.9588 Time: 14.17\n",
      "Epoch: 454 Train Loss: 0.1134 Val Loss: 0.3257 Acc: 0.8986 Pre: 0.9432 Recall: 0.8586 F1: 0.8989 Train AUC: 0.9925 Val AUC: 0.9565 Time: 14.65\n",
      "Epoch: 455 Train Loss: 0.1183 Val Loss: 0.3052 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9919 Val AUC: 0.9563 Time: 15.42\n",
      "Epoch: 456 Train Loss: 0.1171 Val Loss: 0.2811 Acc: 0.9040 Pre: 0.9341 Recall: 0.8793 F1: 0.9059 Train AUC: 0.9921 Val AUC: 0.9588 Time: 14.06\n",
      "Epoch: 457 Train Loss: 0.1201 Val Loss: 0.2923 Acc: 0.9058 Pre: 0.9474 Recall: 0.8690 F1: 0.9065 Train AUC: 0.9931 Val AUC: 0.9592 Time: 13.04\n",
      "Epoch: 458 Train Loss: 0.1177 Val Loss: 0.3144 Acc: 0.8986 Pre: 0.9398 Recall: 0.8621 F1: 0.8993 Train AUC: 0.9932 Val AUC: 0.9552 Time: 12.62\n",
      "Epoch: 459 Train Loss: 0.1285 Val Loss: 0.3245 Acc: 0.9004 Pre: 0.9273 Recall: 0.8793 F1: 0.9027 Train AUC: 0.9904 Val AUC: 0.9516 Time: 13.17\n",
      "Epoch: 460 Train Loss: 0.1274 Val Loss: 0.3139 Acc: 0.8986 Pre: 0.9239 Recall: 0.8793 F1: 0.9011 Train AUC: 0.9907 Val AUC: 0.9510 Time: 13.63\n",
      "Epoch: 461 Train Loss: 0.1193 Val Loss: 0.3192 Acc: 0.9112 Pre: 0.9582 Recall: 0.8690 F1: 0.9114 Train AUC: 0.9927 Val AUC: 0.9542 Time: 14.30\n",
      "Epoch: 462 Train Loss: 0.1138 Val Loss: 0.3151 Acc: 0.9094 Pre: 0.9651 Recall: 0.8586 F1: 0.9088 Train AUC: 0.9939 Val AUC: 0.9596 Time: 15.13\n",
      "Epoch: 463 Train Loss: 0.1216 Val Loss: 0.2677 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9925 Val AUC: 0.9630 Time: 14.46\n",
      "Epoch: 464 Train Loss: 0.1211 Val Loss: 0.2700 Acc: 0.9040 Pre: 0.9278 Recall: 0.8862 F1: 0.9065 Train AUC: 0.9922 Val AUC: 0.9634 Time: 13.21\n",
      "Epoch: 465 Train Loss: 0.1241 Val Loss: 0.2875 Acc: 0.8986 Pre: 0.9432 Recall: 0.8586 F1: 0.8989 Train AUC: 0.9913 Val AUC: 0.9606 Time: 12.85\n",
      "Epoch: 466 Train Loss: 0.1232 Val Loss: 0.2976 Acc: 0.9004 Pre: 0.9368 Recall: 0.8690 F1: 0.9016 Train AUC: 0.9917 Val AUC: 0.9561 Time: 13.41\n",
      "Epoch: 467 Train Loss: 0.1089 Val Loss: 0.3141 Acc: 0.8949 Pre: 0.9361 Recall: 0.8586 F1: 0.8957 Train AUC: 0.9940 Val AUC: 0.9512 Time: 14.02\n",
      "Epoch: 468 Train Loss: 0.1142 Val Loss: 0.3186 Acc: 0.9022 Pre: 0.9504 Recall: 0.8586 F1: 0.9022 Train AUC: 0.9935 Val AUC: 0.9521 Time: 15.07\n",
      "Epoch: 469 Train Loss: 0.1161 Val Loss: 0.2961 Acc: 0.9058 Pre: 0.9440 Recall: 0.8724 F1: 0.9068 Train AUC: 0.9927 Val AUC: 0.9571 Time: 14.90\n",
      "Epoch: 470 Train Loss: 0.1044 Val Loss: 0.2798 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9947 Val AUC: 0.9615 Time: 13.54\n",
      "Epoch: 471 Train Loss: 0.1086 Val Loss: 0.2753 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9935 Val AUC: 0.9633 Time: 13.02\n",
      "Epoch: 472 Train Loss: 0.1138 Val Loss: 0.2719 Acc: 0.9076 Pre: 0.9377 Recall: 0.8828 F1: 0.9094 Train AUC: 0.9926 Val AUC: 0.9630 Time: 13.14\n",
      "Epoch: 473 Train Loss: 0.1140 Val Loss: 0.2886 Acc: 0.9094 Pre: 0.9511 Recall: 0.8724 F1: 0.9101 Train AUC: 0.9935 Val AUC: 0.9587 Time: 13.64\n",
      "Epoch: 474 Train Loss: 0.1081 Val Loss: 0.3382 Acc: 0.9040 Pre: 0.9647 Recall: 0.8483 F1: 0.9028 Train AUC: 0.9939 Val AUC: 0.9534 Time: 14.24\n",
      "Epoch: 475 Train Loss: 0.1109 Val Loss: 0.3352 Acc: 0.8986 Pre: 0.9466 Recall: 0.8552 F1: 0.8986 Train AUC: 0.9937 Val AUC: 0.9501 Time: 14.26\n",
      "Epoch: 476 Train Loss: 0.1080 Val Loss: 0.3062 Acc: 0.9004 Pre: 0.9242 Recall: 0.8828 F1: 0.9030 Train AUC: 0.9936 Val AUC: 0.9531 Time: 14.78\n",
      "Epoch: 477 Train Loss: 0.1104 Val Loss: 0.3108 Acc: 0.9094 Pre: 0.9545 Recall: 0.8690 F1: 0.9097 Train AUC: 0.9946 Val AUC: 0.9561 Time: 13.76\n",
      "Epoch: 478 Train Loss: 0.1053 Val Loss: 0.3010 Acc: 0.9004 Pre: 0.9468 Recall: 0.8586 F1: 0.9005 Train AUC: 0.9940 Val AUC: 0.9587 Time: 12.65\n",
      "Epoch: 479 Train Loss: 0.1048 Val Loss: 0.2749 Acc: 0.9022 Pre: 0.9155 Recall: 0.8966 F1: 0.9059 Train AUC: 0.9941 Val AUC: 0.9607 Time: 13.11\n",
      "Epoch: 480 Train Loss: 0.1133 Val Loss: 0.2779 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9932 Val AUC: 0.9613 Time: 13.41\n",
      "Epoch: 481 Train Loss: 0.1041 Val Loss: 0.3058 Acc: 0.9058 Pre: 0.9542 Recall: 0.8621 F1: 0.9058 Train AUC: 0.9942 Val AUC: 0.9605 Time: 13.87\n",
      "Epoch: 482 Train Loss: 0.1156 Val Loss: 0.2939 Acc: 0.9094 Pre: 0.9478 Recall: 0.8759 F1: 0.9104 Train AUC: 0.9939 Val AUC: 0.9586 Time: 14.49\n",
      "Epoch: 483 Train Loss: 0.1036 Val Loss: 0.2947 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9941 Val AUC: 0.9563 Time: 15.22\n",
      "Epoch: 484 Train Loss: 0.1123 Val Loss: 0.2974 Acc: 0.9112 Pre: 0.9382 Recall: 0.8897 F1: 0.9133 Train AUC: 0.9933 Val AUC: 0.9559 Time: 14.94\n",
      "Epoch: 485 Train Loss: 0.1150 Val Loss: 0.3044 Acc: 0.9185 Pre: 0.9658 Recall: 0.8759 F1: 0.9186 Train AUC: 0.9932 Val AUC: 0.9592 Time: 13.68\n",
      "Epoch: 486 Train Loss: 0.1129 Val Loss: 0.2856 Acc: 0.9112 Pre: 0.9547 Recall: 0.8724 F1: 0.9117 Train AUC: 0.9928 Val AUC: 0.9626 Time: 12.95\n",
      "Epoch: 487 Train Loss: 0.1088 Val Loss: 0.2517 Acc: 0.9076 Pre: 0.9193 Recall: 0.9034 F1: 0.9113 Train AUC: 0.9942 Val AUC: 0.9654 Time: 12.50\n",
      "Epoch: 488 Train Loss: 0.1291 Val Loss: 0.2843 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9918 Val AUC: 0.9627 Time: 13.11\n",
      "Epoch: 489 Train Loss: 0.1056 Val Loss: 0.3209 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9940 Val AUC: 0.9575 Time: 13.47\n",
      "Epoch: 490 Train Loss: 0.1098 Val Loss: 0.3220 Acc: 0.9076 Pre: 0.9476 Recall: 0.8724 F1: 0.9084 Train AUC: 0.9930 Val AUC: 0.9551 Time: 14.05\n",
      "Epoch: 491 Train Loss: 0.0963 Val Loss: 0.3091 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9949 Val AUC: 0.9537 Time: 14.75\n",
      "Epoch: 492 Train Loss: 0.1082 Val Loss: 0.3152 Acc: 0.9058 Pre: 0.9508 Recall: 0.8655 F1: 0.9061 Train AUC: 0.9944 Val AUC: 0.9560 Time: 15.34\n",
      "Epoch: 493 Train Loss: 0.1065 Val Loss: 0.3076 Acc: 0.9058 Pre: 0.9474 Recall: 0.8690 F1: 0.9065 Train AUC: 0.9945 Val AUC: 0.9585 Time: 13.92\n",
      "Epoch: 494 Train Loss: 0.1074 Val Loss: 0.2675 Acc: 0.9076 Pre: 0.9253 Recall: 0.8966 F1: 0.9107 Train AUC: 0.9941 Val AUC: 0.9626 Time: 12.96\n",
      "Epoch: 495 Train Loss: 0.1012 Val Loss: 0.2621 Acc: 0.9094 Pre: 0.9225 Recall: 0.9034 F1: 0.9129 Train AUC: 0.9953 Val AUC: 0.9635 Time: 12.65\n",
      "Epoch: 496 Train Loss: 0.1061 Val Loss: 0.3009 Acc: 0.9076 Pre: 0.9544 Recall: 0.8655 F1: 0.9078 Train AUC: 0.9950 Val AUC: 0.9620 Time: 13.43\n",
      "Epoch: 497 Train Loss: 0.1040 Val Loss: 0.3131 Acc: 0.9058 Pre: 0.9577 Recall: 0.8586 F1: 0.9055 Train AUC: 0.9949 Val AUC: 0.9606 Time: 13.93\n",
      "Epoch: 498 Train Loss: 0.1115 Val Loss: 0.2739 Acc: 0.9004 Pre: 0.9123 Recall: 0.8966 F1: 0.9043 Train AUC: 0.9943 Val AUC: 0.9600 Time: 14.28\n",
      "Epoch: 499 Train Loss: 0.1063 Val Loss: 0.2711 Acc: 0.9040 Pre: 0.9217 Recall: 0.8931 F1: 0.9072 Train AUC: 0.9947 Val AUC: 0.9600 Time: 14.97\n",
      "Epoch: 500 Train Loss: 0.1085 Val Loss: 0.3064 Acc: 0.9094 Pre: 0.9545 Recall: 0.8690 F1: 0.9097 Train AUC: 0.9947 Val AUC: 0.9591 Time: 14.70\n",
      "Epoch: 501 Train Loss: 0.0995 Val Loss: 0.3245 Acc: 0.9058 Pre: 0.9612 Recall: 0.8552 F1: 0.9051 Train AUC: 0.9946 Val AUC: 0.9579 Time: 13.53\n",
      "Epoch: 502 Train Loss: 0.0958 Val Loss: 0.2934 Acc: 0.9058 Pre: 0.9407 Recall: 0.8759 F1: 0.9071 Train AUC: 0.9959 Val AUC: 0.9589 Time: 12.80\n",
      "Epoch: 503 Train Loss: 0.0983 Val Loss: 0.2751 Acc: 0.9022 Pre: 0.9184 Recall: 0.8931 F1: 0.9056 Train AUC: 0.9952 Val AUC: 0.9593 Time: 12.94\n",
      "Epoch: 504 Train Loss: 0.1110 Val Loss: 0.2999 Acc: 0.9112 Pre: 0.9513 Recall: 0.8759 F1: 0.9120 Train AUC: 0.9940 Val AUC: 0.9598 Time: 13.38\n",
      "Epoch: 505 Train Loss: 0.0897 Val Loss: 0.3234 Acc: 0.9022 Pre: 0.9538 Recall: 0.8552 F1: 0.9018 Train AUC: 0.9959 Val AUC: 0.9588 Time: 14.00\n",
      "Epoch: 506 Train Loss: 0.1040 Val Loss: 0.2897 Acc: 0.9094 Pre: 0.9444 Recall: 0.8793 F1: 0.9107 Train AUC: 0.9938 Val AUC: 0.9597 Time: 14.54\n",
      "Epoch: 507 Train Loss: 0.1019 Val Loss: 0.2760 Acc: 0.9040 Pre: 0.9309 Recall: 0.8828 F1: 0.9062 Train AUC: 0.9942 Val AUC: 0.9595 Time: 14.49\n",
      "Epoch: 508 Train Loss: 0.1019 Val Loss: 0.2954 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9955 Val AUC: 0.9591 Time: 14.11\n",
      "Epoch: 509 Train Loss: 0.1029 Val Loss: 0.3254 Acc: 0.9004 Pre: 0.9608 Recall: 0.8448 F1: 0.8991 Train AUC: 0.9948 Val AUC: 0.9578 Time: 13.18\n",
      "Epoch: 510 Train Loss: 0.0986 Val Loss: 0.3051 Acc: 0.9058 Pre: 0.9508 Recall: 0.8655 F1: 0.9061 Train AUC: 0.9953 Val AUC: 0.9578 Time: 13.05\n",
      "Epoch: 511 Train Loss: 0.1030 Val Loss: 0.2756 Acc: 0.9094 Pre: 0.9225 Recall: 0.9034 F1: 0.9129 Train AUC: 0.9943 Val AUC: 0.9601 Time: 13.57\n",
      "Epoch: 512 Train Loss: 0.1006 Val Loss: 0.2762 Acc: 0.9149 Pre: 0.9451 Recall: 0.8897 F1: 0.9165 Train AUC: 0.9953 Val AUC: 0.9616 Time: 14.26\n",
      "Epoch: 513 Train Loss: 0.0946 Val Loss: 0.2985 Acc: 0.9076 Pre: 0.9650 Recall: 0.8552 F1: 0.9068 Train AUC: 0.9956 Val AUC: 0.9611 Time: 14.41\n",
      "Epoch: 514 Train Loss: 0.0937 Val Loss: 0.3013 Acc: 0.9094 Pre: 0.9545 Recall: 0.8690 F1: 0.9097 Train AUC: 0.9961 Val AUC: 0.9608 Time: 13.69\n",
      "Epoch: 515 Train Loss: 0.1017 Val Loss: 0.2786 Acc: 0.9058 Pre: 0.9375 Recall: 0.8793 F1: 0.9075 Train AUC: 0.9949 Val AUC: 0.9603 Time: 13.51\n",
      "Epoch: 516 Train Loss: 0.0982 Val Loss: 0.2751 Acc: 0.9112 Pre: 0.9382 Recall: 0.8897 F1: 0.9133 Train AUC: 0.9957 Val AUC: 0.9598 Time: 13.96\n",
      "Epoch: 517 Train Loss: 0.0953 Val Loss: 0.3124 Acc: 0.9058 Pre: 0.9508 Recall: 0.8655 F1: 0.9061 Train AUC: 0.9966 Val AUC: 0.9577 Time: 13.79\n",
      "Epoch: 518 Train Loss: 0.1018 Val Loss: 0.3323 Acc: 0.8967 Pre: 0.9533 Recall: 0.8448 F1: 0.8958 Train AUC: 0.9941 Val AUC: 0.9576 Time: 13.99\n",
      "Epoch: 519 Train Loss: 0.1115 Val Loss: 0.2841 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9933 Val AUC: 0.9598 Time: 13.89\n",
      "Epoch: 520 Train Loss: 0.1001 Val Loss: 0.2827 Acc: 0.9040 Pre: 0.9341 Recall: 0.8793 F1: 0.9059 Train AUC: 0.9952 Val AUC: 0.9602 Time: 13.74\n",
      "Epoch: 521 Train Loss: 0.1047 Val Loss: 0.2894 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9943 Val AUC: 0.9606 Time: 14.30\n",
      "Epoch: 522 Train Loss: 0.1105 Val Loss: 0.3103 Acc: 0.9040 Pre: 0.9540 Recall: 0.8586 F1: 0.9038 Train AUC: 0.9936 Val AUC: 0.9599 Time: 13.84\n",
      "Epoch: 523 Train Loss: 0.1020 Val Loss: 0.3088 Acc: 0.9058 Pre: 0.9542 Recall: 0.8621 F1: 0.9058 Train AUC: 0.9939 Val AUC: 0.9593 Time: 13.26\n",
      "Epoch: 524 Train Loss: 0.1081 Val Loss: 0.2945 Acc: 0.9112 Pre: 0.9513 Recall: 0.8759 F1: 0.9120 Train AUC: 0.9933 Val AUC: 0.9605 Time: 13.03\n",
      "Epoch: 525 Train Loss: 0.0940 Val Loss: 0.2794 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9953 Val AUC: 0.9616 Time: 13.45\n",
      "Epoch: 526 Train Loss: 0.0960 Val Loss: 0.2714 Acc: 0.9076 Pre: 0.9314 Recall: 0.8897 F1: 0.9101 Train AUC: 0.9952 Val AUC: 0.9626 Time: 14.15\n",
      "Epoch: 527 Train Loss: 0.0935 Val Loss: 0.2684 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9965 Val AUC: 0.9630 Time: 14.17\n",
      "Epoch: 528 Train Loss: 0.0939 Val Loss: 0.2863 Acc: 0.9058 Pre: 0.9474 Recall: 0.8690 F1: 0.9065 Train AUC: 0.9963 Val AUC: 0.9622 Time: 13.80\n",
      "Epoch: 529 Train Loss: 0.0933 Val Loss: 0.2980 Acc: 0.9076 Pre: 0.9509 Recall: 0.8690 F1: 0.9081 Train AUC: 0.9956 Val AUC: 0.9612 Time: 13.86\n",
      "Epoch: 530 Train Loss: 0.1047 Val Loss: 0.2996 Acc: 0.9112 Pre: 0.9480 Recall: 0.8793 F1: 0.9123 Train AUC: 0.9936 Val AUC: 0.9600 Time: 14.57\n",
      "Epoch: 531 Train Loss: 0.0917 Val Loss: 0.2946 Acc: 0.9076 Pre: 0.9442 Recall: 0.8759 F1: 0.9088 Train AUC: 0.9957 Val AUC: 0.9597 Time: 14.15\n",
      "Epoch: 532 Train Loss: 0.0947 Val Loss: 0.2907 Acc: 0.9040 Pre: 0.9341 Recall: 0.8793 F1: 0.9059 Train AUC: 0.9952 Val AUC: 0.9597 Time: 13.41\n",
      "Epoch: 533 Train Loss: 0.0964 Val Loss: 0.2972 Acc: 0.9076 Pre: 0.9442 Recall: 0.8759 F1: 0.9088 Train AUC: 0.9954 Val AUC: 0.9622 Time: 13.34\n",
      "Epoch: 534 Train Loss: 0.0873 Val Loss: 0.3041 Acc: 0.9076 Pre: 0.9509 Recall: 0.8690 F1: 0.9081 Train AUC: 0.9964 Val AUC: 0.9621 Time: 13.23\n",
      "Epoch: 535 Train Loss: 0.0904 Val Loss: 0.2856 Acc: 0.9076 Pre: 0.9314 Recall: 0.8897 F1: 0.9101 Train AUC: 0.9959 Val AUC: 0.9617 Time: 13.74\n",
      "Epoch: 536 Train Loss: 0.0965 Val Loss: 0.2836 Acc: 0.9004 Pre: 0.9181 Recall: 0.8897 F1: 0.9037 Train AUC: 0.9948 Val AUC: 0.9596 Time: 14.46\n",
      "Epoch: 537 Train Loss: 0.0988 Val Loss: 0.3157 Acc: 0.9004 Pre: 0.9434 Recall: 0.8621 F1: 0.9009 Train AUC: 0.9953 Val AUC: 0.9573 Time: 14.13\n",
      "Epoch: 538 Train Loss: 0.0918 Val Loss: 0.3178 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9961 Val AUC: 0.9575 Time: 13.36\n",
      "Epoch: 539 Train Loss: 0.0986 Val Loss: 0.2715 Acc: 0.9112 Pre: 0.9319 Recall: 0.8966 F1: 0.9139 Train AUC: 0.9958 Val AUC: 0.9626 Time: 13.52\n",
      "Epoch: 540 Train Loss: 0.0832 Val Loss: 0.2576 Acc: 0.9112 Pre: 0.9199 Recall: 0.9103 F1: 0.9151 Train AUC: 0.9969 Val AUC: 0.9658 Time: 14.04\n",
      "Epoch: 541 Train Loss: 0.0984 Val Loss: 0.2707 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9955 Val AUC: 0.9654 Time: 14.73\n",
      "Epoch: 542 Train Loss: 0.0956 Val Loss: 0.2925 Acc: 0.9076 Pre: 0.9476 Recall: 0.8724 F1: 0.9084 Train AUC: 0.9950 Val AUC: 0.9645 Time: 14.28\n",
      "Epoch: 543 Train Loss: 0.1003 Val Loss: 0.2870 Acc: 0.9167 Pre: 0.9485 Recall: 0.8897 F1: 0.9181 Train AUC: 0.9947 Val AUC: 0.9597 Time: 13.23\n",
      "Epoch: 544 Train Loss: 0.1052 Val Loss: 0.2975 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9945 Val AUC: 0.9577 Time: 13.24\n",
      "Epoch: 545 Train Loss: 0.1004 Val Loss: 0.3182 Acc: 0.9094 Pre: 0.9545 Recall: 0.8690 F1: 0.9097 Train AUC: 0.9949 Val AUC: 0.9582 Time: 13.73\n",
      "Epoch: 546 Train Loss: 0.0917 Val Loss: 0.3102 Acc: 0.9022 Pre: 0.9436 Recall: 0.8655 F1: 0.9029 Train AUC: 0.9957 Val AUC: 0.9592 Time: 14.02\n",
      "Epoch: 547 Train Loss: 0.0989 Val Loss: 0.2754 Acc: 0.9022 Pre: 0.9155 Recall: 0.8966 F1: 0.9059 Train AUC: 0.9948 Val AUC: 0.9616 Time: 13.77\n",
      "Epoch: 548 Train Loss: 0.1015 Val Loss: 0.2711 Acc: 0.9076 Pre: 0.9223 Recall: 0.9000 F1: 0.9110 Train AUC: 0.9952 Val AUC: 0.9622 Time: 13.55\n",
      "Epoch: 549 Train Loss: 0.0991 Val Loss: 0.3174 Acc: 0.8986 Pre: 0.9432 Recall: 0.8586 F1: 0.8989 Train AUC: 0.9959 Val AUC: 0.9588 Time: 13.49\n",
      "Epoch: 550 Train Loss: 0.0925 Val Loss: 0.3510 Acc: 0.8949 Pre: 0.9496 Recall: 0.8448 F1: 0.8942 Train AUC: 0.9954 Val AUC: 0.9552 Time: 13.46\n",
      "Epoch: 551 Train Loss: 0.1016 Val Loss: 0.3303 Acc: 0.8986 Pre: 0.9500 Recall: 0.8517 F1: 0.8982 Train AUC: 0.9938 Val AUC: 0.9543 Time: 14.09\n",
      "Epoch: 552 Train Loss: 0.1002 Val Loss: 0.2959 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9954 Val AUC: 0.9560 Time: 14.85\n",
      "Epoch: 553 Train Loss: 0.1056 Val Loss: 0.2964 Acc: 0.9004 Pre: 0.9368 Recall: 0.8690 F1: 0.9016 Train AUC: 0.9951 Val AUC: 0.9593 Time: 14.64\n",
      "Epoch: 554 Train Loss: 0.0862 Val Loss: 0.3266 Acc: 0.9004 Pre: 0.9572 Recall: 0.8483 F1: 0.8995 Train AUC: 0.9966 Val AUC: 0.9591 Time: 13.48\n",
      "Epoch: 555 Train Loss: 0.1060 Val Loss: 0.2768 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9947 Val AUC: 0.9621 Time: 13.01\n",
      "Epoch: 556 Train Loss: 0.0967 Val Loss: 0.2691 Acc: 0.9040 Pre: 0.9217 Recall: 0.8931 F1: 0.9072 Train AUC: 0.9956 Val AUC: 0.9622 Time: 13.16\n",
      "Epoch: 557 Train Loss: 0.0944 Val Loss: 0.2960 Acc: 0.9058 Pre: 0.9407 Recall: 0.8759 F1: 0.9071 Train AUC: 0.9965 Val AUC: 0.9610 Time: 13.30\n",
      "Epoch: 558 Train Loss: 0.0890 Val Loss: 0.3012 Acc: 0.8986 Pre: 0.9366 Recall: 0.8655 F1: 0.8996 Train AUC: 0.9963 Val AUC: 0.9614 Time: 13.75\n",
      "Epoch: 559 Train Loss: 0.0949 Val Loss: 0.2931 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9953 Val AUC: 0.9607 Time: 14.27\n",
      "Epoch: 560 Train Loss: 0.1010 Val Loss: 0.2911 Acc: 0.9076 Pre: 0.9377 Recall: 0.8828 F1: 0.9094 Train AUC: 0.9940 Val AUC: 0.9603 Time: 13.91\n",
      "Epoch: 561 Train Loss: 0.0883 Val Loss: 0.2983 Acc: 0.8986 Pre: 0.9333 Recall: 0.8690 F1: 0.9000 Train AUC: 0.9966 Val AUC: 0.9601 Time: 13.63\n",
      "Epoch: 562 Train Loss: 0.0874 Val Loss: 0.2962 Acc: 0.8986 Pre: 0.9270 Recall: 0.8759 F1: 0.9007 Train AUC: 0.9966 Val AUC: 0.9610 Time: 14.06\n",
      "Epoch: 563 Train Loss: 0.0949 Val Loss: 0.2998 Acc: 0.8967 Pre: 0.9236 Recall: 0.8759 F1: 0.8991 Train AUC: 0.9951 Val AUC: 0.9595 Time: 13.62\n",
      "Epoch: 564 Train Loss: 0.0926 Val Loss: 0.2972 Acc: 0.9004 Pre: 0.9211 Recall: 0.8862 F1: 0.9033 Train AUC: 0.9955 Val AUC: 0.9590 Time: 13.44\n",
      "Epoch: 565 Train Loss: 0.0948 Val Loss: 0.2986 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9954 Val AUC: 0.9583 Time: 13.94\n",
      "Epoch: 566 Train Loss: 0.0926 Val Loss: 0.3016 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9955 Val AUC: 0.9580 Time: 14.14\n",
      "Epoch: 567 Train Loss: 0.0948 Val Loss: 0.3329 Acc: 0.9022 Pre: 0.9504 Recall: 0.8586 F1: 0.9022 Train AUC: 0.9962 Val AUC: 0.9592 Time: 13.56\n",
      "Epoch: 568 Train Loss: 0.0995 Val Loss: 0.3100 Acc: 0.9112 Pre: 0.9617 Recall: 0.8655 F1: 0.9111 Train AUC: 0.9959 Val AUC: 0.9610 Time: 13.10\n",
      "Epoch: 569 Train Loss: 0.0971 Val Loss: 0.2664 Acc: 0.9022 Pre: 0.9041 Recall: 0.9103 F1: 0.9072 Train AUC: 0.9954 Val AUC: 0.9628 Time: 13.01\n",
      "Epoch: 570 Train Loss: 0.1035 Val Loss: 0.2726 Acc: 0.9004 Pre: 0.9066 Recall: 0.9034 F1: 0.9050 Train AUC: 0.9957 Val AUC: 0.9617 Time: 13.22\n",
      "Epoch: 571 Train Loss: 0.1053 Val Loss: 0.3336 Acc: 0.8949 Pre: 0.9427 Recall: 0.8517 F1: 0.8949 Train AUC: 0.9957 Val AUC: 0.9567 Time: 13.64\n",
      "Epoch: 572 Train Loss: 0.0973 Val Loss: 0.3559 Acc: 0.8895 Pre: 0.9421 Recall: 0.8414 F1: 0.8889 Train AUC: 0.9956 Val AUC: 0.9529 Time: 14.13\n",
      "Epoch: 573 Train Loss: 0.1068 Val Loss: 0.3023 Acc: 0.9022 Pre: 0.9184 Recall: 0.8931 F1: 0.9056 Train AUC: 0.9950 Val AUC: 0.9549 Time: 14.88\n",
      "Epoch: 574 Train Loss: 0.0956 Val Loss: 0.2841 Acc: 0.9076 Pre: 0.9283 Recall: 0.8931 F1: 0.9104 Train AUC: 0.9961 Val AUC: 0.9594 Time: 14.31\n",
      "Epoch: 575 Train Loss: 0.0904 Val Loss: 0.3069 Acc: 0.8895 Pre: 0.9354 Recall: 0.8483 F1: 0.8897 Train AUC: 0.9970 Val AUC: 0.9628 Time: 13.17\n",
      "Epoch: 576 Train Loss: 0.0930 Val Loss: 0.3217 Acc: 0.8859 Pre: 0.9349 Recall: 0.8414 F1: 0.8857 Train AUC: 0.9955 Val AUC: 0.9633 Time: 12.93\n",
      "Epoch: 577 Train Loss: 0.1085 Val Loss: 0.2706 Acc: 0.8986 Pre: 0.9209 Recall: 0.8828 F1: 0.9014 Train AUC: 0.9941 Val AUC: 0.9652 Time: 13.53\n",
      "Epoch: 578 Train Loss: 0.1038 Val Loss: 0.2747 Acc: 0.9149 Pre: 0.9263 Recall: 0.9103 F1: 0.9183 Train AUC: 0.9940 Val AUC: 0.9598 Time: 13.85\n",
      "Epoch: 579 Train Loss: 0.1093 Val Loss: 0.3174 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9956 Val AUC: 0.9565 Time: 14.71\n",
      "Epoch: 580 Train Loss: 0.0937 Val Loss: 0.3820 Acc: 0.8822 Pre: 0.9592 Recall: 0.8103 F1: 0.8785 Train AUC: 0.9955 Val AUC: 0.9535 Time: 14.94\n",
      "Epoch: 581 Train Loss: 0.1174 Val Loss: 0.3099 Acc: 0.8986 Pre: 0.9398 Recall: 0.8621 F1: 0.8993 Train AUC: 0.9937 Val AUC: 0.9582 Time: 13.60\n",
      "Epoch: 582 Train Loss: 0.0813 Val Loss: 0.2624 Acc: 0.9112 Pre: 0.9258 Recall: 0.9034 F1: 0.9145 Train AUC: 0.9970 Val AUC: 0.9627 Time: 12.83\n",
      "Epoch: 583 Train Loss: 0.1000 Val Loss: 0.2634 Acc: 0.9149 Pre: 0.9355 Recall: 0.9000 F1: 0.9174 Train AUC: 0.9962 Val AUC: 0.9647 Time: 13.10\n",
      "Epoch: 584 Train Loss: 0.0894 Val Loss: 0.2920 Acc: 0.8986 Pre: 0.9466 Recall: 0.8552 F1: 0.8986 Train AUC: 0.9963 Val AUC: 0.9643 Time: 13.56\n",
      "Epoch: 585 Train Loss: 0.0981 Val Loss: 0.2949 Acc: 0.8931 Pre: 0.9425 Recall: 0.8483 F1: 0.8929 Train AUC: 0.9945 Val AUC: 0.9646 Time: 14.23\n",
      "Epoch: 586 Train Loss: 0.0921 Val Loss: 0.2662 Acc: 0.9094 Pre: 0.9286 Recall: 0.8966 F1: 0.9123 Train AUC: 0.9962 Val AUC: 0.9638 Time: 14.71\n",
      "Epoch: 587 Train Loss: 0.0911 Val Loss: 0.2680 Acc: 0.9094 Pre: 0.9167 Recall: 0.9103 F1: 0.9135 Train AUC: 0.9963 Val AUC: 0.9605 Time: 14.32\n",
      "Epoch: 588 Train Loss: 0.0947 Val Loss: 0.2937 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9968 Val AUC: 0.9578 Time: 13.82\n",
      "Epoch: 589 Train Loss: 0.0919 Val Loss: 0.3538 Acc: 0.9004 Pre: 0.9608 Recall: 0.8448 F1: 0.8991 Train AUC: 0.9965 Val AUC: 0.9538 Time: 12.84\n",
      "Epoch: 590 Train Loss: 0.0895 Val Loss: 0.3562 Acc: 0.8986 Pre: 0.9606 Recall: 0.8414 F1: 0.8971 Train AUC: 0.9965 Val AUC: 0.9531 Time: 12.97\n",
      "Epoch: 591 Train Loss: 0.0974 Val Loss: 0.3032 Acc: 0.9112 Pre: 0.9513 Recall: 0.8759 F1: 0.9120 Train AUC: 0.9946 Val AUC: 0.9576 Time: 13.31\n",
      "Epoch: 592 Train Loss: 0.0850 Val Loss: 0.2703 Acc: 0.9076 Pre: 0.9253 Recall: 0.8966 F1: 0.9107 Train AUC: 0.9969 Val AUC: 0.9621 Time: 14.01\n",
      "Epoch: 593 Train Loss: 0.0895 Val Loss: 0.2695 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9975 Val AUC: 0.9650 Time: 14.44\n",
      "Epoch: 594 Train Loss: 0.0901 Val Loss: 0.2871 Acc: 0.8949 Pre: 0.9394 Recall: 0.8552 F1: 0.8953 Train AUC: 0.9964 Val AUC: 0.9644 Time: 14.74\n",
      "Epoch: 595 Train Loss: 0.0953 Val Loss: 0.2923 Acc: 0.9076 Pre: 0.9509 Recall: 0.8690 F1: 0.9081 Train AUC: 0.9950 Val AUC: 0.9635 Time: 15.14\n",
      "Epoch: 596 Train Loss: 0.1031 Val Loss: 0.2787 Acc: 0.9130 Pre: 0.9321 Recall: 0.9000 F1: 0.9158 Train AUC: 0.9946 Val AUC: 0.9623 Time: 14.59\n",
      "Epoch: 597 Train Loss: 0.0897 Val Loss: 0.2847 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9961 Val AUC: 0.9592 Time: 13.32\n",
      "Epoch: 598 Train Loss: 0.0945 Val Loss: 0.3150 Acc: 0.9094 Pre: 0.9478 Recall: 0.8759 F1: 0.9104 Train AUC: 0.9960 Val AUC: 0.9568 Time: 13.06\n",
      "Epoch: 599 Train Loss: 0.0932 Val Loss: 0.3262 Acc: 0.8949 Pre: 0.9462 Recall: 0.8483 F1: 0.8945 Train AUC: 0.9964 Val AUC: 0.9576 Time: 13.10\n",
      "Epoch: 600 Train Loss: 0.0947 Val Loss: 0.3100 Acc: 0.9058 Pre: 0.9312 Recall: 0.8862 F1: 0.9081 Train AUC: 0.9963 Val AUC: 0.9578 Time: 13.53\n",
      "Epoch: 601 Train Loss: 0.0873 Val Loss: 0.2987 Acc: 0.8967 Pre: 0.9003 Recall: 0.9034 F1: 0.9019 Train AUC: 0.9963 Val AUC: 0.9590 Time: 14.03\n",
      "Epoch: 602 Train Loss: 0.0929 Val Loss: 0.2846 Acc: 0.9094 Pre: 0.9167 Recall: 0.9103 F1: 0.9135 Train AUC: 0.9959 Val AUC: 0.9613 Time: 14.45\n",
      "Epoch: 603 Train Loss: 0.0848 Val Loss: 0.2966 Acc: 0.9149 Pre: 0.9483 Recall: 0.8862 F1: 0.9162 Train AUC: 0.9970 Val AUC: 0.9623 Time: 14.02\n",
      "Epoch: 604 Train Loss: 0.0815 Val Loss: 0.3193 Acc: 0.9076 Pre: 0.9509 Recall: 0.8690 F1: 0.9081 Train AUC: 0.9970 Val AUC: 0.9613 Time: 13.37\n",
      "Epoch: 605 Train Loss: 0.0850 Val Loss: 0.2942 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9975 Val AUC: 0.9607 Time: 13.18\n",
      "Epoch: 606 Train Loss: 0.0868 Val Loss: 0.2825 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9965 Val AUC: 0.9619 Time: 13.22\n",
      "Epoch: 607 Train Loss: 0.0888 Val Loss: 0.2880 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9962 Val AUC: 0.9630 Time: 13.58\n",
      "Epoch: 608 Train Loss: 0.0839 Val Loss: 0.3116 Acc: 0.8967 Pre: 0.9430 Recall: 0.8552 F1: 0.8969 Train AUC: 0.9962 Val AUC: 0.9617 Time: 14.42\n",
      "Epoch: 609 Train Loss: 0.0851 Val Loss: 0.3050 Acc: 0.9040 Pre: 0.9506 Recall: 0.8621 F1: 0.9042 Train AUC: 0.9961 Val AUC: 0.9621 Time: 14.83\n",
      "Epoch: 610 Train Loss: 0.0835 Val Loss: 0.2788 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9969 Val AUC: 0.9617 Time: 13.43\n",
      "Epoch: 611 Train Loss: 0.0918 Val Loss: 0.2792 Acc: 0.9058 Pre: 0.9220 Recall: 0.8966 F1: 0.9091 Train AUC: 0.9963 Val AUC: 0.9613 Time: 12.90\n",
      "Epoch: 612 Train Loss: 0.0893 Val Loss: 0.3031 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9965 Val AUC: 0.9612 Time: 13.49\n",
      "Epoch: 613 Train Loss: 0.0866 Val Loss: 0.3229 Acc: 0.9022 Pre: 0.9504 Recall: 0.8586 F1: 0.9022 Train AUC: 0.9957 Val AUC: 0.9597 Time: 14.14\n",
      "Epoch: 614 Train Loss: 0.0811 Val Loss: 0.3121 Acc: 0.9130 Pre: 0.9481 Recall: 0.8828 F1: 0.9143 Train AUC: 0.9966 Val AUC: 0.9615 Time: 14.53\n",
      "Epoch: 615 Train Loss: 0.0814 Val Loss: 0.2806 Acc: 0.9094 Pre: 0.9286 Recall: 0.8966 F1: 0.9123 Train AUC: 0.9966 Val AUC: 0.9635 Time: 14.07\n",
      "Epoch: 616 Train Loss: 0.0787 Val Loss: 0.2723 Acc: 0.9203 Pre: 0.9362 Recall: 0.9103 F1: 0.9231 Train AUC: 0.9969 Val AUC: 0.9637 Time: 13.39\n",
      "Epoch: 617 Train Loss: 0.0837 Val Loss: 0.2808 Acc: 0.9167 Pre: 0.9357 Recall: 0.9034 F1: 0.9193 Train AUC: 0.9973 Val AUC: 0.9635 Time: 12.68\n",
      "Epoch: 618 Train Loss: 0.0976 Val Loss: 0.3104 Acc: 0.9149 Pre: 0.9483 Recall: 0.8862 F1: 0.9162 Train AUC: 0.9952 Val AUC: 0.9600 Time: 13.33\n",
      "Epoch: 619 Train Loss: 0.0809 Val Loss: 0.3417 Acc: 0.9094 Pre: 0.9511 Recall: 0.8724 F1: 0.9101 Train AUC: 0.9966 Val AUC: 0.9549 Time: 13.66\n",
      "Epoch: 620 Train Loss: 0.0925 Val Loss: 0.3244 Acc: 0.9058 Pre: 0.9375 Recall: 0.8793 F1: 0.9075 Train AUC: 0.9952 Val AUC: 0.9556 Time: 14.23\n",
      "Epoch: 621 Train Loss: 0.0816 Val Loss: 0.2928 Acc: 0.9076 Pre: 0.9223 Recall: 0.9000 F1: 0.9110 Train AUC: 0.9968 Val AUC: 0.9594 Time: 15.04\n",
      "Epoch: 622 Train Loss: 0.0836 Val Loss: 0.2784 Acc: 0.9040 Pre: 0.9187 Recall: 0.8966 F1: 0.9075 Train AUC: 0.9971 Val AUC: 0.9627 Time: 14.11\n",
      "Epoch: 623 Train Loss: 0.0779 Val Loss: 0.2915 Acc: 0.8949 Pre: 0.9328 Recall: 0.8621 F1: 0.8961 Train AUC: 0.9975 Val AUC: 0.9643 Time: 13.01\n",
      "Epoch: 624 Train Loss: 0.0897 Val Loss: 0.2805 Acc: 0.9022 Pre: 0.9275 Recall: 0.8828 F1: 0.9046 Train AUC: 0.9964 Val AUC: 0.9654 Time: 12.72\n",
      "Epoch: 625 Train Loss: 0.0816 Val Loss: 0.2718 Acc: 0.9130 Pre: 0.9291 Recall: 0.9034 F1: 0.9161 Train AUC: 0.9969 Val AUC: 0.9644 Time: 12.47\n",
      "Epoch: 626 Train Loss: 0.0737 Val Loss: 0.2870 Acc: 0.9130 Pre: 0.9291 Recall: 0.9034 F1: 0.9161 Train AUC: 0.9980 Val AUC: 0.9613 Time: 12.75\n",
      "Epoch: 627 Train Loss: 0.0765 Val Loss: 0.3250 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9980 Val AUC: 0.9570 Time: 13.52\n",
      "Epoch: 628 Train Loss: 0.0858 Val Loss: 0.3508 Acc: 0.9022 Pre: 0.9609 Recall: 0.8483 F1: 0.9011 Train AUC: 0.9963 Val AUC: 0.9563 Time: 13.85\n",
      "Epoch: 629 Train Loss: 0.0799 Val Loss: 0.3330 Acc: 0.9112 Pre: 0.9617 Recall: 0.8655 F1: 0.9111 Train AUC: 0.9969 Val AUC: 0.9575 Time: 14.72\n",
      "Epoch: 630 Train Loss: 0.0826 Val Loss: 0.2936 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9970 Val AUC: 0.9611 Time: 15.21\n",
      "Epoch: 631 Train Loss: 0.0770 Val Loss: 0.2914 Acc: 0.9040 Pre: 0.9187 Recall: 0.8966 F1: 0.9075 Train AUC: 0.9978 Val AUC: 0.9626 Time: 15.69\n",
      "Epoch: 632 Train Loss: 0.0819 Val Loss: 0.2934 Acc: 0.9076 Pre: 0.9314 Recall: 0.8897 F1: 0.9101 Train AUC: 0.9965 Val AUC: 0.9633 Time: 13.86\n",
      "Epoch: 633 Train Loss: 0.0883 Val Loss: 0.2916 Acc: 0.9094 Pre: 0.9286 Recall: 0.8966 F1: 0.9123 Train AUC: 0.9956 Val AUC: 0.9626 Time: 12.91\n",
      "Epoch: 634 Train Loss: 0.0862 Val Loss: 0.2991 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9957 Val AUC: 0.9594 Time: 12.36\n",
      "Epoch: 635 Train Loss: 0.0900 Val Loss: 0.3123 Acc: 0.9094 Pre: 0.9511 Recall: 0.8724 F1: 0.9101 Train AUC: 0.9960 Val AUC: 0.9600 Time: 12.91\n",
      "Epoch: 636 Train Loss: 0.0782 Val Loss: 0.3166 Acc: 0.9094 Pre: 0.9511 Recall: 0.8724 F1: 0.9101 Train AUC: 0.9981 Val AUC: 0.9606 Time: 13.51\n",
      "Epoch: 637 Train Loss: 0.0796 Val Loss: 0.2984 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9971 Val AUC: 0.9620 Time: 13.93\n",
      "Epoch: 638 Train Loss: 0.0766 Val Loss: 0.2928 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9970 Val AUC: 0.9621 Time: 14.55\n",
      "Epoch: 639 Train Loss: 0.0835 Val Loss: 0.3079 Acc: 0.9058 Pre: 0.9407 Recall: 0.8759 F1: 0.9071 Train AUC: 0.9968 Val AUC: 0.9616 Time: 14.95\n",
      "Epoch: 640 Train Loss: 0.0777 Val Loss: 0.3124 Acc: 0.9149 Pre: 0.9517 Recall: 0.8828 F1: 0.9159 Train AUC: 0.9969 Val AUC: 0.9613 Time: 14.12\n",
      "Epoch: 641 Train Loss: 0.0740 Val Loss: 0.2973 Acc: 0.9058 Pre: 0.9312 Recall: 0.8862 F1: 0.9081 Train AUC: 0.9975 Val AUC: 0.9621 Time: 13.08\n",
      "Epoch: 642 Train Loss: 0.0682 Val Loss: 0.2871 Acc: 0.9058 Pre: 0.9220 Recall: 0.8966 F1: 0.9091 Train AUC: 0.9982 Val AUC: 0.9625 Time: 12.70\n",
      "Epoch: 643 Train Loss: 0.0753 Val Loss: 0.2920 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9975 Val AUC: 0.9621 Time: 12.47\n",
      "Epoch: 644 Train Loss: 0.0783 Val Loss: 0.3099 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9971 Val AUC: 0.9610 Time: 12.95\n",
      "Epoch: 645 Train Loss: 0.0705 Val Loss: 0.3089 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9978 Val AUC: 0.9607 Time: 13.56\n",
      "Epoch: 646 Train Loss: 0.0727 Val Loss: 0.2929 Acc: 0.9130 Pre: 0.9321 Recall: 0.9000 F1: 0.9158 Train AUC: 0.9978 Val AUC: 0.9609 Time: 14.05\n",
      "Epoch: 647 Train Loss: 0.0804 Val Loss: 0.2980 Acc: 0.9167 Pre: 0.9420 Recall: 0.8966 F1: 0.9187 Train AUC: 0.9972 Val AUC: 0.9617 Time: 14.86\n",
      "Epoch: 648 Train Loss: 0.0754 Val Loss: 0.2988 Acc: 0.9149 Pre: 0.9418 Recall: 0.8931 F1: 0.9168 Train AUC: 0.9973 Val AUC: 0.9628 Time: 15.38\n",
      "Epoch: 649 Train Loss: 0.0708 Val Loss: 0.2967 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9979 Val AUC: 0.9634 Time: 14.05\n",
      "Epoch: 650 Train Loss: 0.0776 Val Loss: 0.2887 Acc: 0.9167 Pre: 0.9357 Recall: 0.9034 F1: 0.9193 Train AUC: 0.9970 Val AUC: 0.9640 Time: 13.42\n",
      "Epoch: 651 Train Loss: 0.0693 Val Loss: 0.2793 Acc: 0.9130 Pre: 0.9291 Recall: 0.9034 F1: 0.9161 Train AUC: 0.9981 Val AUC: 0.9643 Time: 13.26\n",
      "Epoch: 652 Train Loss: 0.0760 Val Loss: 0.2829 Acc: 0.9149 Pre: 0.9324 Recall: 0.9034 F1: 0.9177 Train AUC: 0.9970 Val AUC: 0.9632 Time: 13.15\n",
      "Epoch: 653 Train Loss: 0.0743 Val Loss: 0.3013 Acc: 0.9167 Pre: 0.9519 Recall: 0.8862 F1: 0.9179 Train AUC: 0.9974 Val AUC: 0.9617 Time: 13.77\n",
      "Epoch: 654 Train Loss: 0.0792 Val Loss: 0.3146 Acc: 0.9130 Pre: 0.9549 Recall: 0.8759 F1: 0.9137 Train AUC: 0.9967 Val AUC: 0.9608 Time: 14.39\n",
      "Epoch: 655 Train Loss: 0.0852 Val Loss: 0.3000 Acc: 0.9112 Pre: 0.9382 Recall: 0.8897 F1: 0.9133 Train AUC: 0.9965 Val AUC: 0.9610 Time: 14.21\n",
      "Epoch: 656 Train Loss: 0.0725 Val Loss: 0.2996 Acc: 0.9167 Pre: 0.9420 Recall: 0.8966 F1: 0.9187 Train AUC: 0.9979 Val AUC: 0.9619 Time: 14.09\n",
      "Epoch: 657 Train Loss: 0.0736 Val Loss: 0.2960 Acc: 0.9130 Pre: 0.9321 Recall: 0.9000 F1: 0.9158 Train AUC: 0.9976 Val AUC: 0.9628 Time: 13.13\n",
      "Epoch: 658 Train Loss: 0.0841 Val Loss: 0.2994 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9964 Val AUC: 0.9629 Time: 12.68\n",
      "Epoch: 659 Train Loss: 0.0794 Val Loss: 0.2952 Acc: 0.9076 Pre: 0.9314 Recall: 0.8897 F1: 0.9101 Train AUC: 0.9972 Val AUC: 0.9619 Time: 12.75\n",
      "Epoch: 660 Train Loss: 0.0793 Val Loss: 0.3005 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9971 Val AUC: 0.9615 Time: 13.37\n",
      "Epoch: 661 Train Loss: 0.0660 Val Loss: 0.3018 Acc: 0.9094 Pre: 0.9444 Recall: 0.8793 F1: 0.9107 Train AUC: 0.9984 Val AUC: 0.9614 Time: 13.85\n",
      "Epoch: 662 Train Loss: 0.0742 Val Loss: 0.3029 Acc: 0.9058 Pre: 0.9343 Recall: 0.8828 F1: 0.9078 Train AUC: 0.9978 Val AUC: 0.9620 Time: 14.60\n",
      "Epoch: 663 Train Loss: 0.0706 Val Loss: 0.2963 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9978 Val AUC: 0.9632 Time: 15.01\n",
      "Epoch: 664 Train Loss: 0.0774 Val Loss: 0.2731 Acc: 0.9167 Pre: 0.9236 Recall: 0.9172 F1: 0.9204 Train AUC: 0.9978 Val AUC: 0.9652 Time: 14.06\n",
      "Epoch: 665 Train Loss: 0.0805 Val Loss: 0.2725 Acc: 0.9167 Pre: 0.9266 Recall: 0.9138 F1: 0.9201 Train AUC: 0.9972 Val AUC: 0.9651 Time: 13.09\n",
      "Epoch: 666 Train Loss: 0.0833 Val Loss: 0.3064 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9973 Val AUC: 0.9633 Time: 13.25\n",
      "Epoch: 667 Train Loss: 0.0766 Val Loss: 0.3529 Acc: 0.9004 Pre: 0.9608 Recall: 0.8448 F1: 0.8991 Train AUC: 0.9972 Val AUC: 0.9610 Time: 13.53\n",
      "Epoch: 668 Train Loss: 0.1020 Val Loss: 0.3080 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9966 Val AUC: 0.9592 Time: 14.13\n",
      "Epoch: 669 Train Loss: 0.0703 Val Loss: 0.3077 Acc: 0.9040 Pre: 0.9044 Recall: 0.9138 F1: 0.9091 Train AUC: 0.9979 Val AUC: 0.9579 Time: 14.96\n",
      "Epoch: 670 Train Loss: 0.0834 Val Loss: 0.3111 Acc: 0.9076 Pre: 0.9253 Recall: 0.8966 F1: 0.9107 Train AUC: 0.9975 Val AUC: 0.9593 Time: 13.68\n",
      "Epoch: 671 Train Loss: 0.0779 Val Loss: 0.3383 Acc: 0.9004 Pre: 0.9502 Recall: 0.8552 F1: 0.9002 Train AUC: 0.9976 Val AUC: 0.9596 Time: 12.72\n",
      "Epoch: 672 Train Loss: 0.0901 Val Loss: 0.2978 Acc: 0.9022 Pre: 0.9307 Recall: 0.8793 F1: 0.9043 Train AUC: 0.9960 Val AUC: 0.9628 Time: 12.79\n",
      "Epoch: 673 Train Loss: 0.0812 Val Loss: 0.2783 Acc: 0.9094 Pre: 0.9196 Recall: 0.9069 F1: 0.9132 Train AUC: 0.9968 Val AUC: 0.9618 Time: 13.25\n",
      "Epoch: 674 Train Loss: 0.0804 Val Loss: 0.2887 Acc: 0.9076 Pre: 0.9223 Recall: 0.9000 F1: 0.9110 Train AUC: 0.9972 Val AUC: 0.9606 Time: 14.14\n",
      "Epoch: 675 Train Loss: 0.0821 Val Loss: 0.3518 Acc: 0.8986 Pre: 0.9570 Recall: 0.8448 F1: 0.8974 Train AUC: 0.9972 Val AUC: 0.9566 Time: 14.57\n",
      "Epoch: 676 Train Loss: 0.0758 Val Loss: 0.3844 Acc: 0.8895 Pre: 0.9455 Recall: 0.8379 F1: 0.8885 Train AUC: 0.9975 Val AUC: 0.9533 Time: 15.16\n",
      "Epoch: 677 Train Loss: 0.0916 Val Loss: 0.3221 Acc: 0.9149 Pre: 0.9451 Recall: 0.8897 F1: 0.9165 Train AUC: 0.9957 Val AUC: 0.9571 Time: 14.62\n",
      "Epoch: 678 Train Loss: 0.0737 Val Loss: 0.2818 Acc: 0.9040 Pre: 0.9129 Recall: 0.9034 F1: 0.9081 Train AUC: 0.9975 Val AUC: 0.9617 Time: 13.34\n",
      "Epoch: 679 Train Loss: 0.0859 Val Loss: 0.2830 Acc: 0.9149 Pre: 0.9324 Recall: 0.9034 F1: 0.9177 Train AUC: 0.9979 Val AUC: 0.9640 Time: 13.03\n",
      "Epoch: 680 Train Loss: 0.0831 Val Loss: 0.3282 Acc: 0.9004 Pre: 0.9502 Recall: 0.8552 F1: 0.9002 Train AUC: 0.9967 Val AUC: 0.9639 Time: 13.33\n",
      "Epoch: 681 Train Loss: 0.0872 Val Loss: 0.3162 Acc: 0.8913 Pre: 0.9259 Recall: 0.8621 F1: 0.8929 Train AUC: 0.9974 Val AUC: 0.9627 Time: 13.45\n",
      "Epoch: 682 Train Loss: 0.0798 Val Loss: 0.2938 Acc: 0.9130 Pre: 0.9231 Recall: 0.9103 F1: 0.9167 Train AUC: 0.9968 Val AUC: 0.9604 Time: 13.42\n",
      "Epoch: 683 Train Loss: 0.0823 Val Loss: 0.2877 Acc: 0.9022 Pre: 0.9155 Recall: 0.8966 F1: 0.9059 Train AUC: 0.9967 Val AUC: 0.9606 Time: 13.94\n",
      "Epoch: 684 Train Loss: 0.0764 Val Loss: 0.3188 Acc: 0.9076 Pre: 0.9476 Recall: 0.8724 F1: 0.9084 Train AUC: 0.9981 Val AUC: 0.9595 Time: 14.17\n",
      "Epoch: 685 Train Loss: 0.0766 Val Loss: 0.3262 Acc: 0.9040 Pre: 0.9506 Recall: 0.8621 F1: 0.9042 Train AUC: 0.9974 Val AUC: 0.9587 Time: 13.45\n",
      "Epoch: 686 Train Loss: 0.0771 Val Loss: 0.3017 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9975 Val AUC: 0.9607 Time: 12.72\n",
      "Epoch: 687 Train Loss: 0.0744 Val Loss: 0.2896 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9978 Val AUC: 0.9618 Time: 13.22\n",
      "Epoch: 688 Train Loss: 0.0673 Val Loss: 0.2992 Acc: 0.9076 Pre: 0.9442 Recall: 0.8759 F1: 0.9088 Train AUC: 0.9987 Val AUC: 0.9622 Time: 13.80\n",
      "Epoch: 689 Train Loss: 0.0779 Val Loss: 0.3123 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9971 Val AUC: 0.9621 Time: 14.08\n",
      "Epoch: 690 Train Loss: 0.0653 Val Loss: 0.3119 Acc: 0.9076 Pre: 0.9509 Recall: 0.8690 F1: 0.9081 Train AUC: 0.9979 Val AUC: 0.9618 Time: 14.29\n",
      "Epoch: 691 Train Loss: 0.0763 Val Loss: 0.2918 Acc: 0.9149 Pre: 0.9386 Recall: 0.8966 F1: 0.9171 Train AUC: 0.9977 Val AUC: 0.9615 Time: 14.84\n",
      "Epoch: 692 Train Loss: 0.0730 Val Loss: 0.2898 Acc: 0.9149 Pre: 0.9324 Recall: 0.9034 F1: 0.9177 Train AUC: 0.9980 Val AUC: 0.9611 Time: 13.57\n",
      "Epoch: 693 Train Loss: 0.0742 Val Loss: 0.3017 Acc: 0.9130 Pre: 0.9321 Recall: 0.9000 F1: 0.9158 Train AUC: 0.9979 Val AUC: 0.9605 Time: 12.96\n",
      "Epoch: 694 Train Loss: 0.0798 Val Loss: 0.3177 Acc: 0.9076 Pre: 0.9314 Recall: 0.8897 F1: 0.9101 Train AUC: 0.9969 Val AUC: 0.9591 Time: 12.78\n",
      "Epoch: 695 Train Loss: 0.0714 Val Loss: 0.3183 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9974 Val AUC: 0.9586 Time: 13.56\n",
      "Epoch: 696 Train Loss: 0.0800 Val Loss: 0.3144 Acc: 0.9112 Pre: 0.9382 Recall: 0.8897 F1: 0.9133 Train AUC: 0.9966 Val AUC: 0.9589 Time: 13.98\n",
      "Epoch: 697 Train Loss: 0.0707 Val Loss: 0.3284 Acc: 0.9112 Pre: 0.9547 Recall: 0.8724 F1: 0.9117 Train AUC: 0.9978 Val AUC: 0.9589 Time: 14.47\n",
      "Epoch: 698 Train Loss: 0.0782 Val Loss: 0.3077 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9968 Val AUC: 0.9605 Time: 14.45\n",
      "Epoch: 699 Train Loss: 0.0714 Val Loss: 0.3059 Acc: 0.9112 Pre: 0.9446 Recall: 0.8828 F1: 0.9127 Train AUC: 0.9982 Val AUC: 0.9611 Time: 13.83\n",
      "Epoch: 700 Train Loss: 0.0772 Val Loss: 0.2962 Acc: 0.9185 Pre: 0.9422 Recall: 0.9000 F1: 0.9206 Train AUC: 0.9969 Val AUC: 0.9626 Time: 12.57\n",
      "Epoch: 701 Train Loss: 0.0770 Val Loss: 0.2981 Acc: 0.9149 Pre: 0.9418 Recall: 0.8931 F1: 0.9168 Train AUC: 0.9970 Val AUC: 0.9623 Time: 12.52\n",
      "Epoch: 702 Train Loss: 0.0770 Val Loss: 0.3083 Acc: 0.9112 Pre: 0.9513 Recall: 0.8759 F1: 0.9120 Train AUC: 0.9975 Val AUC: 0.9614 Time: 13.04\n",
      "Epoch: 703 Train Loss: 0.0691 Val Loss: 0.3130 Acc: 0.9076 Pre: 0.9509 Recall: 0.8690 F1: 0.9081 Train AUC: 0.9979 Val AUC: 0.9604 Time: 13.47\n",
      "Epoch: 704 Train Loss: 0.0759 Val Loss: 0.3075 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9972 Val AUC: 0.9601 Time: 14.00\n",
      "Epoch: 705 Train Loss: 0.0764 Val Loss: 0.3044 Acc: 0.9094 Pre: 0.9317 Recall: 0.8931 F1: 0.9120 Train AUC: 0.9973 Val AUC: 0.9599 Time: 14.76\n",
      "Epoch: 706 Train Loss: 0.0701 Val Loss: 0.3095 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9982 Val AUC: 0.9604 Time: 15.35\n",
      "Epoch: 707 Train Loss: 0.0672 Val Loss: 0.3146 Acc: 0.9094 Pre: 0.9444 Recall: 0.8793 F1: 0.9107 Train AUC: 0.9979 Val AUC: 0.9608 Time: 14.45\n",
      "Epoch: 708 Train Loss: 0.0806 Val Loss: 0.3185 Acc: 0.9076 Pre: 0.9476 Recall: 0.8724 F1: 0.9084 Train AUC: 0.9972 Val AUC: 0.9593 Time: 13.41\n",
      "Epoch: 709 Train Loss: 0.0687 Val Loss: 0.3093 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9979 Val AUC: 0.9592 Time: 12.45\n",
      "Epoch: 710 Train Loss: 0.0701 Val Loss: 0.3018 Acc: 0.9094 Pre: 0.9286 Recall: 0.8966 F1: 0.9123 Train AUC: 0.9979 Val AUC: 0.9600 Time: 12.06\n",
      "Epoch: 711 Train Loss: 0.0679 Val Loss: 0.3030 Acc: 0.9149 Pre: 0.9386 Recall: 0.8966 F1: 0.9171 Train AUC: 0.9984 Val AUC: 0.9610 Time: 12.54\n",
      "Epoch: 712 Train Loss: 0.0681 Val Loss: 0.3109 Acc: 0.9112 Pre: 0.9382 Recall: 0.8897 F1: 0.9133 Train AUC: 0.9983 Val AUC: 0.9610 Time: 12.92\n",
      "Epoch: 713 Train Loss: 0.0760 Val Loss: 0.3159 Acc: 0.9004 Pre: 0.9368 Recall: 0.8690 F1: 0.9016 Train AUC: 0.9969 Val AUC: 0.9600 Time: 13.45\n",
      "Epoch: 714 Train Loss: 0.0723 Val Loss: 0.3015 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9976 Val AUC: 0.9601 Time: 14.30\n",
      "Epoch: 715 Train Loss: 0.0763 Val Loss: 0.3146 Acc: 0.9094 Pre: 0.9478 Recall: 0.8759 F1: 0.9104 Train AUC: 0.9973 Val AUC: 0.9584 Time: 14.80\n",
      "Epoch: 716 Train Loss: 0.0775 Val Loss: 0.3234 Acc: 0.9112 Pre: 0.9582 Recall: 0.8690 F1: 0.9114 Train AUC: 0.9972 Val AUC: 0.9578 Time: 15.27\n",
      "Epoch: 717 Train Loss: 0.0780 Val Loss: 0.3269 Acc: 0.9149 Pre: 0.9620 Recall: 0.8724 F1: 0.9150 Train AUC: 0.9974 Val AUC: 0.9590 Time: 13.98\n",
      "Epoch: 718 Train Loss: 0.0694 Val Loss: 0.3132 Acc: 0.9130 Pre: 0.9449 Recall: 0.8862 F1: 0.9146 Train AUC: 0.9976 Val AUC: 0.9596 Time: 12.81\n",
      "Epoch: 719 Train Loss: 0.0754 Val Loss: 0.2996 Acc: 0.9185 Pre: 0.9359 Recall: 0.9069 F1: 0.9212 Train AUC: 0.9972 Val AUC: 0.9611 Time: 12.69\n",
      "Epoch: 720 Train Loss: 0.0701 Val Loss: 0.3040 Acc: 0.9149 Pre: 0.9386 Recall: 0.8966 F1: 0.9171 Train AUC: 0.9979 Val AUC: 0.9611 Time: 13.32\n",
      "Epoch: 721 Train Loss: 0.0667 Val Loss: 0.3245 Acc: 0.9130 Pre: 0.9549 Recall: 0.8759 F1: 0.9137 Train AUC: 0.9983 Val AUC: 0.9593 Time: 13.69\n",
      "Epoch: 722 Train Loss: 0.0711 Val Loss: 0.3222 Acc: 0.9130 Pre: 0.9481 Recall: 0.8828 F1: 0.9143 Train AUC: 0.9975 Val AUC: 0.9585 Time: 14.32\n",
      "Epoch: 723 Train Loss: 0.0653 Val Loss: 0.3212 Acc: 0.9112 Pre: 0.9446 Recall: 0.8828 F1: 0.9127 Train AUC: 0.9987 Val AUC: 0.9590 Time: 15.13\n",
      "Epoch: 724 Train Loss: 0.0666 Val Loss: 0.3176 Acc: 0.9112 Pre: 0.9446 Recall: 0.8828 F1: 0.9127 Train AUC: 0.9980 Val AUC: 0.9599 Time: 14.12\n",
      "Epoch: 725 Train Loss: 0.0790 Val Loss: 0.3174 Acc: 0.9130 Pre: 0.9481 Recall: 0.8828 F1: 0.9143 Train AUC: 0.9965 Val AUC: 0.9605 Time: 13.00\n",
      "Epoch: 726 Train Loss: 0.0708 Val Loss: 0.3204 Acc: 0.9149 Pre: 0.9620 Recall: 0.8724 F1: 0.9150 Train AUC: 0.9975 Val AUC: 0.9615 Time: 12.45\n",
      "Epoch: 727 Train Loss: 0.0700 Val Loss: 0.2948 Acc: 0.9040 Pre: 0.9187 Recall: 0.8966 F1: 0.9075 Train AUC: 0.9987 Val AUC: 0.9620 Time: 12.86\n",
      "Epoch: 728 Train Loss: 0.0697 Val Loss: 0.2940 Acc: 0.9058 Pre: 0.9103 Recall: 0.9103 F1: 0.9103 Train AUC: 0.9978 Val AUC: 0.9615 Time: 13.42\n",
      "Epoch: 729 Train Loss: 0.0760 Val Loss: 0.3339 Acc: 0.8986 Pre: 0.9239 Recall: 0.8793 F1: 0.9011 Train AUC: 0.9976 Val AUC: 0.9576 Time: 13.94\n",
      "Epoch: 730 Train Loss: 0.0723 Val Loss: 0.3522 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9972 Val AUC: 0.9561 Time: 14.83\n",
      "Epoch: 731 Train Loss: 0.0762 Val Loss: 0.3248 Acc: 0.9112 Pre: 0.9480 Recall: 0.8793 F1: 0.9123 Train AUC: 0.9972 Val AUC: 0.9586 Time: 15.00\n",
      "Epoch: 732 Train Loss: 0.0692 Val Loss: 0.2945 Acc: 0.9094 Pre: 0.9286 Recall: 0.8966 F1: 0.9123 Train AUC: 0.9982 Val AUC: 0.9607 Time: 13.82\n",
      "Epoch: 733 Train Loss: 0.0705 Val Loss: 0.3022 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9981 Val AUC: 0.9625 Time: 12.97\n",
      "Epoch: 734 Train Loss: 0.0711 Val Loss: 0.3364 Acc: 0.9058 Pre: 0.9508 Recall: 0.8655 F1: 0.9061 Train AUC: 0.9979 Val AUC: 0.9609 Time: 12.54\n",
      "Epoch: 735 Train Loss: 0.0780 Val Loss: 0.3179 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9975 Val AUC: 0.9602 Time: 13.00\n",
      "Epoch: 736 Train Loss: 0.0699 Val Loss: 0.3135 Acc: 0.9094 Pre: 0.9225 Recall: 0.9034 F1: 0.9129 Train AUC: 0.9978 Val AUC: 0.9595 Time: 13.44\n",
      "Epoch: 737 Train Loss: 0.0820 Val Loss: 0.3279 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9970 Val AUC: 0.9561 Time: 14.08\n",
      "Epoch: 738 Train Loss: 0.0673 Val Loss: 0.3646 Acc: 0.9058 Pre: 0.9612 Recall: 0.8552 F1: 0.9051 Train AUC: 0.9982 Val AUC: 0.9552 Time: 14.83\n",
      "Epoch: 739 Train Loss: 0.0652 Val Loss: 0.3685 Acc: 0.9058 Pre: 0.9612 Recall: 0.8552 F1: 0.9051 Train AUC: 0.9980 Val AUC: 0.9557 Time: 14.03\n",
      "Epoch: 740 Train Loss: 0.0717 Val Loss: 0.3145 Acc: 0.9149 Pre: 0.9451 Recall: 0.8897 F1: 0.9165 Train AUC: 0.9980 Val AUC: 0.9589 Time: 13.17\n",
      "Epoch: 741 Train Loss: 0.0680 Val Loss: 0.2899 Acc: 0.9094 Pre: 0.9255 Recall: 0.9000 F1: 0.9126 Train AUC: 0.9978 Val AUC: 0.9616 Time: 13.11\n",
      "Epoch: 742 Train Loss: 0.0804 Val Loss: 0.3039 Acc: 0.9130 Pre: 0.9384 Recall: 0.8931 F1: 0.9152 Train AUC: 0.9981 Val AUC: 0.9629 Time: 13.09\n",
      "Epoch: 743 Train Loss: 0.0718 Val Loss: 0.3297 Acc: 0.9004 Pre: 0.9401 Recall: 0.8655 F1: 0.9013 Train AUC: 0.9973 Val AUC: 0.9613 Time: 13.66\n",
      "Epoch: 744 Train Loss: 0.0720 Val Loss: 0.3354 Acc: 0.9076 Pre: 0.9476 Recall: 0.8724 F1: 0.9084 Train AUC: 0.9977 Val AUC: 0.9576 Time: 14.24\n",
      "Epoch: 745 Train Loss: 0.0734 Val Loss: 0.3248 Acc: 0.9022 Pre: 0.9275 Recall: 0.8828 F1: 0.9046 Train AUC: 0.9978 Val AUC: 0.9567 Time: 14.29\n",
      "Epoch: 746 Train Loss: 0.0749 Val Loss: 0.3459 Acc: 0.8967 Pre: 0.9206 Recall: 0.8793 F1: 0.8995 Train AUC: 0.9977 Val AUC: 0.9547 Time: 13.49\n",
      "Epoch: 747 Train Loss: 0.0669 Val Loss: 0.3485 Acc: 0.8986 Pre: 0.9270 Recall: 0.8759 F1: 0.9007 Train AUC: 0.9978 Val AUC: 0.9539 Time: 13.48\n",
      "Epoch: 748 Train Loss: 0.0767 Val Loss: 0.3330 Acc: 0.9130 Pre: 0.9449 Recall: 0.8862 F1: 0.9146 Train AUC: 0.9969 Val AUC: 0.9568 Time: 13.83\n",
      "Epoch: 749 Train Loss: 0.0719 Val Loss: 0.3172 Acc: 0.9094 Pre: 0.9444 Recall: 0.8793 F1: 0.9107 Train AUC: 0.9979 Val AUC: 0.9606 Time: 13.97\n",
      "Epoch: 750 Train Loss: 0.0862 Val Loss: 0.2896 Acc: 0.9112 Pre: 0.9319 Recall: 0.8966 F1: 0.9139 Train AUC: 0.9975 Val AUC: 0.9648 Time: 14.64\n",
      "Epoch: 751 Train Loss: 0.0705 Val Loss: 0.2941 Acc: 0.9149 Pre: 0.9263 Recall: 0.9103 F1: 0.9183 Train AUC: 0.9978 Val AUC: 0.9636 Time: 13.82\n",
      "Epoch: 752 Train Loss: 0.0813 Val Loss: 0.3169 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9967 Val AUC: 0.9589 Time: 12.89\n",
      "Epoch: 753 Train Loss: 0.0640 Val Loss: 0.3669 Acc: 0.9040 Pre: 0.9575 Recall: 0.8552 F1: 0.9035 Train AUC: 0.9983 Val AUC: 0.9536 Time: 12.73\n",
      "Epoch: 754 Train Loss: 0.0695 Val Loss: 0.4155 Acc: 0.8949 Pre: 0.9640 Recall: 0.8310 F1: 0.8926 Train AUC: 0.9975 Val AUC: 0.9494 Time: 13.18\n",
      "Epoch: 755 Train Loss: 0.0822 Val Loss: 0.3751 Acc: 0.9004 Pre: 0.9572 Recall: 0.8483 F1: 0.8995 Train AUC: 0.9973 Val AUC: 0.9517 Time: 13.67\n",
      "Epoch: 756 Train Loss: 0.0700 Val Loss: 0.3122 Acc: 0.9094 Pre: 0.9380 Recall: 0.8862 F1: 0.9113 Train AUC: 0.9980 Val AUC: 0.9586 Time: 14.34\n",
      "Epoch: 757 Train Loss: 0.0765 Val Loss: 0.2859 Acc: 0.9167 Pre: 0.9296 Recall: 0.9103 F1: 0.9199 Train AUC: 0.9975 Val AUC: 0.9646 Time: 14.78\n",
      "Epoch: 758 Train Loss: 0.0749 Val Loss: 0.2955 Acc: 0.9167 Pre: 0.9326 Recall: 0.9069 F1: 0.9196 Train AUC: 0.9973 Val AUC: 0.9638 Time: 13.54\n",
      "Epoch: 759 Train Loss: 0.0764 Val Loss: 0.3221 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9971 Val AUC: 0.9614 Time: 13.64\n",
      "Epoch: 760 Train Loss: 0.0786 Val Loss: 0.3227 Acc: 0.9130 Pre: 0.9549 Recall: 0.8759 F1: 0.9137 Train AUC: 0.9966 Val AUC: 0.9585 Time: 13.90\n",
      "Epoch: 761 Train Loss: 0.0647 Val Loss: 0.3343 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9980 Val AUC: 0.9536 Time: 13.72\n",
      "Epoch: 762 Train Loss: 0.0752 Val Loss: 0.3541 Acc: 0.9040 Pre: 0.9506 Recall: 0.8621 F1: 0.9042 Train AUC: 0.9979 Val AUC: 0.9529 Time: 13.44\n",
      "Epoch: 763 Train Loss: 0.0686 Val Loss: 0.3485 Acc: 0.9058 Pre: 0.9542 Recall: 0.8621 F1: 0.9058 Train AUC: 0.9980 Val AUC: 0.9557 Time: 13.25\n",
      "Epoch: 764 Train Loss: 0.0696 Val Loss: 0.3095 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9973 Val AUC: 0.9600 Time: 13.80\n",
      "Epoch: 765 Train Loss: 0.0653 Val Loss: 0.2824 Acc: 0.9112 Pre: 0.9258 Recall: 0.9034 F1: 0.9145 Train AUC: 0.9980 Val AUC: 0.9639 Time: 14.27\n",
      "Epoch: 766 Train Loss: 0.0767 Val Loss: 0.2881 Acc: 0.9167 Pre: 0.9357 Recall: 0.9034 F1: 0.9193 Train AUC: 0.9973 Val AUC: 0.9648 Time: 13.75\n",
      "Epoch: 767 Train Loss: 0.0731 Val Loss: 0.3008 Acc: 0.9112 Pre: 0.9446 Recall: 0.8828 F1: 0.9127 Train AUC: 0.9975 Val AUC: 0.9629 Time: 12.90\n",
      "Epoch: 768 Train Loss: 0.0668 Val Loss: 0.3060 Acc: 0.9076 Pre: 0.9314 Recall: 0.8897 F1: 0.9101 Train AUC: 0.9981 Val AUC: 0.9612 Time: 12.47\n",
      "Epoch: 769 Train Loss: 0.0730 Val Loss: 0.3108 Acc: 0.9058 Pre: 0.9190 Recall: 0.9000 F1: 0.9094 Train AUC: 0.9974 Val AUC: 0.9582 Time: 12.91\n",
      "Epoch: 770 Train Loss: 0.0692 Val Loss: 0.3304 Acc: 0.9076 Pre: 0.9377 Recall: 0.8828 F1: 0.9094 Train AUC: 0.9987 Val AUC: 0.9560 Time: 13.36\n",
      "Epoch: 771 Train Loss: 0.0735 Val Loss: 0.3353 Acc: 0.9094 Pre: 0.9444 Recall: 0.8793 F1: 0.9107 Train AUC: 0.9977 Val AUC: 0.9568 Time: 14.04\n",
      "Epoch: 772 Train Loss: 0.0659 Val Loss: 0.3281 Acc: 0.9130 Pre: 0.9549 Recall: 0.8759 F1: 0.9137 Train AUC: 0.9982 Val AUC: 0.9588 Time: 14.69\n",
      "Epoch: 773 Train Loss: 0.0727 Val Loss: 0.3085 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9975 Val AUC: 0.9594 Time: 14.87\n",
      "Epoch: 774 Train Loss: 0.0590 Val Loss: 0.3055 Acc: 0.9112 Pre: 0.9319 Recall: 0.8966 F1: 0.9139 Train AUC: 0.9987 Val AUC: 0.9593 Time: 13.49\n",
      "Epoch: 775 Train Loss: 0.0711 Val Loss: 0.3180 Acc: 0.9076 Pre: 0.9377 Recall: 0.8828 F1: 0.9094 Train AUC: 0.9979 Val AUC: 0.9581 Time: 12.49\n",
      "Epoch: 776 Train Loss: 0.0717 Val Loss: 0.3322 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9974 Val AUC: 0.9588 Time: 12.64\n",
      "Epoch: 777 Train Loss: 0.0681 Val Loss: 0.3219 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9981 Val AUC: 0.9604 Time: 13.27\n",
      "Epoch: 778 Train Loss: 0.0700 Val Loss: 0.3052 Acc: 0.9076 Pre: 0.9283 Recall: 0.8931 F1: 0.9104 Train AUC: 0.9976 Val AUC: 0.9602 Time: 13.56\n",
      "Epoch: 779 Train Loss: 0.0692 Val Loss: 0.2933 Acc: 0.9094 Pre: 0.9196 Recall: 0.9069 F1: 0.9132 Train AUC: 0.9977 Val AUC: 0.9602 Time: 14.10\n",
      "Epoch: 780 Train Loss: 0.0786 Val Loss: 0.3119 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9970 Val AUC: 0.9601 Time: 15.00\n",
      "Epoch: 781 Train Loss: 0.0605 Val Loss: 0.3464 Acc: 0.9004 Pre: 0.9537 Recall: 0.8517 F1: 0.8998 Train AUC: 0.9986 Val AUC: 0.9593 Time: 15.22\n",
      "Epoch: 782 Train Loss: 0.0790 Val Loss: 0.3224 Acc: 0.9058 Pre: 0.9440 Recall: 0.8724 F1: 0.9068 Train AUC: 0.9972 Val AUC: 0.9595 Time: 13.69\n",
      "Epoch: 783 Train Loss: 0.0661 Val Loss: 0.3021 Acc: 0.9094 Pre: 0.9225 Recall: 0.9034 F1: 0.9129 Train AUC: 0.9977 Val AUC: 0.9600 Time: 12.77\n",
      "Epoch: 784 Train Loss: 0.0688 Val Loss: 0.3022 Acc: 0.9076 Pre: 0.9193 Recall: 0.9034 F1: 0.9113 Train AUC: 0.9981 Val AUC: 0.9603 Time: 12.74\n",
      "Epoch: 785 Train Loss: 0.0745 Val Loss: 0.3412 Acc: 0.9076 Pre: 0.9544 Recall: 0.8655 F1: 0.9078 Train AUC: 0.9976 Val AUC: 0.9592 Time: 13.28\n",
      "Epoch: 786 Train Loss: 0.0686 Val Loss: 0.3627 Acc: 0.9004 Pre: 0.9572 Recall: 0.8483 F1: 0.8995 Train AUC: 0.9978 Val AUC: 0.9579 Time: 13.87\n",
      "Epoch: 787 Train Loss: 0.0753 Val Loss: 0.3204 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9976 Val AUC: 0.9580 Time: 14.33\n",
      "Epoch: 788 Train Loss: 0.0648 Val Loss: 0.3125 Acc: 0.9094 Pre: 0.9286 Recall: 0.8966 F1: 0.9123 Train AUC: 0.9983 Val AUC: 0.9592 Time: 14.61\n",
      "Epoch: 789 Train Loss: 0.0682 Val Loss: 0.3155 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9985 Val AUC: 0.9597 Time: 15.80\n",
      "Epoch: 790 Train Loss: 0.0718 Val Loss: 0.3461 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9975 Val AUC: 0.9585 Time: 13.05\n",
      "Epoch: 791 Train Loss: 0.0786 Val Loss: 0.3158 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9973 Val AUC: 0.9604 Time: 13.51\n",
      "Epoch: 792 Train Loss: 0.0612 Val Loss: 0.2957 Acc: 0.9040 Pre: 0.9100 Recall: 0.9069 F1: 0.9085 Train AUC: 0.9987 Val AUC: 0.9594 Time: 14.61\n",
      "Epoch: 793 Train Loss: 0.0777 Val Loss: 0.3168 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9984 Val AUC: 0.9584 Time: 13.91\n",
      "Epoch: 794 Train Loss: 0.0598 Val Loss: 0.3486 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9984 Val AUC: 0.9573 Time: 14.17\n",
      "Epoch: 795 Train Loss: 0.0772 Val Loss: 0.3408 Acc: 0.9130 Pre: 0.9549 Recall: 0.8759 F1: 0.9137 Train AUC: 0.9966 Val AUC: 0.9580 Time: 14.49\n",
      "Epoch: 796 Train Loss: 0.0723 Val Loss: 0.3143 Acc: 0.9149 Pre: 0.9451 Recall: 0.8897 F1: 0.9165 Train AUC: 0.9973 Val AUC: 0.9592 Time: 14.60\n",
      "Epoch: 797 Train Loss: 0.0680 Val Loss: 0.2877 Acc: 0.9130 Pre: 0.9291 Recall: 0.9034 F1: 0.9161 Train AUC: 0.9981 Val AUC: 0.9621 Time: 12.60\n",
      "Epoch: 798 Train Loss: 0.0712 Val Loss: 0.2948 Acc: 0.9167 Pre: 0.9453 Recall: 0.8931 F1: 0.9184 Train AUC: 0.9987 Val AUC: 0.9646 Time: 13.06\n",
      "Epoch: 799 Train Loss: 0.0660 Val Loss: 0.3135 Acc: 0.9004 Pre: 0.9401 Recall: 0.8655 F1: 0.9013 Train AUC: 0.9984 Val AUC: 0.9640 Time: 13.52\n",
      "Epoch: 800 Train Loss: 0.0726 Val Loss: 0.3121 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9974 Val AUC: 0.9625 Time: 13.52\n",
      "Epoch: 801 Train Loss: 0.0715 Val Loss: 0.3178 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9972 Val AUC: 0.9591 Time: 14.60\n",
      "Epoch: 802 Train Loss: 0.0663 Val Loss: 0.3366 Acc: 0.9094 Pre: 0.9444 Recall: 0.8793 F1: 0.9107 Train AUC: 0.9984 Val AUC: 0.9544 Time: 14.62\n",
      "Epoch: 803 Train Loss: 0.0692 Val Loss: 0.3375 Acc: 0.9058 Pre: 0.9343 Recall: 0.8828 F1: 0.9078 Train AUC: 0.9982 Val AUC: 0.9551 Time: 14.46\n",
      "Epoch: 804 Train Loss: 0.0692 Val Loss: 0.3340 Acc: 0.8986 Pre: 0.9398 Recall: 0.8621 F1: 0.8993 Train AUC: 0.9979 Val AUC: 0.9571 Time: 12.86\n",
      "Epoch: 805 Train Loss: 0.0669 Val Loss: 0.3104 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9986 Val AUC: 0.9614 Time: 12.86\n",
      "Epoch: 806 Train Loss: 0.0683 Val Loss: 0.2913 Acc: 0.9167 Pre: 0.9357 Recall: 0.9034 F1: 0.9193 Train AUC: 0.9982 Val AUC: 0.9634 Time: 13.53\n",
      "Epoch: 807 Train Loss: 0.0732 Val Loss: 0.2933 Acc: 0.9221 Pre: 0.9458 Recall: 0.9034 F1: 0.9242 Train AUC: 0.9976 Val AUC: 0.9636 Time: 14.31\n",
      "Epoch: 808 Train Loss: 0.0626 Val Loss: 0.3133 Acc: 0.9112 Pre: 0.9480 Recall: 0.8793 F1: 0.9123 Train AUC: 0.9985 Val AUC: 0.9621 Time: 14.83\n",
      "Epoch: 809 Train Loss: 0.0739 Val Loss: 0.3403 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9973 Val AUC: 0.9588 Time: 13.90\n",
      "Epoch: 810 Train Loss: 0.0665 Val Loss: 0.3471 Acc: 0.9058 Pre: 0.9542 Recall: 0.8621 F1: 0.9058 Train AUC: 0.9981 Val AUC: 0.9576 Time: 14.62\n",
      "Epoch: 811 Train Loss: 0.0637 Val Loss: 0.3247 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9982 Val AUC: 0.9572 Time: 12.64\n",
      "Epoch: 812 Train Loss: 0.0646 Val Loss: 0.3101 Acc: 0.8913 Pre: 0.8966 Recall: 0.8966 F1: 0.8966 Train AUC: 0.9982 Val AUC: 0.9580 Time: 13.37\n",
      "Epoch: 813 Train Loss: 0.0764 Val Loss: 0.3251 Acc: 0.9022 Pre: 0.9275 Recall: 0.8828 F1: 0.9046 Train AUC: 0.9979 Val AUC: 0.9576 Time: 13.84\n",
      "Epoch: 814 Train Loss: 0.0653 Val Loss: 0.3625 Acc: 0.9022 Pre: 0.9538 Recall: 0.8552 F1: 0.9018 Train AUC: 0.9982 Val AUC: 0.9580 Time: 14.45\n",
      "Epoch: 815 Train Loss: 0.0750 Val Loss: 0.3333 Acc: 0.9004 Pre: 0.9401 Recall: 0.8655 F1: 0.9013 Train AUC: 0.9983 Val AUC: 0.9596 Time: 14.82\n",
      "Epoch: 816 Train Loss: 0.0634 Val Loss: 0.3088 Acc: 0.9167 Pre: 0.9296 Recall: 0.9103 F1: 0.9199 Train AUC: 0.9984 Val AUC: 0.9596 Time: 13.50\n",
      "Epoch: 817 Train Loss: 0.0913 Val Loss: 0.3033 Acc: 0.9185 Pre: 0.9391 Recall: 0.9034 F1: 0.9209 Train AUC: 0.9965 Val AUC: 0.9622 Time: 14.38\n",
      "Epoch: 818 Train Loss: 0.0686 Val Loss: 0.3394 Acc: 0.9112 Pre: 0.9582 Recall: 0.8690 F1: 0.9114 Train AUC: 0.9979 Val AUC: 0.9611 Time: 13.45\n",
      "Epoch: 819 Train Loss: 0.0743 Val Loss: 0.3342 Acc: 0.9058 Pre: 0.9508 Recall: 0.8655 F1: 0.9061 Train AUC: 0.9974 Val AUC: 0.9601 Time: 12.95\n",
      "Epoch: 820 Train Loss: 0.0686 Val Loss: 0.2993 Acc: 0.8986 Pre: 0.9179 Recall: 0.8862 F1: 0.9018 Train AUC: 0.9980 Val AUC: 0.9603 Time: 12.84\n",
      "Epoch: 821 Train Loss: 0.0701 Val Loss: 0.3015 Acc: 0.9076 Pre: 0.9164 Recall: 0.9069 F1: 0.9116 Train AUC: 0.9980 Val AUC: 0.9585 Time: 13.04\n",
      "Epoch: 822 Train Loss: 0.0722 Val Loss: 0.3236 Acc: 0.9004 Pre: 0.9273 Recall: 0.8793 F1: 0.9027 Train AUC: 0.9983 Val AUC: 0.9581 Time: 14.33\n",
      "Epoch: 823 Train Loss: 0.0663 Val Loss: 0.3511 Acc: 0.9112 Pre: 0.9513 Recall: 0.8759 F1: 0.9120 Train AUC: 0.9981 Val AUC: 0.9584 Time: 14.56\n",
      "Epoch: 824 Train Loss: 0.0730 Val Loss: 0.3216 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9974 Val AUC: 0.9603 Time: 14.82\n",
      "Epoch: 825 Train Loss: 0.0708 Val Loss: 0.3050 Acc: 0.9058 Pre: 0.9161 Recall: 0.9034 F1: 0.9097 Train AUC: 0.9976 Val AUC: 0.9608 Time: 13.76\n",
      "Epoch: 826 Train Loss: 0.0639 Val Loss: 0.3114 Acc: 0.9112 Pre: 0.9258 Recall: 0.9034 F1: 0.9145 Train AUC: 0.9986 Val AUC: 0.9593 Time: 13.15\n",
      "Epoch: 827 Train Loss: 0.0686 Val Loss: 0.3394 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9979 Val AUC: 0.9576 Time: 14.23\n",
      "Epoch: 828 Train Loss: 0.0599 Val Loss: 0.3534 Acc: 0.8986 Pre: 0.9333 Recall: 0.8690 F1: 0.9000 Train AUC: 0.9986 Val AUC: 0.9572 Time: 14.51\n",
      "Epoch: 829 Train Loss: 0.0664 Val Loss: 0.3355 Acc: 0.9040 Pre: 0.9341 Recall: 0.8793 F1: 0.9059 Train AUC: 0.9977 Val AUC: 0.9579 Time: 14.43\n",
      "Epoch: 830 Train Loss: 0.0657 Val Loss: 0.3176 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9984 Val AUC: 0.9596 Time: 13.23\n",
      "Epoch: 831 Train Loss: 0.0598 Val Loss: 0.3034 Acc: 0.9076 Pre: 0.9193 Recall: 0.9034 F1: 0.9113 Train AUC: 0.9985 Val AUC: 0.9609 Time: 12.52\n",
      "Epoch: 832 Train Loss: 0.0702 Val Loss: 0.2976 Acc: 0.9094 Pre: 0.9255 Recall: 0.9000 F1: 0.9126 Train AUC: 0.9977 Val AUC: 0.9616 Time: 12.35\n",
      "Epoch: 833 Train Loss: 0.0642 Val Loss: 0.2966 Acc: 0.9076 Pre: 0.9253 Recall: 0.8966 F1: 0.9107 Train AUC: 0.9984 Val AUC: 0.9615 Time: 12.90\n",
      "Epoch: 834 Train Loss: 0.0660 Val Loss: 0.3222 Acc: 0.9094 Pre: 0.9478 Recall: 0.8759 F1: 0.9104 Train AUC: 0.9983 Val AUC: 0.9616 Time: 13.26\n",
      "Epoch: 835 Train Loss: 0.0632 Val Loss: 0.3368 Acc: 0.8986 Pre: 0.9535 Recall: 0.8483 F1: 0.8978 Train AUC: 0.9985 Val AUC: 0.9615 Time: 13.77\n",
      "Epoch: 836 Train Loss: 0.0806 Val Loss: 0.3093 Acc: 0.9112 Pre: 0.9319 Recall: 0.8966 F1: 0.9139 Train AUC: 0.9973 Val AUC: 0.9618 Time: 14.72\n",
      "Epoch: 837 Train Loss: 0.0702 Val Loss: 0.3065 Acc: 0.9167 Pre: 0.9296 Recall: 0.9103 F1: 0.9199 Train AUC: 0.9976 Val AUC: 0.9605 Time: 15.16\n",
      "Epoch: 838 Train Loss: 0.0685 Val Loss: 0.3270 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9982 Val AUC: 0.9581 Time: 15.19\n",
      "Epoch: 839 Train Loss: 0.0705 Val Loss: 0.3531 Acc: 0.8967 Pre: 0.9498 Recall: 0.8483 F1: 0.8962 Train AUC: 0.9977 Val AUC: 0.9572 Time: 12.40\n",
      "Epoch: 840 Train Loss: 0.0719 Val Loss: 0.3296 Acc: 0.8967 Pre: 0.9363 Recall: 0.8621 F1: 0.8977 Train AUC: 0.9975 Val AUC: 0.9581 Time: 12.65\n",
      "Epoch: 841 Train Loss: 0.0645 Val Loss: 0.3122 Acc: 0.9022 Pre: 0.9245 Recall: 0.8862 F1: 0.9049 Train AUC: 0.9985 Val AUC: 0.9591 Time: 13.20\n",
      "Epoch: 842 Train Loss: 0.0704 Val Loss: 0.3029 Acc: 0.9076 Pre: 0.9283 Recall: 0.8931 F1: 0.9104 Train AUC: 0.9979 Val AUC: 0.9601 Time: 13.07\n",
      "Epoch: 843 Train Loss: 0.0637 Val Loss: 0.3129 Acc: 0.9076 Pre: 0.9345 Recall: 0.8862 F1: 0.9097 Train AUC: 0.9984 Val AUC: 0.9602 Time: 14.35\n",
      "Epoch: 844 Train Loss: 0.0668 Val Loss: 0.3178 Acc: 0.9040 Pre: 0.9438 Recall: 0.8690 F1: 0.9048 Train AUC: 0.9980 Val AUC: 0.9613 Time: 14.45\n",
      "Epoch: 845 Train Loss: 0.0694 Val Loss: 0.3068 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9979 Val AUC: 0.9606 Time: 14.88\n",
      "Epoch: 846 Train Loss: 0.0663 Val Loss: 0.3010 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9982 Val AUC: 0.9605 Time: 13.30\n",
      "Epoch: 847 Train Loss: 0.0708 Val Loss: 0.3075 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9974 Val AUC: 0.9597 Time: 13.47\n",
      "Epoch: 848 Train Loss: 0.0624 Val Loss: 0.3188 Acc: 0.9094 Pre: 0.9380 Recall: 0.8862 F1: 0.9113 Train AUC: 0.9982 Val AUC: 0.9582 Time: 13.87\n",
      "Epoch: 849 Train Loss: 0.0710 Val Loss: 0.3163 Acc: 0.9149 Pre: 0.9418 Recall: 0.8931 F1: 0.9168 Train AUC: 0.9977 Val AUC: 0.9589 Time: 13.02\n",
      "Epoch: 850 Train Loss: 0.0621 Val Loss: 0.3138 Acc: 0.9221 Pre: 0.9591 Recall: 0.8897 F1: 0.9231 Train AUC: 0.9985 Val AUC: 0.9599 Time: 13.88\n",
      "Epoch: 851 Train Loss: 0.0660 Val Loss: 0.3251 Acc: 0.9076 Pre: 0.9442 Recall: 0.8759 F1: 0.9088 Train AUC: 0.9980 Val AUC: 0.9586 Time: 14.80\n",
      "Epoch: 852 Train Loss: 0.0689 Val Loss: 0.3028 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9985 Val AUC: 0.9607 Time: 14.36\n",
      "Epoch: 853 Train Loss: 0.0680 Val Loss: 0.3057 Acc: 0.9203 Pre: 0.9424 Recall: 0.9034 F1: 0.9225 Train AUC: 0.9984 Val AUC: 0.9625 Time: 13.38\n",
      "Epoch: 854 Train Loss: 0.0612 Val Loss: 0.3234 Acc: 0.9149 Pre: 0.9386 Recall: 0.8966 F1: 0.9171 Train AUC: 0.9983 Val AUC: 0.9613 Time: 13.87\n",
      "Epoch: 855 Train Loss: 0.0720 Val Loss: 0.3192 Acc: 0.9167 Pre: 0.9388 Recall: 0.9000 F1: 0.9190 Train AUC: 0.9972 Val AUC: 0.9604 Time: 12.49\n",
      "Epoch: 856 Train Loss: 0.0704 Val Loss: 0.3109 Acc: 0.9094 Pre: 0.9286 Recall: 0.8966 F1: 0.9123 Train AUC: 0.9976 Val AUC: 0.9583 Time: 13.20\n",
      "Epoch: 857 Train Loss: 0.0715 Val Loss: 0.3381 Acc: 0.9094 Pre: 0.9511 Recall: 0.8724 F1: 0.9101 Train AUC: 0.9982 Val AUC: 0.9554 Time: 13.66\n",
      "Epoch: 858 Train Loss: 0.0700 Val Loss: 0.3660 Acc: 0.9040 Pre: 0.9540 Recall: 0.8586 F1: 0.9038 Train AUC: 0.9978 Val AUC: 0.9540 Time: 14.66\n",
      "Epoch: 859 Train Loss: 0.0647 Val Loss: 0.3531 Acc: 0.8967 Pre: 0.9396 Recall: 0.8586 F1: 0.8973 Train AUC: 0.9983 Val AUC: 0.9554 Time: 15.18\n",
      "Epoch: 860 Train Loss: 0.0707 Val Loss: 0.3155 Acc: 0.9094 Pre: 0.9317 Recall: 0.8931 F1: 0.9120 Train AUC: 0.9976 Val AUC: 0.9597 Time: 15.76\n",
      "Epoch: 861 Train Loss: 0.0576 Val Loss: 0.2898 Acc: 0.9094 Pre: 0.9167 Recall: 0.9103 F1: 0.9135 Train AUC: 0.9988 Val AUC: 0.9630 Time: 14.58\n",
      "Epoch: 862 Train Loss: 0.0638 Val Loss: 0.2925 Acc: 0.9167 Pre: 0.9296 Recall: 0.9103 F1: 0.9199 Train AUC: 0.9987 Val AUC: 0.9636 Time: 13.21\n",
      "Epoch: 863 Train Loss: 0.0816 Val Loss: 0.3248 Acc: 0.9112 Pre: 0.9480 Recall: 0.8793 F1: 0.9123 Train AUC: 0.9967 Val AUC: 0.9613 Time: 12.86\n",
      "Epoch: 864 Train Loss: 0.0630 Val Loss: 0.3271 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9986 Val AUC: 0.9587 Time: 14.00\n",
      "Epoch: 865 Train Loss: 0.0614 Val Loss: 0.3360 Acc: 0.9040 Pre: 0.9373 Recall: 0.8759 F1: 0.9055 Train AUC: 0.9985 Val AUC: 0.9558 Time: 14.35\n",
      "Epoch: 866 Train Loss: 0.0670 Val Loss: 0.3460 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9982 Val AUC: 0.9558 Time: 14.92\n",
      "Epoch: 867 Train Loss: 0.0671 Val Loss: 0.3423 Acc: 0.9130 Pre: 0.9549 Recall: 0.8759 F1: 0.9137 Train AUC: 0.9981 Val AUC: 0.9576 Time: 15.79\n",
      "Epoch: 868 Train Loss: 0.0732 Val Loss: 0.3106 Acc: 0.9130 Pre: 0.9321 Recall: 0.9000 F1: 0.9158 Train AUC: 0.9973 Val AUC: 0.9596 Time: 14.71\n",
      "Epoch: 869 Train Loss: 0.0733 Val Loss: 0.2995 Acc: 0.9130 Pre: 0.9291 Recall: 0.9034 F1: 0.9161 Train AUC: 0.9975 Val AUC: 0.9610 Time: 14.30\n",
      "Epoch: 870 Train Loss: 0.0625 Val Loss: 0.3166 Acc: 0.9130 Pre: 0.9321 Recall: 0.9000 F1: 0.9158 Train AUC: 0.9989 Val AUC: 0.9603 Time: 12.91\n",
      "Epoch: 871 Train Loss: 0.0660 Val Loss: 0.3357 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9981 Val AUC: 0.9594 Time: 13.26\n",
      "Epoch: 872 Train Loss: 0.0710 Val Loss: 0.3395 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9973 Val AUC: 0.9581 Time: 13.28\n",
      "Epoch: 873 Train Loss: 0.0634 Val Loss: 0.3277 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9983 Val AUC: 0.9570 Time: 14.22\n",
      "Epoch: 874 Train Loss: 0.0614 Val Loss: 0.3261 Acc: 0.9058 Pre: 0.9407 Recall: 0.8759 F1: 0.9071 Train AUC: 0.9985 Val AUC: 0.9568 Time: 14.83\n",
      "Epoch: 875 Train Loss: 0.0715 Val Loss: 0.3304 Acc: 0.9167 Pre: 0.9586 Recall: 0.8793 F1: 0.9173 Train AUC: 0.9978 Val AUC: 0.9593 Time: 15.16\n",
      "Epoch: 876 Train Loss: 0.0601 Val Loss: 0.3174 Acc: 0.9149 Pre: 0.9451 Recall: 0.8897 F1: 0.9165 Train AUC: 0.9984 Val AUC: 0.9606 Time: 13.36\n",
      "Epoch: 877 Train Loss: 0.0636 Val Loss: 0.2997 Acc: 0.9112 Pre: 0.9258 Recall: 0.9034 F1: 0.9145 Train AUC: 0.9986 Val AUC: 0.9617 Time: 13.01\n",
      "Epoch: 878 Train Loss: 0.0598 Val Loss: 0.3084 Acc: 0.9130 Pre: 0.9291 Recall: 0.9034 F1: 0.9161 Train AUC: 0.9989 Val AUC: 0.9595 Time: 13.83\n",
      "Epoch: 879 Train Loss: 0.0688 Val Loss: 0.3177 Acc: 0.9112 Pre: 0.9288 Recall: 0.9000 F1: 0.9142 Train AUC: 0.9981 Val AUC: 0.9588 Time: 14.38\n",
      "Epoch: 880 Train Loss: 0.0623 Val Loss: 0.3138 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9986 Val AUC: 0.9600 Time: 14.24\n",
      "Epoch: 881 Train Loss: 0.0639 Val Loss: 0.3324 Acc: 0.9112 Pre: 0.9547 Recall: 0.8724 F1: 0.9117 Train AUC: 0.9985 Val AUC: 0.9615 Time: 12.51\n",
      "Epoch: 882 Train Loss: 0.0714 Val Loss: 0.3125 Acc: 0.9149 Pre: 0.9418 Recall: 0.8931 F1: 0.9168 Train AUC: 0.9980 Val AUC: 0.9618 Time: 12.60\n",
      "Epoch: 883 Train Loss: 0.0689 Val Loss: 0.3086 Acc: 0.9112 Pre: 0.9350 Recall: 0.8931 F1: 0.9136 Train AUC: 0.9980 Val AUC: 0.9604 Time: 12.96\n",
      "Epoch: 884 Train Loss: 0.0606 Val Loss: 0.3167 Acc: 0.9040 Pre: 0.9247 Recall: 0.8897 F1: 0.9069 Train AUC: 0.9988 Val AUC: 0.9575 Time: 13.80\n",
      "Epoch: 885 Train Loss: 0.0785 Val Loss: 0.3279 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9973 Val AUC: 0.9583 Time: 13.88\n",
      "Epoch: 886 Train Loss: 0.0668 Val Loss: 0.3322 Acc: 0.9094 Pre: 0.9511 Recall: 0.8724 F1: 0.9101 Train AUC: 0.9980 Val AUC: 0.9593 Time: 14.68\n",
      "Epoch: 887 Train Loss: 0.0664 Val Loss: 0.3217 Acc: 0.9149 Pre: 0.9551 Recall: 0.8793 F1: 0.9156 Train AUC: 0.9987 Val AUC: 0.9589 Time: 15.30\n",
      "Epoch: 888 Train Loss: 0.0688 Val Loss: 0.3169 Acc: 0.9185 Pre: 0.9455 Recall: 0.8966 F1: 0.9204 Train AUC: 0.9982 Val AUC: 0.9589 Time: 14.11\n",
      "Epoch: 889 Train Loss: 0.0687 Val Loss: 0.3202 Acc: 0.9203 Pre: 0.9424 Recall: 0.9034 F1: 0.9225 Train AUC: 0.9978 Val AUC: 0.9600 Time: 12.66\n",
      "Epoch: 890 Train Loss: 0.0695 Val Loss: 0.3306 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9975 Val AUC: 0.9591 Time: 12.84\n",
      "Epoch: 891 Train Loss: 0.0793 Val Loss: 0.3222 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9963 Val AUC: 0.9591 Time: 13.47\n",
      "Epoch: 892 Train Loss: 0.0677 Val Loss: 0.3354 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9979 Val AUC: 0.9593 Time: 13.77\n",
      "Epoch: 893 Train Loss: 0.0689 Val Loss: 0.3300 Acc: 0.9040 Pre: 0.9472 Recall: 0.8655 F1: 0.9045 Train AUC: 0.9978 Val AUC: 0.9574 Time: 14.55\n",
      "Epoch: 894 Train Loss: 0.0657 Val Loss: 0.3205 Acc: 0.9076 Pre: 0.9253 Recall: 0.8966 F1: 0.9107 Train AUC: 0.9984 Val AUC: 0.9565 Time: 14.72\n",
      "Epoch: 895 Train Loss: 0.0663 Val Loss: 0.3192 Acc: 0.9076 Pre: 0.9253 Recall: 0.8966 F1: 0.9107 Train AUC: 0.9984 Val AUC: 0.9570 Time: 14.86\n",
      "Epoch: 896 Train Loss: 0.0663 Val Loss: 0.3213 Acc: 0.9040 Pre: 0.9309 Recall: 0.8828 F1: 0.9062 Train AUC: 0.9981 Val AUC: 0.9572 Time: 12.22\n",
      "Epoch: 897 Train Loss: 0.0622 Val Loss: 0.3304 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9983 Val AUC: 0.9572 Time: 12.56\n",
      "Epoch: 898 Train Loss: 0.0681 Val Loss: 0.3221 Acc: 0.9004 Pre: 0.9304 Recall: 0.8759 F1: 0.9023 Train AUC: 0.9980 Val AUC: 0.9592 Time: 12.60\n",
      "Epoch: 899 Train Loss: 0.0688 Val Loss: 0.2982 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9979 Val AUC: 0.9618 Time: 13.54\n",
      "Epoch: 900 Train Loss: 0.0693 Val Loss: 0.3010 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9981 Val AUC: 0.9633 Time: 14.15\n",
      "Epoch: 901 Train Loss: 0.0623 Val Loss: 0.3147 Acc: 0.9076 Pre: 0.9377 Recall: 0.8828 F1: 0.9094 Train AUC: 0.9984 Val AUC: 0.9617 Time: 14.52\n",
      "Epoch: 902 Train Loss: 0.0717 Val Loss: 0.3190 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9972 Val AUC: 0.9606 Time: 15.04\n",
      "Epoch: 903 Train Loss: 0.0574 Val Loss: 0.3232 Acc: 0.9076 Pre: 0.9410 Recall: 0.8793 F1: 0.9091 Train AUC: 0.9987 Val AUC: 0.9583 Time: 14.76\n",
      "Epoch: 904 Train Loss: 0.0677 Val Loss: 0.3306 Acc: 0.9004 Pre: 0.9273 Recall: 0.8793 F1: 0.9027 Train AUC: 0.9981 Val AUC: 0.9534 Time: 14.09\n",
      "Epoch: 905 Train Loss: 0.0801 Val Loss: 0.3294 Acc: 0.9058 Pre: 0.9440 Recall: 0.8724 F1: 0.9068 Train AUC: 0.9971 Val AUC: 0.9560 Time: 13.43\n",
      "Epoch: 906 Train Loss: 0.0653 Val Loss: 0.3353 Acc: 0.9149 Pre: 0.9483 Recall: 0.8862 F1: 0.9162 Train AUC: 0.9983 Val AUC: 0.9586 Time: 13.18\n",
      "Epoch: 907 Train Loss: 0.0715 Val Loss: 0.3185 Acc: 0.9257 Pre: 0.9495 Recall: 0.9069 F1: 0.9277 Train AUC: 0.9971 Val AUC: 0.9617 Time: 12.48\n",
      "Epoch: 908 Train Loss: 0.0817 Val Loss: 0.2945 Acc: 0.9203 Pre: 0.9362 Recall: 0.9103 F1: 0.9231 Train AUC: 0.9961 Val AUC: 0.9631 Time: 13.27\n",
      "Epoch: 909 Train Loss: 0.0788 Val Loss: 0.2993 Acc: 0.9167 Pre: 0.9357 Recall: 0.9034 F1: 0.9193 Train AUC: 0.9970 Val AUC: 0.9619 Time: 13.24\n",
      "Epoch: 910 Train Loss: 0.0693 Val Loss: 0.3333 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9980 Val AUC: 0.9597 Time: 14.34\n",
      "Epoch: 911 Train Loss: 0.0813 Val Loss: 0.3330 Acc: 0.9004 Pre: 0.9336 Recall: 0.8724 F1: 0.9020 Train AUC: 0.9967 Val AUC: 0.9573 Time: 14.51\n",
      "Epoch: 912 Train Loss: 0.0720 Val Loss: 0.3080 Acc: 0.9094 Pre: 0.9225 Recall: 0.9034 F1: 0.9129 Train AUC: 0.9971 Val AUC: 0.9595 Time: 14.50\n",
      "Epoch: 913 Train Loss: 0.0638 Val Loss: 0.3023 Acc: 0.9094 Pre: 0.9255 Recall: 0.9000 F1: 0.9126 Train AUC: 0.9987 Val AUC: 0.9601 Time: 15.08\n",
      "Epoch: 914 Train Loss: 0.0607 Val Loss: 0.3015 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9988 Val AUC: 0.9614 Time: 12.37\n",
      "Epoch: 915 Train Loss: 0.0665 Val Loss: 0.3075 Acc: 0.9149 Pre: 0.9451 Recall: 0.8897 F1: 0.9165 Train AUC: 0.9986 Val AUC: 0.9618 Time: 12.69\n",
      "Epoch: 916 Train Loss: 0.0679 Val Loss: 0.3112 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9981 Val AUC: 0.9607 Time: 12.53\n",
      "Epoch: 917 Train Loss: 0.0704 Val Loss: 0.3105 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9978 Val AUC: 0.9602 Time: 12.66\n",
      "Epoch: 918 Train Loss: 0.0569 Val Loss: 0.3180 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9987 Val AUC: 0.9605 Time: 13.66\n",
      "Epoch: 919 Train Loss: 0.0673 Val Loss: 0.3289 Acc: 0.9076 Pre: 0.9476 Recall: 0.8724 F1: 0.9084 Train AUC: 0.9980 Val AUC: 0.9594 Time: 14.22\n",
      "Epoch: 920 Train Loss: 0.0666 Val Loss: 0.3166 Acc: 0.9058 Pre: 0.9250 Recall: 0.8931 F1: 0.9088 Train AUC: 0.9984 Val AUC: 0.9580 Time: 14.74\n",
      "Epoch: 921 Train Loss: 0.0700 Val Loss: 0.3207 Acc: 0.9130 Pre: 0.9321 Recall: 0.9000 F1: 0.9158 Train AUC: 0.9978 Val AUC: 0.9570 Time: 15.34\n",
      "Epoch: 922 Train Loss: 0.0679 Val Loss: 0.3388 Acc: 0.9094 Pre: 0.9444 Recall: 0.8793 F1: 0.9107 Train AUC: 0.9982 Val AUC: 0.9581 Time: 13.88\n",
      "Epoch: 923 Train Loss: 0.0674 Val Loss: 0.3370 Acc: 0.9130 Pre: 0.9583 Recall: 0.8724 F1: 0.9134 Train AUC: 0.9978 Val AUC: 0.9593 Time: 14.95\n",
      "Epoch: 924 Train Loss: 0.0702 Val Loss: 0.3228 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9975 Val AUC: 0.9592 Time: 12.48\n",
      "Epoch: 925 Train Loss: 0.0674 Val Loss: 0.3214 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9983 Val AUC: 0.9583 Time: 12.74\n",
      "Epoch: 926 Train Loss: 0.0693 Val Loss: 0.3177 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9982 Val AUC: 0.9600 Time: 12.61\n",
      "Epoch: 927 Train Loss: 0.0660 Val Loss: 0.3256 Acc: 0.9058 Pre: 0.9440 Recall: 0.8724 F1: 0.9068 Train AUC: 0.9980 Val AUC: 0.9623 Time: 12.64\n",
      "Epoch: 928 Train Loss: 0.0704 Val Loss: 0.3104 Acc: 0.9112 Pre: 0.9480 Recall: 0.8793 F1: 0.9123 Train AUC: 0.9972 Val AUC: 0.9643 Time: 12.49\n",
      "Epoch: 929 Train Loss: 0.0647 Val Loss: 0.2892 Acc: 0.9167 Pre: 0.9296 Recall: 0.9103 F1: 0.9199 Train AUC: 0.9983 Val AUC: 0.9626 Time: 13.77\n",
      "Epoch: 930 Train Loss: 0.0695 Val Loss: 0.3109 Acc: 0.8986 Pre: 0.9179 Recall: 0.8862 F1: 0.9018 Train AUC: 0.9982 Val AUC: 0.9581 Time: 13.97\n",
      "Epoch: 931 Train Loss: 0.0706 Val Loss: 0.3365 Acc: 0.9022 Pre: 0.9338 Recall: 0.8759 F1: 0.9039 Train AUC: 0.9980 Val AUC: 0.9535 Time: 14.73\n",
      "Epoch: 932 Train Loss: 0.0674 Val Loss: 0.3698 Acc: 0.9040 Pre: 0.9540 Recall: 0.8586 F1: 0.9038 Train AUC: 0.9983 Val AUC: 0.9534 Time: 15.72\n",
      "Epoch: 933 Train Loss: 0.0672 Val Loss: 0.3588 Acc: 0.8967 Pre: 0.9430 Recall: 0.8552 F1: 0.8969 Train AUC: 0.9977 Val AUC: 0.9566 Time: 14.77\n",
      "Epoch: 934 Train Loss: 0.0618 Val Loss: 0.3276 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9986 Val AUC: 0.9600 Time: 14.81\n",
      "Epoch: 935 Train Loss: 0.0617 Val Loss: 0.3009 Acc: 0.9221 Pre: 0.9458 Recall: 0.9034 F1: 0.9242 Train AUC: 0.9984 Val AUC: 0.9635 Time: 12.30\n",
      "Epoch: 936 Train Loss: 0.0633 Val Loss: 0.2787 Acc: 0.9275 Pre: 0.9464 Recall: 0.9138 F1: 0.9298 Train AUC: 0.9985 Val AUC: 0.9660 Time: 12.49\n",
      "Epoch: 937 Train Loss: 0.0687 Val Loss: 0.2930 Acc: 0.9167 Pre: 0.9388 Recall: 0.9000 F1: 0.9190 Train AUC: 0.9983 Val AUC: 0.9649 Time: 12.53\n",
      "Epoch: 938 Train Loss: 0.0707 Val Loss: 0.3063 Acc: 0.9185 Pre: 0.9487 Recall: 0.8931 F1: 0.9201 Train AUC: 0.9973 Val AUC: 0.9626 Time: 13.37\n",
      "Epoch: 939 Train Loss: 0.0675 Val Loss: 0.3112 Acc: 0.9094 Pre: 0.9380 Recall: 0.8862 F1: 0.9113 Train AUC: 0.9982 Val AUC: 0.9593 Time: 13.46\n",
      "Epoch: 940 Train Loss: 0.0547 Val Loss: 0.3219 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9991 Val AUC: 0.9574 Time: 14.40\n",
      "Epoch: 941 Train Loss: 0.0591 Val Loss: 0.3495 Acc: 0.9058 Pre: 0.9440 Recall: 0.8724 F1: 0.9068 Train AUC: 0.9991 Val AUC: 0.9562 Time: 15.18\n",
      "Epoch: 942 Train Loss: 0.0728 Val Loss: 0.3271 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9973 Val AUC: 0.9588 Time: 14.41\n",
      "Epoch: 943 Train Loss: 0.0652 Val Loss: 0.2942 Acc: 0.9167 Pre: 0.9296 Recall: 0.9103 F1: 0.9199 Train AUC: 0.9979 Val AUC: 0.9627 Time: 15.06\n",
      "Epoch: 944 Train Loss: 0.0626 Val Loss: 0.3003 Acc: 0.9167 Pre: 0.9420 Recall: 0.8966 F1: 0.9187 Train AUC: 0.9988 Val AUC: 0.9635 Time: 12.52\n",
      "Epoch: 945 Train Loss: 0.0701 Val Loss: 0.3274 Acc: 0.9040 Pre: 0.9405 Recall: 0.8724 F1: 0.9052 Train AUC: 0.9978 Val AUC: 0.9618 Time: 13.01\n",
      "Epoch: 946 Train Loss: 0.0646 Val Loss: 0.3299 Acc: 0.9112 Pre: 0.9513 Recall: 0.8759 F1: 0.9120 Train AUC: 0.9980 Val AUC: 0.9606 Time: 13.14\n",
      "Epoch: 947 Train Loss: 0.0680 Val Loss: 0.3015 Acc: 0.9058 Pre: 0.9132 Recall: 0.9069 F1: 0.9100 Train AUC: 0.9979 Val AUC: 0.9593 Time: 13.89\n",
      "Epoch: 948 Train Loss: 0.0718 Val Loss: 0.3033 Acc: 0.9076 Pre: 0.9193 Recall: 0.9034 F1: 0.9113 Train AUC: 0.9977 Val AUC: 0.9586 Time: 14.64\n",
      "Epoch: 949 Train Loss: 0.0758 Val Loss: 0.3368 Acc: 0.9185 Pre: 0.9520 Recall: 0.8897 F1: 0.9198 Train AUC: 0.9976 Val AUC: 0.9576 Time: 14.43\n",
      "Epoch: 950 Train Loss: 0.0638 Val Loss: 0.3728 Acc: 0.8949 Pre: 0.9462 Recall: 0.8483 F1: 0.8945 Train AUC: 0.9980 Val AUC: 0.9566 Time: 14.49\n",
      "Epoch: 951 Train Loss: 0.0626 Val Loss: 0.3466 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9983 Val AUC: 0.9581 Time: 12.44\n",
      "Epoch: 952 Train Loss: 0.0656 Val Loss: 0.3028 Acc: 0.9203 Pre: 0.9362 Recall: 0.9103 F1: 0.9231 Train AUC: 0.9979 Val AUC: 0.9616 Time: 12.47\n",
      "Epoch: 953 Train Loss: 0.0682 Val Loss: 0.2943 Acc: 0.9167 Pre: 0.9357 Recall: 0.9034 F1: 0.9193 Train AUC: 0.9985 Val AUC: 0.9627 Time: 13.07\n",
      "Epoch: 954 Train Loss: 0.0560 Val Loss: 0.3079 Acc: 0.9185 Pre: 0.9391 Recall: 0.9034 F1: 0.9209 Train AUC: 0.9992 Val AUC: 0.9625 Time: 13.39\n",
      "Epoch: 955 Train Loss: 0.0631 Val Loss: 0.3266 Acc: 0.9004 Pre: 0.9434 Recall: 0.8621 F1: 0.9009 Train AUC: 0.9981 Val AUC: 0.9611 Time: 14.13\n",
      "Epoch: 956 Train Loss: 0.0761 Val Loss: 0.3261 Acc: 0.9130 Pre: 0.9549 Recall: 0.8759 F1: 0.9137 Train AUC: 0.9971 Val AUC: 0.9599 Time: 14.77\n",
      "Epoch: 957 Train Loss: 0.0678 Val Loss: 0.3071 Acc: 0.9167 Pre: 0.9485 Recall: 0.8897 F1: 0.9181 Train AUC: 0.9981 Val AUC: 0.9589 Time: 15.08\n",
      "Epoch: 958 Train Loss: 0.0634 Val Loss: 0.3058 Acc: 0.9167 Pre: 0.9485 Recall: 0.8897 F1: 0.9181 Train AUC: 0.9979 Val AUC: 0.9589 Time: 15.06\n",
      "Epoch: 959 Train Loss: 0.0567 Val Loss: 0.3080 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9990 Val AUC: 0.9609 Time: 12.45\n",
      "Epoch: 960 Train Loss: 0.0616 Val Loss: 0.2936 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9984 Val AUC: 0.9637 Time: 12.33\n",
      "Epoch: 961 Train Loss: 0.0741 Val Loss: 0.2916 Acc: 0.9112 Pre: 0.9319 Recall: 0.8966 F1: 0.9139 Train AUC: 0.9973 Val AUC: 0.9638 Time: 12.42\n",
      "Epoch: 962 Train Loss: 0.0568 Val Loss: 0.3077 Acc: 0.9149 Pre: 0.9386 Recall: 0.8966 F1: 0.9171 Train AUC: 0.9990 Val AUC: 0.9617 Time: 13.18\n",
      "Epoch: 963 Train Loss: 0.0633 Val Loss: 0.3099 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9982 Val AUC: 0.9606 Time: 13.46\n",
      "Epoch: 964 Train Loss: 0.0582 Val Loss: 0.3109 Acc: 0.9167 Pre: 0.9420 Recall: 0.8966 F1: 0.9187 Train AUC: 0.9990 Val AUC: 0.9588 Time: 14.24\n",
      "Epoch: 965 Train Loss: 0.0653 Val Loss: 0.3132 Acc: 0.9112 Pre: 0.9414 Recall: 0.8862 F1: 0.9130 Train AUC: 0.9981 Val AUC: 0.9584 Time: 14.88\n",
      "Epoch: 966 Train Loss: 0.0674 Val Loss: 0.3432 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9984 Val AUC: 0.9581 Time: 14.71\n",
      "Epoch: 967 Train Loss: 0.0698 Val Loss: 0.3353 Acc: 0.9022 Pre: 0.9275 Recall: 0.8828 F1: 0.9046 Train AUC: 0.9982 Val AUC: 0.9586 Time: 15.48\n",
      "Epoch: 968 Train Loss: 0.0657 Val Loss: 0.3077 Acc: 0.9130 Pre: 0.9291 Recall: 0.9034 F1: 0.9161 Train AUC: 0.9981 Val AUC: 0.9603 Time: 12.32\n",
      "Epoch: 969 Train Loss: 0.0566 Val Loss: 0.2945 Acc: 0.9112 Pre: 0.9258 Recall: 0.9034 F1: 0.9145 Train AUC: 0.9988 Val AUC: 0.9618 Time: 13.00\n",
      "Epoch: 970 Train Loss: 0.0657 Val Loss: 0.3115 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9986 Val AUC: 0.9608 Time: 13.46\n",
      "Epoch: 971 Train Loss: 0.0660 Val Loss: 0.3617 Acc: 0.9004 Pre: 0.9681 Recall: 0.8379 F1: 0.8983 Train AUC: 0.9980 Val AUC: 0.9603 Time: 13.73\n",
      "Epoch: 972 Train Loss: 0.0720 Val Loss: 0.3203 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9984 Val AUC: 0.9608 Time: 14.07\n",
      "Epoch: 973 Train Loss: 0.0599 Val Loss: 0.2972 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9986 Val AUC: 0.9616 Time: 13.95\n",
      "Epoch: 974 Train Loss: 0.0629 Val Loss: 0.2884 Acc: 0.9040 Pre: 0.9187 Recall: 0.8966 F1: 0.9075 Train AUC: 0.9984 Val AUC: 0.9619 Time: 14.29\n",
      "Epoch: 975 Train Loss: 0.0584 Val Loss: 0.3052 Acc: 0.9022 Pre: 0.9307 Recall: 0.8793 F1: 0.9043 Train AUC: 0.9989 Val AUC: 0.9600 Time: 13.52\n",
      "Epoch: 976 Train Loss: 0.0613 Val Loss: 0.3338 Acc: 0.9112 Pre: 0.9582 Recall: 0.8690 F1: 0.9114 Train AUC: 0.9989 Val AUC: 0.9582 Time: 13.85\n",
      "Epoch: 977 Train Loss: 0.0610 Val Loss: 0.3364 Acc: 0.9130 Pre: 0.9515 Recall: 0.8793 F1: 0.9140 Train AUC: 0.9988 Val AUC: 0.9583 Time: 13.40\n",
      "Epoch: 978 Train Loss: 0.0650 Val Loss: 0.3107 Acc: 0.9203 Pre: 0.9393 Recall: 0.9069 F1: 0.9228 Train AUC: 0.9979 Val AUC: 0.9590 Time: 14.19\n",
      "Epoch: 979 Train Loss: 0.0688 Val Loss: 0.3129 Acc: 0.9149 Pre: 0.9386 Recall: 0.8966 F1: 0.9171 Train AUC: 0.9980 Val AUC: 0.9604 Time: 14.51\n",
      "Epoch: 980 Train Loss: 0.0618 Val Loss: 0.3319 Acc: 0.9022 Pre: 0.9403 Recall: 0.8690 F1: 0.9032 Train AUC: 0.9983 Val AUC: 0.9598 Time: 14.78\n",
      "Epoch: 981 Train Loss: 0.0619 Val Loss: 0.3281 Acc: 0.9058 Pre: 0.9407 Recall: 0.8759 F1: 0.9071 Train AUC: 0.9982 Val AUC: 0.9599 Time: 13.80\n",
      "Epoch: 982 Train Loss: 0.0655 Val Loss: 0.3154 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9980 Val AUC: 0.9592 Time: 12.54\n",
      "Epoch: 983 Train Loss: 0.0605 Val Loss: 0.3016 Acc: 0.9094 Pre: 0.9225 Recall: 0.9034 F1: 0.9129 Train AUC: 0.9986 Val AUC: 0.9602 Time: 13.45\n",
      "Epoch: 984 Train Loss: 0.0603 Val Loss: 0.3151 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9988 Val AUC: 0.9594 Time: 13.69\n",
      "Epoch: 985 Train Loss: 0.0610 Val Loss: 0.3358 Acc: 0.9076 Pre: 0.9442 Recall: 0.8759 F1: 0.9088 Train AUC: 0.9987 Val AUC: 0.9593 Time: 13.86\n",
      "Epoch: 986 Train Loss: 0.0705 Val Loss: 0.2999 Acc: 0.9058 Pre: 0.9281 Recall: 0.8897 F1: 0.9085 Train AUC: 0.9976 Val AUC: 0.9618 Time: 14.32\n",
      "Epoch: 987 Train Loss: 0.0585 Val Loss: 0.2889 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9984 Val AUC: 0.9624 Time: 15.11\n",
      "Epoch: 988 Train Loss: 0.0575 Val Loss: 0.3066 Acc: 0.9094 Pre: 0.9412 Recall: 0.8828 F1: 0.9110 Train AUC: 0.9992 Val AUC: 0.9625 Time: 12.96\n",
      "Epoch: 989 Train Loss: 0.0621 Val Loss: 0.3443 Acc: 0.9022 Pre: 0.9470 Recall: 0.8621 F1: 0.9025 Train AUC: 0.9987 Val AUC: 0.9603 Time: 12.77\n",
      "Epoch: 990 Train Loss: 0.0789 Val Loss: 0.3092 Acc: 0.9167 Pre: 0.9420 Recall: 0.8966 F1: 0.9187 Train AUC: 0.9972 Val AUC: 0.9616 Time: 12.75\n",
      "Epoch: 991 Train Loss: 0.0681 Val Loss: 0.2960 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9980 Val AUC: 0.9623 Time: 13.27\n",
      "Epoch: 992 Train Loss: 0.0564 Val Loss: 0.3083 Acc: 0.9094 Pre: 0.9348 Recall: 0.8897 F1: 0.9117 Train AUC: 0.9990 Val AUC: 0.9607 Time: 14.46\n",
      "Epoch: 993 Train Loss: 0.0654 Val Loss: 0.3571 Acc: 0.9094 Pre: 0.9545 Recall: 0.8690 F1: 0.9097 Train AUC: 0.9982 Val AUC: 0.9577 Time: 14.63\n",
      "Epoch: 994 Train Loss: 0.0697 Val Loss: 0.3510 Acc: 0.9040 Pre: 0.9540 Recall: 0.8586 F1: 0.9038 Train AUC: 0.9983 Val AUC: 0.9568 Time: 14.63\n",
      "Epoch: 995 Train Loss: 0.0605 Val Loss: 0.3257 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9987 Val AUC: 0.9573 Time: 13.89\n",
      "Epoch: 996 Train Loss: 0.0647 Val Loss: 0.3065 Acc: 0.9130 Pre: 0.9353 Recall: 0.8966 F1: 0.9155 Train AUC: 0.9987 Val AUC: 0.9610 Time: 12.30\n",
      "Epoch: 997 Train Loss: 0.0614 Val Loss: 0.3033 Acc: 0.9130 Pre: 0.9449 Recall: 0.8862 F1: 0.9146 Train AUC: 0.9987 Val AUC: 0.9644 Time: 12.46\n",
      "Epoch: 998 Train Loss: 0.0582 Val Loss: 0.3118 Acc: 0.9076 Pre: 0.9476 Recall: 0.8724 F1: 0.9084 Train AUC: 0.9990 Val AUC: 0.9643 Time: 13.35\n",
      "Epoch: 999 Train Loss: 0.0603 Val Loss: 0.2947 Acc: 0.9130 Pre: 0.9416 Recall: 0.8897 F1: 0.9149 Train AUC: 0.9988 Val AUC: 0.9633 Time: 13.55\n",
      "Epoch: 1000 Train Loss: 0.0577 Val Loss: 0.2951 Acc: 0.9022 Pre: 0.9184 Recall: 0.8931 F1: 0.9056 Train AUC: 0.9990 Val AUC: 0.9611 Time: 14.20\n",
      "Fold: 3 Best Epoch: 936 Test acc: 0.9275 Test Pre: 0.9464 Test Recall: 0.9138 Test F1: 0.9298 Test PRC: 0.9731 Test AUC: 0.9660\n",
      "Training for Fold 4\n",
      "## Training edges: 2208\n",
      "## Testing edges: 552\n",
      "Epoch: 1 Train Loss: 0.9143 Val Loss: 1.8084 Acc: 0.5000 Pre: 0.4493 Recall: 0.5000 F1: 0.4733 Train AUC: 0.5554 Val AUC: 0.5878 Time: 14.83\n",
      "Epoch: 2 Train Loss: 1.8876 Val Loss: 0.6842 Acc: 0.5435 Pre: 0.4931 Recall: 0.5726 F1: 0.5299 Train AUC: 0.5716 Val AUC: 0.6841 Time: 14.56\n",
      "Epoch: 3 Train Loss: 0.8402 Val Loss: 0.5946 Acc: 0.6830 Pre: 0.5995 Recall: 0.8871 F1: 0.7154 Train AUC: 0.6154 Val AUC: 0.8104 Time: 13.28\n",
      "Epoch: 4 Train Loss: 0.8607 Val Loss: 0.4737 Acc: 0.7301 Pre: 0.6562 Recall: 0.8387 F1: 0.7363 Train AUC: 0.6256 Val AUC: 0.8791 Time: 13.62\n",
      "Epoch: 5 Train Loss: 0.6300 Val Loss: 0.4260 Acc: 0.7971 Pre: 0.7833 Recall: 0.7581 F1: 0.7705 Train AUC: 0.7893 Val AUC: 0.8808 Time: 13.12\n",
      "Epoch: 6 Train Loss: 0.5908 Val Loss: 0.3799 Acc: 0.8351 Pre: 0.8685 Recall: 0.7460 F1: 0.8026 Train AUC: 0.7994 Val AUC: 0.9040 Time: 13.77\n",
      "Epoch: 7 Train Loss: 0.5625 Val Loss: 0.3889 Acc: 0.8152 Pre: 0.8093 Recall: 0.7702 F1: 0.7893 Train AUC: 0.8449 Val AUC: 0.9067 Time: 14.09\n",
      "Epoch: 8 Train Loss: 0.4953 Val Loss: 0.4428 Acc: 0.8116 Pre: 0.7857 Recall: 0.7984 F1: 0.7920 Train AUC: 0.8668 Val AUC: 0.8992 Time: 14.35\n",
      "Epoch: 9 Train Loss: 0.5646 Val Loss: 0.4620 Acc: 0.8152 Pre: 0.7829 Recall: 0.8145 F1: 0.7984 Train AUC: 0.8619 Val AUC: 0.8976 Time: 14.03\n",
      "Epoch: 10 Train Loss: 0.6073 Val Loss: 0.4330 Acc: 0.8188 Pre: 0.8109 Recall: 0.7782 F1: 0.7942 Train AUC: 0.8603 Val AUC: 0.9043 Time: 13.28\n",
      "Epoch: 11 Train Loss: 0.5578 Val Loss: 0.4042 Acc: 0.8333 Pre: 0.8482 Recall: 0.7661 F1: 0.8051 Train AUC: 0.8600 Val AUC: 0.9114 Time: 16.00\n",
      "Epoch: 12 Train Loss: 0.5269 Val Loss: 0.3876 Acc: 0.8370 Pre: 0.8591 Recall: 0.7621 F1: 0.8077 Train AUC: 0.8838 Val AUC: 0.9154 Time: 15.21\n",
      "Epoch: 13 Train Loss: 0.4979 Val Loss: 0.3785 Acc: 0.8351 Pre: 0.8552 Recall: 0.7621 F1: 0.8060 Train AUC: 0.8796 Val AUC: 0.9143 Time: 16.03\n",
      "Epoch: 14 Train Loss: 0.4904 Val Loss: 0.3738 Acc: 0.8333 Pre: 0.8333 Recall: 0.7863 F1: 0.8091 Train AUC: 0.8801 Val AUC: 0.9126 Time: 14.03\n",
      "Epoch: 15 Train Loss: 0.4734 Val Loss: 0.3718 Acc: 0.8261 Pre: 0.8140 Recall: 0.7944 F1: 0.8041 Train AUC: 0.8720 Val AUC: 0.9118 Time: 14.62\n",
      "Epoch: 16 Train Loss: 0.4580 Val Loss: 0.3628 Acc: 0.8279 Pre: 0.8174 Recall: 0.7944 F1: 0.8057 Train AUC: 0.8827 Val AUC: 0.9136 Time: 14.26\n",
      "Epoch: 17 Train Loss: 0.4298 Val Loss: 0.3514 Acc: 0.8370 Pre: 0.8319 Recall: 0.7984 F1: 0.8148 Train AUC: 0.8880 Val AUC: 0.9180 Time: 12.62\n",
      "Epoch: 18 Train Loss: 0.4386 Val Loss: 0.3477 Acc: 0.8315 Pre: 0.8270 Recall: 0.7903 F1: 0.8082 Train AUC: 0.8772 Val AUC: 0.9216 Time: 12.00\n",
      "Epoch: 19 Train Loss: 0.4469 Val Loss: 0.3452 Acc: 0.8406 Pre: 0.8361 Recall: 0.8024 F1: 0.8189 Train AUC: 0.8725 Val AUC: 0.9235 Time: 12.81\n",
      "Epoch: 20 Train Loss: 0.4337 Val Loss: 0.3436 Acc: 0.8424 Pre: 0.8340 Recall: 0.8105 F1: 0.8221 Train AUC: 0.8783 Val AUC: 0.9233 Time: 12.94\n",
      "Epoch: 21 Train Loss: 0.4725 Val Loss: 0.3402 Acc: 0.8388 Pre: 0.8299 Recall: 0.8065 F1: 0.8180 Train AUC: 0.8534 Val AUC: 0.9229 Time: 13.47\n",
      "Epoch: 22 Train Loss: 0.4172 Val Loss: 0.3370 Acc: 0.8388 Pre: 0.8354 Recall: 0.7984 F1: 0.8165 Train AUC: 0.8876 Val AUC: 0.9237 Time: 14.03\n",
      "Epoch: 23 Train Loss: 0.3948 Val Loss: 0.3342 Acc: 0.8351 Pre: 0.8340 Recall: 0.7903 F1: 0.8116 Train AUC: 0.8986 Val AUC: 0.9243 Time: 14.20\n",
      "Epoch: 24 Train Loss: 0.3907 Val Loss: 0.3327 Acc: 0.8351 Pre: 0.8458 Recall: 0.7742 F1: 0.8084 Train AUC: 0.9040 Val AUC: 0.9250 Time: 14.02\n",
      "Epoch: 25 Train Loss: 0.3970 Val Loss: 0.3323 Acc: 0.8388 Pre: 0.8533 Recall: 0.7742 F1: 0.8118 Train AUC: 0.8997 Val AUC: 0.9253 Time: 13.33\n",
      "Epoch: 26 Train Loss: 0.3804 Val Loss: 0.3322 Acc: 0.8406 Pre: 0.8540 Recall: 0.7782 F1: 0.8143 Train AUC: 0.9071 Val AUC: 0.9255 Time: 12.63\n",
      "Epoch: 27 Train Loss: 0.3838 Val Loss: 0.3353 Acc: 0.8370 Pre: 0.8435 Recall: 0.7823 F1: 0.8117 Train AUC: 0.9085 Val AUC: 0.9251 Time: 13.79\n",
      "Epoch: 28 Train Loss: 0.3938 Val Loss: 0.3380 Acc: 0.8315 Pre: 0.8189 Recall: 0.8024 F1: 0.8106 Train AUC: 0.9039 Val AUC: 0.9248 Time: 14.33\n",
      "Epoch: 29 Train Loss: 0.3858 Val Loss: 0.3389 Acc: 0.8315 Pre: 0.8112 Recall: 0.8145 F1: 0.8129 Train AUC: 0.9058 Val AUC: 0.9252 Time: 13.83\n",
      "Epoch: 30 Train Loss: 0.3827 Val Loss: 0.3357 Acc: 0.8351 Pre: 0.8153 Recall: 0.8185 F1: 0.8169 Train AUC: 0.9046 Val AUC: 0.9258 Time: 15.18\n",
      "Epoch: 31 Train Loss: 0.3894 Val Loss: 0.3328 Acc: 0.8351 Pre: 0.8127 Recall: 0.8226 F1: 0.8176 Train AUC: 0.9026 Val AUC: 0.9267 Time: 16.99\n",
      "Epoch: 32 Train Loss: 0.3609 Val Loss: 0.3261 Acc: 0.8388 Pre: 0.8219 Recall: 0.8185 F1: 0.8202 Train AUC: 0.9155 Val AUC: 0.9284 Time: 13.17\n",
      "Epoch: 33 Train Loss: 0.3595 Val Loss: 0.3193 Acc: 0.8460 Pre: 0.8410 Recall: 0.8105 F1: 0.8255 Train AUC: 0.9144 Val AUC: 0.9306 Time: 13.58\n",
      "Epoch: 34 Train Loss: 0.3710 Val Loss: 0.3148 Acc: 0.8460 Pre: 0.8528 Recall: 0.7944 F1: 0.8225 Train AUC: 0.9117 Val AUC: 0.9320 Time: 13.79\n",
      "Epoch: 35 Train Loss: 0.3716 Val Loss: 0.3130 Acc: 0.8551 Pre: 0.8684 Recall: 0.7984 F1: 0.8319 Train AUC: 0.9113 Val AUC: 0.9333 Time: 14.56\n",
      "Epoch: 36 Train Loss: 0.3646 Val Loss: 0.3128 Acc: 0.8587 Pre: 0.8664 Recall: 0.8105 F1: 0.8375 Train AUC: 0.9154 Val AUC: 0.9335 Time: 13.00\n",
      "Epoch: 37 Train Loss: 0.3708 Val Loss: 0.3162 Acc: 0.8533 Pre: 0.8408 Recall: 0.8306 F1: 0.8357 Train AUC: 0.9148 Val AUC: 0.9331 Time: 12.33\n",
      "Epoch: 38 Train Loss: 0.3572 Val Loss: 0.3193 Acc: 0.8442 Pre: 0.8214 Recall: 0.8347 F1: 0.8280 Train AUC: 0.9178 Val AUC: 0.9329 Time: 12.58\n",
      "Epoch: 39 Train Loss: 0.3585 Val Loss: 0.3192 Acc: 0.8442 Pre: 0.8214 Recall: 0.8347 F1: 0.8280 Train AUC: 0.9164 Val AUC: 0.9333 Time: 12.81\n",
      "Epoch: 40 Train Loss: 0.3488 Val Loss: 0.3165 Acc: 0.8478 Pre: 0.8280 Recall: 0.8347 F1: 0.8313 Train AUC: 0.9219 Val AUC: 0.9338 Time: 13.75\n",
      "Epoch: 41 Train Loss: 0.3702 Val Loss: 0.3144 Acc: 0.8496 Pre: 0.8367 Recall: 0.8266 F1: 0.8316 Train AUC: 0.9140 Val AUC: 0.9341 Time: 14.07\n",
      "Epoch: 42 Train Loss: 0.3534 Val Loss: 0.3118 Acc: 0.8460 Pre: 0.8410 Recall: 0.8105 F1: 0.8255 Train AUC: 0.9187 Val AUC: 0.9346 Time: 14.71\n",
      "Epoch: 43 Train Loss: 0.3451 Val Loss: 0.3082 Acc: 0.8605 Pre: 0.8734 Recall: 0.8065 F1: 0.8386 Train AUC: 0.9227 Val AUC: 0.9354 Time: 14.60\n",
      "Epoch: 44 Train Loss: 0.3473 Val Loss: 0.3066 Acc: 0.8659 Pre: 0.8884 Recall: 0.8024 F1: 0.8432 Train AUC: 0.9231 Val AUC: 0.9360 Time: 13.52\n",
      "Epoch: 45 Train Loss: 0.3425 Val Loss: 0.3052 Acc: 0.8678 Pre: 0.9032 Recall: 0.7903 F1: 0.8430 Train AUC: 0.9241 Val AUC: 0.9366 Time: 12.91\n",
      "Epoch: 46 Train Loss: 0.3499 Val Loss: 0.3038 Acc: 0.8714 Pre: 0.9078 Recall: 0.7944 F1: 0.8473 Train AUC: 0.9195 Val AUC: 0.9374 Time: 13.07\n",
      "Epoch: 47 Train Loss: 0.3330 Val Loss: 0.3029 Acc: 0.8696 Pre: 0.8964 Recall: 0.8024 F1: 0.8468 Train AUC: 0.9294 Val AUC: 0.9380 Time: 13.74\n",
      "Epoch: 48 Train Loss: 0.3380 Val Loss: 0.3033 Acc: 0.8696 Pre: 0.8929 Recall: 0.8065 F1: 0.8475 Train AUC: 0.9270 Val AUC: 0.9383 Time: 13.72\n",
      "Epoch: 49 Train Loss: 0.3355 Val Loss: 0.3053 Acc: 0.8750 Pre: 0.8841 Recall: 0.8306 F1: 0.8565 Train AUC: 0.9296 Val AUC: 0.9380 Time: 13.61\n",
      "Epoch: 50 Train Loss: 0.3295 Val Loss: 0.3061 Acc: 0.8750 Pre: 0.8776 Recall: 0.8387 F1: 0.8577 Train AUC: 0.9314 Val AUC: 0.9378 Time: 14.12\n",
      "Epoch: 51 Train Loss: 0.3424 Val Loss: 0.3043 Acc: 0.8732 Pre: 0.8771 Recall: 0.8347 F1: 0.8554 Train AUC: 0.9256 Val AUC: 0.9382 Time: 14.08\n",
      "Epoch: 52 Train Loss: 0.3307 Val Loss: 0.3042 Acc: 0.8714 Pre: 0.8734 Recall: 0.8347 F1: 0.8536 Train AUC: 0.9308 Val AUC: 0.9380 Time: 14.70\n",
      "Epoch: 53 Train Loss: 0.3232 Val Loss: 0.3036 Acc: 0.8732 Pre: 0.8771 Recall: 0.8347 F1: 0.8554 Train AUC: 0.9330 Val AUC: 0.9385 Time: 12.27\n",
      "Epoch: 54 Train Loss: 0.3351 Val Loss: 0.3036 Acc: 0.8714 Pre: 0.8766 Recall: 0.8306 F1: 0.8530 Train AUC: 0.9284 Val AUC: 0.9386 Time: 12.23\n",
      "Epoch: 55 Train Loss: 0.3493 Val Loss: 0.3043 Acc: 0.8678 Pre: 0.8661 Recall: 0.8347 F1: 0.8501 Train AUC: 0.9222 Val AUC: 0.9384 Time: 12.75\n",
      "Epoch: 56 Train Loss: 0.3200 Val Loss: 0.3054 Acc: 0.8678 Pre: 0.8631 Recall: 0.8387 F1: 0.8507 Train AUC: 0.9345 Val AUC: 0.9382 Time: 13.35\n",
      "Epoch: 57 Train Loss: 0.3315 Val Loss: 0.3038 Acc: 0.8714 Pre: 0.8703 Recall: 0.8387 F1: 0.8542 Train AUC: 0.9304 Val AUC: 0.9386 Time: 14.11\n",
      "Epoch: 58 Train Loss: 0.3171 Val Loss: 0.3013 Acc: 0.8768 Pre: 0.8814 Recall: 0.8387 F1: 0.8595 Train AUC: 0.9363 Val AUC: 0.9393 Time: 14.58\n",
      "Epoch: 59 Train Loss: 0.3166 Val Loss: 0.2976 Acc: 0.8859 Pre: 0.9075 Recall: 0.8306 F1: 0.8674 Train AUC: 0.9353 Val AUC: 0.9398 Time: 14.93\n",
      "Epoch: 60 Train Loss: 0.3217 Val Loss: 0.2972 Acc: 0.8877 Pre: 0.9043 Recall: 0.8387 F1: 0.8703 Train AUC: 0.9347 Val AUC: 0.9399 Time: 14.36\n",
      "Epoch: 61 Train Loss: 0.3156 Val Loss: 0.2998 Acc: 0.8822 Pre: 0.8927 Recall: 0.8387 F1: 0.8649 Train AUC: 0.9367 Val AUC: 0.9394 Time: 14.14\n",
      "Epoch: 62 Train Loss: 0.3231 Val Loss: 0.3022 Acc: 0.8786 Pre: 0.8851 Recall: 0.8387 F1: 0.8613 Train AUC: 0.9336 Val AUC: 0.9392 Time: 12.77\n",
      "Epoch: 63 Train Loss: 0.3256 Val Loss: 0.3036 Acc: 0.8768 Pre: 0.8782 Recall: 0.8427 F1: 0.8601 Train AUC: 0.9348 Val AUC: 0.9390 Time: 12.49\n",
      "Epoch: 64 Train Loss: 0.3136 Val Loss: 0.3011 Acc: 0.8786 Pre: 0.8851 Recall: 0.8387 F1: 0.8613 Train AUC: 0.9388 Val AUC: 0.9393 Time: 12.53\n",
      "Epoch: 65 Train Loss: 0.3079 Val Loss: 0.2982 Acc: 0.8822 Pre: 0.8927 Recall: 0.8387 F1: 0.8649 Train AUC: 0.9394 Val AUC: 0.9397 Time: 12.33\n",
      "Epoch: 66 Train Loss: 0.3078 Val Loss: 0.2959 Acc: 0.8877 Pre: 0.9043 Recall: 0.8387 F1: 0.8703 Train AUC: 0.9389 Val AUC: 0.9406 Time: 13.55\n",
      "Epoch: 67 Train Loss: 0.3066 Val Loss: 0.2954 Acc: 0.8913 Pre: 0.9123 Recall: 0.8387 F1: 0.8739 Train AUC: 0.9403 Val AUC: 0.9412 Time: 14.10\n",
      "Epoch: 68 Train Loss: 0.3088 Val Loss: 0.2953 Acc: 0.8895 Pre: 0.9083 Recall: 0.8387 F1: 0.8721 Train AUC: 0.9396 Val AUC: 0.9415 Time: 14.42\n",
      "Epoch: 69 Train Loss: 0.3118 Val Loss: 0.2942 Acc: 0.8895 Pre: 0.9083 Recall: 0.8387 F1: 0.8721 Train AUC: 0.9374 Val AUC: 0.9418 Time: 14.91\n",
      "Epoch: 70 Train Loss: 0.3037 Val Loss: 0.2930 Acc: 0.8877 Pre: 0.9043 Recall: 0.8387 F1: 0.8703 Train AUC: 0.9412 Val AUC: 0.9421 Time: 14.46\n",
      "Epoch: 71 Train Loss: 0.3137 Val Loss: 0.2935 Acc: 0.8859 Pre: 0.8970 Recall: 0.8427 F1: 0.8690 Train AUC: 0.9372 Val AUC: 0.9418 Time: 13.34\n",
      "Epoch: 72 Train Loss: 0.3045 Val Loss: 0.2963 Acc: 0.8822 Pre: 0.8894 Recall: 0.8427 F1: 0.8654 Train AUC: 0.9416 Val AUC: 0.9412 Time: 12.35\n",
      "Epoch: 73 Train Loss: 0.3013 Val Loss: 0.2945 Acc: 0.8822 Pre: 0.8894 Recall: 0.8427 F1: 0.8654 Train AUC: 0.9437 Val AUC: 0.9417 Time: 12.80\n",
      "Epoch: 74 Train Loss: 0.3038 Val Loss: 0.2913 Acc: 0.8841 Pre: 0.8932 Recall: 0.8427 F1: 0.8672 Train AUC: 0.9435 Val AUC: 0.9429 Time: 13.19\n",
      "Epoch: 75 Train Loss: 0.3015 Val Loss: 0.2899 Acc: 0.8895 Pre: 0.9083 Recall: 0.8387 F1: 0.8721 Train AUC: 0.9429 Val AUC: 0.9430 Time: 13.96\n",
      "Epoch: 76 Train Loss: 0.3097 Val Loss: 0.2899 Acc: 0.8822 Pre: 0.9031 Recall: 0.8266 F1: 0.8632 Train AUC: 0.9415 Val AUC: 0.9422 Time: 14.75\n",
      "Epoch: 77 Train Loss: 0.2910 Val Loss: 0.2915 Acc: 0.8822 Pre: 0.8996 Recall: 0.8306 F1: 0.8637 Train AUC: 0.9462 Val AUC: 0.9418 Time: 14.80\n",
      "Epoch: 78 Train Loss: 0.3087 Val Loss: 0.2962 Acc: 0.8841 Pre: 0.8966 Recall: 0.8387 F1: 0.8667 Train AUC: 0.9403 Val AUC: 0.9417 Time: 14.79\n",
      "Epoch: 79 Train Loss: 0.3030 Val Loss: 0.2959 Acc: 0.8859 Pre: 0.9111 Recall: 0.8266 F1: 0.8668 Train AUC: 0.9428 Val AUC: 0.9417 Time: 12.25\n",
      "Epoch: 80 Train Loss: 0.2871 Val Loss: 0.2961 Acc: 0.8877 Pre: 0.9152 Recall: 0.8266 F1: 0.8686 Train AUC: 0.9481 Val AUC: 0.9420 Time: 12.61\n",
      "Epoch: 81 Train Loss: 0.2952 Val Loss: 0.2954 Acc: 0.8877 Pre: 0.9152 Recall: 0.8266 F1: 0.8686 Train AUC: 0.9447 Val AUC: 0.9420 Time: 13.20\n",
      "Epoch: 82 Train Loss: 0.2984 Val Loss: 0.2947 Acc: 0.8877 Pre: 0.9043 Recall: 0.8387 F1: 0.8703 Train AUC: 0.9423 Val AUC: 0.9420 Time: 13.58\n",
      "Epoch: 83 Train Loss: 0.3207 Val Loss: 0.2940 Acc: 0.8895 Pre: 0.9013 Recall: 0.8468 F1: 0.8732 Train AUC: 0.9353 Val AUC: 0.9414 Time: 14.83\n",
      "Epoch: 84 Train Loss: 0.2920 Val Loss: 0.2933 Acc: 0.8841 Pre: 0.8898 Recall: 0.8468 F1: 0.8678 Train AUC: 0.9462 Val AUC: 0.9413 Time: 14.13\n",
      "Epoch: 85 Train Loss: 0.2990 Val Loss: 0.2957 Acc: 0.8841 Pre: 0.8898 Recall: 0.8468 F1: 0.8678 Train AUC: 0.9442 Val AUC: 0.9410 Time: 13.86\n",
      "Epoch: 86 Train Loss: 0.3007 Val Loss: 0.2959 Acc: 0.8841 Pre: 0.8898 Recall: 0.8468 F1: 0.8678 Train AUC: 0.9447 Val AUC: 0.9410 Time: 14.13\n",
      "Epoch: 87 Train Loss: 0.2876 Val Loss: 0.2934 Acc: 0.8859 Pre: 0.8936 Recall: 0.8468 F1: 0.8696 Train AUC: 0.9481 Val AUC: 0.9417 Time: 12.88\n",
      "Epoch: 88 Train Loss: 0.2846 Val Loss: 0.2904 Acc: 0.8877 Pre: 0.9009 Recall: 0.8427 F1: 0.8708 Train AUC: 0.9490 Val AUC: 0.9426 Time: 12.30\n",
      "Epoch: 89 Train Loss: 0.2908 Val Loss: 0.2894 Acc: 0.8913 Pre: 0.9087 Recall: 0.8427 F1: 0.8745 Train AUC: 0.9470 Val AUC: 0.9433 Time: 13.42\n",
      "Epoch: 90 Train Loss: 0.2877 Val Loss: 0.2878 Acc: 0.8931 Pre: 0.9315 Recall: 0.8226 F1: 0.8737 Train AUC: 0.9475 Val AUC: 0.9441 Time: 14.06\n",
      "Epoch: 91 Train Loss: 0.2965 Val Loss: 0.2882 Acc: 0.8949 Pre: 0.9279 Recall: 0.8306 F1: 0.8766 Train AUC: 0.9462 Val AUC: 0.9440 Time: 14.32\n",
      "Epoch: 92 Train Loss: 0.3001 Val Loss: 0.2930 Acc: 0.8877 Pre: 0.8974 Recall: 0.8468 F1: 0.8714 Train AUC: 0.9439 Val AUC: 0.9428 Time: 13.95\n",
      "Epoch: 93 Train Loss: 0.2889 Val Loss: 0.2967 Acc: 0.8877 Pre: 0.8908 Recall: 0.8548 F1: 0.8724 Train AUC: 0.9480 Val AUC: 0.9424 Time: 13.14\n",
      "Epoch: 94 Train Loss: 0.2871 Val Loss: 0.2938 Acc: 0.8877 Pre: 0.8908 Recall: 0.8548 F1: 0.8724 Train AUC: 0.9485 Val AUC: 0.9430 Time: 12.76\n",
      "Epoch: 95 Train Loss: 0.2939 Val Loss: 0.2866 Acc: 0.8913 Pre: 0.9159 Recall: 0.8347 F1: 0.8734 Train AUC: 0.9467 Val AUC: 0.9447 Time: 13.70\n",
      "Epoch: 96 Train Loss: 0.2830 Val Loss: 0.2849 Acc: 0.8913 Pre: 0.9352 Recall: 0.8145 F1: 0.8707 Train AUC: 0.9511 Val AUC: 0.9457 Time: 13.91\n",
      "Epoch: 97 Train Loss: 0.2905 Val Loss: 0.2851 Acc: 0.8895 Pre: 0.9269 Recall: 0.8185 F1: 0.8694 Train AUC: 0.9495 Val AUC: 0.9458 Time: 14.03\n",
      "Epoch: 98 Train Loss: 0.2885 Val Loss: 0.2867 Acc: 0.8895 Pre: 0.9119 Recall: 0.8347 F1: 0.8716 Train AUC: 0.9483 Val AUC: 0.9450 Time: 13.40\n",
      "Epoch: 99 Train Loss: 0.2716 Val Loss: 0.2896 Acc: 0.8895 Pre: 0.8945 Recall: 0.8548 F1: 0.8742 Train AUC: 0.9531 Val AUC: 0.9438 Time: 13.78\n",
      "Epoch: 100 Train Loss: 0.2837 Val Loss: 0.2914 Acc: 0.8895 Pre: 0.8945 Recall: 0.8548 F1: 0.8742 Train AUC: 0.9489 Val AUC: 0.9431 Time: 13.60\n",
      "Epoch: 101 Train Loss: 0.2734 Val Loss: 0.2887 Acc: 0.8877 Pre: 0.8941 Recall: 0.8508 F1: 0.8719 Train AUC: 0.9545 Val AUC: 0.9432 Time: 12.23\n",
      "Epoch: 102 Train Loss: 0.2731 Val Loss: 0.2849 Acc: 0.8931 Pre: 0.9238 Recall: 0.8306 F1: 0.8747 Train AUC: 0.9537 Val AUC: 0.9440 Time: 12.95\n",
      "Epoch: 103 Train Loss: 0.2763 Val Loss: 0.2845 Acc: 0.8895 Pre: 0.9269 Recall: 0.8185 F1: 0.8694 Train AUC: 0.9526 Val AUC: 0.9443 Time: 14.07\n",
      "Epoch: 104 Train Loss: 0.2909 Val Loss: 0.2859 Acc: 0.8895 Pre: 0.9119 Recall: 0.8347 F1: 0.8716 Train AUC: 0.9507 Val AUC: 0.9438 Time: 14.17\n",
      "Epoch: 105 Train Loss: 0.2711 Val Loss: 0.2879 Acc: 0.8913 Pre: 0.9052 Recall: 0.8468 F1: 0.8750 Train AUC: 0.9549 Val AUC: 0.9434 Time: 14.59\n",
      "Epoch: 106 Train Loss: 0.2719 Val Loss: 0.2904 Acc: 0.8859 Pre: 0.8903 Recall: 0.8508 F1: 0.8701 Train AUC: 0.9537 Val AUC: 0.9432 Time: 14.76\n",
      "Epoch: 107 Train Loss: 0.2736 Val Loss: 0.2897 Acc: 0.8895 Pre: 0.9013 Recall: 0.8468 F1: 0.8732 Train AUC: 0.9531 Val AUC: 0.9435 Time: 12.32\n",
      "Epoch: 108 Train Loss: 0.2685 Val Loss: 0.2867 Acc: 0.8967 Pre: 0.9283 Recall: 0.8347 F1: 0.8790 Train AUC: 0.9548 Val AUC: 0.9438 Time: 12.32\n",
      "Epoch: 109 Train Loss: 0.2791 Val Loss: 0.2863 Acc: 0.8967 Pre: 0.9283 Recall: 0.8347 F1: 0.8790 Train AUC: 0.9516 Val AUC: 0.9439 Time: 12.50\n",
      "Epoch: 110 Train Loss: 0.2807 Val Loss: 0.2871 Acc: 0.8967 Pre: 0.9207 Recall: 0.8427 F1: 0.8800 Train AUC: 0.9526 Val AUC: 0.9439 Time: 13.55\n",
      "Epoch: 111 Train Loss: 0.2775 Val Loss: 0.2942 Acc: 0.8859 Pre: 0.8870 Recall: 0.8548 F1: 0.8706 Train AUC: 0.9537 Val AUC: 0.9436 Time: 13.50\n",
      "Epoch: 112 Train Loss: 0.2720 Val Loss: 0.3013 Acc: 0.8750 Pre: 0.8623 Recall: 0.8589 F1: 0.8606 Train AUC: 0.9543 Val AUC: 0.9431 Time: 14.25\n",
      "Epoch: 113 Train Loss: 0.2688 Val Loss: 0.2949 Acc: 0.8931 Pre: 0.9091 Recall: 0.8468 F1: 0.8768 Train AUC: 0.9581 Val AUC: 0.9438 Time: 15.01\n",
      "Epoch: 114 Train Loss: 0.2632 Val Loss: 0.2898 Acc: 0.8967 Pre: 0.9207 Recall: 0.8427 F1: 0.8800 Train AUC: 0.9582 Val AUC: 0.9443 Time: 14.66\n",
      "Epoch: 115 Train Loss: 0.2619 Val Loss: 0.2874 Acc: 0.8931 Pre: 0.9315 Recall: 0.8226 F1: 0.8737 Train AUC: 0.9569 Val AUC: 0.9449 Time: 13.41\n",
      "Epoch: 116 Train Loss: 0.2710 Val Loss: 0.2869 Acc: 0.8931 Pre: 0.9200 Recall: 0.8347 F1: 0.8753 Train AUC: 0.9560 Val AUC: 0.9443 Time: 12.57\n",
      "Epoch: 117 Train Loss: 0.2802 Val Loss: 0.2930 Acc: 0.8859 Pre: 0.8870 Recall: 0.8548 F1: 0.8706 Train AUC: 0.9521 Val AUC: 0.9422 Time: 12.60\n",
      "Epoch: 118 Train Loss: 0.2622 Val Loss: 0.3015 Acc: 0.8696 Pre: 0.8548 Recall: 0.8548 F1: 0.8548 Train AUC: 0.9573 Val AUC: 0.9414 Time: 13.21\n",
      "Epoch: 119 Train Loss: 0.2691 Val Loss: 0.2947 Acc: 0.8750 Pre: 0.8653 Recall: 0.8548 F1: 0.8600 Train AUC: 0.9579 Val AUC: 0.9420 Time: 14.11\n",
      "Epoch: 120 Train Loss: 0.2601 Val Loss: 0.2867 Acc: 0.8986 Pre: 0.9248 Recall: 0.8427 F1: 0.8819 Train AUC: 0.9588 Val AUC: 0.9435 Time: 13.60\n",
      "Epoch: 121 Train Loss: 0.2566 Val Loss: 0.2890 Acc: 0.8913 Pre: 0.9393 Recall: 0.8105 F1: 0.8701 Train AUC: 0.9596 Val AUC: 0.9455 Time: 13.91\n",
      "Epoch: 122 Train Loss: 0.2644 Val Loss: 0.2877 Acc: 0.8913 Pre: 0.9273 Recall: 0.8226 F1: 0.8718 Train AUC: 0.9598 Val AUC: 0.9447 Time: 14.18\n",
      "Epoch: 123 Train Loss: 0.2669 Val Loss: 0.2918 Acc: 0.8913 Pre: 0.9052 Recall: 0.8468 F1: 0.8750 Train AUC: 0.9566 Val AUC: 0.9432 Time: 14.32\n",
      "Epoch: 124 Train Loss: 0.2617 Val Loss: 0.2990 Acc: 0.8732 Pre: 0.8618 Recall: 0.8548 F1: 0.8583 Train AUC: 0.9575 Val AUC: 0.9428 Time: 13.70\n",
      "Epoch: 125 Train Loss: 0.2664 Val Loss: 0.2921 Acc: 0.8804 Pre: 0.8824 Recall: 0.8468 F1: 0.8642 Train AUC: 0.9573 Val AUC: 0.9444 Time: 12.48\n",
      "Epoch: 126 Train Loss: 0.2570 Val Loss: 0.2855 Acc: 0.8931 Pre: 0.9238 Recall: 0.8306 F1: 0.8747 Train AUC: 0.9605 Val AUC: 0.9461 Time: 12.68\n",
      "Epoch: 127 Train Loss: 0.2557 Val Loss: 0.2869 Acc: 0.8913 Pre: 0.9352 Recall: 0.8145 F1: 0.8707 Train AUC: 0.9599 Val AUC: 0.9469 Time: 13.55\n",
      "Epoch: 128 Train Loss: 0.2661 Val Loss: 0.2860 Acc: 0.8804 Pre: 0.9027 Recall: 0.8226 F1: 0.8608 Train AUC: 0.9593 Val AUC: 0.9467 Time: 13.87\n",
      "Epoch: 129 Train Loss: 0.2670 Val Loss: 0.2903 Acc: 0.8768 Pre: 0.8689 Recall: 0.8548 F1: 0.8618 Train AUC: 0.9573 Val AUC: 0.9456 Time: 13.84\n",
      "Epoch: 130 Train Loss: 0.2577 Val Loss: 0.3041 Acc: 0.8605 Pre: 0.8327 Recall: 0.8629 F1: 0.8475 Train AUC: 0.9597 Val AUC: 0.9426 Time: 14.32\n",
      "Epoch: 131 Train Loss: 0.2541 Val Loss: 0.3088 Acc: 0.8587 Pre: 0.8320 Recall: 0.8589 F1: 0.8452 Train AUC: 0.9618 Val AUC: 0.9417 Time: 13.38\n",
      "Epoch: 132 Train Loss: 0.2589 Val Loss: 0.3013 Acc: 0.8877 Pre: 0.8974 Recall: 0.8468 F1: 0.8714 Train AUC: 0.9608 Val AUC: 0.9421 Time: 13.23\n",
      "Epoch: 133 Train Loss: 0.2532 Val Loss: 0.2956 Acc: 0.8931 Pre: 0.9200 Recall: 0.8347 F1: 0.8753 Train AUC: 0.9607 Val AUC: 0.9439 Time: 13.95\n",
      "Epoch: 134 Train Loss: 0.2574 Val Loss: 0.2946 Acc: 0.8895 Pre: 0.9349 Recall: 0.8105 F1: 0.8683 Train AUC: 0.9604 Val AUC: 0.9454 Time: 13.12\n",
      "Epoch: 135 Train Loss: 0.2634 Val Loss: 0.2894 Acc: 0.8967 Pre: 0.9283 Recall: 0.8347 F1: 0.8790 Train AUC: 0.9597 Val AUC: 0.9459 Time: 13.77\n",
      "Epoch: 136 Train Loss: 0.2589 Val Loss: 0.2978 Acc: 0.8732 Pre: 0.8618 Recall: 0.8548 F1: 0.8583 Train AUC: 0.9615 Val AUC: 0.9444 Time: 14.16\n",
      "Epoch: 137 Train Loss: 0.2556 Val Loss: 0.3070 Acc: 0.8750 Pre: 0.8456 Recall: 0.8831 F1: 0.8639 Train AUC: 0.9612 Val AUC: 0.9437 Time: 14.16\n",
      "Epoch: 138 Train Loss: 0.2527 Val Loss: 0.2979 Acc: 0.8768 Pre: 0.8629 Recall: 0.8629 F1: 0.8629 Train AUC: 0.9637 Val AUC: 0.9445 Time: 13.01\n",
      "Epoch: 139 Train Loss: 0.2444 Val Loss: 0.2891 Acc: 0.8877 Pre: 0.9009 Recall: 0.8427 F1: 0.8708 Train AUC: 0.9650 Val AUC: 0.9456 Time: 12.69\n",
      "Epoch: 140 Train Loss: 0.2450 Val Loss: 0.2899 Acc: 0.8949 Pre: 0.9279 Recall: 0.8306 F1: 0.8766 Train AUC: 0.9636 Val AUC: 0.9458 Time: 12.38\n",
      "Epoch: 141 Train Loss: 0.2518 Val Loss: 0.2904 Acc: 0.8986 Pre: 0.9286 Recall: 0.8387 F1: 0.8814 Train AUC: 0.9636 Val AUC: 0.9450 Time: 12.51\n",
      "Epoch: 142 Train Loss: 0.2612 Val Loss: 0.2909 Acc: 0.8931 Pre: 0.9127 Recall: 0.8427 F1: 0.8763 Train AUC: 0.9582 Val AUC: 0.9443 Time: 13.09\n",
      "Epoch: 143 Train Loss: 0.2496 Val Loss: 0.2934 Acc: 0.8841 Pre: 0.8898 Recall: 0.8468 F1: 0.8678 Train AUC: 0.9613 Val AUC: 0.9443 Time: 13.94\n",
      "Epoch: 144 Train Loss: 0.2397 Val Loss: 0.2933 Acc: 0.8822 Pre: 0.8765 Recall: 0.8589 F1: 0.8676 Train AUC: 0.9654 Val AUC: 0.9455 Time: 14.11\n",
      "Epoch: 145 Train Loss: 0.2418 Val Loss: 0.2899 Acc: 0.8841 Pre: 0.8802 Recall: 0.8589 F1: 0.8694 Train AUC: 0.9653 Val AUC: 0.9466 Time: 14.80\n",
      "Epoch: 146 Train Loss: 0.2394 Val Loss: 0.2875 Acc: 0.8804 Pre: 0.8792 Recall: 0.8508 F1: 0.8648 Train AUC: 0.9648 Val AUC: 0.9478 Time: 13.97\n",
      "Epoch: 147 Train Loss: 0.2456 Val Loss: 0.2876 Acc: 0.8841 Pre: 0.9000 Recall: 0.8347 F1: 0.8661 Train AUC: 0.9647 Val AUC: 0.9480 Time: 14.69\n",
      "Epoch: 148 Train Loss: 0.2403 Val Loss: 0.2893 Acc: 0.8931 Pre: 0.9200 Recall: 0.8347 F1: 0.8753 Train AUC: 0.9652 Val AUC: 0.9481 Time: 12.72\n",
      "Epoch: 149 Train Loss: 0.2391 Val Loss: 0.2930 Acc: 0.8841 Pre: 0.8898 Recall: 0.8468 F1: 0.8678 Train AUC: 0.9665 Val AUC: 0.9463 Time: 13.24\n",
      "Epoch: 150 Train Loss: 0.2316 Val Loss: 0.2989 Acc: 0.8768 Pre: 0.8719 Recall: 0.8508 F1: 0.8612 Train AUC: 0.9679 Val AUC: 0.9450 Time: 14.05\n",
      "Epoch: 151 Train Loss: 0.2288 Val Loss: 0.2990 Acc: 0.8804 Pre: 0.8824 Recall: 0.8468 F1: 0.8642 Train AUC: 0.9681 Val AUC: 0.9447 Time: 13.71\n",
      "Epoch: 152 Train Loss: 0.2373 Val Loss: 0.2951 Acc: 0.8967 Pre: 0.9170 Recall: 0.8468 F1: 0.8805 Train AUC: 0.9660 Val AUC: 0.9454 Time: 13.05\n",
      "Epoch: 153 Train Loss: 0.2368 Val Loss: 0.2956 Acc: 0.8913 Pre: 0.9052 Recall: 0.8468 F1: 0.8750 Train AUC: 0.9660 Val AUC: 0.9459 Time: 12.73\n",
      "Epoch: 154 Train Loss: 0.2294 Val Loss: 0.2976 Acc: 0.8841 Pre: 0.8740 Recall: 0.8669 F1: 0.8704 Train AUC: 0.9681 Val AUC: 0.9459 Time: 14.27\n",
      "Epoch: 155 Train Loss: 0.2336 Val Loss: 0.2951 Acc: 0.8859 Pre: 0.8745 Recall: 0.8710 F1: 0.8727 Train AUC: 0.9672 Val AUC: 0.9468 Time: 14.09\n",
      "Epoch: 156 Train Loss: 0.2332 Val Loss: 0.2898 Acc: 0.8877 Pre: 0.8908 Recall: 0.8548 F1: 0.8724 Train AUC: 0.9676 Val AUC: 0.9478 Time: 14.09\n",
      "Epoch: 157 Train Loss: 0.2314 Val Loss: 0.2901 Acc: 0.8931 Pre: 0.9056 Recall: 0.8508 F1: 0.8773 Train AUC: 0.9681 Val AUC: 0.9479 Time: 13.64\n",
      "Epoch: 158 Train Loss: 0.2267 Val Loss: 0.2918 Acc: 0.8967 Pre: 0.9134 Recall: 0.8508 F1: 0.8810 Train AUC: 0.9687 Val AUC: 0.9477 Time: 12.19\n",
      "Epoch: 159 Train Loss: 0.2307 Val Loss: 0.2902 Acc: 0.8986 Pre: 0.9211 Recall: 0.8468 F1: 0.8824 Train AUC: 0.9679 Val AUC: 0.9481 Time: 12.74\n",
      "Epoch: 160 Train Loss: 0.2290 Val Loss: 0.2913 Acc: 0.9004 Pre: 0.9177 Recall: 0.8548 F1: 0.8852 Train AUC: 0.9678 Val AUC: 0.9479 Time: 13.79\n",
      "Epoch: 161 Train Loss: 0.2324 Val Loss: 0.2976 Acc: 0.8913 Pre: 0.8917 Recall: 0.8629 F1: 0.8770 Train AUC: 0.9675 Val AUC: 0.9466 Time: 13.27\n",
      "Epoch: 162 Train Loss: 0.2319 Val Loss: 0.2971 Acc: 0.8931 Pre: 0.8889 Recall: 0.8710 F1: 0.8798 Train AUC: 0.9671 Val AUC: 0.9470 Time: 14.59\n",
      "Epoch: 163 Train Loss: 0.2211 Val Loss: 0.2976 Acc: 0.8949 Pre: 0.8926 Recall: 0.8710 F1: 0.8816 Train AUC: 0.9709 Val AUC: 0.9472 Time: 14.36\n",
      "Epoch: 164 Train Loss: 0.2327 Val Loss: 0.2944 Acc: 0.8967 Pre: 0.9134 Recall: 0.8508 F1: 0.8810 Train AUC: 0.9673 Val AUC: 0.9474 Time: 13.06\n",
      "Epoch: 165 Train Loss: 0.2291 Val Loss: 0.2946 Acc: 0.8931 Pre: 0.9091 Recall: 0.8468 F1: 0.8768 Train AUC: 0.9678 Val AUC: 0.9475 Time: 13.02\n",
      "Epoch: 166 Train Loss: 0.2207 Val Loss: 0.2961 Acc: 0.8931 Pre: 0.9056 Recall: 0.8508 F1: 0.8773 Train AUC: 0.9704 Val AUC: 0.9473 Time: 12.85\n",
      "Epoch: 167 Train Loss: 0.2255 Val Loss: 0.2954 Acc: 0.8949 Pre: 0.8992 Recall: 0.8629 F1: 0.8807 Train AUC: 0.9692 Val AUC: 0.9477 Time: 13.71\n",
      "Epoch: 168 Train Loss: 0.2280 Val Loss: 0.2920 Acc: 0.8986 Pre: 0.9000 Recall: 0.8710 F1: 0.8852 Train AUC: 0.9690 Val AUC: 0.9485 Time: 13.80\n",
      "Epoch: 169 Train Loss: 0.2208 Val Loss: 0.2920 Acc: 0.8967 Pre: 0.8996 Recall: 0.8669 F1: 0.8830 Train AUC: 0.9715 Val AUC: 0.9489 Time: 14.54\n",
      "Epoch: 170 Train Loss: 0.2196 Val Loss: 0.2904 Acc: 0.9040 Pre: 0.9149 Recall: 0.8669 F1: 0.8903 Train AUC: 0.9710 Val AUC: 0.9489 Time: 13.79\n",
      "Epoch: 171 Train Loss: 0.2245 Val Loss: 0.2910 Acc: 0.9058 Pre: 0.9261 Recall: 0.8589 F1: 0.8912 Train AUC: 0.9695 Val AUC: 0.9490 Time: 13.73\n",
      "Epoch: 172 Train Loss: 0.2242 Val Loss: 0.2917 Acc: 0.8986 Pre: 0.9248 Recall: 0.8427 F1: 0.8819 Train AUC: 0.9694 Val AUC: 0.9493 Time: 12.27\n",
      "Epoch: 173 Train Loss: 0.2146 Val Loss: 0.2945 Acc: 0.8986 Pre: 0.9174 Recall: 0.8508 F1: 0.8828 Train AUC: 0.9721 Val AUC: 0.9489 Time: 13.40\n",
      "Epoch: 174 Train Loss: 0.2138 Val Loss: 0.2977 Acc: 0.8895 Pre: 0.8945 Recall: 0.8548 F1: 0.8742 Train AUC: 0.9724 Val AUC: 0.9479 Time: 13.39\n",
      "Epoch: 175 Train Loss: 0.2228 Val Loss: 0.2994 Acc: 0.8877 Pre: 0.8780 Recall: 0.8710 F1: 0.8745 Train AUC: 0.9703 Val AUC: 0.9481 Time: 14.29\n",
      "Epoch: 176 Train Loss: 0.2265 Val Loss: 0.2948 Acc: 0.9022 Pre: 0.9254 Recall: 0.8508 F1: 0.8866 Train AUC: 0.9698 Val AUC: 0.9492 Time: 14.54\n",
      "Epoch: 177 Train Loss: 0.2216 Val Loss: 0.2938 Acc: 0.8986 Pre: 0.9286 Recall: 0.8387 F1: 0.8814 Train AUC: 0.9697 Val AUC: 0.9495 Time: 13.07\n",
      "Epoch: 178 Train Loss: 0.2276 Val Loss: 0.2947 Acc: 0.9040 Pre: 0.9185 Recall: 0.8629 F1: 0.8898 Train AUC: 0.9697 Val AUC: 0.9492 Time: 12.99\n",
      "Epoch: 179 Train Loss: 0.2148 Val Loss: 0.3018 Acc: 0.8696 Pre: 0.8385 Recall: 0.8790 F1: 0.8583 Train AUC: 0.9717 Val AUC: 0.9482 Time: 12.56\n",
      "Epoch: 180 Train Loss: 0.2201 Val Loss: 0.2943 Acc: 0.9094 Pre: 0.9195 Recall: 0.8750 F1: 0.8967 Train AUC: 0.9730 Val AUC: 0.9486 Time: 13.43\n",
      "Epoch: 181 Train Loss: 0.2145 Val Loss: 0.2905 Acc: 0.9022 Pre: 0.9292 Recall: 0.8468 F1: 0.8861 Train AUC: 0.9727 Val AUC: 0.9494 Time: 14.10\n",
      "Epoch: 182 Train Loss: 0.2179 Val Loss: 0.2902 Acc: 0.9022 Pre: 0.9330 Recall: 0.8427 F1: 0.8856 Train AUC: 0.9722 Val AUC: 0.9494 Time: 13.59\n",
      "Epoch: 183 Train Loss: 0.2041 Val Loss: 0.2914 Acc: 0.9058 Pre: 0.9188 Recall: 0.8669 F1: 0.8921 Train AUC: 0.9759 Val AUC: 0.9491 Time: 14.11\n",
      "Epoch: 184 Train Loss: 0.2169 Val Loss: 0.2980 Acc: 0.8714 Pre: 0.8444 Recall: 0.8750 F1: 0.8594 Train AUC: 0.9720 Val AUC: 0.9485 Time: 13.94\n",
      "Epoch: 185 Train Loss: 0.2170 Val Loss: 0.3001 Acc: 0.8659 Pre: 0.8346 Recall: 0.8750 F1: 0.8543 Train AUC: 0.9718 Val AUC: 0.9482 Time: 13.99\n",
      "Epoch: 186 Train Loss: 0.2081 Val Loss: 0.2980 Acc: 0.8895 Pre: 0.8816 Recall: 0.8710 F1: 0.8763 Train AUC: 0.9750 Val AUC: 0.9487 Time: 13.46\n",
      "Epoch: 187 Train Loss: 0.2110 Val Loss: 0.2951 Acc: 0.8913 Pre: 0.9123 Recall: 0.8387 F1: 0.8739 Train AUC: 0.9737 Val AUC: 0.9496 Time: 13.00\n",
      "Epoch: 188 Train Loss: 0.2088 Val Loss: 0.2964 Acc: 0.8913 Pre: 0.9017 Recall: 0.8508 F1: 0.8755 Train AUC: 0.9753 Val AUC: 0.9487 Time: 13.59\n",
      "Epoch: 189 Train Loss: 0.2119 Val Loss: 0.2968 Acc: 0.8859 Pre: 0.8715 Recall: 0.8750 F1: 0.8732 Train AUC: 0.9723 Val AUC: 0.9488 Time: 13.87\n",
      "Epoch: 190 Train Loss: 0.2129 Val Loss: 0.2928 Acc: 0.8877 Pre: 0.8750 Recall: 0.8750 F1: 0.8750 Train AUC: 0.9730 Val AUC: 0.9489 Time: 13.75\n",
      "Epoch: 191 Train Loss: 0.2077 Val Loss: 0.2899 Acc: 0.8967 Pre: 0.8963 Recall: 0.8710 F1: 0.8834 Train AUC: 0.9766 Val AUC: 0.9495 Time: 13.68\n",
      "Epoch: 192 Train Loss: 0.2044 Val Loss: 0.2894 Acc: 0.9022 Pre: 0.9145 Recall: 0.8629 F1: 0.8880 Train AUC: 0.9765 Val AUC: 0.9507 Time: 12.65\n",
      "Epoch: 193 Train Loss: 0.2062 Val Loss: 0.2932 Acc: 0.9004 Pre: 0.9072 Recall: 0.8669 F1: 0.8866 Train AUC: 0.9753 Val AUC: 0.9504 Time: 13.12\n",
      "Epoch: 194 Train Loss: 0.2083 Val Loss: 0.3016 Acc: 0.8895 Pre: 0.8785 Recall: 0.8750 F1: 0.8768 Train AUC: 0.9744 Val AUC: 0.9501 Time: 13.77\n",
      "Epoch: 195 Train Loss: 0.2028 Val Loss: 0.3033 Acc: 0.8895 Pre: 0.8755 Recall: 0.8790 F1: 0.8773 Train AUC: 0.9747 Val AUC: 0.9503 Time: 13.53\n",
      "Epoch: 196 Train Loss: 0.2070 Val Loss: 0.3007 Acc: 0.8913 Pre: 0.8821 Recall: 0.8750 F1: 0.8785 Train AUC: 0.9745 Val AUC: 0.9504 Time: 14.08\n",
      "Epoch: 197 Train Loss: 0.2060 Val Loss: 0.2950 Acc: 0.8949 Pre: 0.8862 Recall: 0.8790 F1: 0.8826 Train AUC: 0.9736 Val AUC: 0.9513 Time: 14.10\n",
      "Epoch: 198 Train Loss: 0.2070 Val Loss: 0.2937 Acc: 0.9004 Pre: 0.9038 Recall: 0.8710 F1: 0.8871 Train AUC: 0.9750 Val AUC: 0.9515 Time: 13.57\n",
      "Epoch: 199 Train Loss: 0.2045 Val Loss: 0.2982 Acc: 0.8895 Pre: 0.8638 Recall: 0.8952 F1: 0.8792 Train AUC: 0.9760 Val AUC: 0.9515 Time: 14.23\n",
      "Epoch: 200 Train Loss: 0.2043 Val Loss: 0.3106 Acc: 0.8895 Pre: 0.8610 Recall: 0.8992 F1: 0.8797 Train AUC: 0.9751 Val AUC: 0.9505 Time: 13.30\n",
      "Epoch: 201 Train Loss: 0.2124 Val Loss: 0.3054 Acc: 0.8877 Pre: 0.8750 Recall: 0.8750 F1: 0.8750 Train AUC: 0.9737 Val AUC: 0.9504 Time: 13.20\n",
      "Epoch: 202 Train Loss: 0.2112 Val Loss: 0.2951 Acc: 0.9004 Pre: 0.9327 Recall: 0.8387 F1: 0.8832 Train AUC: 0.9728 Val AUC: 0.9525 Time: 14.10\n",
      "Epoch: 203 Train Loss: 0.2004 Val Loss: 0.2858 Acc: 0.9112 Pre: 0.9345 Recall: 0.8629 F1: 0.8973 Train AUC: 0.9765 Val AUC: 0.9535 Time: 12.51\n",
      "Epoch: 204 Train Loss: 0.2058 Val Loss: 0.2921 Acc: 0.8877 Pre: 0.8605 Recall: 0.8952 F1: 0.8775 Train AUC: 0.9749 Val AUC: 0.9508 Time: 13.17\n",
      "Epoch: 205 Train Loss: 0.2048 Val Loss: 0.2957 Acc: 0.8822 Pre: 0.8560 Recall: 0.8871 F1: 0.8713 Train AUC: 0.9768 Val AUC: 0.9510 Time: 14.03\n",
      "Epoch: 206 Train Loss: 0.2010 Val Loss: 0.2930 Acc: 0.8967 Pre: 0.8963 Recall: 0.8710 F1: 0.8834 Train AUC: 0.9772 Val AUC: 0.9512 Time: 14.20\n",
      "Epoch: 207 Train Loss: 0.2004 Val Loss: 0.2978 Acc: 0.8931 Pre: 0.9127 Recall: 0.8427 F1: 0.8763 Train AUC: 0.9761 Val AUC: 0.9510 Time: 14.13\n",
      "Epoch: 208 Train Loss: 0.2086 Val Loss: 0.2935 Acc: 0.8986 Pre: 0.9034 Recall: 0.8669 F1: 0.8848 Train AUC: 0.9747 Val AUC: 0.9518 Time: 12.76\n",
      "Epoch: 209 Train Loss: 0.2020 Val Loss: 0.3071 Acc: 0.8913 Pre: 0.8534 Recall: 0.9153 F1: 0.8833 Train AUC: 0.9766 Val AUC: 0.9504 Time: 13.47\n",
      "Epoch: 210 Train Loss: 0.2102 Val Loss: 0.3019 Acc: 0.8967 Pre: 0.8805 Recall: 0.8911 F1: 0.8858 Train AUC: 0.9750 Val AUC: 0.9505 Time: 13.91\n",
      "Epoch: 211 Train Loss: 0.1979 Val Loss: 0.2954 Acc: 0.8877 Pre: 0.8941 Recall: 0.8508 F1: 0.8719 Train AUC: 0.9774 Val AUC: 0.9509 Time: 14.14\n",
      "Epoch: 212 Train Loss: 0.2016 Val Loss: 0.2934 Acc: 0.8931 Pre: 0.9056 Recall: 0.8508 F1: 0.8773 Train AUC: 0.9761 Val AUC: 0.9513 Time: 12.49\n",
      "Epoch: 213 Train Loss: 0.2029 Val Loss: 0.2938 Acc: 0.8949 Pre: 0.8862 Recall: 0.8790 F1: 0.8826 Train AUC: 0.9767 Val AUC: 0.9512 Time: 13.52\n",
      "Epoch: 214 Train Loss: 0.1991 Val Loss: 0.2951 Acc: 0.8913 Pre: 0.8760 Recall: 0.8831 F1: 0.8795 Train AUC: 0.9762 Val AUC: 0.9513 Time: 13.61\n",
      "Epoch: 215 Train Loss: 0.1967 Val Loss: 0.2891 Acc: 0.8986 Pre: 0.8902 Recall: 0.8831 F1: 0.8866 Train AUC: 0.9777 Val AUC: 0.9522 Time: 14.15\n",
      "Epoch: 216 Train Loss: 0.2016 Val Loss: 0.2870 Acc: 0.9022 Pre: 0.9181 Recall: 0.8589 F1: 0.8875 Train AUC: 0.9769 Val AUC: 0.9527 Time: 14.18\n",
      "Epoch: 217 Train Loss: 0.1986 Val Loss: 0.2882 Acc: 0.8986 Pre: 0.9138 Recall: 0.8548 F1: 0.8833 Train AUC: 0.9769 Val AUC: 0.9528 Time: 12.15\n",
      "Epoch: 218 Train Loss: 0.1984 Val Loss: 0.2907 Acc: 0.8913 Pre: 0.8821 Recall: 0.8750 F1: 0.8785 Train AUC: 0.9774 Val AUC: 0.9528 Time: 12.92\n",
      "Epoch: 219 Train Loss: 0.1899 Val Loss: 0.3024 Acc: 0.8913 Pre: 0.8643 Recall: 0.8992 F1: 0.8814 Train AUC: 0.9790 Val AUC: 0.9521 Time: 12.72\n",
      "Epoch: 220 Train Loss: 0.2005 Val Loss: 0.2950 Acc: 0.8931 Pre: 0.8735 Recall: 0.8911 F1: 0.8822 Train AUC: 0.9772 Val AUC: 0.9526 Time: 13.08\n",
      "Epoch: 221 Train Loss: 0.1962 Val Loss: 0.2882 Acc: 0.8967 Pre: 0.9030 Recall: 0.8629 F1: 0.8825 Train AUC: 0.9777 Val AUC: 0.9534 Time: 13.86\n",
      "Epoch: 222 Train Loss: 0.1859 Val Loss: 0.2886 Acc: 0.8967 Pre: 0.9099 Recall: 0.8548 F1: 0.8815 Train AUC: 0.9801 Val AUC: 0.9535 Time: 14.08\n",
      "Epoch: 223 Train Loss: 0.1897 Val Loss: 0.2883 Acc: 0.8895 Pre: 0.8816 Recall: 0.8710 F1: 0.8763 Train AUC: 0.9792 Val AUC: 0.9533 Time: 14.42\n",
      "Epoch: 224 Train Loss: 0.1944 Val Loss: 0.2987 Acc: 0.8967 Pre: 0.8745 Recall: 0.8992 F1: 0.8867 Train AUC: 0.9775 Val AUC: 0.9529 Time: 14.18\n",
      "Epoch: 225 Train Loss: 0.1940 Val Loss: 0.2949 Acc: 0.8949 Pre: 0.8800 Recall: 0.8871 F1: 0.8835 Train AUC: 0.9791 Val AUC: 0.9530 Time: 12.37\n",
      "Epoch: 226 Train Loss: 0.1933 Val Loss: 0.2860 Acc: 0.8949 Pre: 0.8992 Recall: 0.8629 F1: 0.8807 Train AUC: 0.9773 Val AUC: 0.9538 Time: 12.53\n",
      "Epoch: 227 Train Loss: 0.1944 Val Loss: 0.2834 Acc: 0.8949 Pre: 0.8958 Recall: 0.8669 F1: 0.8811 Train AUC: 0.9776 Val AUC: 0.9534 Time: 12.80\n",
      "Epoch: 228 Train Loss: 0.1841 Val Loss: 0.2896 Acc: 0.8931 Pre: 0.8826 Recall: 0.8790 F1: 0.8808 Train AUC: 0.9803 Val AUC: 0.9518 Time: 13.67\n",
      "Epoch: 229 Train Loss: 0.1866 Val Loss: 0.2931 Acc: 0.8859 Pre: 0.8571 Recall: 0.8952 F1: 0.8757 Train AUC: 0.9799 Val AUC: 0.9519 Time: 14.14\n",
      "Epoch: 230 Train Loss: 0.1896 Val Loss: 0.2873 Acc: 0.8986 Pre: 0.8840 Recall: 0.8911 F1: 0.8876 Train AUC: 0.9793 Val AUC: 0.9535 Time: 14.39\n",
      "Epoch: 231 Train Loss: 0.1878 Val Loss: 0.2850 Acc: 0.9022 Pre: 0.8975 Recall: 0.8831 F1: 0.8902 Train AUC: 0.9790 Val AUC: 0.9540 Time: 14.58\n",
      "Epoch: 232 Train Loss: 0.1875 Val Loss: 0.2831 Acc: 0.9112 Pre: 0.9198 Recall: 0.8790 F1: 0.8990 Train AUC: 0.9792 Val AUC: 0.9545 Time: 13.16\n",
      "Epoch: 233 Train Loss: 0.1986 Val Loss: 0.2815 Acc: 0.9058 Pre: 0.8984 Recall: 0.8911 F1: 0.8947 Train AUC: 0.9770 Val AUC: 0.9548 Time: 12.40\n",
      "Epoch: 234 Train Loss: 0.1929 Val Loss: 0.2887 Acc: 0.9004 Pre: 0.8784 Recall: 0.9032 F1: 0.8907 Train AUC: 0.9779 Val AUC: 0.9537 Time: 12.75\n",
      "Epoch: 235 Train Loss: 0.1816 Val Loss: 0.2951 Acc: 0.8841 Pre: 0.8622 Recall: 0.8831 F1: 0.8725 Train AUC: 0.9813 Val AUC: 0.9521 Time: 14.23\n",
      "Epoch: 236 Train Loss: 0.1836 Val Loss: 0.2904 Acc: 0.8895 Pre: 0.8755 Recall: 0.8790 F1: 0.8773 Train AUC: 0.9800 Val AUC: 0.9522 Time: 14.37\n",
      "Epoch: 237 Train Loss: 0.1943 Val Loss: 0.2831 Acc: 0.8931 Pre: 0.9021 Recall: 0.8548 F1: 0.8778 Train AUC: 0.9779 Val AUC: 0.9544 Time: 14.49\n",
      "Epoch: 238 Train Loss: 0.1932 Val Loss: 0.2794 Acc: 0.9094 Pre: 0.9091 Recall: 0.8871 F1: 0.8980 Train AUC: 0.9783 Val AUC: 0.9547 Time: 14.54\n",
      "Epoch: 239 Train Loss: 0.1881 Val Loss: 0.2916 Acc: 0.8841 Pre: 0.8433 Recall: 0.9113 F1: 0.8760 Train AUC: 0.9798 Val AUC: 0.9540 Time: 12.73\n",
      "Epoch: 240 Train Loss: 0.1877 Val Loss: 0.2954 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9799 Val AUC: 0.9537 Time: 12.45\n",
      "Epoch: 241 Train Loss: 0.1921 Val Loss: 0.2900 Acc: 0.8967 Pre: 0.8963 Recall: 0.8710 F1: 0.8834 Train AUC: 0.9790 Val AUC: 0.9537 Time: 12.30\n",
      "Epoch: 242 Train Loss: 0.1838 Val Loss: 0.2938 Acc: 0.8895 Pre: 0.8979 Recall: 0.8508 F1: 0.8737 Train AUC: 0.9802 Val AUC: 0.9527 Time: 13.06\n",
      "Epoch: 243 Train Loss: 0.1791 Val Loss: 0.2902 Acc: 0.8949 Pre: 0.8992 Recall: 0.8629 F1: 0.8807 Train AUC: 0.9814 Val AUC: 0.9531 Time: 14.12\n",
      "Epoch: 244 Train Loss: 0.1790 Val Loss: 0.2862 Acc: 0.9004 Pre: 0.8907 Recall: 0.8871 F1: 0.8889 Train AUC: 0.9808 Val AUC: 0.9535 Time: 14.42\n",
      "Epoch: 245 Train Loss: 0.1755 Val Loss: 0.2835 Acc: 0.9040 Pre: 0.8824 Recall: 0.9073 F1: 0.8946 Train AUC: 0.9821 Val AUC: 0.9540 Time: 14.86\n",
      "Epoch: 246 Train Loss: 0.1770 Val Loss: 0.2834 Acc: 0.8986 Pre: 0.8810 Recall: 0.8952 F1: 0.8880 Train AUC: 0.9827 Val AUC: 0.9541 Time: 14.44\n",
      "Epoch: 247 Train Loss: 0.1773 Val Loss: 0.2854 Acc: 0.9040 Pre: 0.8980 Recall: 0.8871 F1: 0.8925 Train AUC: 0.9820 Val AUC: 0.9536 Time: 12.92\n",
      "Epoch: 248 Train Loss: 0.1726 Val Loss: 0.2915 Acc: 0.8986 Pre: 0.9000 Recall: 0.8710 F1: 0.8852 Train AUC: 0.9827 Val AUC: 0.9529 Time: 12.37\n",
      "Epoch: 249 Train Loss: 0.1790 Val Loss: 0.2934 Acc: 0.9040 Pre: 0.8916 Recall: 0.8952 F1: 0.8934 Train AUC: 0.9812 Val AUC: 0.9536 Time: 12.43\n",
      "Epoch: 250 Train Loss: 0.1670 Val Loss: 0.2902 Acc: 0.9040 Pre: 0.8916 Recall: 0.8952 F1: 0.8934 Train AUC: 0.9834 Val AUC: 0.9540 Time: 12.39\n",
      "Epoch: 251 Train Loss: 0.1712 Val Loss: 0.2861 Acc: 0.9004 Pre: 0.8876 Recall: 0.8911 F1: 0.8893 Train AUC: 0.9829 Val AUC: 0.9542 Time: 13.55\n",
      "Epoch: 252 Train Loss: 0.1739 Val Loss: 0.2844 Acc: 0.9022 Pre: 0.8943 Recall: 0.8871 F1: 0.8907 Train AUC: 0.9824 Val AUC: 0.9536 Time: 13.77\n",
      "Epoch: 253 Train Loss: 0.1749 Val Loss: 0.2893 Acc: 0.8967 Pre: 0.8898 Recall: 0.8790 F1: 0.8844 Train AUC: 0.9844 Val AUC: 0.9543 Time: 14.31\n",
      "Epoch: 254 Train Loss: 0.1722 Val Loss: 0.2937 Acc: 0.9076 Pre: 0.8893 Recall: 0.9073 F1: 0.8982 Train AUC: 0.9829 Val AUC: 0.9540 Time: 15.02\n",
      "Epoch: 255 Train Loss: 0.1765 Val Loss: 0.2869 Acc: 0.9058 Pre: 0.8889 Recall: 0.9032 F1: 0.8960 Train AUC: 0.9815 Val AUC: 0.9547 Time: 13.64\n",
      "Epoch: 256 Train Loss: 0.1775 Val Loss: 0.2842 Acc: 0.9040 Pre: 0.8884 Recall: 0.8992 F1: 0.8938 Train AUC: 0.9818 Val AUC: 0.9554 Time: 12.70\n",
      "Epoch: 257 Train Loss: 0.1679 Val Loss: 0.2818 Acc: 0.9022 Pre: 0.8880 Recall: 0.8952 F1: 0.8916 Train AUC: 0.9838 Val AUC: 0.9558 Time: 13.49\n",
      "Epoch: 258 Train Loss: 0.1727 Val Loss: 0.2825 Acc: 0.9112 Pre: 0.9061 Recall: 0.8952 F1: 0.9006 Train AUC: 0.9831 Val AUC: 0.9552 Time: 13.06\n",
      "Epoch: 259 Train Loss: 0.1673 Val Loss: 0.2879 Acc: 0.9058 Pre: 0.8984 Recall: 0.8911 F1: 0.8947 Train AUC: 0.9841 Val AUC: 0.9547 Time: 13.47\n",
      "Epoch: 260 Train Loss: 0.1763 Val Loss: 0.2995 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9823 Val AUC: 0.9538 Time: 13.92\n",
      "Epoch: 261 Train Loss: 0.1679 Val Loss: 0.2971 Acc: 0.9076 Pre: 0.8988 Recall: 0.8952 F1: 0.8970 Train AUC: 0.9841 Val AUC: 0.9540 Time: 14.52\n",
      "Epoch: 262 Train Loss: 0.1703 Val Loss: 0.2923 Acc: 0.9130 Pre: 0.9065 Recall: 0.8992 F1: 0.9028 Train AUC: 0.9830 Val AUC: 0.9539 Time: 13.26\n",
      "Epoch: 263 Train Loss: 0.1694 Val Loss: 0.2896 Acc: 0.9076 Pre: 0.9053 Recall: 0.8871 F1: 0.8961 Train AUC: 0.9827 Val AUC: 0.9538 Time: 13.34\n",
      "Epoch: 264 Train Loss: 0.1694 Val Loss: 0.2866 Acc: 0.9058 Pre: 0.8952 Recall: 0.8952 F1: 0.8952 Train AUC: 0.9831 Val AUC: 0.9541 Time: 13.56\n",
      "Epoch: 265 Train Loss: 0.1638 Val Loss: 0.2868 Acc: 0.9004 Pre: 0.8845 Recall: 0.8952 F1: 0.8898 Train AUC: 0.9842 Val AUC: 0.9545 Time: 13.84\n",
      "Epoch: 266 Train Loss: 0.1717 Val Loss: 0.2942 Acc: 0.9022 Pre: 0.8911 Recall: 0.8911 F1: 0.8911 Train AUC: 0.9835 Val AUC: 0.9545 Time: 12.85\n",
      "Epoch: 267 Train Loss: 0.1612 Val Loss: 0.3045 Acc: 0.8913 Pre: 0.8821 Recall: 0.8750 F1: 0.8785 Train AUC: 0.9849 Val AUC: 0.9533 Time: 12.95\n",
      "Epoch: 268 Train Loss: 0.1670 Val Loss: 0.2993 Acc: 0.8967 Pre: 0.8930 Recall: 0.8750 F1: 0.8839 Train AUC: 0.9837 Val AUC: 0.9542 Time: 13.15\n",
      "Epoch: 269 Train Loss: 0.1667 Val Loss: 0.2925 Acc: 0.9112 Pre: 0.8964 Recall: 0.9073 F1: 0.9018 Train AUC: 0.9837 Val AUC: 0.9551 Time: 13.46\n",
      "Epoch: 270 Train Loss: 0.1644 Val Loss: 0.2901 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9842 Val AUC: 0.9549 Time: 13.89\n",
      "Epoch: 271 Train Loss: 0.1715 Val Loss: 0.2899 Acc: 0.9112 Pre: 0.9061 Recall: 0.8952 F1: 0.9006 Train AUC: 0.9836 Val AUC: 0.9556 Time: 14.52\n",
      "Epoch: 272 Train Loss: 0.1727 Val Loss: 0.2976 Acc: 0.9094 Pre: 0.9024 Recall: 0.8952 F1: 0.8988 Train AUC: 0.9819 Val AUC: 0.9543 Time: 13.81\n",
      "Epoch: 273 Train Loss: 0.1700 Val Loss: 0.3077 Acc: 0.8986 Pre: 0.8780 Recall: 0.8992 F1: 0.8884 Train AUC: 0.9826 Val AUC: 0.9528 Time: 13.54\n",
      "Epoch: 274 Train Loss: 0.1710 Val Loss: 0.2957 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9829 Val AUC: 0.9545 Time: 14.01\n",
      "Epoch: 275 Train Loss: 0.1720 Val Loss: 0.2758 Acc: 0.9076 Pre: 0.8988 Recall: 0.8952 F1: 0.8970 Train AUC: 0.9830 Val AUC: 0.9567 Time: 12.37\n",
      "Epoch: 276 Train Loss: 0.1614 Val Loss: 0.2749 Acc: 0.9022 Pre: 0.8911 Recall: 0.8911 F1: 0.8911 Train AUC: 0.9853 Val AUC: 0.9565 Time: 12.49\n",
      "Epoch: 277 Train Loss: 0.1637 Val Loss: 0.2830 Acc: 0.9022 Pre: 0.8880 Recall: 0.8952 F1: 0.8916 Train AUC: 0.9850 Val AUC: 0.9566 Time: 12.32\n",
      "Epoch: 278 Train Loss: 0.1608 Val Loss: 0.2885 Acc: 0.9094 Pre: 0.8992 Recall: 0.8992 F1: 0.8992 Train AUC: 0.9845 Val AUC: 0.9564 Time: 12.49\n",
      "Epoch: 279 Train Loss: 0.1615 Val Loss: 0.3018 Acc: 0.9112 Pre: 0.8964 Recall: 0.9073 F1: 0.9018 Train AUC: 0.9856 Val AUC: 0.9548 Time: 13.58\n",
      "Epoch: 280 Train Loss: 0.1543 Val Loss: 0.2973 Acc: 0.9040 Pre: 0.8980 Recall: 0.8871 F1: 0.8925 Train AUC: 0.9860 Val AUC: 0.9547 Time: 14.10\n",
      "Epoch: 281 Train Loss: 0.1609 Val Loss: 0.2826 Acc: 0.9130 Pre: 0.9098 Recall: 0.8952 F1: 0.9024 Train AUC: 0.9845 Val AUC: 0.9566 Time: 14.57\n",
      "Epoch: 282 Train Loss: 0.1549 Val Loss: 0.2750 Acc: 0.9076 Pre: 0.8988 Recall: 0.8952 F1: 0.8970 Train AUC: 0.9864 Val AUC: 0.9568 Time: 14.84\n",
      "Epoch: 283 Train Loss: 0.1530 Val Loss: 0.2802 Acc: 0.8986 Pre: 0.8721 Recall: 0.9073 F1: 0.8893 Train AUC: 0.9875 Val AUC: 0.9573 Time: 14.55\n",
      "Epoch: 284 Train Loss: 0.1581 Val Loss: 0.2896 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9869 Val AUC: 0.9563 Time: 12.55\n",
      "Epoch: 285 Train Loss: 0.1578 Val Loss: 0.2958 Acc: 0.9094 Pre: 0.9057 Recall: 0.8911 F1: 0.8984 Train AUC: 0.9857 Val AUC: 0.9551 Time: 12.30\n",
      "Epoch: 286 Train Loss: 0.1685 Val Loss: 0.2892 Acc: 0.9076 Pre: 0.8956 Recall: 0.8992 F1: 0.8974 Train AUC: 0.9831 Val AUC: 0.9560 Time: 12.22\n",
      "Epoch: 287 Train Loss: 0.1532 Val Loss: 0.2866 Acc: 0.9076 Pre: 0.8893 Recall: 0.9073 F1: 0.8982 Train AUC: 0.9866 Val AUC: 0.9567 Time: 12.46\n",
      "Epoch: 288 Train Loss: 0.1561 Val Loss: 0.2810 Acc: 0.9058 Pre: 0.8889 Recall: 0.9032 F1: 0.8960 Train AUC: 0.9864 Val AUC: 0.9564 Time: 13.75\n",
      "Epoch: 289 Train Loss: 0.1484 Val Loss: 0.2819 Acc: 0.9076 Pre: 0.8988 Recall: 0.8952 F1: 0.8970 Train AUC: 0.9878 Val AUC: 0.9560 Time: 13.87\n",
      "Epoch: 290 Train Loss: 0.1521 Val Loss: 0.2932 Acc: 0.8986 Pre: 0.9000 Recall: 0.8710 F1: 0.8852 Train AUC: 0.9864 Val AUC: 0.9549 Time: 14.46\n",
      "Epoch: 291 Train Loss: 0.1595 Val Loss: 0.2944 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9855 Val AUC: 0.9554 Time: 14.77\n",
      "Epoch: 292 Train Loss: 0.1469 Val Loss: 0.2941 Acc: 0.8949 Pre: 0.8654 Recall: 0.9073 F1: 0.8858 Train AUC: 0.9881 Val AUC: 0.9563 Time: 14.69\n",
      "Epoch: 293 Train Loss: 0.1550 Val Loss: 0.2845 Acc: 0.9040 Pre: 0.8824 Recall: 0.9073 F1: 0.8946 Train AUC: 0.9871 Val AUC: 0.9568 Time: 12.40\n",
      "Epoch: 294 Train Loss: 0.1568 Val Loss: 0.2834 Acc: 0.9022 Pre: 0.8943 Recall: 0.8871 F1: 0.8907 Train AUC: 0.9854 Val AUC: 0.9560 Time: 12.51\n",
      "Epoch: 295 Train Loss: 0.1663 Val Loss: 0.2803 Acc: 0.9094 Pre: 0.8992 Recall: 0.8992 F1: 0.8992 Train AUC: 0.9838 Val AUC: 0.9571 Time: 13.00\n",
      "Epoch: 296 Train Loss: 0.1499 Val Loss: 0.2918 Acc: 0.9112 Pre: 0.8902 Recall: 0.9153 F1: 0.9026 Train AUC: 0.9882 Val AUC: 0.9567 Time: 13.38\n",
      "Epoch: 297 Train Loss: 0.1503 Val Loss: 0.3215 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9872 Val AUC: 0.9534 Time: 14.09\n",
      "Epoch: 298 Train Loss: 0.1547 Val Loss: 0.3108 Acc: 0.9022 Pre: 0.8789 Recall: 0.9073 F1: 0.8929 Train AUC: 0.9857 Val AUC: 0.9541 Time: 14.92\n",
      "Epoch: 299 Train Loss: 0.1472 Val Loss: 0.2806 Acc: 0.9112 Pre: 0.9061 Recall: 0.8952 F1: 0.9006 Train AUC: 0.9872 Val AUC: 0.9575 Time: 14.67\n",
      "Epoch: 300 Train Loss: 0.1491 Val Loss: 0.2734 Acc: 0.9076 Pre: 0.9020 Recall: 0.8911 F1: 0.8966 Train AUC: 0.9873 Val AUC: 0.9578 Time: 12.68\n",
      "Epoch: 301 Train Loss: 0.1624 Val Loss: 0.2817 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9861 Val AUC: 0.9588 Time: 12.48\n",
      "Epoch: 302 Train Loss: 0.1519 Val Loss: 0.3088 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9874 Val AUC: 0.9563 Time: 12.65\n",
      "Epoch: 303 Train Loss: 0.1572 Val Loss: 0.3055 Acc: 0.9022 Pre: 0.8849 Recall: 0.8992 F1: 0.8920 Train AUC: 0.9868 Val AUC: 0.9550 Time: 13.08\n",
      "Epoch: 304 Train Loss: 0.1552 Val Loss: 0.2820 Acc: 0.9130 Pre: 0.9098 Recall: 0.8952 F1: 0.9024 Train AUC: 0.9855 Val AUC: 0.9583 Time: 14.19\n",
      "Epoch: 305 Train Loss: 0.1460 Val Loss: 0.2694 Acc: 0.9022 Pre: 0.8911 Recall: 0.8911 F1: 0.8911 Train AUC: 0.9876 Val AUC: 0.9576 Time: 14.11\n",
      "Epoch: 306 Train Loss: 0.1792 Val Loss: 0.2797 Acc: 0.9112 Pre: 0.9061 Recall: 0.8952 F1: 0.9006 Train AUC: 0.9817 Val AUC: 0.9584 Time: 14.06\n",
      "Epoch: 307 Train Loss: 0.1432 Val Loss: 0.3131 Acc: 0.9076 Pre: 0.8956 Recall: 0.8992 F1: 0.8974 Train AUC: 0.9896 Val AUC: 0.9552 Time: 14.84\n",
      "Epoch: 308 Train Loss: 0.1576 Val Loss: 0.3281 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9856 Val AUC: 0.9543 Time: 13.32\n",
      "Epoch: 309 Train Loss: 0.1653 Val Loss: 0.3043 Acc: 0.9094 Pre: 0.9024 Recall: 0.8952 F1: 0.8988 Train AUC: 0.9834 Val AUC: 0.9564 Time: 12.35\n",
      "Epoch: 310 Train Loss: 0.1495 Val Loss: 0.2818 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9864 Val AUC: 0.9588 Time: 12.41\n",
      "Epoch: 311 Train Loss: 0.1498 Val Loss: 0.2757 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9870 Val AUC: 0.9578 Time: 12.52\n",
      "Epoch: 312 Train Loss: 0.1542 Val Loss: 0.2781 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9866 Val AUC: 0.9574 Time: 12.76\n",
      "Epoch: 313 Train Loss: 0.1586 Val Loss: 0.2956 Acc: 0.9058 Pre: 0.8984 Recall: 0.8911 F1: 0.8947 Train AUC: 0.9858 Val AUC: 0.9560 Time: 13.75\n",
      "Epoch: 314 Train Loss: 0.1419 Val Loss: 0.3136 Acc: 0.8986 Pre: 0.8840 Recall: 0.8911 F1: 0.8876 Train AUC: 0.9883 Val AUC: 0.9529 Time: 14.25\n",
      "Epoch: 315 Train Loss: 0.1480 Val Loss: 0.3122 Acc: 0.8967 Pre: 0.8745 Recall: 0.8992 F1: 0.8867 Train AUC: 0.9872 Val AUC: 0.9537 Time: 14.86\n",
      "Epoch: 316 Train Loss: 0.1476 Val Loss: 0.2984 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9870 Val AUC: 0.9554 Time: 15.30\n",
      "Epoch: 317 Train Loss: 0.1447 Val Loss: 0.2855 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9878 Val AUC: 0.9570 Time: 13.14\n",
      "Epoch: 318 Train Loss: 0.1489 Val Loss: 0.2786 Acc: 0.9112 Pre: 0.9028 Recall: 0.8992 F1: 0.9010 Train AUC: 0.9884 Val AUC: 0.9578 Time: 12.68\n",
      "Epoch: 319 Train Loss: 0.1480 Val Loss: 0.2845 Acc: 0.9022 Pre: 0.8975 Recall: 0.8831 F1: 0.8902 Train AUC: 0.9886 Val AUC: 0.9564 Time: 13.24\n",
      "Epoch: 320 Train Loss: 0.1566 Val Loss: 0.2952 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9872 Val AUC: 0.9563 Time: 14.03\n",
      "Epoch: 321 Train Loss: 0.1370 Val Loss: 0.2999 Acc: 0.9004 Pre: 0.8784 Recall: 0.9032 F1: 0.8907 Train AUC: 0.9901 Val AUC: 0.9565 Time: 14.20\n",
      "Epoch: 322 Train Loss: 0.1298 Val Loss: 0.2967 Acc: 0.9058 Pre: 0.8952 Recall: 0.8952 F1: 0.8952 Train AUC: 0.9910 Val AUC: 0.9564 Time: 13.05\n",
      "Epoch: 323 Train Loss: 0.1417 Val Loss: 0.2872 Acc: 0.9130 Pre: 0.9032 Recall: 0.9032 F1: 0.9032 Train AUC: 0.9884 Val AUC: 0.9572 Time: 13.61\n",
      "Epoch: 324 Train Loss: 0.1405 Val Loss: 0.2808 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9883 Val AUC: 0.9579 Time: 14.38\n",
      "Epoch: 325 Train Loss: 0.1348 Val Loss: 0.2811 Acc: 0.9040 Pre: 0.8824 Recall: 0.9073 F1: 0.8946 Train AUC: 0.9906 Val AUC: 0.9576 Time: 14.08\n",
      "Epoch: 326 Train Loss: 0.1362 Val Loss: 0.2874 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9906 Val AUC: 0.9565 Time: 14.06\n",
      "Epoch: 327 Train Loss: 0.1344 Val Loss: 0.2972 Acc: 0.9040 Pre: 0.8854 Recall: 0.9032 F1: 0.8942 Train AUC: 0.9904 Val AUC: 0.9557 Time: 13.38\n",
      "Epoch: 328 Train Loss: 0.1395 Val Loss: 0.3069 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9898 Val AUC: 0.9557 Time: 12.89\n",
      "Epoch: 329 Train Loss: 0.1420 Val Loss: 0.2990 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9882 Val AUC: 0.9570 Time: 13.25\n",
      "Epoch: 330 Train Loss: 0.1386 Val Loss: 0.2842 Acc: 0.9112 Pre: 0.8996 Recall: 0.9032 F1: 0.9014 Train AUC: 0.9897 Val AUC: 0.9582 Time: 12.71\n",
      "Epoch: 331 Train Loss: 0.1260 Val Loss: 0.2798 Acc: 0.9076 Pre: 0.8956 Recall: 0.8992 F1: 0.8974 Train AUC: 0.9913 Val AUC: 0.9584 Time: 13.38\n",
      "Epoch: 332 Train Loss: 0.1454 Val Loss: 0.2916 Acc: 0.9058 Pre: 0.8740 Recall: 0.9234 F1: 0.8980 Train AUC: 0.9891 Val AUC: 0.9591 Time: 13.72\n",
      "Epoch: 333 Train Loss: 0.1420 Val Loss: 0.3131 Acc: 0.8895 Pre: 0.8528 Recall: 0.9113 F1: 0.8811 Train AUC: 0.9897 Val AUC: 0.9574 Time: 14.51\n",
      "Epoch: 334 Train Loss: 0.1375 Val Loss: 0.3170 Acc: 0.8967 Pre: 0.8835 Recall: 0.8871 F1: 0.8853 Train AUC: 0.9904 Val AUC: 0.9550 Time: 15.02\n",
      "Epoch: 335 Train Loss: 0.1469 Val Loss: 0.3072 Acc: 0.9022 Pre: 0.8975 Recall: 0.8831 F1: 0.8902 Train AUC: 0.9870 Val AUC: 0.9560 Time: 13.34\n",
      "Epoch: 336 Train Loss: 0.1406 Val Loss: 0.2782 Acc: 0.9022 Pre: 0.8880 Recall: 0.8952 F1: 0.8916 Train AUC: 0.9889 Val AUC: 0.9581 Time: 12.33\n",
      "Epoch: 337 Train Loss: 0.1328 Val Loss: 0.2791 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9908 Val AUC: 0.9595 Time: 12.36\n",
      "Epoch: 338 Train Loss: 0.1446 Val Loss: 0.2829 Acc: 0.9076 Pre: 0.8774 Recall: 0.9234 F1: 0.8998 Train AUC: 0.9891 Val AUC: 0.9593 Time: 12.79\n",
      "Epoch: 339 Train Loss: 0.1387 Val Loss: 0.3134 Acc: 0.9040 Pre: 0.8884 Recall: 0.8992 F1: 0.8938 Train AUC: 0.9899 Val AUC: 0.9561 Time: 13.87\n",
      "Epoch: 340 Train Loss: 0.1420 Val Loss: 0.3354 Acc: 0.8949 Pre: 0.8682 Recall: 0.9032 F1: 0.8854 Train AUC: 0.9879 Val AUC: 0.9544 Time: 14.14\n",
      "Epoch: 341 Train Loss: 0.1431 Val Loss: 0.3146 Acc: 0.9004 Pre: 0.8755 Recall: 0.9073 F1: 0.8911 Train AUC: 0.9880 Val AUC: 0.9558 Time: 13.78\n",
      "Epoch: 342 Train Loss: 0.1315 Val Loss: 0.2862 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9898 Val AUC: 0.9585 Time: 14.54\n",
      "Epoch: 343 Train Loss: 0.1328 Val Loss: 0.2795 Acc: 0.8895 Pre: 0.8528 Recall: 0.9113 F1: 0.8811 Train AUC: 0.9902 Val AUC: 0.9582 Time: 13.30\n",
      "Epoch: 344 Train Loss: 0.1453 Val Loss: 0.2787 Acc: 0.9040 Pre: 0.8884 Recall: 0.8992 F1: 0.8938 Train AUC: 0.9890 Val AUC: 0.9586 Time: 12.27\n",
      "Epoch: 345 Train Loss: 0.1318 Val Loss: 0.3030 Acc: 0.9058 Pre: 0.8984 Recall: 0.8911 F1: 0.8947 Train AUC: 0.9909 Val AUC: 0.9565 Time: 12.39\n",
      "Epoch: 346 Train Loss: 0.1344 Val Loss: 0.3314 Acc: 0.8949 Pre: 0.8740 Recall: 0.8952 F1: 0.8845 Train AUC: 0.9898 Val AUC: 0.9534 Time: 13.05\n",
      "Epoch: 347 Train Loss: 0.1335 Val Loss: 0.3327 Acc: 0.8949 Pre: 0.8654 Recall: 0.9073 F1: 0.8858 Train AUC: 0.9897 Val AUC: 0.9551 Time: 13.42\n",
      "Epoch: 348 Train Loss: 0.1432 Val Loss: 0.2942 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9893 Val AUC: 0.9591 Time: 14.00\n",
      "Epoch: 349 Train Loss: 0.1235 Val Loss: 0.2845 Acc: 0.9004 Pre: 0.8755 Recall: 0.9073 F1: 0.8911 Train AUC: 0.9920 Val AUC: 0.9587 Time: 14.66\n",
      "Epoch: 350 Train Loss: 0.1372 Val Loss: 0.2884 Acc: 0.8986 Pre: 0.8721 Recall: 0.9073 F1: 0.8893 Train AUC: 0.9895 Val AUC: 0.9579 Time: 14.80\n",
      "Epoch: 351 Train Loss: 0.1452 Val Loss: 0.2939 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9880 Val AUC: 0.9587 Time: 14.04\n",
      "Epoch: 352 Train Loss: 0.1308 Val Loss: 0.3090 Acc: 0.9004 Pre: 0.8814 Recall: 0.8992 F1: 0.8902 Train AUC: 0.9904 Val AUC: 0.9574 Time: 12.42\n",
      "Epoch: 353 Train Loss: 0.1315 Val Loss: 0.3297 Acc: 0.8931 Pre: 0.8765 Recall: 0.8871 F1: 0.8818 Train AUC: 0.9895 Val AUC: 0.9544 Time: 12.76\n",
      "Epoch: 354 Train Loss: 0.1444 Val Loss: 0.3220 Acc: 0.8931 Pre: 0.8765 Recall: 0.8871 F1: 0.8818 Train AUC: 0.9874 Val AUC: 0.9545 Time: 12.29\n",
      "Epoch: 355 Train Loss: 0.1308 Val Loss: 0.2955 Acc: 0.8949 Pre: 0.8682 Recall: 0.9032 F1: 0.8854 Train AUC: 0.9902 Val AUC: 0.9570 Time: 12.56\n",
      "Epoch: 356 Train Loss: 0.1249 Val Loss: 0.2783 Acc: 0.9004 Pre: 0.8755 Recall: 0.9073 F1: 0.8911 Train AUC: 0.9928 Val AUC: 0.9599 Time: 14.09\n",
      "Epoch: 357 Train Loss: 0.1293 Val Loss: 0.2888 Acc: 0.9004 Pre: 0.8814 Recall: 0.8992 F1: 0.8902 Train AUC: 0.9914 Val AUC: 0.9591 Time: 13.97\n",
      "Epoch: 358 Train Loss: 0.1274 Val Loss: 0.3065 Acc: 0.8949 Pre: 0.8598 Recall: 0.9153 F1: 0.8867 Train AUC: 0.9917 Val AUC: 0.9584 Time: 14.66\n",
      "Epoch: 359 Train Loss: 0.1372 Val Loss: 0.3148 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9889 Val AUC: 0.9581 Time: 14.61\n",
      "Epoch: 360 Train Loss: 0.1313 Val Loss: 0.3255 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9899 Val AUC: 0.9572 Time: 12.67\n",
      "Epoch: 361 Train Loss: 0.1362 Val Loss: 0.3287 Acc: 0.8913 Pre: 0.8534 Recall: 0.9153 F1: 0.8833 Train AUC: 0.9889 Val AUC: 0.9550 Time: 12.43\n",
      "Epoch: 362 Train Loss: 0.1221 Val Loss: 0.3146 Acc: 0.8877 Pre: 0.8577 Recall: 0.8992 F1: 0.8780 Train AUC: 0.9915 Val AUC: 0.9543 Time: 12.70\n",
      "Epoch: 363 Train Loss: 0.1322 Val Loss: 0.2975 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9900 Val AUC: 0.9560 Time: 13.10\n",
      "Epoch: 364 Train Loss: 0.1300 Val Loss: 0.2961 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9908 Val AUC: 0.9565 Time: 13.48\n",
      "Epoch: 365 Train Loss: 0.1285 Val Loss: 0.2999 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9911 Val AUC: 0.9569 Time: 14.16\n",
      "Epoch: 366 Train Loss: 0.1239 Val Loss: 0.3087 Acc: 0.9040 Pre: 0.8884 Recall: 0.8992 F1: 0.8938 Train AUC: 0.9915 Val AUC: 0.9571 Time: 14.06\n",
      "Epoch: 367 Train Loss: 0.1225 Val Loss: 0.3180 Acc: 0.9058 Pre: 0.8952 Recall: 0.8952 F1: 0.8952 Train AUC: 0.9911 Val AUC: 0.9561 Time: 14.00\n",
      "Epoch: 368 Train Loss: 0.1273 Val Loss: 0.3081 Acc: 0.8967 Pre: 0.8716 Recall: 0.9032 F1: 0.8871 Train AUC: 0.9903 Val AUC: 0.9574 Time: 12.58\n",
      "Epoch: 369 Train Loss: 0.1266 Val Loss: 0.2892 Acc: 0.8967 Pre: 0.8716 Recall: 0.9032 F1: 0.8871 Train AUC: 0.9910 Val AUC: 0.9588 Time: 12.82\n",
      "Epoch: 370 Train Loss: 0.1266 Val Loss: 0.2799 Acc: 0.9130 Pre: 0.9032 Recall: 0.9032 F1: 0.9032 Train AUC: 0.9913 Val AUC: 0.9597 Time: 13.21\n",
      "Epoch: 371 Train Loss: 0.1318 Val Loss: 0.2880 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9913 Val AUC: 0.9600 Time: 13.70\n",
      "Epoch: 372 Train Loss: 0.1166 Val Loss: 0.3045 Acc: 0.8949 Pre: 0.8654 Recall: 0.9073 F1: 0.8858 Train AUC: 0.9930 Val AUC: 0.9583 Time: 14.45\n",
      "Epoch: 373 Train Loss: 0.1260 Val Loss: 0.3087 Acc: 0.9022 Pre: 0.8789 Recall: 0.9073 F1: 0.8929 Train AUC: 0.9911 Val AUC: 0.9573 Time: 15.29\n",
      "Epoch: 374 Train Loss: 0.1210 Val Loss: 0.3060 Acc: 0.9004 Pre: 0.8814 Recall: 0.8992 F1: 0.8902 Train AUC: 0.9916 Val AUC: 0.9569 Time: 13.33\n",
      "Epoch: 375 Train Loss: 0.1200 Val Loss: 0.2973 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9924 Val AUC: 0.9573 Time: 12.30\n",
      "Epoch: 376 Train Loss: 0.1182 Val Loss: 0.2938 Acc: 0.8949 Pre: 0.8598 Recall: 0.9153 F1: 0.8867 Train AUC: 0.9928 Val AUC: 0.9579 Time: 12.25\n",
      "Epoch: 377 Train Loss: 0.1129 Val Loss: 0.2931 Acc: 0.9112 Pre: 0.8902 Recall: 0.9153 F1: 0.9026 Train AUC: 0.9942 Val AUC: 0.9584 Time: 12.47\n",
      "Epoch: 378 Train Loss: 0.1122 Val Loss: 0.3006 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9941 Val AUC: 0.9585 Time: 12.26\n",
      "Epoch: 379 Train Loss: 0.1137 Val Loss: 0.3075 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9929 Val AUC: 0.9585 Time: 13.53\n",
      "Epoch: 380 Train Loss: 0.1149 Val Loss: 0.3036 Acc: 0.9076 Pre: 0.8956 Recall: 0.8992 F1: 0.8974 Train AUC: 0.9928 Val AUC: 0.9585 Time: 13.83\n",
      "Epoch: 381 Train Loss: 0.1135 Val Loss: 0.2936 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9926 Val AUC: 0.9599 Time: 14.39\n",
      "Epoch: 382 Train Loss: 0.1176 Val Loss: 0.2954 Acc: 0.8931 Pre: 0.8487 Recall: 0.9274 F1: 0.8863 Train AUC: 0.9925 Val AUC: 0.9605 Time: 15.16\n",
      "Epoch: 383 Train Loss: 0.1232 Val Loss: 0.3037 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9923 Val AUC: 0.9596 Time: 15.12\n",
      "Epoch: 384 Train Loss: 0.1201 Val Loss: 0.3055 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9925 Val AUC: 0.9586 Time: 13.82\n",
      "Epoch: 385 Train Loss: 0.1140 Val Loss: 0.3138 Acc: 0.9076 Pre: 0.8988 Recall: 0.8952 F1: 0.8970 Train AUC: 0.9930 Val AUC: 0.9580 Time: 12.09\n",
      "Epoch: 386 Train Loss: 0.1213 Val Loss: 0.3045 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9916 Val AUC: 0.9590 Time: 12.13\n",
      "Epoch: 387 Train Loss: 0.1140 Val Loss: 0.2948 Acc: 0.8986 Pre: 0.8582 Recall: 0.9274 F1: 0.8915 Train AUC: 0.9926 Val AUC: 0.9600 Time: 12.36\n",
      "Epoch: 388 Train Loss: 0.1175 Val Loss: 0.2917 Acc: 0.8986 Pre: 0.8582 Recall: 0.9274 F1: 0.8915 Train AUC: 0.9933 Val AUC: 0.9597 Time: 12.72\n",
      "Epoch: 389 Train Loss: 0.1112 Val Loss: 0.2968 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9940 Val AUC: 0.9592 Time: 13.53\n",
      "Epoch: 390 Train Loss: 0.1208 Val Loss: 0.3213 Acc: 0.8967 Pre: 0.8716 Recall: 0.9032 F1: 0.8871 Train AUC: 0.9926 Val AUC: 0.9569 Time: 13.86\n",
      "Epoch: 391 Train Loss: 0.1191 Val Loss: 0.3345 Acc: 0.8949 Pre: 0.8654 Recall: 0.9073 F1: 0.8858 Train AUC: 0.9920 Val AUC: 0.9563 Time: 14.88\n",
      "Epoch: 392 Train Loss: 0.1201 Val Loss: 0.3209 Acc: 0.8967 Pre: 0.8687 Recall: 0.9073 F1: 0.8876 Train AUC: 0.9916 Val AUC: 0.9577 Time: 14.80\n",
      "Epoch: 393 Train Loss: 0.1155 Val Loss: 0.3036 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9923 Val AUC: 0.9596 Time: 13.53\n",
      "Epoch: 394 Train Loss: 0.1073 Val Loss: 0.2937 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9941 Val AUC: 0.9605 Time: 14.47\n",
      "Epoch: 395 Train Loss: 0.1130 Val Loss: 0.2946 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9939 Val AUC: 0.9600 Time: 12.15\n",
      "Epoch: 396 Train Loss: 0.1124 Val Loss: 0.2999 Acc: 0.9040 Pre: 0.8854 Recall: 0.9032 F1: 0.8942 Train AUC: 0.9930 Val AUC: 0.9591 Time: 12.36\n",
      "Epoch: 397 Train Loss: 0.1113 Val Loss: 0.3004 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9930 Val AUC: 0.9596 Time: 12.59\n",
      "Epoch: 398 Train Loss: 0.1112 Val Loss: 0.3059 Acc: 0.9058 Pre: 0.8889 Recall: 0.9032 F1: 0.8960 Train AUC: 0.9938 Val AUC: 0.9584 Time: 13.65\n",
      "Epoch: 399 Train Loss: 0.1107 Val Loss: 0.3178 Acc: 0.9004 Pre: 0.8755 Recall: 0.9073 F1: 0.8911 Train AUC: 0.9941 Val AUC: 0.9574 Time: 13.97\n",
      "Epoch: 400 Train Loss: 0.1175 Val Loss: 0.3258 Acc: 0.9040 Pre: 0.8625 Recall: 0.9355 F1: 0.8975 Train AUC: 0.9924 Val AUC: 0.9582 Time: 14.39\n",
      "Epoch: 401 Train Loss: 0.1050 Val Loss: 0.3113 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9946 Val AUC: 0.9587 Time: 14.19\n",
      "Epoch: 402 Train Loss: 0.1079 Val Loss: 0.2960 Acc: 0.9058 Pre: 0.8920 Recall: 0.8992 F1: 0.8956 Train AUC: 0.9942 Val AUC: 0.9590 Time: 14.23\n",
      "Epoch: 403 Train Loss: 0.1193 Val Loss: 0.2919 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9927 Val AUC: 0.9594 Time: 12.73\n",
      "Epoch: 404 Train Loss: 0.1159 Val Loss: 0.3054 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9935 Val AUC: 0.9596 Time: 13.11\n",
      "Epoch: 405 Train Loss: 0.1059 Val Loss: 0.3130 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9952 Val AUC: 0.9599 Time: 13.44\n",
      "Epoch: 406 Train Loss: 0.1129 Val Loss: 0.3173 Acc: 0.9040 Pre: 0.8854 Recall: 0.9032 F1: 0.8942 Train AUC: 0.9942 Val AUC: 0.9587 Time: 13.74\n",
      "Epoch: 407 Train Loss: 0.1134 Val Loss: 0.3185 Acc: 0.9112 Pre: 0.9095 Recall: 0.8911 F1: 0.9002 Train AUC: 0.9925 Val AUC: 0.9587 Time: 14.33\n",
      "Epoch: 408 Train Loss: 0.1204 Val Loss: 0.2979 Acc: 0.9112 Pre: 0.8902 Recall: 0.9153 F1: 0.9026 Train AUC: 0.9927 Val AUC: 0.9597 Time: 13.21\n",
      "Epoch: 409 Train Loss: 0.1127 Val Loss: 0.3069 Acc: 0.8913 Pre: 0.8431 Recall: 0.9315 F1: 0.8851 Train AUC: 0.9931 Val AUC: 0.9599 Time: 13.71\n",
      "Epoch: 410 Train Loss: 0.1264 Val Loss: 0.3023 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9934 Val AUC: 0.9596 Time: 12.91\n",
      "Epoch: 411 Train Loss: 0.0998 Val Loss: 0.3170 Acc: 0.9058 Pre: 0.8952 Recall: 0.8952 F1: 0.8952 Train AUC: 0.9956 Val AUC: 0.9587 Time: 13.47\n",
      "Epoch: 412 Train Loss: 0.1158 Val Loss: 0.3230 Acc: 0.9058 Pre: 0.8920 Recall: 0.8992 F1: 0.8956 Train AUC: 0.9927 Val AUC: 0.9582 Time: 13.94\n",
      "Epoch: 413 Train Loss: 0.1125 Val Loss: 0.3265 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9932 Val AUC: 0.9594 Time: 14.40\n",
      "Epoch: 414 Train Loss: 0.1171 Val Loss: 0.3205 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9932 Val AUC: 0.9595 Time: 14.89\n",
      "Epoch: 415 Train Loss: 0.1130 Val Loss: 0.3201 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9934 Val AUC: 0.9569 Time: 13.52\n",
      "Epoch: 416 Train Loss: 0.1011 Val Loss: 0.3249 Acc: 0.8986 Pre: 0.8780 Recall: 0.8992 F1: 0.8884 Train AUC: 0.9947 Val AUC: 0.9564 Time: 12.30\n",
      "Epoch: 417 Train Loss: 0.1124 Val Loss: 0.3247 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9935 Val AUC: 0.9572 Time: 12.29\n",
      "Epoch: 418 Train Loss: 0.1070 Val Loss: 0.3221 Acc: 0.8986 Pre: 0.8582 Recall: 0.9274 F1: 0.8915 Train AUC: 0.9937 Val AUC: 0.9582 Time: 12.53\n",
      "Epoch: 419 Train Loss: 0.1142 Val Loss: 0.3154 Acc: 0.8949 Pre: 0.8519 Recall: 0.9274 F1: 0.8880 Train AUC: 0.9928 Val AUC: 0.9596 Time: 12.13\n",
      "Epoch: 420 Train Loss: 0.1083 Val Loss: 0.3033 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9951 Val AUC: 0.9602 Time: 12.24\n",
      "Epoch: 421 Train Loss: 0.0987 Val Loss: 0.2996 Acc: 0.9040 Pre: 0.8916 Recall: 0.8952 F1: 0.8934 Train AUC: 0.9949 Val AUC: 0.9604 Time: 12.47\n",
      "Epoch: 422 Train Loss: 0.1066 Val Loss: 0.2921 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9945 Val AUC: 0.9615 Time: 12.35\n",
      "Epoch: 423 Train Loss: 0.1111 Val Loss: 0.3041 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9933 Val AUC: 0.9612 Time: 13.88\n",
      "Epoch: 424 Train Loss: 0.1161 Val Loss: 0.3175 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9932 Val AUC: 0.9595 Time: 14.15\n",
      "Epoch: 425 Train Loss: 0.1081 Val Loss: 0.3300 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9944 Val AUC: 0.9576 Time: 14.67\n",
      "Epoch: 426 Train Loss: 0.1122 Val Loss: 0.3265 Acc: 0.9004 Pre: 0.8784 Recall: 0.9032 F1: 0.8907 Train AUC: 0.9932 Val AUC: 0.9577 Time: 15.62\n",
      "Epoch: 427 Train Loss: 0.1068 Val Loss: 0.3067 Acc: 0.9058 Pre: 0.8712 Recall: 0.9274 F1: 0.8984 Train AUC: 0.9935 Val AUC: 0.9606 Time: 14.38\n",
      "Epoch: 428 Train Loss: 0.1013 Val Loss: 0.3077 Acc: 0.8949 Pre: 0.8519 Recall: 0.9274 F1: 0.8880 Train AUC: 0.9953 Val AUC: 0.9603 Time: 14.84\n",
      "Epoch: 429 Train Loss: 0.1139 Val Loss: 0.3077 Acc: 0.9004 Pre: 0.8614 Recall: 0.9274 F1: 0.8932 Train AUC: 0.9939 Val AUC: 0.9586 Time: 12.04\n",
      "Epoch: 430 Train Loss: 0.1052 Val Loss: 0.3371 Acc: 0.8949 Pre: 0.8740 Recall: 0.8952 F1: 0.8845 Train AUC: 0.9944 Val AUC: 0.9553 Time: 12.29\n",
      "Epoch: 431 Train Loss: 0.1176 Val Loss: 0.3462 Acc: 0.8986 Pre: 0.8840 Recall: 0.8911 F1: 0.8876 Train AUC: 0.9923 Val AUC: 0.9550 Time: 12.41\n",
      "Epoch: 432 Train Loss: 0.1210 Val Loss: 0.3256 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9917 Val AUC: 0.9589 Time: 12.35\n",
      "Epoch: 433 Train Loss: 0.1060 Val Loss: 0.3151 Acc: 0.8949 Pre: 0.8493 Recall: 0.9315 F1: 0.8885 Train AUC: 0.9938 Val AUC: 0.9627 Time: 12.61\n",
      "Epoch: 434 Train Loss: 0.1150 Val Loss: 0.2894 Acc: 0.9076 Pre: 0.8774 Recall: 0.9234 F1: 0.8998 Train AUC: 0.9946 Val AUC: 0.9625 Time: 13.76\n",
      "Epoch: 435 Train Loss: 0.1097 Val Loss: 0.2950 Acc: 0.9022 Pre: 0.8880 Recall: 0.8952 F1: 0.8916 Train AUC: 0.9940 Val AUC: 0.9618 Time: 13.94\n",
      "Epoch: 436 Train Loss: 0.1071 Val Loss: 0.3076 Acc: 0.9040 Pre: 0.8854 Recall: 0.9032 F1: 0.8942 Train AUC: 0.9943 Val AUC: 0.9609 Time: 14.60\n",
      "Epoch: 437 Train Loss: 0.1094 Val Loss: 0.3393 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9935 Val AUC: 0.9595 Time: 14.09\n",
      "Epoch: 438 Train Loss: 0.1263 Val Loss: 0.3168 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9923 Val AUC: 0.9600 Time: 14.14\n",
      "Epoch: 439 Train Loss: 0.1081 Val Loss: 0.2902 Acc: 0.9040 Pre: 0.8916 Recall: 0.8952 F1: 0.8934 Train AUC: 0.9940 Val AUC: 0.9597 Time: 13.31\n",
      "Epoch: 440 Train Loss: 0.1108 Val Loss: 0.2926 Acc: 0.9040 Pre: 0.8947 Recall: 0.8911 F1: 0.8929 Train AUC: 0.9945 Val AUC: 0.9604 Time: 13.15\n",
      "Epoch: 441 Train Loss: 0.1022 Val Loss: 0.2949 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9948 Val AUC: 0.9608 Time: 13.36\n",
      "Epoch: 442 Train Loss: 0.1119 Val Loss: 0.3308 Acc: 0.8913 Pre: 0.8561 Recall: 0.9113 F1: 0.8828 Train AUC: 0.9935 Val AUC: 0.9592 Time: 13.21\n",
      "Epoch: 443 Train Loss: 0.1127 Val Loss: 0.3303 Acc: 0.8931 Pre: 0.8649 Recall: 0.9032 F1: 0.8836 Train AUC: 0.9942 Val AUC: 0.9581 Time: 13.00\n",
      "Epoch: 444 Train Loss: 0.1118 Val Loss: 0.3196 Acc: 0.9040 Pre: 0.8854 Recall: 0.9032 F1: 0.8942 Train AUC: 0.9933 Val AUC: 0.9586 Time: 14.26\n",
      "Epoch: 445 Train Loss: 0.1052 Val Loss: 0.2976 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9944 Val AUC: 0.9604 Time: 14.98\n",
      "Epoch: 446 Train Loss: 0.1000 Val Loss: 0.2932 Acc: 0.9004 Pre: 0.8614 Recall: 0.9274 F1: 0.8932 Train AUC: 0.9947 Val AUC: 0.9605 Time: 13.57\n",
      "Epoch: 447 Train Loss: 0.1059 Val Loss: 0.2971 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9944 Val AUC: 0.9602 Time: 13.60\n",
      "Epoch: 448 Train Loss: 0.1005 Val Loss: 0.3215 Acc: 0.9022 Pre: 0.8880 Recall: 0.8952 F1: 0.8916 Train AUC: 0.9947 Val AUC: 0.9577 Time: 12.43\n",
      "Epoch: 449 Train Loss: 0.1048 Val Loss: 0.3429 Acc: 0.8949 Pre: 0.8740 Recall: 0.8952 F1: 0.8845 Train AUC: 0.9941 Val AUC: 0.9555 Time: 13.31\n",
      "Epoch: 450 Train Loss: 0.0999 Val Loss: 0.3359 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9946 Val AUC: 0.9563 Time: 13.74\n",
      "Epoch: 451 Train Loss: 0.1046 Val Loss: 0.3135 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9946 Val AUC: 0.9601 Time: 14.34\n",
      "Epoch: 452 Train Loss: 0.0928 Val Loss: 0.3048 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9963 Val AUC: 0.9605 Time: 14.13\n",
      "Epoch: 453 Train Loss: 0.1121 Val Loss: 0.3045 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9937 Val AUC: 0.9602 Time: 13.61\n",
      "Epoch: 454 Train Loss: 0.1003 Val Loss: 0.3187 Acc: 0.8967 Pre: 0.8687 Recall: 0.9073 F1: 0.8876 Train AUC: 0.9950 Val AUC: 0.9593 Time: 12.25\n",
      "Epoch: 455 Train Loss: 0.1048 Val Loss: 0.3253 Acc: 0.8913 Pre: 0.8588 Recall: 0.9073 F1: 0.8824 Train AUC: 0.9943 Val AUC: 0.9600 Time: 12.55\n",
      "Epoch: 456 Train Loss: 0.0972 Val Loss: 0.3146 Acc: 0.8967 Pre: 0.8631 Recall: 0.9153 F1: 0.8885 Train AUC: 0.9948 Val AUC: 0.9610 Time: 14.08\n",
      "Epoch: 457 Train Loss: 0.0952 Val Loss: 0.2953 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9954 Val AUC: 0.9619 Time: 13.84\n",
      "Epoch: 458 Train Loss: 0.0955 Val Loss: 0.2866 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9953 Val AUC: 0.9623 Time: 14.94\n",
      "Epoch: 459 Train Loss: 0.1172 Val Loss: 0.2928 Acc: 0.9094 Pre: 0.8779 Recall: 0.9274 F1: 0.9020 Train AUC: 0.9929 Val AUC: 0.9626 Time: 13.58\n",
      "Epoch: 460 Train Loss: 0.0946 Val Loss: 0.3089 Acc: 0.8986 Pre: 0.8664 Recall: 0.9153 F1: 0.8902 Train AUC: 0.9955 Val AUC: 0.9611 Time: 12.69\n",
      "Epoch: 461 Train Loss: 0.1014 Val Loss: 0.3252 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9946 Val AUC: 0.9590 Time: 13.22\n",
      "Epoch: 462 Train Loss: 0.0947 Val Loss: 0.3289 Acc: 0.8949 Pre: 0.8598 Recall: 0.9153 F1: 0.8867 Train AUC: 0.9955 Val AUC: 0.9586 Time: 13.80\n",
      "Epoch: 463 Train Loss: 0.0956 Val Loss: 0.3324 Acc: 0.8913 Pre: 0.8534 Recall: 0.9153 F1: 0.8833 Train AUC: 0.9955 Val AUC: 0.9582 Time: 13.71\n",
      "Epoch: 464 Train Loss: 0.1020 Val Loss: 0.3205 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9948 Val AUC: 0.9593 Time: 14.09\n",
      "Epoch: 465 Train Loss: 0.0930 Val Loss: 0.3133 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9959 Val AUC: 0.9597 Time: 13.24\n",
      "Epoch: 466 Train Loss: 0.1027 Val Loss: 0.3138 Acc: 0.9094 Pre: 0.8960 Recall: 0.9032 F1: 0.8996 Train AUC: 0.9944 Val AUC: 0.9595 Time: 13.17\n",
      "Epoch: 467 Train Loss: 0.0999 Val Loss: 0.3297 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9948 Val AUC: 0.9579 Time: 12.81\n",
      "Epoch: 468 Train Loss: 0.0964 Val Loss: 0.3322 Acc: 0.8931 Pre: 0.8649 Recall: 0.9032 F1: 0.8836 Train AUC: 0.9951 Val AUC: 0.9577 Time: 13.43\n",
      "Epoch: 469 Train Loss: 0.1025 Val Loss: 0.3316 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9945 Val AUC: 0.9571 Time: 13.72\n",
      "Epoch: 470 Train Loss: 0.0987 Val Loss: 0.3134 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9954 Val AUC: 0.9586 Time: 14.54\n",
      "Epoch: 471 Train Loss: 0.0911 Val Loss: 0.3144 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9964 Val AUC: 0.9603 Time: 13.15\n",
      "Epoch: 472 Train Loss: 0.0905 Val Loss: 0.3190 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9959 Val AUC: 0.9618 Time: 12.97\n",
      "Epoch: 473 Train Loss: 0.0934 Val Loss: 0.3263 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9956 Val AUC: 0.9616 Time: 13.10\n",
      "Epoch: 474 Train Loss: 0.0995 Val Loss: 0.3141 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9948 Val AUC: 0.9614 Time: 13.72\n",
      "Epoch: 475 Train Loss: 0.0932 Val Loss: 0.3039 Acc: 0.9112 Pre: 0.8842 Recall: 0.9234 F1: 0.9034 Train AUC: 0.9954 Val AUC: 0.9619 Time: 13.31\n",
      "Epoch: 476 Train Loss: 0.0992 Val Loss: 0.3152 Acc: 0.9094 Pre: 0.8929 Recall: 0.9073 F1: 0.9000 Train AUC: 0.9948 Val AUC: 0.9594 Time: 13.86\n",
      "Epoch: 477 Train Loss: 0.1038 Val Loss: 0.3369 Acc: 0.8913 Pre: 0.8561 Recall: 0.9113 F1: 0.8828 Train AUC: 0.9945 Val AUC: 0.9572 Time: 13.63\n",
      "Epoch: 478 Train Loss: 0.0928 Val Loss: 0.3422 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9958 Val AUC: 0.9565 Time: 13.74\n",
      "Epoch: 479 Train Loss: 0.0991 Val Loss: 0.3268 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9945 Val AUC: 0.9589 Time: 12.51\n",
      "Epoch: 480 Train Loss: 0.0883 Val Loss: 0.3155 Acc: 0.9094 Pre: 0.8867 Recall: 0.9153 F1: 0.9008 Train AUC: 0.9960 Val AUC: 0.9602 Time: 12.78\n",
      "Epoch: 481 Train Loss: 0.0994 Val Loss: 0.3154 Acc: 0.9058 Pre: 0.8798 Recall: 0.9153 F1: 0.8972 Train AUC: 0.9949 Val AUC: 0.9614 Time: 14.04\n",
      "Epoch: 482 Train Loss: 0.0971 Val Loss: 0.3107 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9950 Val AUC: 0.9608 Time: 14.18\n",
      "Epoch: 483 Train Loss: 0.1002 Val Loss: 0.3058 Acc: 0.8986 Pre: 0.8721 Recall: 0.9073 F1: 0.8893 Train AUC: 0.9948 Val AUC: 0.9606 Time: 13.75\n",
      "Epoch: 484 Train Loss: 0.0972 Val Loss: 0.3097 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9952 Val AUC: 0.9609 Time: 14.09\n",
      "Epoch: 485 Train Loss: 0.1041 Val Loss: 0.3230 Acc: 0.8967 Pre: 0.8550 Recall: 0.9274 F1: 0.8897 Train AUC: 0.9948 Val AUC: 0.9610 Time: 12.28\n",
      "Epoch: 486 Train Loss: 0.0900 Val Loss: 0.3219 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9967 Val AUC: 0.9601 Time: 12.20\n",
      "Epoch: 487 Train Loss: 0.0856 Val Loss: 0.3349 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9971 Val AUC: 0.9583 Time: 12.24\n",
      "Epoch: 488 Train Loss: 0.1002 Val Loss: 0.3394 Acc: 0.9022 Pre: 0.8819 Recall: 0.9032 F1: 0.8924 Train AUC: 0.9948 Val AUC: 0.9577 Time: 13.73\n",
      "Epoch: 489 Train Loss: 0.1046 Val Loss: 0.3501 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9944 Val AUC: 0.9562 Time: 13.44\n",
      "Epoch: 490 Train Loss: 0.0931 Val Loss: 0.3544 Acc: 0.8877 Pre: 0.8444 Recall: 0.9194 F1: 0.8803 Train AUC: 0.9956 Val AUC: 0.9570 Time: 14.24\n",
      "Epoch: 491 Train Loss: 0.1102 Val Loss: 0.3140 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9947 Val AUC: 0.9611 Time: 15.00\n",
      "Epoch: 492 Train Loss: 0.0925 Val Loss: 0.3030 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9959 Val AUC: 0.9623 Time: 14.95\n",
      "Epoch: 493 Train Loss: 0.0860 Val Loss: 0.3062 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9963 Val AUC: 0.9627 Time: 13.07\n",
      "Epoch: 494 Train Loss: 0.1036 Val Loss: 0.3106 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9937 Val AUC: 0.9621 Time: 12.78\n",
      "Epoch: 495 Train Loss: 0.0889 Val Loss: 0.3220 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9961 Val AUC: 0.9606 Time: 12.40\n",
      "Epoch: 496 Train Loss: 0.0970 Val Loss: 0.3312 Acc: 0.8986 Pre: 0.8664 Recall: 0.9153 F1: 0.8902 Train AUC: 0.9951 Val AUC: 0.9581 Time: 12.51\n",
      "Epoch: 497 Train Loss: 0.0951 Val Loss: 0.3220 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9953 Val AUC: 0.9582 Time: 12.98\n",
      "Epoch: 498 Train Loss: 0.0876 Val Loss: 0.3149 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9964 Val AUC: 0.9594 Time: 13.80\n",
      "Epoch: 499 Train Loss: 0.0979 Val Loss: 0.3161 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9950 Val AUC: 0.9601 Time: 13.63\n",
      "Epoch: 500 Train Loss: 0.0945 Val Loss: 0.3251 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9955 Val AUC: 0.9607 Time: 13.75\n",
      "Epoch: 501 Train Loss: 0.0983 Val Loss: 0.3163 Acc: 0.9130 Pre: 0.8906 Recall: 0.9194 F1: 0.9048 Train AUC: 0.9951 Val AUC: 0.9608 Time: 14.35\n",
      "Epoch: 502 Train Loss: 0.0926 Val Loss: 0.3154 Acc: 0.9004 Pre: 0.8814 Recall: 0.8992 F1: 0.8902 Train AUC: 0.9952 Val AUC: 0.9607 Time: 13.15\n",
      "Epoch: 503 Train Loss: 0.0981 Val Loss: 0.3191 Acc: 0.8913 Pre: 0.8615 Recall: 0.9032 F1: 0.8819 Train AUC: 0.9957 Val AUC: 0.9607 Time: 12.55\n",
      "Epoch: 504 Train Loss: 0.0918 Val Loss: 0.3285 Acc: 0.8949 Pre: 0.8493 Recall: 0.9315 F1: 0.8885 Train AUC: 0.9957 Val AUC: 0.9625 Time: 12.40\n",
      "Epoch: 505 Train Loss: 0.1055 Val Loss: 0.3209 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9954 Val AUC: 0.9621 Time: 12.45\n",
      "Epoch: 506 Train Loss: 0.0896 Val Loss: 0.3212 Acc: 0.9058 Pre: 0.8889 Recall: 0.9032 F1: 0.8960 Train AUC: 0.9967 Val AUC: 0.9602 Time: 12.52\n",
      "Epoch: 507 Train Loss: 0.0993 Val Loss: 0.3227 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9959 Val AUC: 0.9594 Time: 12.95\n",
      "Epoch: 508 Train Loss: 0.0947 Val Loss: 0.3308 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9954 Val AUC: 0.9576 Time: 13.69\n",
      "Epoch: 509 Train Loss: 0.0940 Val Loss: 0.3253 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9959 Val AUC: 0.9587 Time: 14.15\n",
      "Epoch: 510 Train Loss: 0.0850 Val Loss: 0.3152 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9965 Val AUC: 0.9604 Time: 14.90\n",
      "Epoch: 511 Train Loss: 0.0920 Val Loss: 0.3077 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9956 Val AUC: 0.9615 Time: 14.59\n",
      "Epoch: 512 Train Loss: 0.0891 Val Loss: 0.3053 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9961 Val AUC: 0.9622 Time: 14.53\n",
      "Epoch: 513 Train Loss: 0.0911 Val Loss: 0.3237 Acc: 0.8986 Pre: 0.8664 Recall: 0.9153 F1: 0.8902 Train AUC: 0.9958 Val AUC: 0.9613 Time: 12.30\n",
      "Epoch: 514 Train Loss: 0.0929 Val Loss: 0.3365 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9954 Val AUC: 0.9603 Time: 12.57\n",
      "Epoch: 515 Train Loss: 0.0873 Val Loss: 0.3267 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9960 Val AUC: 0.9602 Time: 12.41\n",
      "Epoch: 516 Train Loss: 0.0915 Val Loss: 0.3080 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9958 Val AUC: 0.9603 Time: 13.38\n",
      "Epoch: 517 Train Loss: 0.0909 Val Loss: 0.3122 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9959 Val AUC: 0.9599 Time: 13.94\n",
      "Epoch: 518 Train Loss: 0.0873 Val Loss: 0.3290 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9967 Val AUC: 0.9589 Time: 14.26\n",
      "Epoch: 519 Train Loss: 0.0850 Val Loss: 0.3508 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9968 Val AUC: 0.9581 Time: 14.99\n",
      "Epoch: 520 Train Loss: 0.0886 Val Loss: 0.3722 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9963 Val AUC: 0.9566 Time: 13.65\n",
      "Epoch: 521 Train Loss: 0.1047 Val Loss: 0.3450 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9939 Val AUC: 0.9590 Time: 12.24\n",
      "Epoch: 522 Train Loss: 0.0919 Val Loss: 0.3230 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9953 Val AUC: 0.9600 Time: 12.17\n",
      "Epoch: 523 Train Loss: 0.0902 Val Loss: 0.3149 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9958 Val AUC: 0.9597 Time: 12.82\n",
      "Epoch: 524 Train Loss: 0.0863 Val Loss: 0.3227 Acc: 0.9004 Pre: 0.8642 Recall: 0.9234 F1: 0.8928 Train AUC: 0.9968 Val AUC: 0.9598 Time: 13.48\n",
      "Epoch: 525 Train Loss: 0.0879 Val Loss: 0.3409 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9966 Val AUC: 0.9593 Time: 14.18\n",
      "Epoch: 526 Train Loss: 0.0898 Val Loss: 0.3513 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9957 Val AUC: 0.9595 Time: 14.44\n",
      "Epoch: 527 Train Loss: 0.1016 Val Loss: 0.3327 Acc: 0.8967 Pre: 0.8716 Recall: 0.9032 F1: 0.8871 Train AUC: 0.9941 Val AUC: 0.9607 Time: 14.00\n",
      "Epoch: 528 Train Loss: 0.0965 Val Loss: 0.3092 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9945 Val AUC: 0.9613 Time: 14.23\n",
      "Epoch: 529 Train Loss: 0.0884 Val Loss: 0.3067 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9966 Val AUC: 0.9615 Time: 12.16\n",
      "Epoch: 530 Train Loss: 0.0944 Val Loss: 0.3345 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9953 Val AUC: 0.9597 Time: 12.45\n",
      "Epoch: 531 Train Loss: 0.0944 Val Loss: 0.3527 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9958 Val AUC: 0.9587 Time: 12.34\n",
      "Epoch: 532 Train Loss: 0.0829 Val Loss: 0.3429 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9965 Val AUC: 0.9598 Time: 12.30\n",
      "Epoch: 533 Train Loss: 0.0887 Val Loss: 0.3312 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9960 Val AUC: 0.9602 Time: 13.55\n",
      "Epoch: 534 Train Loss: 0.0888 Val Loss: 0.3207 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9961 Val AUC: 0.9604 Time: 13.94\n",
      "Epoch: 535 Train Loss: 0.0896 Val Loss: 0.3216 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9958 Val AUC: 0.9604 Time: 14.35\n",
      "Epoch: 536 Train Loss: 0.0888 Val Loss: 0.3412 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9963 Val AUC: 0.9584 Time: 14.59\n",
      "Epoch: 537 Train Loss: 0.0855 Val Loss: 0.3512 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9967 Val AUC: 0.9574 Time: 14.45\n",
      "Epoch: 538 Train Loss: 0.0919 Val Loss: 0.3427 Acc: 0.9004 Pre: 0.8755 Recall: 0.9073 F1: 0.8911 Train AUC: 0.9957 Val AUC: 0.9582 Time: 12.37\n",
      "Epoch: 539 Train Loss: 0.0856 Val Loss: 0.3191 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9966 Val AUC: 0.9613 Time: 12.25\n",
      "Epoch: 540 Train Loss: 0.0832 Val Loss: 0.3132 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9970 Val AUC: 0.9626 Time: 12.49\n",
      "Epoch: 541 Train Loss: 0.0952 Val Loss: 0.3169 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9957 Val AUC: 0.9614 Time: 12.49\n",
      "Epoch: 542 Train Loss: 0.0907 Val Loss: 0.3291 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9960 Val AUC: 0.9601 Time: 13.21\n",
      "Epoch: 543 Train Loss: 0.0897 Val Loss: 0.3340 Acc: 0.8967 Pre: 0.8687 Recall: 0.9073 F1: 0.8876 Train AUC: 0.9959 Val AUC: 0.9591 Time: 14.53\n",
      "Epoch: 544 Train Loss: 0.0907 Val Loss: 0.3233 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9960 Val AUC: 0.9598 Time: 14.41\n",
      "Epoch: 545 Train Loss: 0.0884 Val Loss: 0.3083 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9960 Val AUC: 0.9601 Time: 14.80\n",
      "Epoch: 546 Train Loss: 0.0864 Val Loss: 0.3176 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9970 Val AUC: 0.9596 Time: 13.82\n",
      "Epoch: 547 Train Loss: 0.0871 Val Loss: 0.3392 Acc: 0.8949 Pre: 0.8598 Recall: 0.9153 F1: 0.8867 Train AUC: 0.9968 Val AUC: 0.9585 Time: 13.75\n",
      "Epoch: 548 Train Loss: 0.0862 Val Loss: 0.3367 Acc: 0.9022 Pre: 0.8789 Recall: 0.9073 F1: 0.8929 Train AUC: 0.9963 Val AUC: 0.9589 Time: 12.20\n",
      "Epoch: 549 Train Loss: 0.0815 Val Loss: 0.3318 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9969 Val AUC: 0.9597 Time: 12.54\n",
      "Epoch: 550 Train Loss: 0.0827 Val Loss: 0.3282 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9970 Val AUC: 0.9607 Time: 13.94\n",
      "Epoch: 551 Train Loss: 0.0824 Val Loss: 0.3220 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9967 Val AUC: 0.9610 Time: 14.23\n",
      "Epoch: 552 Train Loss: 0.0846 Val Loss: 0.3242 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9968 Val AUC: 0.9604 Time: 14.43\n",
      "Epoch: 553 Train Loss: 0.0873 Val Loss: 0.3214 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9960 Val AUC: 0.9598 Time: 14.24\n",
      "Epoch: 554 Train Loss: 0.0901 Val Loss: 0.3089 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9958 Val AUC: 0.9608 Time: 12.17\n",
      "Epoch: 555 Train Loss: 0.0957 Val Loss: 0.3192 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9956 Val AUC: 0.9619 Time: 12.51\n",
      "Epoch: 556 Train Loss: 0.0802 Val Loss: 0.3321 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9972 Val AUC: 0.9609 Time: 13.40\n",
      "Epoch: 557 Train Loss: 0.0780 Val Loss: 0.3347 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9966 Val AUC: 0.9605 Time: 13.56\n",
      "Epoch: 558 Train Loss: 0.0924 Val Loss: 0.3251 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9951 Val AUC: 0.9613 Time: 14.32\n",
      "Epoch: 559 Train Loss: 0.0863 Val Loss: 0.3268 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9962 Val AUC: 0.9601 Time: 14.20\n",
      "Epoch: 560 Train Loss: 0.0913 Val Loss: 0.3295 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9960 Val AUC: 0.9590 Time: 14.31\n",
      "Epoch: 561 Train Loss: 0.0851 Val Loss: 0.3359 Acc: 0.9004 Pre: 0.8784 Recall: 0.9032 F1: 0.8907 Train AUC: 0.9965 Val AUC: 0.9598 Time: 13.44\n",
      "Epoch: 562 Train Loss: 0.0820 Val Loss: 0.3309 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9969 Val AUC: 0.9608 Time: 12.66\n",
      "Epoch: 563 Train Loss: 0.0956 Val Loss: 0.3070 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9947 Val AUC: 0.9627 Time: 12.83\n",
      "Epoch: 564 Train Loss: 0.0968 Val Loss: 0.2970 Acc: 0.9149 Pre: 0.8972 Recall: 0.9153 F1: 0.9062 Train AUC: 0.9956 Val AUC: 0.9617 Time: 13.32\n",
      "Epoch: 565 Train Loss: 0.0846 Val Loss: 0.3129 Acc: 0.9058 Pre: 0.8920 Recall: 0.8992 F1: 0.8956 Train AUC: 0.9968 Val AUC: 0.9607 Time: 13.74\n",
      "Epoch: 566 Train Loss: 0.0897 Val Loss: 0.3234 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9964 Val AUC: 0.9606 Time: 14.40\n",
      "Epoch: 567 Train Loss: 0.0894 Val Loss: 0.3477 Acc: 0.8913 Pre: 0.8507 Recall: 0.9194 F1: 0.8837 Train AUC: 0.9959 Val AUC: 0.9599 Time: 14.20\n",
      "Epoch: 568 Train Loss: 0.0861 Val Loss: 0.3440 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9969 Val AUC: 0.9598 Time: 13.35\n",
      "Epoch: 569 Train Loss: 0.0846 Val Loss: 0.3318 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9968 Val AUC: 0.9606 Time: 12.45\n",
      "Epoch: 570 Train Loss: 0.0893 Val Loss: 0.3242 Acc: 0.9130 Pre: 0.8968 Recall: 0.9113 F1: 0.9040 Train AUC: 0.9957 Val AUC: 0.9604 Time: 12.58\n",
      "Epoch: 571 Train Loss: 0.0886 Val Loss: 0.3231 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9962 Val AUC: 0.9604 Time: 12.51\n",
      "Epoch: 572 Train Loss: 0.0815 Val Loss: 0.3434 Acc: 0.8877 Pre: 0.8444 Recall: 0.9194 F1: 0.8803 Train AUC: 0.9974 Val AUC: 0.9592 Time: 13.08\n",
      "Epoch: 573 Train Loss: 0.1014 Val Loss: 0.3343 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9962 Val AUC: 0.9605 Time: 14.02\n",
      "Epoch: 574 Train Loss: 0.0829 Val Loss: 0.3297 Acc: 0.9076 Pre: 0.8924 Recall: 0.9032 F1: 0.8978 Train AUC: 0.9968 Val AUC: 0.9613 Time: 14.48\n",
      "Epoch: 575 Train Loss: 0.0811 Val Loss: 0.3219 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9971 Val AUC: 0.9623 Time: 14.08\n",
      "Epoch: 576 Train Loss: 0.0907 Val Loss: 0.3114 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9956 Val AUC: 0.9634 Time: 14.59\n",
      "Epoch: 577 Train Loss: 0.0892 Val Loss: 0.3296 Acc: 0.8986 Pre: 0.8609 Recall: 0.9234 F1: 0.8911 Train AUC: 0.9960 Val AUC: 0.9615 Time: 12.31\n",
      "Epoch: 578 Train Loss: 0.0869 Val Loss: 0.3429 Acc: 0.8895 Pre: 0.8555 Recall: 0.9073 F1: 0.8806 Train AUC: 0.9965 Val AUC: 0.9591 Time: 12.39\n",
      "Epoch: 579 Train Loss: 0.0896 Val Loss: 0.3353 Acc: 0.8931 Pre: 0.8706 Recall: 0.8952 F1: 0.8827 Train AUC: 0.9960 Val AUC: 0.9601 Time: 12.30\n",
      "Epoch: 580 Train Loss: 0.0905 Val Loss: 0.3390 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9964 Val AUC: 0.9606 Time: 12.47\n",
      "Epoch: 581 Train Loss: 0.0851 Val Loss: 0.3189 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9961 Val AUC: 0.9623 Time: 13.14\n",
      "Epoch: 582 Train Loss: 0.0910 Val Loss: 0.2992 Acc: 0.9130 Pre: 0.8906 Recall: 0.9194 F1: 0.9048 Train AUC: 0.9953 Val AUC: 0.9628 Time: 14.26\n",
      "Epoch: 583 Train Loss: 0.0846 Val Loss: 0.2881 Acc: 0.9130 Pre: 0.8876 Recall: 0.9234 F1: 0.9051 Train AUC: 0.9963 Val AUC: 0.9627 Time: 14.60\n",
      "Epoch: 584 Train Loss: 0.0846 Val Loss: 0.3016 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9971 Val AUC: 0.9626 Time: 14.94\n",
      "Epoch: 585 Train Loss: 0.0817 Val Loss: 0.3291 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9969 Val AUC: 0.9617 Time: 13.22\n",
      "Epoch: 586 Train Loss: 0.0719 Val Loss: 0.3477 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9976 Val AUC: 0.9602 Time: 12.47\n",
      "Epoch: 587 Train Loss: 0.0844 Val Loss: 0.3348 Acc: 0.8967 Pre: 0.8631 Recall: 0.9153 F1: 0.8885 Train AUC: 0.9963 Val AUC: 0.9614 Time: 13.30\n",
      "Epoch: 588 Train Loss: 0.0808 Val Loss: 0.3169 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9965 Val AUC: 0.9624 Time: 12.79\n",
      "Epoch: 589 Train Loss: 0.0768 Val Loss: 0.3200 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9975 Val AUC: 0.9623 Time: 14.60\n",
      "Epoch: 590 Train Loss: 0.0826 Val Loss: 0.3414 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9970 Val AUC: 0.9609 Time: 13.95\n",
      "Epoch: 591 Train Loss: 0.0825 Val Loss: 0.3524 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9965 Val AUC: 0.9589 Time: 13.29\n",
      "Epoch: 592 Train Loss: 0.0919 Val Loss: 0.3291 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9952 Val AUC: 0.9599 Time: 13.68\n",
      "Epoch: 593 Train Loss: 0.0855 Val Loss: 0.3198 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9966 Val AUC: 0.9605 Time: 13.79\n",
      "Epoch: 594 Train Loss: 0.0801 Val Loss: 0.3218 Acc: 0.8895 Pre: 0.8476 Recall: 0.9194 F1: 0.8820 Train AUC: 0.9973 Val AUC: 0.9604 Time: 13.32\n",
      "Epoch: 595 Train Loss: 0.0893 Val Loss: 0.3340 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9970 Val AUC: 0.9606 Time: 14.25\n",
      "Epoch: 596 Train Loss: 0.0885 Val Loss: 0.3589 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9962 Val AUC: 0.9597 Time: 14.46\n",
      "Epoch: 597 Train Loss: 0.1026 Val Loss: 0.3452 Acc: 0.9040 Pre: 0.8707 Recall: 0.9234 F1: 0.8963 Train AUC: 0.9940 Val AUC: 0.9605 Time: 12.94\n",
      "Epoch: 598 Train Loss: 0.0849 Val Loss: 0.3195 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9961 Val AUC: 0.9611 Time: 12.27\n",
      "Epoch: 599 Train Loss: 0.0782 Val Loss: 0.2997 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9973 Val AUC: 0.9617 Time: 12.91\n",
      "Epoch: 600 Train Loss: 0.0864 Val Loss: 0.3071 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9969 Val AUC: 0.9623 Time: 12.88\n",
      "Epoch: 601 Train Loss: 0.0806 Val Loss: 0.3343 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9970 Val AUC: 0.9611 Time: 13.26\n",
      "Epoch: 602 Train Loss: 0.0808 Val Loss: 0.3440 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9966 Val AUC: 0.9609 Time: 14.24\n",
      "Epoch: 603 Train Loss: 0.0846 Val Loss: 0.3270 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9963 Val AUC: 0.9625 Time: 14.38\n",
      "Epoch: 604 Train Loss: 0.0787 Val Loss: 0.3037 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9971 Val AUC: 0.9624 Time: 13.84\n",
      "Epoch: 605 Train Loss: 0.0934 Val Loss: 0.3219 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9954 Val AUC: 0.9608 Time: 13.36\n",
      "Epoch: 606 Train Loss: 0.0759 Val Loss: 0.3406 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9976 Val AUC: 0.9591 Time: 12.78\n",
      "Epoch: 607 Train Loss: 0.0766 Val Loss: 0.3654 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9975 Val AUC: 0.9577 Time: 12.75\n",
      "Epoch: 608 Train Loss: 0.0836 Val Loss: 0.3596 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9962 Val AUC: 0.9583 Time: 12.76\n",
      "Epoch: 609 Train Loss: 0.0772 Val Loss: 0.3290 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9971 Val AUC: 0.9600 Time: 13.48\n",
      "Epoch: 610 Train Loss: 0.0801 Val Loss: 0.3102 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9969 Val AUC: 0.9614 Time: 13.98\n",
      "Epoch: 611 Train Loss: 0.0833 Val Loss: 0.3175 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9968 Val AUC: 0.9600 Time: 14.55\n",
      "Epoch: 612 Train Loss: 0.0816 Val Loss: 0.3491 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9970 Val AUC: 0.9582 Time: 14.95\n",
      "Epoch: 613 Train Loss: 0.0821 Val Loss: 0.3756 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9968 Val AUC: 0.9563 Time: 13.16\n",
      "Epoch: 614 Train Loss: 0.0876 Val Loss: 0.3538 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9961 Val AUC: 0.9596 Time: 12.50\n",
      "Epoch: 615 Train Loss: 0.0815 Val Loss: 0.3196 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9968 Val AUC: 0.9616 Time: 13.00\n",
      "Epoch: 616 Train Loss: 0.0846 Val Loss: 0.3028 Acc: 0.9076 Pre: 0.8988 Recall: 0.8952 F1: 0.8970 Train AUC: 0.9966 Val AUC: 0.9628 Time: 14.04\n",
      "Epoch: 617 Train Loss: 0.0845 Val Loss: 0.2994 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9966 Val AUC: 0.9636 Time: 14.12\n",
      "Epoch: 618 Train Loss: 0.0822 Val Loss: 0.3258 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9968 Val AUC: 0.9609 Time: 13.96\n",
      "Epoch: 619 Train Loss: 0.0909 Val Loss: 0.3406 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9963 Val AUC: 0.9588 Time: 13.02\n",
      "Epoch: 620 Train Loss: 0.0780 Val Loss: 0.3464 Acc: 0.9004 Pre: 0.8845 Recall: 0.8952 F1: 0.8898 Train AUC: 0.9970 Val AUC: 0.9591 Time: 12.44\n",
      "Epoch: 621 Train Loss: 0.0880 Val Loss: 0.3251 Acc: 0.9040 Pre: 0.8707 Recall: 0.9234 F1: 0.8963 Train AUC: 0.9960 Val AUC: 0.9614 Time: 12.83\n",
      "Epoch: 622 Train Loss: 0.0784 Val Loss: 0.3212 Acc: 0.9076 Pre: 0.8774 Recall: 0.9234 F1: 0.8998 Train AUC: 0.9972 Val AUC: 0.9629 Time: 13.29\n",
      "Epoch: 623 Train Loss: 0.0885 Val Loss: 0.3239 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9966 Val AUC: 0.9610 Time: 13.78\n",
      "Epoch: 624 Train Loss: 0.0767 Val Loss: 0.3449 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9975 Val AUC: 0.9589 Time: 14.56\n",
      "Epoch: 625 Train Loss: 0.0790 Val Loss: 0.3668 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9971 Val AUC: 0.9578 Time: 14.06\n",
      "Epoch: 626 Train Loss: 0.0790 Val Loss: 0.3579 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9971 Val AUC: 0.9582 Time: 13.58\n",
      "Epoch: 627 Train Loss: 0.0839 Val Loss: 0.3445 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9965 Val AUC: 0.9594 Time: 12.52\n",
      "Epoch: 628 Train Loss: 0.0818 Val Loss: 0.3344 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9966 Val AUC: 0.9605 Time: 12.42\n",
      "Epoch: 629 Train Loss: 0.0795 Val Loss: 0.3370 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9966 Val AUC: 0.9614 Time: 12.27\n",
      "Epoch: 630 Train Loss: 0.0895 Val Loss: 0.3286 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9957 Val AUC: 0.9620 Time: 13.60\n",
      "Epoch: 631 Train Loss: 0.0683 Val Loss: 0.3330 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9984 Val AUC: 0.9601 Time: 13.82\n",
      "Epoch: 632 Train Loss: 0.0809 Val Loss: 0.3257 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9964 Val AUC: 0.9603 Time: 14.47\n",
      "Epoch: 633 Train Loss: 0.0776 Val Loss: 0.3123 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9973 Val AUC: 0.9617 Time: 14.18\n",
      "Epoch: 634 Train Loss: 0.0897 Val Loss: 0.3240 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9967 Val AUC: 0.9626 Time: 14.30\n",
      "Epoch: 635 Train Loss: 0.0827 Val Loss: 0.3432 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9966 Val AUC: 0.9596 Time: 12.14\n",
      "Epoch: 636 Train Loss: 0.0925 Val Loss: 0.3434 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9952 Val AUC: 0.9592 Time: 12.49\n",
      "Epoch: 637 Train Loss: 0.0802 Val Loss: 0.3395 Acc: 0.8877 Pre: 0.8470 Recall: 0.9153 F1: 0.8798 Train AUC: 0.9967 Val AUC: 0.9596 Time: 12.48\n",
      "Epoch: 638 Train Loss: 0.0904 Val Loss: 0.3331 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9964 Val AUC: 0.9598 Time: 13.50\n",
      "Epoch: 639 Train Loss: 0.0800 Val Loss: 0.3434 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9976 Val AUC: 0.9590 Time: 14.36\n",
      "Epoch: 640 Train Loss: 0.0819 Val Loss: 0.3381 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9969 Val AUC: 0.9596 Time: 14.61\n",
      "Epoch: 641 Train Loss: 0.0885 Val Loss: 0.3278 Acc: 0.9040 Pre: 0.8707 Recall: 0.9234 F1: 0.8963 Train AUC: 0.9958 Val AUC: 0.9610 Time: 14.01\n",
      "Epoch: 642 Train Loss: 0.0917 Val Loss: 0.3129 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9953 Val AUC: 0.9622 Time: 13.14\n",
      "Epoch: 643 Train Loss: 0.0799 Val Loss: 0.3063 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9975 Val AUC: 0.9606 Time: 12.91\n",
      "Epoch: 644 Train Loss: 0.0802 Val Loss: 0.3065 Acc: 0.9058 Pre: 0.8858 Recall: 0.9073 F1: 0.8964 Train AUC: 0.9972 Val AUC: 0.9600 Time: 14.02\n",
      "Epoch: 645 Train Loss: 0.0941 Val Loss: 0.3311 Acc: 0.9040 Pre: 0.8854 Recall: 0.9032 F1: 0.8942 Train AUC: 0.9962 Val AUC: 0.9597 Time: 13.18\n",
      "Epoch: 646 Train Loss: 0.0758 Val Loss: 0.3441 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9974 Val AUC: 0.9596 Time: 13.15\n",
      "Epoch: 647 Train Loss: 0.0876 Val Loss: 0.3267 Acc: 0.9112 Pre: 0.8902 Recall: 0.9153 F1: 0.9026 Train AUC: 0.9960 Val AUC: 0.9613 Time: 13.23\n",
      "Epoch: 648 Train Loss: 0.0848 Val Loss: 0.3180 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9960 Val AUC: 0.9616 Time: 12.83\n",
      "Epoch: 649 Train Loss: 0.0831 Val Loss: 0.3403 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9965 Val AUC: 0.9584 Time: 12.93\n",
      "Epoch: 650 Train Loss: 0.0881 Val Loss: 0.3455 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9963 Val AUC: 0.9584 Time: 14.62\n",
      "Epoch: 651 Train Loss: 0.0846 Val Loss: 0.3413 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9965 Val AUC: 0.9597 Time: 14.32\n",
      "Epoch: 652 Train Loss: 0.0746 Val Loss: 0.3274 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9975 Val AUC: 0.9616 Time: 14.11\n",
      "Epoch: 653 Train Loss: 0.0815 Val Loss: 0.3158 Acc: 0.8986 Pre: 0.8664 Recall: 0.9153 F1: 0.8902 Train AUC: 0.9964 Val AUC: 0.9635 Time: 12.78\n",
      "Epoch: 654 Train Loss: 0.0770 Val Loss: 0.3052 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9972 Val AUC: 0.9632 Time: 13.05\n",
      "Epoch: 655 Train Loss: 0.0890 Val Loss: 0.3318 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9960 Val AUC: 0.9602 Time: 14.02\n",
      "Epoch: 656 Train Loss: 0.0855 Val Loss: 0.3693 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9969 Val AUC: 0.9579 Time: 14.33\n",
      "Epoch: 657 Train Loss: 0.0840 Val Loss: 0.3632 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9964 Val AUC: 0.9597 Time: 13.21\n",
      "Epoch: 658 Train Loss: 0.0751 Val Loss: 0.3365 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9970 Val AUC: 0.9615 Time: 13.19\n",
      "Epoch: 659 Train Loss: 0.0781 Val Loss: 0.3144 Acc: 0.9112 Pre: 0.8842 Recall: 0.9234 F1: 0.9034 Train AUC: 0.9968 Val AUC: 0.9629 Time: 13.54\n",
      "Epoch: 660 Train Loss: 0.0836 Val Loss: 0.3120 Acc: 0.9094 Pre: 0.8808 Recall: 0.9234 F1: 0.9016 Train AUC: 0.9963 Val AUC: 0.9623 Time: 14.25\n",
      "Epoch: 661 Train Loss: 0.0733 Val Loss: 0.3269 Acc: 0.8986 Pre: 0.8582 Recall: 0.9274 F1: 0.8915 Train AUC: 0.9981 Val AUC: 0.9615 Time: 14.00\n",
      "Epoch: 662 Train Loss: 0.0847 Val Loss: 0.3626 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9966 Val AUC: 0.9589 Time: 13.54\n",
      "Epoch: 663 Train Loss: 0.0824 Val Loss: 0.3613 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9968 Val AUC: 0.9596 Time: 12.38\n",
      "Epoch: 664 Train Loss: 0.0757 Val Loss: 0.3319 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9971 Val AUC: 0.9619 Time: 12.37\n",
      "Epoch: 665 Train Loss: 0.0739 Val Loss: 0.3098 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9976 Val AUC: 0.9639 Time: 12.65\n",
      "Epoch: 666 Train Loss: 0.0804 Val Loss: 0.3055 Acc: 0.9004 Pre: 0.8614 Recall: 0.9274 F1: 0.8932 Train AUC: 0.9966 Val AUC: 0.9647 Time: 13.58\n",
      "Epoch: 667 Train Loss: 0.0879 Val Loss: 0.3152 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9962 Val AUC: 0.9634 Time: 13.98\n",
      "Epoch: 668 Train Loss: 0.0718 Val Loss: 0.3508 Acc: 0.8949 Pre: 0.8740 Recall: 0.8952 F1: 0.8845 Train AUC: 0.9981 Val AUC: 0.9595 Time: 14.68\n",
      "Epoch: 669 Train Loss: 0.0833 Val Loss: 0.3818 Acc: 0.8967 Pre: 0.8745 Recall: 0.8992 F1: 0.8867 Train AUC: 0.9969 Val AUC: 0.9567 Time: 12.79\n",
      "Epoch: 670 Train Loss: 0.0960 Val Loss: 0.3461 Acc: 0.8967 Pre: 0.8687 Recall: 0.9073 F1: 0.8876 Train AUC: 0.9949 Val AUC: 0.9594 Time: 12.68\n",
      "Epoch: 671 Train Loss: 0.0728 Val Loss: 0.3263 Acc: 0.9040 Pre: 0.8707 Recall: 0.9234 F1: 0.8963 Train AUC: 0.9976 Val AUC: 0.9607 Time: 13.27\n",
      "Epoch: 672 Train Loss: 0.0730 Val Loss: 0.3123 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9978 Val AUC: 0.9605 Time: 13.50\n",
      "Epoch: 673 Train Loss: 0.0868 Val Loss: 0.3263 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9968 Val AUC: 0.9602 Time: 14.28\n",
      "Epoch: 674 Train Loss: 0.0790 Val Loss: 0.3636 Acc: 0.9004 Pre: 0.8755 Recall: 0.9073 F1: 0.8911 Train AUC: 0.9976 Val AUC: 0.9578 Time: 14.44\n",
      "Epoch: 675 Train Loss: 0.0839 Val Loss: 0.3840 Acc: 0.8931 Pre: 0.8621 Recall: 0.9073 F1: 0.8841 Train AUC: 0.9966 Val AUC: 0.9577 Time: 14.56\n",
      "Epoch: 676 Train Loss: 0.0969 Val Loss: 0.3459 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9950 Val AUC: 0.9609 Time: 12.35\n",
      "Epoch: 677 Train Loss: 0.0797 Val Loss: 0.3012 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9970 Val AUC: 0.9643 Time: 12.17\n",
      "Epoch: 678 Train Loss: 0.0807 Val Loss: 0.2988 Acc: 0.9112 Pre: 0.8842 Recall: 0.9234 F1: 0.9034 Train AUC: 0.9969 Val AUC: 0.9627 Time: 12.46\n",
      "Epoch: 679 Train Loss: 0.0916 Val Loss: 0.3249 Acc: 0.9094 Pre: 0.8808 Recall: 0.9234 F1: 0.9016 Train AUC: 0.9956 Val AUC: 0.9614 Time: 13.38\n",
      "Epoch: 680 Train Loss: 0.0847 Val Loss: 0.3561 Acc: 0.8949 Pre: 0.8740 Recall: 0.8952 F1: 0.8845 Train AUC: 0.9959 Val AUC: 0.9589 Time: 13.87\n",
      "Epoch: 681 Train Loss: 0.0815 Val Loss: 0.3617 Acc: 0.9004 Pre: 0.8784 Recall: 0.9032 F1: 0.8907 Train AUC: 0.9966 Val AUC: 0.9579 Time: 14.21\n",
      "Epoch: 682 Train Loss: 0.0806 Val Loss: 0.3338 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9968 Val AUC: 0.9592 Time: 14.89\n",
      "Epoch: 683 Train Loss: 0.0841 Val Loss: 0.3068 Acc: 0.8913 Pre: 0.8507 Recall: 0.9194 F1: 0.8837 Train AUC: 0.9966 Val AUC: 0.9621 Time: 12.67\n",
      "Epoch: 684 Train Loss: 0.0880 Val Loss: 0.2987 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9966 Val AUC: 0.9621 Time: 12.53\n",
      "Epoch: 685 Train Loss: 0.0814 Val Loss: 0.3305 Acc: 0.9094 Pre: 0.8867 Recall: 0.9153 F1: 0.9008 Train AUC: 0.9968 Val AUC: 0.9597 Time: 12.41\n",
      "Epoch: 686 Train Loss: 0.0755 Val Loss: 0.3605 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9975 Val AUC: 0.9579 Time: 13.42\n",
      "Epoch: 687 Train Loss: 0.0842 Val Loss: 0.3637 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9964 Val AUC: 0.9582 Time: 13.80\n",
      "Epoch: 688 Train Loss: 0.0851 Val Loss: 0.3267 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9964 Val AUC: 0.9609 Time: 13.89\n",
      "Epoch: 689 Train Loss: 0.0694 Val Loss: 0.3084 Acc: 0.9130 Pre: 0.8968 Recall: 0.9113 F1: 0.9040 Train AUC: 0.9982 Val AUC: 0.9614 Time: 13.78\n",
      "Epoch: 690 Train Loss: 0.0799 Val Loss: 0.3066 Acc: 0.9130 Pre: 0.8968 Recall: 0.9113 F1: 0.9040 Train AUC: 0.9974 Val AUC: 0.9614 Time: 14.68\n",
      "Epoch: 691 Train Loss: 0.0918 Val Loss: 0.3177 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9955 Val AUC: 0.9610 Time: 12.32\n",
      "Epoch: 692 Train Loss: 0.0715 Val Loss: 0.3365 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9980 Val AUC: 0.9597 Time: 12.43\n",
      "Epoch: 693 Train Loss: 0.0783 Val Loss: 0.3453 Acc: 0.8967 Pre: 0.8550 Recall: 0.9274 F1: 0.8897 Train AUC: 0.9974 Val AUC: 0.9589 Time: 12.38\n",
      "Epoch: 694 Train Loss: 0.0893 Val Loss: 0.3255 Acc: 0.9058 Pre: 0.8740 Recall: 0.9234 F1: 0.8980 Train AUC: 0.9958 Val AUC: 0.9605 Time: 12.68\n",
      "Epoch: 695 Train Loss: 0.0733 Val Loss: 0.3190 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9982 Val AUC: 0.9619 Time: 13.73\n",
      "Epoch: 696 Train Loss: 0.0750 Val Loss: 0.3225 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9976 Val AUC: 0.9612 Time: 14.28\n",
      "Epoch: 697 Train Loss: 0.0710 Val Loss: 0.3327 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9980 Val AUC: 0.9614 Time: 14.41\n",
      "Epoch: 698 Train Loss: 0.0776 Val Loss: 0.3359 Acc: 0.8949 Pre: 0.8598 Recall: 0.9153 F1: 0.8867 Train AUC: 0.9973 Val AUC: 0.9606 Time: 14.82\n",
      "Epoch: 699 Train Loss: 0.0756 Val Loss: 0.3359 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9974 Val AUC: 0.9595 Time: 14.13\n",
      "Epoch: 700 Train Loss: 0.0718 Val Loss: 0.3273 Acc: 0.9130 Pre: 0.8937 Recall: 0.9153 F1: 0.9044 Train AUC: 0.9978 Val AUC: 0.9601 Time: 12.91\n",
      "Epoch: 701 Train Loss: 0.0765 Val Loss: 0.3219 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9971 Val AUC: 0.9602 Time: 12.32\n",
      "Epoch: 702 Train Loss: 0.0771 Val Loss: 0.3294 Acc: 0.8986 Pre: 0.8609 Recall: 0.9234 F1: 0.8911 Train AUC: 0.9970 Val AUC: 0.9603 Time: 12.22\n",
      "Epoch: 703 Train Loss: 0.0776 Val Loss: 0.3410 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9972 Val AUC: 0.9608 Time: 12.80\n",
      "Epoch: 704 Train Loss: 0.0744 Val Loss: 0.3360 Acc: 0.8986 Pre: 0.8692 Recall: 0.9113 F1: 0.8898 Train AUC: 0.9977 Val AUC: 0.9613 Time: 13.23\n",
      "Epoch: 705 Train Loss: 0.0732 Val Loss: 0.3308 Acc: 0.9112 Pre: 0.8964 Recall: 0.9073 F1: 0.9018 Train AUC: 0.9975 Val AUC: 0.9614 Time: 14.47\n",
      "Epoch: 706 Train Loss: 0.0805 Val Loss: 0.3269 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9969 Val AUC: 0.9613 Time: 14.80\n",
      "Epoch: 707 Train Loss: 0.0745 Val Loss: 0.3226 Acc: 0.8913 Pre: 0.8481 Recall: 0.9234 F1: 0.8842 Train AUC: 0.9973 Val AUC: 0.9619 Time: 14.60\n",
      "Epoch: 708 Train Loss: 0.0848 Val Loss: 0.3082 Acc: 0.9094 Pre: 0.8808 Recall: 0.9234 F1: 0.9016 Train AUC: 0.9966 Val AUC: 0.9634 Time: 12.97\n",
      "Epoch: 709 Train Loss: 0.0697 Val Loss: 0.3113 Acc: 0.9130 Pre: 0.8906 Recall: 0.9194 F1: 0.9048 Train AUC: 0.9981 Val AUC: 0.9628 Time: 12.52\n",
      "Epoch: 710 Train Loss: 0.0733 Val Loss: 0.3282 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9975 Val AUC: 0.9615 Time: 13.02\n",
      "Epoch: 711 Train Loss: 0.0768 Val Loss: 0.3279 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9971 Val AUC: 0.9610 Time: 13.70\n",
      "Epoch: 712 Train Loss: 0.0748 Val Loss: 0.3242 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9974 Val AUC: 0.9600 Time: 14.12\n",
      "Epoch: 713 Train Loss: 0.0690 Val Loss: 0.3259 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9985 Val AUC: 0.9604 Time: 13.98\n",
      "Epoch: 714 Train Loss: 0.0668 Val Loss: 0.3144 Acc: 0.9203 Pre: 0.9080 Recall: 0.9153 F1: 0.9116 Train AUC: 0.9984 Val AUC: 0.9630 Time: 12.62\n",
      "Epoch: 715 Train Loss: 0.0742 Val Loss: 0.3090 Acc: 0.9094 Pre: 0.8808 Recall: 0.9234 F1: 0.9016 Train AUC: 0.9978 Val AUC: 0.9642 Time: 12.39\n",
      "Epoch: 716 Train Loss: 0.0748 Val Loss: 0.3155 Acc: 0.9130 Pre: 0.8846 Recall: 0.9274 F1: 0.9055 Train AUC: 0.9974 Val AUC: 0.9641 Time: 12.40\n",
      "Epoch: 717 Train Loss: 0.0745 Val Loss: 0.3257 Acc: 0.9076 Pre: 0.8774 Recall: 0.9234 F1: 0.8998 Train AUC: 0.9972 Val AUC: 0.9626 Time: 13.46\n",
      "Epoch: 718 Train Loss: 0.0718 Val Loss: 0.3332 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9976 Val AUC: 0.9607 Time: 13.89\n",
      "Epoch: 719 Train Loss: 0.0712 Val Loss: 0.3405 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9979 Val AUC: 0.9587 Time: 14.24\n",
      "Epoch: 720 Train Loss: 0.0753 Val Loss: 0.3530 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9975 Val AUC: 0.9581 Time: 14.43\n",
      "Epoch: 721 Train Loss: 0.0794 Val Loss: 0.3536 Acc: 0.9112 Pre: 0.8842 Recall: 0.9234 F1: 0.9034 Train AUC: 0.9968 Val AUC: 0.9591 Time: 14.18\n",
      "Epoch: 722 Train Loss: 0.0737 Val Loss: 0.3445 Acc: 0.9130 Pre: 0.8906 Recall: 0.9194 F1: 0.9048 Train AUC: 0.9971 Val AUC: 0.9606 Time: 12.12\n",
      "Epoch: 723 Train Loss: 0.0800 Val Loss: 0.3181 Acc: 0.9130 Pre: 0.8968 Recall: 0.9113 F1: 0.9040 Train AUC: 0.9965 Val AUC: 0.9629 Time: 12.34\n",
      "Epoch: 724 Train Loss: 0.0736 Val Loss: 0.3075 Acc: 0.9130 Pre: 0.8968 Recall: 0.9113 F1: 0.9040 Train AUC: 0.9973 Val AUC: 0.9637 Time: 12.51\n",
      "Epoch: 725 Train Loss: 0.0694 Val Loss: 0.3157 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9981 Val AUC: 0.9633 Time: 12.67\n",
      "Epoch: 726 Train Loss: 0.0798 Val Loss: 0.3300 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9974 Val AUC: 0.9620 Time: 13.52\n",
      "Epoch: 727 Train Loss: 0.0702 Val Loss: 0.3501 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9978 Val AUC: 0.9609 Time: 13.65\n",
      "Epoch: 728 Train Loss: 0.0715 Val Loss: 0.3633 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9976 Val AUC: 0.9598 Time: 14.39\n",
      "Epoch: 729 Train Loss: 0.0789 Val Loss: 0.3447 Acc: 0.9076 Pre: 0.8774 Recall: 0.9234 F1: 0.8998 Train AUC: 0.9967 Val AUC: 0.9606 Time: 14.86\n",
      "Epoch: 730 Train Loss: 0.0732 Val Loss: 0.3431 Acc: 0.8967 Pre: 0.8550 Recall: 0.9274 F1: 0.8897 Train AUC: 0.9975 Val AUC: 0.9605 Time: 14.22\n",
      "Epoch: 731 Train Loss: 0.0760 Val Loss: 0.3354 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9973 Val AUC: 0.9611 Time: 13.97\n",
      "Epoch: 732 Train Loss: 0.0702 Val Loss: 0.3429 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9980 Val AUC: 0.9590 Time: 12.66\n",
      "Epoch: 733 Train Loss: 0.0752 Val Loss: 0.3570 Acc: 0.9203 Pre: 0.9113 Recall: 0.9113 F1: 0.9113 Train AUC: 0.9975 Val AUC: 0.9586 Time: 12.37\n",
      "Epoch: 734 Train Loss: 0.0895 Val Loss: 0.3486 Acc: 0.8986 Pre: 0.8664 Recall: 0.9153 F1: 0.8902 Train AUC: 0.9965 Val AUC: 0.9606 Time: 12.47\n",
      "Epoch: 735 Train Loss: 0.0763 Val Loss: 0.3443 Acc: 0.9004 Pre: 0.8642 Recall: 0.9234 F1: 0.8928 Train AUC: 0.9978 Val AUC: 0.9612 Time: 12.42\n",
      "Epoch: 736 Train Loss: 0.0717 Val Loss: 0.3221 Acc: 0.9094 Pre: 0.8808 Recall: 0.9234 F1: 0.9016 Train AUC: 0.9980 Val AUC: 0.9619 Time: 12.37\n",
      "Epoch: 737 Train Loss: 0.0703 Val Loss: 0.3189 Acc: 0.9149 Pre: 0.9102 Recall: 0.8992 F1: 0.9047 Train AUC: 0.9975 Val AUC: 0.9617 Time: 12.62\n",
      "Epoch: 738 Train Loss: 0.0768 Val Loss: 0.3226 Acc: 0.9112 Pre: 0.8902 Recall: 0.9153 F1: 0.9026 Train AUC: 0.9978 Val AUC: 0.9616 Time: 13.89\n",
      "Epoch: 739 Train Loss: 0.0642 Val Loss: 0.3312 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9983 Val AUC: 0.9632 Time: 14.09\n",
      "Epoch: 740 Train Loss: 0.0705 Val Loss: 0.3397 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9983 Val AUC: 0.9623 Time: 14.03\n",
      "Epoch: 741 Train Loss: 0.0844 Val Loss: 0.3425 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9973 Val AUC: 0.9597 Time: 14.71\n",
      "Epoch: 742 Train Loss: 0.0715 Val Loss: 0.3483 Acc: 0.9094 Pre: 0.8929 Recall: 0.9073 F1: 0.9000 Train AUC: 0.9975 Val AUC: 0.9585 Time: 14.02\n",
      "Epoch: 743 Train Loss: 0.0772 Val Loss: 0.3360 Acc: 0.9004 Pre: 0.8642 Recall: 0.9234 F1: 0.8928 Train AUC: 0.9974 Val AUC: 0.9601 Time: 13.62\n",
      "Epoch: 744 Train Loss: 0.0680 Val Loss: 0.3299 Acc: 0.8967 Pre: 0.8550 Recall: 0.9274 F1: 0.8897 Train AUC: 0.9982 Val AUC: 0.9607 Time: 12.35\n",
      "Epoch: 745 Train Loss: 0.0779 Val Loss: 0.3186 Acc: 0.9040 Pre: 0.8679 Recall: 0.9274 F1: 0.8967 Train AUC: 0.9972 Val AUC: 0.9613 Time: 12.55\n",
      "Epoch: 746 Train Loss: 0.0745 Val Loss: 0.3197 Acc: 0.9112 Pre: 0.8964 Recall: 0.9073 F1: 0.9018 Train AUC: 0.9974 Val AUC: 0.9612 Time: 12.26\n",
      "Epoch: 747 Train Loss: 0.0744 Val Loss: 0.3238 Acc: 0.9040 Pre: 0.8824 Recall: 0.9073 F1: 0.8946 Train AUC: 0.9978 Val AUC: 0.9612 Time: 12.33\n",
      "Epoch: 748 Train Loss: 0.0674 Val Loss: 0.3247 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9981 Val AUC: 0.9626 Time: 12.46\n",
      "Epoch: 749 Train Loss: 0.0775 Val Loss: 0.3286 Acc: 0.8895 Pre: 0.8450 Recall: 0.9234 F1: 0.8825 Train AUC: 0.9975 Val AUC: 0.9631 Time: 13.42\n",
      "Epoch: 750 Train Loss: 0.0816 Val Loss: 0.3122 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9972 Val AUC: 0.9622 Time: 14.00\n",
      "Epoch: 751 Train Loss: 0.0738 Val Loss: 0.3167 Acc: 0.9149 Pre: 0.8972 Recall: 0.9153 F1: 0.9062 Train AUC: 0.9975 Val AUC: 0.9611 Time: 14.61\n",
      "Epoch: 752 Train Loss: 0.0771 Val Loss: 0.3231 Acc: 0.9149 Pre: 0.9004 Recall: 0.9113 F1: 0.9058 Train AUC: 0.9974 Val AUC: 0.9603 Time: 15.17\n",
      "Epoch: 753 Train Loss: 0.0682 Val Loss: 0.3418 Acc: 0.8967 Pre: 0.8631 Recall: 0.9153 F1: 0.8885 Train AUC: 0.9983 Val AUC: 0.9593 Time: 13.25\n",
      "Epoch: 754 Train Loss: 0.0703 Val Loss: 0.3488 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9982 Val AUC: 0.9601 Time: 13.18\n",
      "Epoch: 755 Train Loss: 0.0660 Val Loss: 0.3466 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9983 Val AUC: 0.9612 Time: 13.47\n",
      "Epoch: 756 Train Loss: 0.0702 Val Loss: 0.3376 Acc: 0.9058 Pre: 0.8798 Recall: 0.9153 F1: 0.8972 Train AUC: 0.9980 Val AUC: 0.9606 Time: 13.60\n",
      "Epoch: 757 Train Loss: 0.0651 Val Loss: 0.3283 Acc: 0.9112 Pre: 0.8996 Recall: 0.9032 F1: 0.9014 Train AUC: 0.9983 Val AUC: 0.9608 Time: 13.25\n",
      "Epoch: 758 Train Loss: 0.0757 Val Loss: 0.3086 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9972 Val AUC: 0.9620 Time: 13.84\n",
      "Epoch: 759 Train Loss: 0.0703 Val Loss: 0.3016 Acc: 0.8949 Pre: 0.8545 Recall: 0.9234 F1: 0.8876 Train AUC: 0.9978 Val AUC: 0.9634 Time: 13.80\n",
      "Epoch: 760 Train Loss: 0.0786 Val Loss: 0.3104 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9975 Val AUC: 0.9630 Time: 13.89\n",
      "Epoch: 761 Train Loss: 0.0753 Val Loss: 0.3380 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9980 Val AUC: 0.9612 Time: 13.53\n",
      "Epoch: 762 Train Loss: 0.0847 Val Loss: 0.3503 Acc: 0.9130 Pre: 0.8968 Recall: 0.9113 F1: 0.9040 Train AUC: 0.9959 Val AUC: 0.9597 Time: 12.35\n",
      "Epoch: 763 Train Loss: 0.0770 Val Loss: 0.3354 Acc: 0.9130 Pre: 0.8906 Recall: 0.9194 F1: 0.9048 Train AUC: 0.9968 Val AUC: 0.9595 Time: 13.19\n",
      "Epoch: 764 Train Loss: 0.0753 Val Loss: 0.3329 Acc: 0.8895 Pre: 0.8425 Recall: 0.9274 F1: 0.8829 Train AUC: 0.9971 Val AUC: 0.9593 Time: 13.23\n",
      "Epoch: 765 Train Loss: 0.0736 Val Loss: 0.3383 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9983 Val AUC: 0.9584 Time: 13.39\n",
      "Epoch: 766 Train Loss: 0.0788 Val Loss: 0.3458 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9975 Val AUC: 0.9594 Time: 14.37\n",
      "Epoch: 767 Train Loss: 0.0717 Val Loss: 0.3642 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9979 Val AUC: 0.9585 Time: 13.97\n",
      "Epoch: 768 Train Loss: 0.0769 Val Loss: 0.3539 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9968 Val AUC: 0.9596 Time: 13.75\n",
      "Epoch: 769 Train Loss: 0.0825 Val Loss: 0.3355 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9963 Val AUC: 0.9608 Time: 12.26\n",
      "Epoch: 770 Train Loss: 0.0727 Val Loss: 0.3345 Acc: 0.8877 Pre: 0.8444 Recall: 0.9194 F1: 0.8803 Train AUC: 0.9972 Val AUC: 0.9592 Time: 12.11\n",
      "Epoch: 771 Train Loss: 0.0899 Val Loss: 0.3131 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9957 Val AUC: 0.9614 Time: 12.51\n",
      "Epoch: 772 Train Loss: 0.0884 Val Loss: 0.3158 Acc: 0.9167 Pre: 0.9008 Recall: 0.9153 F1: 0.9080 Train AUC: 0.9963 Val AUC: 0.9621 Time: 13.40\n",
      "Epoch: 773 Train Loss: 0.0652 Val Loss: 0.3565 Acc: 0.9130 Pre: 0.8937 Recall: 0.9153 F1: 0.9044 Train AUC: 0.9986 Val AUC: 0.9606 Time: 13.67\n",
      "Epoch: 774 Train Loss: 0.0885 Val Loss: 0.3759 Acc: 0.9040 Pre: 0.8707 Recall: 0.9234 F1: 0.8963 Train AUC: 0.9956 Val AUC: 0.9604 Time: 14.19\n",
      "Epoch: 775 Train Loss: 0.0927 Val Loss: 0.3489 Acc: 0.8986 Pre: 0.8664 Recall: 0.9153 F1: 0.8902 Train AUC: 0.9953 Val AUC: 0.9604 Time: 14.66\n",
      "Epoch: 776 Train Loss: 0.0727 Val Loss: 0.3341 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9977 Val AUC: 0.9605 Time: 14.35\n",
      "Epoch: 777 Train Loss: 0.0704 Val Loss: 0.3321 Acc: 0.8913 Pre: 0.8507 Recall: 0.9194 F1: 0.8837 Train AUC: 0.9979 Val AUC: 0.9588 Time: 12.19\n",
      "Epoch: 778 Train Loss: 0.0812 Val Loss: 0.3270 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9970 Val AUC: 0.9606 Time: 13.12\n",
      "Epoch: 779 Train Loss: 0.0784 Val Loss: 0.3482 Acc: 0.9022 Pre: 0.8647 Recall: 0.9274 F1: 0.8949 Train AUC: 0.9971 Val AUC: 0.9612 Time: 13.26\n",
      "Epoch: 780 Train Loss: 0.0695 Val Loss: 0.3687 Acc: 0.9076 Pre: 0.8745 Recall: 0.9274 F1: 0.9002 Train AUC: 0.9976 Val AUC: 0.9607 Time: 14.19\n",
      "Epoch: 781 Train Loss: 0.0775 Val Loss: 0.3568 Acc: 0.9058 Pre: 0.8740 Recall: 0.9234 F1: 0.8980 Train AUC: 0.9966 Val AUC: 0.9615 Time: 13.69\n",
      "Epoch: 782 Train Loss: 0.0758 Val Loss: 0.3422 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9972 Val AUC: 0.9612 Time: 13.87\n",
      "Epoch: 783 Train Loss: 0.0682 Val Loss: 0.3324 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9983 Val AUC: 0.9616 Time: 13.46\n",
      "Epoch: 784 Train Loss: 0.0762 Val Loss: 0.3347 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9976 Val AUC: 0.9610 Time: 12.48\n",
      "Epoch: 785 Train Loss: 0.0733 Val Loss: 0.3468 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9978 Val AUC: 0.9610 Time: 13.02\n",
      "Epoch: 786 Train Loss: 0.0731 Val Loss: 0.3330 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9975 Val AUC: 0.9623 Time: 13.54\n",
      "Epoch: 787 Train Loss: 0.0736 Val Loss: 0.3333 Acc: 0.9040 Pre: 0.8764 Recall: 0.9153 F1: 0.8955 Train AUC: 0.9973 Val AUC: 0.9623 Time: 14.23\n",
      "Epoch: 788 Train Loss: 0.0892 Val Loss: 0.3464 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9953 Val AUC: 0.9602 Time: 13.98\n",
      "Epoch: 789 Train Loss: 0.0684 Val Loss: 0.3628 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9979 Val AUC: 0.9585 Time: 13.36\n",
      "Epoch: 790 Train Loss: 0.0745 Val Loss: 0.3523 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9976 Val AUC: 0.9584 Time: 12.48\n",
      "Epoch: 791 Train Loss: 0.0757 Val Loss: 0.3274 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9974 Val AUC: 0.9600 Time: 13.32\n",
      "Epoch: 792 Train Loss: 0.0660 Val Loss: 0.3283 Acc: 0.9058 Pre: 0.8740 Recall: 0.9234 F1: 0.8980 Train AUC: 0.9984 Val AUC: 0.9611 Time: 13.70\n",
      "Epoch: 793 Train Loss: 0.0711 Val Loss: 0.3346 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9977 Val AUC: 0.9621 Time: 14.47\n",
      "Epoch: 794 Train Loss: 0.0721 Val Loss: 0.3321 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9975 Val AUC: 0.9622 Time: 14.19\n",
      "Epoch: 795 Train Loss: 0.0789 Val Loss: 0.3358 Acc: 0.9149 Pre: 0.9004 Recall: 0.9113 F1: 0.9058 Train AUC: 0.9968 Val AUC: 0.9606 Time: 12.44\n",
      "Epoch: 796 Train Loss: 0.0826 Val Loss: 0.3261 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9968 Val AUC: 0.9619 Time: 12.22\n",
      "Epoch: 797 Train Loss: 0.0742 Val Loss: 0.3317 Acc: 0.8841 Pre: 0.8382 Recall: 0.9194 F1: 0.8769 Train AUC: 0.9972 Val AUC: 0.9633 Time: 13.02\n",
      "Epoch: 798 Train Loss: 0.0870 Val Loss: 0.3396 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9974 Val AUC: 0.9609 Time: 13.79\n",
      "Epoch: 799 Train Loss: 0.0611 Val Loss: 0.3617 Acc: 0.9094 Pre: 0.8929 Recall: 0.9073 F1: 0.9000 Train AUC: 0.9986 Val AUC: 0.9586 Time: 13.97\n",
      "Epoch: 800 Train Loss: 0.0770 Val Loss: 0.3883 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9980 Val AUC: 0.9578 Time: 14.50\n",
      "Epoch: 801 Train Loss: 0.0706 Val Loss: 0.3691 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9977 Val AUC: 0.9597 Time: 14.13\n",
      "Epoch: 802 Train Loss: 0.0757 Val Loss: 0.3218 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9976 Val AUC: 0.9624 Time: 13.79\n",
      "Epoch: 803 Train Loss: 0.0725 Val Loss: 0.2994 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9978 Val AUC: 0.9637 Time: 12.19\n",
      "Epoch: 804 Train Loss: 0.0752 Val Loss: 0.3077 Acc: 0.9221 Pre: 0.9084 Recall: 0.9194 F1: 0.9138 Train AUC: 0.9973 Val AUC: 0.9627 Time: 12.26\n",
      "Epoch: 805 Train Loss: 0.0666 Val Loss: 0.3322 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9983 Val AUC: 0.9613 Time: 13.20\n",
      "Epoch: 806 Train Loss: 0.0750 Val Loss: 0.3541 Acc: 0.9004 Pre: 0.8697 Recall: 0.9153 F1: 0.8919 Train AUC: 0.9975 Val AUC: 0.9611 Time: 13.44\n",
      "Epoch: 807 Train Loss: 0.0836 Val Loss: 0.3290 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9962 Val AUC: 0.9621 Time: 13.97\n",
      "Epoch: 808 Train Loss: 0.0604 Val Loss: 0.3061 Acc: 0.9094 Pre: 0.8867 Recall: 0.9153 F1: 0.9008 Train AUC: 0.9985 Val AUC: 0.9631 Time: 14.11\n",
      "Epoch: 809 Train Loss: 0.0723 Val Loss: 0.3091 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9979 Val AUC: 0.9634 Time: 13.71\n",
      "Epoch: 810 Train Loss: 0.0681 Val Loss: 0.3205 Acc: 0.9040 Pre: 0.8824 Recall: 0.9073 F1: 0.8946 Train AUC: 0.9980 Val AUC: 0.9626 Time: 13.83\n",
      "Epoch: 811 Train Loss: 0.0770 Val Loss: 0.3407 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9975 Val AUC: 0.9621 Time: 12.34\n",
      "Epoch: 812 Train Loss: 0.0698 Val Loss: 0.3412 Acc: 0.8967 Pre: 0.8550 Recall: 0.9274 F1: 0.8897 Train AUC: 0.9977 Val AUC: 0.9614 Time: 12.29\n",
      "Epoch: 813 Train Loss: 0.0641 Val Loss: 0.3528 Acc: 0.9040 Pre: 0.8707 Recall: 0.9234 F1: 0.8963 Train AUC: 0.9985 Val AUC: 0.9593 Time: 13.07\n",
      "Epoch: 814 Train Loss: 0.0684 Val Loss: 0.3466 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9979 Val AUC: 0.9584 Time: 14.09\n",
      "Epoch: 815 Train Loss: 0.0743 Val Loss: 0.3261 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9973 Val AUC: 0.9615 Time: 14.38\n",
      "Epoch: 816 Train Loss: 0.0729 Val Loss: 0.3199 Acc: 0.9076 Pre: 0.8774 Recall: 0.9234 F1: 0.8998 Train AUC: 0.9974 Val AUC: 0.9624 Time: 14.81\n",
      "Epoch: 817 Train Loss: 0.0690 Val Loss: 0.3278 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9978 Val AUC: 0.9617 Time: 14.03\n",
      "Epoch: 818 Train Loss: 0.0773 Val Loss: 0.3326 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9970 Val AUC: 0.9608 Time: 13.23\n",
      "Epoch: 819 Train Loss: 0.0752 Val Loss: 0.3407 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9976 Val AUC: 0.9600 Time: 12.44\n",
      "Epoch: 820 Train Loss: 0.0689 Val Loss: 0.3393 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9979 Val AUC: 0.9608 Time: 12.58\n",
      "Epoch: 821 Train Loss: 0.0693 Val Loss: 0.3373 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9982 Val AUC: 0.9610 Time: 12.57\n",
      "Epoch: 822 Train Loss: 0.0707 Val Loss: 0.3327 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9976 Val AUC: 0.9610 Time: 12.99\n",
      "Epoch: 823 Train Loss: 0.0693 Val Loss: 0.3264 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9983 Val AUC: 0.9613 Time: 13.74\n",
      "Epoch: 824 Train Loss: 0.0663 Val Loss: 0.3242 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9988 Val AUC: 0.9626 Time: 14.33\n",
      "Epoch: 825 Train Loss: 0.0779 Val Loss: 0.3229 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9977 Val AUC: 0.9624 Time: 14.88\n",
      "Epoch: 826 Train Loss: 0.0720 Val Loss: 0.3219 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9976 Val AUC: 0.9623 Time: 14.51\n",
      "Epoch: 827 Train Loss: 0.0751 Val Loss: 0.3370 Acc: 0.9058 Pre: 0.8740 Recall: 0.9234 F1: 0.8980 Train AUC: 0.9975 Val AUC: 0.9608 Time: 13.30\n",
      "Epoch: 828 Train Loss: 0.0641 Val Loss: 0.3445 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9983 Val AUC: 0.9607 Time: 12.78\n",
      "Epoch: 829 Train Loss: 0.0682 Val Loss: 0.3350 Acc: 0.8877 Pre: 0.8394 Recall: 0.9274 F1: 0.8812 Train AUC: 0.9981 Val AUC: 0.9616 Time: 13.71\n",
      "Epoch: 830 Train Loss: 0.0690 Val Loss: 0.3105 Acc: 0.9094 Pre: 0.8808 Recall: 0.9234 F1: 0.9016 Train AUC: 0.9983 Val AUC: 0.9634 Time: 13.96\n",
      "Epoch: 831 Train Loss: 0.0695 Val Loss: 0.3109 Acc: 0.9185 Pre: 0.9044 Recall: 0.9153 F1: 0.9098 Train AUC: 0.9978 Val AUC: 0.9631 Time: 14.36\n",
      "Epoch: 832 Train Loss: 0.0684 Val Loss: 0.3254 Acc: 0.9167 Pre: 0.9040 Recall: 0.9113 F1: 0.9076 Train AUC: 0.9981 Val AUC: 0.9622 Time: 14.49\n",
      "Epoch: 833 Train Loss: 0.0704 Val Loss: 0.3360 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9974 Val AUC: 0.9613 Time: 13.22\n",
      "Epoch: 834 Train Loss: 0.0704 Val Loss: 0.3437 Acc: 0.8949 Pre: 0.8545 Recall: 0.9234 F1: 0.8876 Train AUC: 0.9977 Val AUC: 0.9621 Time: 13.51\n",
      "Epoch: 835 Train Loss: 0.0745 Val Loss: 0.3265 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9975 Val AUC: 0.9627 Time: 13.25\n",
      "Epoch: 836 Train Loss: 0.0684 Val Loss: 0.3081 Acc: 0.9076 Pre: 0.8774 Recall: 0.9234 F1: 0.8998 Train AUC: 0.9985 Val AUC: 0.9629 Time: 13.03\n",
      "Epoch: 837 Train Loss: 0.0768 Val Loss: 0.3213 Acc: 0.9130 Pre: 0.8937 Recall: 0.9153 F1: 0.9044 Train AUC: 0.9973 Val AUC: 0.9614 Time: 13.66\n",
      "Epoch: 838 Train Loss: 0.0703 Val Loss: 0.3454 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9982 Val AUC: 0.9604 Time: 14.28\n",
      "Epoch: 839 Train Loss: 0.0610 Val Loss: 0.3599 Acc: 0.8967 Pre: 0.8604 Recall: 0.9194 F1: 0.8889 Train AUC: 0.9984 Val AUC: 0.9613 Time: 13.65\n",
      "Epoch: 840 Train Loss: 0.0822 Val Loss: 0.3204 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9974 Val AUC: 0.9630 Time: 13.87\n",
      "Epoch: 841 Train Loss: 0.0660 Val Loss: 0.3013 Acc: 0.9167 Pre: 0.9040 Recall: 0.9113 F1: 0.9076 Train AUC: 0.9983 Val AUC: 0.9632 Time: 14.49\n",
      "Epoch: 842 Train Loss: 0.0711 Val Loss: 0.3028 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9977 Val AUC: 0.9628 Time: 12.28\n",
      "Epoch: 843 Train Loss: 0.0783 Val Loss: 0.3309 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9975 Val AUC: 0.9610 Time: 12.59\n",
      "Epoch: 844 Train Loss: 0.0724 Val Loss: 0.3577 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9979 Val AUC: 0.9596 Time: 12.63\n",
      "Epoch: 845 Train Loss: 0.0652 Val Loss: 0.3612 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9984 Val AUC: 0.9594 Time: 13.20\n",
      "Epoch: 846 Train Loss: 0.0717 Val Loss: 0.3405 Acc: 0.9130 Pre: 0.8968 Recall: 0.9113 F1: 0.9040 Train AUC: 0.9977 Val AUC: 0.9602 Time: 13.44\n",
      "Epoch: 847 Train Loss: 0.0597 Val Loss: 0.3241 Acc: 0.9149 Pre: 0.9004 Recall: 0.9113 F1: 0.9058 Train AUC: 0.9987 Val AUC: 0.9606 Time: 14.03\n",
      "Epoch: 848 Train Loss: 0.0781 Val Loss: 0.3244 Acc: 0.9167 Pre: 0.9008 Recall: 0.9153 F1: 0.9080 Train AUC: 0.9971 Val AUC: 0.9599 Time: 14.74\n",
      "Epoch: 849 Train Loss: 0.0846 Val Loss: 0.3416 Acc: 0.8841 Pre: 0.8382 Recall: 0.9194 F1: 0.8769 Train AUC: 0.9967 Val AUC: 0.9609 Time: 13.69\n",
      "Epoch: 850 Train Loss: 0.0720 Val Loss: 0.3598 Acc: 0.8859 Pre: 0.8364 Recall: 0.9274 F1: 0.8795 Train AUC: 0.9979 Val AUC: 0.9614 Time: 14.11\n",
      "Epoch: 851 Train Loss: 0.0785 Val Loss: 0.3465 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9978 Val AUC: 0.9615 Time: 12.21\n",
      "Epoch: 852 Train Loss: 0.0722 Val Loss: 0.3344 Acc: 0.9094 Pre: 0.8929 Recall: 0.9073 F1: 0.9000 Train AUC: 0.9978 Val AUC: 0.9619 Time: 12.32\n",
      "Epoch: 853 Train Loss: 0.0831 Val Loss: 0.3124 Acc: 0.9130 Pre: 0.8876 Recall: 0.9234 F1: 0.9051 Train AUC: 0.9967 Val AUC: 0.9637 Time: 12.43\n",
      "Epoch: 854 Train Loss: 0.0704 Val Loss: 0.3173 Acc: 0.8931 Pre: 0.8487 Recall: 0.9274 F1: 0.8863 Train AUC: 0.9976 Val AUC: 0.9633 Time: 12.41\n",
      "Epoch: 855 Train Loss: 0.0748 Val Loss: 0.3385 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9979 Val AUC: 0.9605 Time: 13.71\n",
      "Epoch: 856 Train Loss: 0.0711 Val Loss: 0.3533 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9983 Val AUC: 0.9602 Time: 14.03\n",
      "Epoch: 857 Train Loss: 0.0791 Val Loss: 0.3526 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9969 Val AUC: 0.9603 Time: 14.70\n",
      "Epoch: 858 Train Loss: 0.0665 Val Loss: 0.3370 Acc: 0.9004 Pre: 0.8614 Recall: 0.9274 F1: 0.8932 Train AUC: 0.9982 Val AUC: 0.9621 Time: 14.52\n",
      "Epoch: 859 Train Loss: 0.0687 Val Loss: 0.3293 Acc: 0.8986 Pre: 0.8582 Recall: 0.9274 F1: 0.8915 Train AUC: 0.9979 Val AUC: 0.9637 Time: 14.80\n",
      "Epoch: 860 Train Loss: 0.0718 Val Loss: 0.3276 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9981 Val AUC: 0.9627 Time: 12.33\n",
      "Epoch: 861 Train Loss: 0.0670 Val Loss: 0.3483 Acc: 0.9076 Pre: 0.8893 Recall: 0.9073 F1: 0.8982 Train AUC: 0.9982 Val AUC: 0.9600 Time: 12.61\n",
      "Epoch: 862 Train Loss: 0.0680 Val Loss: 0.3538 Acc: 0.9040 Pre: 0.8824 Recall: 0.9073 F1: 0.8946 Train AUC: 0.9982 Val AUC: 0.9600 Time: 12.33\n",
      "Epoch: 863 Train Loss: 0.0603 Val Loss: 0.3540 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9989 Val AUC: 0.9614 Time: 12.73\n",
      "Epoch: 864 Train Loss: 0.0684 Val Loss: 0.3383 Acc: 0.9094 Pre: 0.8722 Recall: 0.9355 F1: 0.9027 Train AUC: 0.9980 Val AUC: 0.9637 Time: 13.67\n",
      "Epoch: 865 Train Loss: 0.0764 Val Loss: 0.3143 Acc: 0.9112 Pre: 0.8902 Recall: 0.9153 F1: 0.9026 Train AUC: 0.9972 Val AUC: 0.9634 Time: 14.13\n",
      "Epoch: 866 Train Loss: 0.0685 Val Loss: 0.3191 Acc: 0.9130 Pre: 0.9098 Recall: 0.8952 F1: 0.9024 Train AUC: 0.9978 Val AUC: 0.9615 Time: 14.72\n",
      "Epoch: 867 Train Loss: 0.0749 Val Loss: 0.3298 Acc: 0.8967 Pre: 0.8716 Recall: 0.9032 F1: 0.8871 Train AUC: 0.9981 Val AUC: 0.9604 Time: 14.47\n",
      "Epoch: 868 Train Loss: 0.0699 Val Loss: 0.3514 Acc: 0.8822 Pre: 0.8376 Recall: 0.9153 F1: 0.8748 Train AUC: 0.9981 Val AUC: 0.9611 Time: 13.44\n",
      "Epoch: 869 Train Loss: 0.0620 Val Loss: 0.3614 Acc: 0.8913 Pre: 0.8456 Recall: 0.9274 F1: 0.8846 Train AUC: 0.9990 Val AUC: 0.9619 Time: 12.27\n",
      "Epoch: 870 Train Loss: 0.0720 Val Loss: 0.3524 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9982 Val AUC: 0.9616 Time: 12.21\n",
      "Epoch: 871 Train Loss: 0.0692 Val Loss: 0.3475 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9978 Val AUC: 0.9611 Time: 12.61\n",
      "Epoch: 872 Train Loss: 0.0716 Val Loss: 0.3314 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9974 Val AUC: 0.9611 Time: 12.78\n",
      "Epoch: 873 Train Loss: 0.0690 Val Loss: 0.3309 Acc: 0.8841 Pre: 0.8382 Recall: 0.9194 F1: 0.8769 Train AUC: 0.9983 Val AUC: 0.9602 Time: 12.71\n",
      "Epoch: 874 Train Loss: 0.0733 Val Loss: 0.3263 Acc: 0.8768 Pre: 0.8261 Recall: 0.9194 F1: 0.8702 Train AUC: 0.9978 Val AUC: 0.9621 Time: 13.00\n",
      "Epoch: 875 Train Loss: 0.0688 Val Loss: 0.3153 Acc: 0.9112 Pre: 0.8842 Recall: 0.9234 F1: 0.9034 Train AUC: 0.9985 Val AUC: 0.9638 Time: 14.14\n",
      "Epoch: 876 Train Loss: 0.0653 Val Loss: 0.3230 Acc: 0.9112 Pre: 0.8902 Recall: 0.9153 F1: 0.9026 Train AUC: 0.9985 Val AUC: 0.9631 Time: 14.65\n",
      "Epoch: 877 Train Loss: 0.0659 Val Loss: 0.3260 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9979 Val AUC: 0.9631 Time: 14.43\n",
      "Epoch: 878 Train Loss: 0.0737 Val Loss: 0.3296 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9971 Val AUC: 0.9633 Time: 14.36\n",
      "Epoch: 879 Train Loss: 0.0576 Val Loss: 0.3405 Acc: 0.8949 Pre: 0.8545 Recall: 0.9234 F1: 0.8876 Train AUC: 0.9987 Val AUC: 0.9633 Time: 13.01\n",
      "Epoch: 880 Train Loss: 0.0699 Val Loss: 0.3294 Acc: 0.8895 Pre: 0.8476 Recall: 0.9194 F1: 0.8820 Train AUC: 0.9983 Val AUC: 0.9638 Time: 12.37\n",
      "Epoch: 881 Train Loss: 0.0705 Val Loss: 0.3137 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9979 Val AUC: 0.9641 Time: 12.54\n",
      "Epoch: 882 Train Loss: 0.0580 Val Loss: 0.3193 Acc: 0.9094 Pre: 0.8867 Recall: 0.9153 F1: 0.9008 Train AUC: 0.9990 Val AUC: 0.9637 Time: 12.93\n",
      "Epoch: 883 Train Loss: 0.0667 Val Loss: 0.3355 Acc: 0.9004 Pre: 0.8669 Recall: 0.9194 F1: 0.8924 Train AUC: 0.9980 Val AUC: 0.9635 Time: 13.92\n",
      "Epoch: 884 Train Loss: 0.0569 Val Loss: 0.3605 Acc: 0.8895 Pre: 0.8450 Recall: 0.9234 F1: 0.8825 Train AUC: 0.9988 Val AUC: 0.9632 Time: 13.93\n",
      "Epoch: 885 Train Loss: 0.0762 Val Loss: 0.3446 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9973 Val AUC: 0.9620 Time: 14.61\n",
      "Epoch: 886 Train Loss: 0.0628 Val Loss: 0.3412 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9985 Val AUC: 0.9614 Time: 13.82\n",
      "Epoch: 887 Train Loss: 0.0607 Val Loss: 0.3223 Acc: 0.8986 Pre: 0.8750 Recall: 0.9032 F1: 0.8889 Train AUC: 0.9989 Val AUC: 0.9615 Time: 12.82\n",
      "Epoch: 888 Train Loss: 0.0633 Val Loss: 0.3221 Acc: 0.9058 Pre: 0.8889 Recall: 0.9032 F1: 0.8960 Train AUC: 0.9987 Val AUC: 0.9616 Time: 13.40\n",
      "Epoch: 889 Train Loss: 0.0781 Val Loss: 0.3274 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9976 Val AUC: 0.9625 Time: 13.34\n",
      "Epoch: 890 Train Loss: 0.0692 Val Loss: 0.3411 Acc: 0.9058 Pre: 0.8712 Recall: 0.9274 F1: 0.8984 Train AUC: 0.9978 Val AUC: 0.9630 Time: 13.67\n",
      "Epoch: 891 Train Loss: 0.0781 Val Loss: 0.3352 Acc: 0.8986 Pre: 0.8609 Recall: 0.9234 F1: 0.8911 Train AUC: 0.9969 Val AUC: 0.9619 Time: 14.48\n",
      "Epoch: 892 Train Loss: 0.0632 Val Loss: 0.3237 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9983 Val AUC: 0.9613 Time: 12.81\n",
      "Epoch: 893 Train Loss: 0.0710 Val Loss: 0.3160 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9977 Val AUC: 0.9627 Time: 12.43\n",
      "Epoch: 894 Train Loss: 0.0641 Val Loss: 0.3177 Acc: 0.9058 Pre: 0.8889 Recall: 0.9032 F1: 0.8960 Train AUC: 0.9983 Val AUC: 0.9630 Time: 12.78\n",
      "Epoch: 895 Train Loss: 0.0710 Val Loss: 0.3453 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9974 Val AUC: 0.9625 Time: 13.69\n",
      "Epoch: 896 Train Loss: 0.0651 Val Loss: 0.3655 Acc: 0.8931 Pre: 0.8593 Recall: 0.9113 F1: 0.8845 Train AUC: 0.9983 Val AUC: 0.9616 Time: 13.72\n",
      "Epoch: 897 Train Loss: 0.0719 Val Loss: 0.3507 Acc: 0.9040 Pre: 0.8824 Recall: 0.9073 F1: 0.8946 Train AUC: 0.9975 Val AUC: 0.9610 Time: 14.41\n",
      "Epoch: 898 Train Loss: 0.0661 Val Loss: 0.3331 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9978 Val AUC: 0.9616 Time: 15.06\n",
      "Epoch: 899 Train Loss: 0.0731 Val Loss: 0.3317 Acc: 0.8859 Pre: 0.8464 Recall: 0.9113 F1: 0.8777 Train AUC: 0.9978 Val AUC: 0.9600 Time: 12.93\n",
      "Epoch: 900 Train Loss: 0.0736 Val Loss: 0.3391 Acc: 0.8750 Pre: 0.8208 Recall: 0.9234 F1: 0.8691 Train AUC: 0.9976 Val AUC: 0.9631 Time: 12.22\n",
      "Epoch: 901 Train Loss: 0.0720 Val Loss: 0.3421 Acc: 0.8967 Pre: 0.8550 Recall: 0.9274 F1: 0.8897 Train AUC: 0.9985 Val AUC: 0.9621 Time: 12.53\n",
      "Epoch: 902 Train Loss: 0.0779 Val Loss: 0.3458 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9972 Val AUC: 0.9613 Time: 12.36\n",
      "Epoch: 903 Train Loss: 0.0780 Val Loss: 0.3480 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9969 Val AUC: 0.9606 Time: 12.88\n",
      "Epoch: 904 Train Loss: 0.0742 Val Loss: 0.3442 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9971 Val AUC: 0.9605 Time: 14.26\n",
      "Epoch: 905 Train Loss: 0.0677 Val Loss: 0.3365 Acc: 0.8913 Pre: 0.8507 Recall: 0.9194 F1: 0.8837 Train AUC: 0.9981 Val AUC: 0.9605 Time: 13.89\n",
      "Epoch: 906 Train Loss: 0.0667 Val Loss: 0.3218 Acc: 0.8967 Pre: 0.8577 Recall: 0.9234 F1: 0.8893 Train AUC: 0.9982 Val AUC: 0.9624 Time: 14.83\n",
      "Epoch: 907 Train Loss: 0.0758 Val Loss: 0.3246 Acc: 0.9112 Pre: 0.8812 Recall: 0.9274 F1: 0.9037 Train AUC: 0.9976 Val AUC: 0.9628 Time: 14.99\n",
      "Epoch: 908 Train Loss: 0.0627 Val Loss: 0.3459 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9988 Val AUC: 0.9611 Time: 15.05\n",
      "Epoch: 909 Train Loss: 0.0625 Val Loss: 0.3509 Acc: 0.8967 Pre: 0.8687 Recall: 0.9073 F1: 0.8876 Train AUC: 0.9983 Val AUC: 0.9607 Time: 12.57\n",
      "Epoch: 910 Train Loss: 0.0725 Val Loss: 0.3304 Acc: 0.8967 Pre: 0.8631 Recall: 0.9153 F1: 0.8885 Train AUC: 0.9970 Val AUC: 0.9629 Time: 12.46\n",
      "Epoch: 911 Train Loss: 0.0712 Val Loss: 0.3192 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9975 Val AUC: 0.9644 Time: 12.54\n",
      "Epoch: 912 Train Loss: 0.0705 Val Loss: 0.3235 Acc: 0.8913 Pre: 0.8507 Recall: 0.9194 F1: 0.8837 Train AUC: 0.9981 Val AUC: 0.9627 Time: 12.49\n",
      "Epoch: 913 Train Loss: 0.0682 Val Loss: 0.3414 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9979 Val AUC: 0.9625 Time: 12.54\n",
      "Epoch: 914 Train Loss: 0.0688 Val Loss: 0.3638 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9981 Val AUC: 0.9608 Time: 13.81\n",
      "Epoch: 915 Train Loss: 0.0690 Val Loss: 0.3777 Acc: 0.8931 Pre: 0.8513 Recall: 0.9234 F1: 0.8859 Train AUC: 0.9980 Val AUC: 0.9605 Time: 14.03\n",
      "Epoch: 916 Train Loss: 0.0635 Val Loss: 0.3572 Acc: 0.9004 Pre: 0.8561 Recall: 0.9355 F1: 0.8940 Train AUC: 0.9981 Val AUC: 0.9617 Time: 14.54\n",
      "Epoch: 917 Train Loss: 0.0806 Val Loss: 0.3274 Acc: 0.9040 Pre: 0.8736 Recall: 0.9194 F1: 0.8959 Train AUC: 0.9970 Val AUC: 0.9616 Time: 14.79\n",
      "Epoch: 918 Train Loss: 0.0598 Val Loss: 0.3352 Acc: 0.8913 Pre: 0.8615 Recall: 0.9032 F1: 0.8819 Train AUC: 0.9985 Val AUC: 0.9581 Time: 14.75\n",
      "Epoch: 919 Train Loss: 0.0944 Val Loss: 0.3502 Acc: 0.8967 Pre: 0.8631 Recall: 0.9153 F1: 0.8885 Train AUC: 0.9949 Val AUC: 0.9587 Time: 12.35\n",
      "Epoch: 920 Train Loss: 0.0724 Val Loss: 0.3711 Acc: 0.8895 Pre: 0.8476 Recall: 0.9194 F1: 0.8820 Train AUC: 0.9979 Val AUC: 0.9591 Time: 12.34\n",
      "Epoch: 921 Train Loss: 0.0752 Val Loss: 0.3734 Acc: 0.8967 Pre: 0.8659 Recall: 0.9113 F1: 0.8880 Train AUC: 0.9977 Val AUC: 0.9600 Time: 12.46\n",
      "Epoch: 922 Train Loss: 0.0817 Val Loss: 0.3488 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9966 Val AUC: 0.9616 Time: 12.33\n",
      "Epoch: 923 Train Loss: 0.0612 Val Loss: 0.3267 Acc: 0.9149 Pre: 0.9004 Recall: 0.9113 F1: 0.9058 Train AUC: 0.9982 Val AUC: 0.9620 Time: 12.30\n",
      "Epoch: 924 Train Loss: 0.0615 Val Loss: 0.3137 Acc: 0.9058 Pre: 0.8889 Recall: 0.9032 F1: 0.8960 Train AUC: 0.9985 Val AUC: 0.9627 Time: 12.30\n",
      "Epoch: 925 Train Loss: 0.0715 Val Loss: 0.3231 Acc: 0.8895 Pre: 0.8476 Recall: 0.9194 F1: 0.8820 Train AUC: 0.9974 Val AUC: 0.9631 Time: 12.94\n",
      "Epoch: 926 Train Loss: 0.0732 Val Loss: 0.3406 Acc: 0.8859 Pre: 0.8413 Recall: 0.9194 F1: 0.8786 Train AUC: 0.9979 Val AUC: 0.9625 Time: 13.81\n",
      "Epoch: 927 Train Loss: 0.0696 Val Loss: 0.3412 Acc: 0.8986 Pre: 0.8664 Recall: 0.9153 F1: 0.8902 Train AUC: 0.9978 Val AUC: 0.9624 Time: 14.61\n",
      "Epoch: 928 Train Loss: 0.0631 Val Loss: 0.3325 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9982 Val AUC: 0.9618 Time: 15.08\n",
      "Epoch: 929 Train Loss: 0.0715 Val Loss: 0.3234 Acc: 0.9076 Pre: 0.8833 Recall: 0.9153 F1: 0.8990 Train AUC: 0.9977 Val AUC: 0.9629 Time: 15.59\n",
      "Epoch: 930 Train Loss: 0.0600 Val Loss: 0.3081 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9987 Val AUC: 0.9639 Time: 13.48\n",
      "Epoch: 931 Train Loss: 0.0621 Val Loss: 0.3080 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9983 Val AUC: 0.9644 Time: 12.40\n",
      "Epoch: 932 Train Loss: 0.0645 Val Loss: 0.3115 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9984 Val AUC: 0.9636 Time: 12.30\n",
      "Epoch: 933 Train Loss: 0.0658 Val Loss: 0.3143 Acc: 0.9022 Pre: 0.8789 Recall: 0.9073 F1: 0.8929 Train AUC: 0.9982 Val AUC: 0.9640 Time: 12.27\n",
      "Epoch: 934 Train Loss: 0.0606 Val Loss: 0.3098 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9986 Val AUC: 0.9643 Time: 12.33\n",
      "Epoch: 935 Train Loss: 0.0619 Val Loss: 0.3075 Acc: 0.9058 Pre: 0.8712 Recall: 0.9274 F1: 0.8984 Train AUC: 0.9983 Val AUC: 0.9650 Time: 12.36\n",
      "Epoch: 936 Train Loss: 0.0646 Val Loss: 0.3186 Acc: 0.8949 Pre: 0.8519 Recall: 0.9274 F1: 0.8880 Train AUC: 0.9986 Val AUC: 0.9648 Time: 13.10\n",
      "Epoch: 937 Train Loss: 0.0657 Val Loss: 0.3276 Acc: 0.9004 Pre: 0.8642 Recall: 0.9234 F1: 0.8928 Train AUC: 0.9983 Val AUC: 0.9621 Time: 13.26\n",
      "Epoch: 938 Train Loss: 0.0587 Val Loss: 0.3390 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9987 Val AUC: 0.9612 Time: 14.32\n",
      "Epoch: 939 Train Loss: 0.0604 Val Loss: 0.3636 Acc: 0.9022 Pre: 0.8760 Recall: 0.9113 F1: 0.8933 Train AUC: 0.9986 Val AUC: 0.9598 Time: 14.71\n",
      "Epoch: 940 Train Loss: 0.0690 Val Loss: 0.3524 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9979 Val AUC: 0.9612 Time: 14.00\n",
      "Epoch: 941 Train Loss: 0.0684 Val Loss: 0.3251 Acc: 0.8931 Pre: 0.8487 Recall: 0.9274 F1: 0.8863 Train AUC: 0.9978 Val AUC: 0.9641 Time: 14.70\n",
      "Epoch: 942 Train Loss: 0.0650 Val Loss: 0.3049 Acc: 0.9040 Pre: 0.8679 Recall: 0.9274 F1: 0.8967 Train AUC: 0.9983 Val AUC: 0.9643 Time: 12.17\n",
      "Epoch: 943 Train Loss: 0.0696 Val Loss: 0.3091 Acc: 0.9167 Pre: 0.8945 Recall: 0.9234 F1: 0.9087 Train AUC: 0.9982 Val AUC: 0.9628 Time: 12.48\n",
      "Epoch: 944 Train Loss: 0.0652 Val Loss: 0.3303 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9985 Val AUC: 0.9620 Time: 12.50\n",
      "Epoch: 945 Train Loss: 0.0706 Val Loss: 0.3475 Acc: 0.8949 Pre: 0.8519 Recall: 0.9274 F1: 0.8880 Train AUC: 0.9980 Val AUC: 0.9626 Time: 13.46\n",
      "Epoch: 946 Train Loss: 0.0668 Val Loss: 0.3450 Acc: 0.8877 Pre: 0.8394 Recall: 0.9274 F1: 0.8812 Train AUC: 0.9980 Val AUC: 0.9637 Time: 13.98\n",
      "Epoch: 947 Train Loss: 0.0688 Val Loss: 0.3226 Acc: 0.8986 Pre: 0.8582 Recall: 0.9274 F1: 0.8915 Train AUC: 0.9986 Val AUC: 0.9630 Time: 14.37\n",
      "Epoch: 948 Train Loss: 0.0832 Val Loss: 0.3241 Acc: 0.9185 Pre: 0.9044 Recall: 0.9153 F1: 0.9098 Train AUC: 0.9962 Val AUC: 0.9619 Time: 15.13\n",
      "Epoch: 949 Train Loss: 0.0652 Val Loss: 0.3307 Acc: 0.9167 Pre: 0.9040 Recall: 0.9113 F1: 0.9076 Train AUC: 0.9983 Val AUC: 0.9616 Time: 13.34\n",
      "Epoch: 950 Train Loss: 0.0730 Val Loss: 0.3397 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9977 Val AUC: 0.9625 Time: 12.58\n",
      "Epoch: 951 Train Loss: 0.0723 Val Loss: 0.3480 Acc: 0.8804 Pre: 0.8321 Recall: 0.9194 F1: 0.8736 Train AUC: 0.9978 Val AUC: 0.9612 Time: 12.70\n",
      "Epoch: 952 Train Loss: 0.0663 Val Loss: 0.3331 Acc: 0.8877 Pre: 0.8444 Recall: 0.9194 F1: 0.8803 Train AUC: 0.9988 Val AUC: 0.9607 Time: 12.79\n",
      "Epoch: 953 Train Loss: 0.0623 Val Loss: 0.3216 Acc: 0.9076 Pre: 0.8803 Recall: 0.9194 F1: 0.8994 Train AUC: 0.9987 Val AUC: 0.9617 Time: 13.88\n",
      "Epoch: 954 Train Loss: 0.0638 Val Loss: 0.3195 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9985 Val AUC: 0.9626 Time: 14.20\n",
      "Epoch: 955 Train Loss: 0.0619 Val Loss: 0.3241 Acc: 0.9076 Pre: 0.8863 Recall: 0.9113 F1: 0.8986 Train AUC: 0.9982 Val AUC: 0.9636 Time: 14.55\n",
      "Epoch: 956 Train Loss: 0.0688 Val Loss: 0.3183 Acc: 0.9058 Pre: 0.8798 Recall: 0.9153 F1: 0.8972 Train AUC: 0.9977 Val AUC: 0.9635 Time: 13.94\n",
      "Epoch: 957 Train Loss: 0.0679 Val Loss: 0.3188 Acc: 0.8949 Pre: 0.8545 Recall: 0.9234 F1: 0.8876 Train AUC: 0.9978 Val AUC: 0.9639 Time: 13.31\n",
      "Epoch: 958 Train Loss: 0.0709 Val Loss: 0.3145 Acc: 0.8949 Pre: 0.8545 Recall: 0.9234 F1: 0.8876 Train AUC: 0.9982 Val AUC: 0.9641 Time: 12.32\n",
      "Epoch: 959 Train Loss: 0.0587 Val Loss: 0.3159 Acc: 0.9094 Pre: 0.8837 Recall: 0.9194 F1: 0.9012 Train AUC: 0.9990 Val AUC: 0.9625 Time: 12.31\n",
      "Epoch: 960 Train Loss: 0.0711 Val Loss: 0.3346 Acc: 0.9022 Pre: 0.8731 Recall: 0.9153 F1: 0.8937 Train AUC: 0.9984 Val AUC: 0.9620 Time: 12.48\n",
      "Epoch: 961 Train Loss: 0.0665 Val Loss: 0.3384 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9979 Val AUC: 0.9617 Time: 13.91\n",
      "Epoch: 962 Train Loss: 0.0731 Val Loss: 0.3497 Acc: 0.9004 Pre: 0.8726 Recall: 0.9113 F1: 0.8915 Train AUC: 0.9974 Val AUC: 0.9601 Time: 13.76\n",
      "Epoch: 963 Train Loss: 0.0696 Val Loss: 0.3390 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9977 Val AUC: 0.9604 Time: 14.38\n",
      "Epoch: 964 Train Loss: 0.0576 Val Loss: 0.3223 Acc: 0.9022 Pre: 0.8702 Recall: 0.9194 F1: 0.8941 Train AUC: 0.9989 Val AUC: 0.9622 Time: 14.71\n",
      "Epoch: 965 Train Loss: 0.0693 Val Loss: 0.3114 Acc: 0.9094 Pre: 0.8779 Recall: 0.9274 F1: 0.9020 Train AUC: 0.9980 Val AUC: 0.9630 Time: 14.84\n",
      "Epoch: 966 Train Loss: 0.0713 Val Loss: 0.3201 Acc: 0.9058 Pre: 0.8712 Recall: 0.9274 F1: 0.8984 Train AUC: 0.9980 Val AUC: 0.9629 Time: 12.14\n",
      "Epoch: 967 Train Loss: 0.0620 Val Loss: 0.3353 Acc: 0.8949 Pre: 0.8519 Recall: 0.9274 F1: 0.8880 Train AUC: 0.9986 Val AUC: 0.9627 Time: 12.32\n",
      "Epoch: 968 Train Loss: 0.0608 Val Loss: 0.3491 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9986 Val AUC: 0.9618 Time: 12.51\n",
      "Epoch: 969 Train Loss: 0.0657 Val Loss: 0.3384 Acc: 0.9094 Pre: 0.8898 Recall: 0.9113 F1: 0.9004 Train AUC: 0.9980 Val AUC: 0.9615 Time: 12.66\n",
      "Epoch: 970 Train Loss: 0.0656 Val Loss: 0.3146 Acc: 0.9112 Pre: 0.8933 Recall: 0.9113 F1: 0.9022 Train AUC: 0.9982 Val AUC: 0.9629 Time: 13.60\n",
      "Epoch: 971 Train Loss: 0.0739 Val Loss: 0.3168 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9975 Val AUC: 0.9631 Time: 14.52\n",
      "Epoch: 972 Train Loss: 0.0646 Val Loss: 0.3387 Acc: 0.8931 Pre: 0.8539 Recall: 0.9194 F1: 0.8854 Train AUC: 0.9984 Val AUC: 0.9627 Time: 14.24\n",
      "Epoch: 973 Train Loss: 0.0688 Val Loss: 0.3435 Acc: 0.8949 Pre: 0.8545 Recall: 0.9234 F1: 0.8876 Train AUC: 0.9981 Val AUC: 0.9624 Time: 13.84\n",
      "Epoch: 974 Train Loss: 0.0764 Val Loss: 0.3401 Acc: 0.9130 Pre: 0.8906 Recall: 0.9194 F1: 0.9048 Train AUC: 0.9975 Val AUC: 0.9615 Time: 12.59\n",
      "Epoch: 975 Train Loss: 0.0665 Val Loss: 0.3356 Acc: 0.9167 Pre: 0.9073 Recall: 0.9073 F1: 0.9073 Train AUC: 0.9981 Val AUC: 0.9611 Time: 12.53\n",
      "Epoch: 976 Train Loss: 0.0687 Val Loss: 0.3171 Acc: 0.9094 Pre: 0.8808 Recall: 0.9234 F1: 0.9016 Train AUC: 0.9985 Val AUC: 0.9636 Time: 12.49\n",
      "Epoch: 977 Train Loss: 0.0615 Val Loss: 0.3386 Acc: 0.8877 Pre: 0.8394 Recall: 0.9274 F1: 0.8812 Train AUC: 0.9989 Val AUC: 0.9632 Time: 13.95\n",
      "Epoch: 978 Train Loss: 0.0728 Val Loss: 0.3582 Acc: 0.8841 Pre: 0.8382 Recall: 0.9194 F1: 0.8769 Train AUC: 0.9979 Val AUC: 0.9611 Time: 13.72\n",
      "Epoch: 979 Train Loss: 0.0708 Val Loss: 0.3436 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9983 Val AUC: 0.9606 Time: 13.83\n",
      "Epoch: 980 Train Loss: 0.0635 Val Loss: 0.3322 Acc: 0.9167 Pre: 0.9040 Recall: 0.9113 F1: 0.9076 Train AUC: 0.9981 Val AUC: 0.9613 Time: 13.88\n",
      "Epoch: 981 Train Loss: 0.0739 Val Loss: 0.3117 Acc: 0.9130 Pre: 0.8906 Recall: 0.9194 F1: 0.9048 Train AUC: 0.9982 Val AUC: 0.9627 Time: 14.25\n",
      "Epoch: 982 Train Loss: 0.0654 Val Loss: 0.3147 Acc: 0.9058 Pre: 0.8712 Recall: 0.9274 F1: 0.8984 Train AUC: 0.9983 Val AUC: 0.9637 Time: 12.32\n",
      "Epoch: 983 Train Loss: 0.0651 Val Loss: 0.3329 Acc: 0.8949 Pre: 0.8571 Recall: 0.9194 F1: 0.8872 Train AUC: 0.9985 Val AUC: 0.9621 Time: 12.63\n",
      "Epoch: 984 Train Loss: 0.0656 Val Loss: 0.3549 Acc: 0.8949 Pre: 0.8626 Recall: 0.9113 F1: 0.8863 Train AUC: 0.9986 Val AUC: 0.9602 Time: 13.35\n",
      "Epoch: 985 Train Loss: 0.0616 Val Loss: 0.3443 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9986 Val AUC: 0.9609 Time: 13.67\n",
      "Epoch: 986 Train Loss: 0.0704 Val Loss: 0.3186 Acc: 0.9094 Pre: 0.8867 Recall: 0.9153 F1: 0.9008 Train AUC: 0.9973 Val AUC: 0.9630 Time: 13.64\n",
      "Epoch: 987 Train Loss: 0.0696 Val Loss: 0.3085 Acc: 0.9058 Pre: 0.8712 Recall: 0.9274 F1: 0.8984 Train AUC: 0.9975 Val AUC: 0.9643 Time: 14.16\n",
      "Epoch: 988 Train Loss: 0.0658 Val Loss: 0.3171 Acc: 0.9058 Pre: 0.8769 Recall: 0.9194 F1: 0.8976 Train AUC: 0.9981 Val AUC: 0.9617 Time: 14.32\n",
      "Epoch: 989 Train Loss: 0.0696 Val Loss: 0.3494 Acc: 0.8804 Pre: 0.8321 Recall: 0.9194 F1: 0.8736 Train AUC: 0.9982 Val AUC: 0.9590 Time: 12.69\n",
      "Epoch: 990 Train Loss: 0.0626 Val Loss: 0.3749 Acc: 0.8804 Pre: 0.8321 Recall: 0.9194 F1: 0.8736 Train AUC: 0.9984 Val AUC: 0.9585 Time: 12.35\n",
      "Epoch: 991 Train Loss: 0.0664 Val Loss: 0.3541 Acc: 0.8931 Pre: 0.8566 Recall: 0.9153 F1: 0.8850 Train AUC: 0.9982 Val AUC: 0.9611 Time: 13.07\n",
      "Epoch: 992 Train Loss: 0.0635 Val Loss: 0.3211 Acc: 0.9058 Pre: 0.8798 Recall: 0.9153 F1: 0.8972 Train AUC: 0.9981 Val AUC: 0.9631 Time: 13.59\n",
      "Epoch: 993 Train Loss: 0.0708 Val Loss: 0.3062 Acc: 0.9112 Pre: 0.8872 Recall: 0.9194 F1: 0.9030 Train AUC: 0.9978 Val AUC: 0.9641 Time: 13.71\n",
      "Epoch: 994 Train Loss: 0.0674 Val Loss: 0.3086 Acc: 0.9076 Pre: 0.8745 Recall: 0.9274 F1: 0.9002 Train AUC: 0.9983 Val AUC: 0.9640 Time: 14.67\n",
      "Epoch: 995 Train Loss: 0.0661 Val Loss: 0.3242 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9981 Val AUC: 0.9628 Time: 15.00\n",
      "Epoch: 996 Train Loss: 0.0706 Val Loss: 0.3425 Acc: 0.8986 Pre: 0.8636 Recall: 0.9194 F1: 0.8906 Train AUC: 0.9982 Val AUC: 0.9620 Time: 13.13\n",
      "Epoch: 997 Train Loss: 0.0652 Val Loss: 0.3539 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9980 Val AUC: 0.9624 Time: 12.39\n",
      "Epoch: 998 Train Loss: 0.0630 Val Loss: 0.3544 Acc: 0.9022 Pre: 0.8674 Recall: 0.9234 F1: 0.8945 Train AUC: 0.9981 Val AUC: 0.9617 Time: 13.47\n",
      "Epoch: 999 Train Loss: 0.0759 Val Loss: 0.3398 Acc: 0.9040 Pre: 0.8794 Recall: 0.9113 F1: 0.8950 Train AUC: 0.9967 Val AUC: 0.9611 Time: 13.41\n",
      "Epoch: 1000 Train Loss: 0.0665 Val Loss: 0.3356 Acc: 0.9058 Pre: 0.8828 Recall: 0.9113 F1: 0.8968 Train AUC: 0.9981 Val AUC: 0.9609 Time: 13.77\n",
      "Fold: 4 Best Epoch: 935 Test acc: 0.9058 Test Pre: 0.8712 Test Recall: 0.9274 Test F1: 0.8984 Test PRC: 0.9655 Test AUC: 0.9650\n",
      "Training for Fold 5\n",
      "## Training edges: 2208\n",
      "## Testing edges: 552\n",
      "Epoch: 1 Train Loss: 1.0512 Val Loss: 1.5141 Acc: 0.5036 Pre: 0.4854 Recall: 0.5000 F1: 0.4926 Train AUC: 0.4425 Val AUC: 0.5530 Time: 14.57\n",
      "Epoch: 2 Train Loss: 1.6622 Val Loss: 1.0291 Acc: 0.5634 Pre: 0.5399 Recall: 0.6353 F1: 0.5838 Train AUC: 0.5382 Val AUC: 0.6338 Time: 13.31\n",
      "Epoch: 3 Train Loss: 1.0011 Val Loss: 0.5020 Acc: 0.7264 Pre: 0.7154 Recall: 0.7180 F1: 0.7167 Train AUC: 0.6533 Val AUC: 0.8294 Time: 12.55\n",
      "Epoch: 4 Train Loss: 0.6525 Val Loss: 0.5166 Acc: 0.7409 Pre: 0.7639 Recall: 0.6692 F1: 0.7134 Train AUC: 0.7487 Val AUC: 0.8233 Time: 13.36\n",
      "Epoch: 5 Train Loss: 0.5558 Val Loss: 0.4967 Acc: 0.7772 Pre: 0.7563 Recall: 0.7932 F1: 0.7743 Train AUC: 0.8124 Val AUC: 0.8458 Time: 14.04\n",
      "Epoch: 6 Train Loss: 0.7667 Val Loss: 0.5806 Acc: 0.7083 Pre: 0.6431 Recall: 0.8872 F1: 0.7457 Train AUC: 0.7135 Val AUC: 0.8593 Time: 14.86\n",
      "Epoch: 7 Train Loss: 0.6270 Val Loss: 0.6123 Acc: 0.7228 Pre: 0.6592 Recall: 0.8797 F1: 0.7536 Train AUC: 0.7962 Val AUC: 0.8594 Time: 13.43\n",
      "Epoch: 8 Train Loss: 0.5935 Val Loss: 0.4796 Acc: 0.7862 Pre: 0.7569 Recall: 0.8195 F1: 0.7870 Train AUC: 0.8525 Val AUC: 0.8732 Time: 13.32\n",
      "Epoch: 9 Train Loss: 0.5516 Val Loss: 0.4477 Acc: 0.8007 Pre: 0.8750 Recall: 0.6842 F1: 0.7679 Train AUC: 0.8469 Val AUC: 0.8908 Time: 14.05\n",
      "Epoch: 10 Train Loss: 0.5381 Val Loss: 0.4679 Acc: 0.8025 Pre: 0.8945 Recall: 0.6692 F1: 0.7656 Train AUC: 0.8718 Val AUC: 0.8987 Time: 14.15\n",
      "Epoch: 11 Train Loss: 0.5312 Val Loss: 0.4528 Acc: 0.8225 Pre: 0.8925 Recall: 0.7180 F1: 0.7958 Train AUC: 0.8948 Val AUC: 0.8969 Time: 14.21\n",
      "Epoch: 12 Train Loss: 0.5258 Val Loss: 0.4421 Acc: 0.8134 Pre: 0.8382 Recall: 0.7594 F1: 0.7968 Train AUC: 0.8798 Val AUC: 0.8926 Time: 13.01\n",
      "Epoch: 13 Train Loss: 0.4683 Val Loss: 0.4456 Acc: 0.8062 Pre: 0.8046 Recall: 0.7895 F1: 0.7970 Train AUC: 0.8837 Val AUC: 0.8903 Time: 12.37\n",
      "Epoch: 14 Train Loss: 0.4669 Val Loss: 0.4487 Acc: 0.8025 Pre: 0.7814 Recall: 0.8195 F1: 0.8000 Train AUC: 0.8806 Val AUC: 0.8911 Time: 12.43\n",
      "Epoch: 15 Train Loss: 0.4446 Val Loss: 0.4412 Acc: 0.8080 Pre: 0.7797 Recall: 0.8383 F1: 0.8080 Train AUC: 0.8869 Val AUC: 0.8928 Time: 13.69\n",
      "Epoch: 16 Train Loss: 0.4438 Val Loss: 0.4137 Acc: 0.8134 Pre: 0.7942 Recall: 0.8271 F1: 0.8103 Train AUC: 0.8898 Val AUC: 0.8976 Time: 13.64\n",
      "Epoch: 17 Train Loss: 0.4153 Val Loss: 0.3935 Acc: 0.8243 Pre: 0.8263 Recall: 0.8045 F1: 0.8152 Train AUC: 0.8881 Val AUC: 0.9009 Time: 14.58\n",
      "Epoch: 18 Train Loss: 0.4528 Val Loss: 0.3837 Acc: 0.8261 Pre: 0.8427 Recall: 0.7857 F1: 0.8132 Train AUC: 0.8670 Val AUC: 0.9050 Time: 14.77\n",
      "Epoch: 19 Train Loss: 0.4028 Val Loss: 0.3762 Acc: 0.8388 Pre: 0.8798 Recall: 0.7707 F1: 0.8216 Train AUC: 0.8950 Val AUC: 0.9086 Time: 13.23\n",
      "Epoch: 20 Train Loss: 0.4333 Val Loss: 0.3691 Acc: 0.8225 Pre: 0.8590 Recall: 0.7556 F1: 0.8040 Train AUC: 0.8782 Val AUC: 0.9107 Time: 12.70\n",
      "Epoch: 21 Train Loss: 0.4406 Val Loss: 0.3686 Acc: 0.8261 Pre: 0.8602 Recall: 0.7632 F1: 0.8088 Train AUC: 0.8700 Val AUC: 0.9102 Time: 12.39\n",
      "Epoch: 22 Train Loss: 0.4149 Val Loss: 0.3770 Acc: 0.8225 Pre: 0.8471 Recall: 0.7707 F1: 0.8071 Train AUC: 0.8902 Val AUC: 0.9078 Time: 12.51\n",
      "Epoch: 23 Train Loss: 0.3946 Val Loss: 0.3869 Acc: 0.8243 Pre: 0.8449 Recall: 0.7782 F1: 0.8102 Train AUC: 0.8996 Val AUC: 0.9066 Time: 13.82\n",
      "Epoch: 24 Train Loss: 0.3876 Val Loss: 0.3951 Acc: 0.8333 Pre: 0.8480 Recall: 0.7970 F1: 0.8217 Train AUC: 0.9049 Val AUC: 0.9058 Time: 13.90\n",
      "Epoch: 25 Train Loss: 0.4004 Val Loss: 0.3989 Acc: 0.8297 Pre: 0.8413 Recall: 0.7970 F1: 0.8185 Train AUC: 0.9035 Val AUC: 0.9056 Time: 14.46\n",
      "Epoch: 26 Train Loss: 0.4030 Val Loss: 0.3983 Acc: 0.8315 Pre: 0.8392 Recall: 0.8045 F1: 0.8215 Train AUC: 0.9006 Val AUC: 0.9058 Time: 14.88\n",
      "Epoch: 27 Train Loss: 0.3699 Val Loss: 0.3931 Acc: 0.8315 Pre: 0.8366 Recall: 0.8083 F1: 0.8222 Train AUC: 0.9152 Val AUC: 0.9070 Time: 13.58\n",
      "Epoch: 28 Train Loss: 0.4072 Val Loss: 0.3830 Acc: 0.8279 Pre: 0.8379 Recall: 0.7970 F1: 0.8170 Train AUC: 0.9027 Val AUC: 0.9085 Time: 13.61\n",
      "Epoch: 29 Train Loss: 0.3913 Val Loss: 0.3742 Acc: 0.8279 Pre: 0.8406 Recall: 0.7932 F1: 0.8162 Train AUC: 0.9055 Val AUC: 0.9104 Time: 13.38\n",
      "Epoch: 30 Train Loss: 0.3816 Val Loss: 0.3668 Acc: 0.8333 Pre: 0.8508 Recall: 0.7932 F1: 0.8210 Train AUC: 0.9075 Val AUC: 0.9122 Time: 13.99\n",
      "Epoch: 31 Train Loss: 0.3918 Val Loss: 0.3628 Acc: 0.8460 Pre: 0.8694 Recall: 0.8008 F1: 0.8337 Train AUC: 0.9024 Val AUC: 0.9122 Time: 14.33\n",
      "Epoch: 32 Train Loss: 0.3934 Val Loss: 0.3622 Acc: 0.8478 Pre: 0.8669 Recall: 0.8083 F1: 0.8366 Train AUC: 0.9038 Val AUC: 0.9123 Time: 14.41\n",
      "Epoch: 33 Train Loss: 0.3797 Val Loss: 0.3625 Acc: 0.8496 Pre: 0.8645 Recall: 0.8158 F1: 0.8395 Train AUC: 0.9069 Val AUC: 0.9128 Time: 13.41\n",
      "Epoch: 34 Train Loss: 0.3560 Val Loss: 0.3608 Acc: 0.8478 Pre: 0.8611 Recall: 0.8158 F1: 0.8378 Train AUC: 0.9188 Val AUC: 0.9133 Time: 12.77\n",
      "Epoch: 35 Train Loss: 0.3970 Val Loss: 0.3573 Acc: 0.8424 Pre: 0.8594 Recall: 0.8045 F1: 0.8311 Train AUC: 0.9005 Val AUC: 0.9145 Time: 12.83\n",
      "Epoch: 36 Train Loss: 0.3571 Val Loss: 0.3549 Acc: 0.8460 Pre: 0.8694 Recall: 0.8008 F1: 0.8337 Train AUC: 0.9184 Val AUC: 0.9150 Time: 13.75\n",
      "Epoch: 37 Train Loss: 0.3601 Val Loss: 0.3554 Acc: 0.8351 Pre: 0.8543 Recall: 0.7932 F1: 0.8226 Train AUC: 0.9178 Val AUC: 0.9149 Time: 14.20\n",
      "Epoch: 38 Train Loss: 0.3640 Val Loss: 0.3570 Acc: 0.8370 Pre: 0.8577 Recall: 0.7932 F1: 0.8242 Train AUC: 0.9147 Val AUC: 0.9151 Time: 14.86\n",
      "Epoch: 39 Train Loss: 0.3696 Val Loss: 0.3560 Acc: 0.8351 Pre: 0.8601 Recall: 0.7857 F1: 0.8212 Train AUC: 0.9132 Val AUC: 0.9166 Time: 13.91\n",
      "Epoch: 40 Train Loss: 0.3588 Val Loss: 0.3528 Acc: 0.8351 Pre: 0.8601 Recall: 0.7857 F1: 0.8212 Train AUC: 0.9162 Val AUC: 0.9175 Time: 12.98\n",
      "Epoch: 41 Train Loss: 0.3429 Val Loss: 0.3490 Acc: 0.8315 Pre: 0.8560 Recall: 0.7820 F1: 0.8173 Train AUC: 0.9223 Val AUC: 0.9185 Time: 12.57\n",
      "Epoch: 42 Train Loss: 0.3524 Val Loss: 0.3458 Acc: 0.8333 Pre: 0.8537 Recall: 0.7895 F1: 0.8203 Train AUC: 0.9192 Val AUC: 0.9193 Time: 12.89\n",
      "Epoch: 43 Train Loss: 0.3444 Val Loss: 0.3451 Acc: 0.8406 Pre: 0.8589 Recall: 0.8008 F1: 0.8288 Train AUC: 0.9242 Val AUC: 0.9197 Time: 12.72\n",
      "Epoch: 44 Train Loss: 0.3447 Val Loss: 0.3467 Acc: 0.8424 Pre: 0.8538 Recall: 0.8120 F1: 0.8324 Train AUC: 0.9242 Val AUC: 0.9196 Time: 13.77\n",
      "Epoch: 45 Train Loss: 0.3457 Val Loss: 0.3498 Acc: 0.8424 Pre: 0.8429 Recall: 0.8271 F1: 0.8349 Train AUC: 0.9249 Val AUC: 0.9195 Time: 14.38\n",
      "Epoch: 46 Train Loss: 0.3468 Val Loss: 0.3494 Acc: 0.8424 Pre: 0.8429 Recall: 0.8271 F1: 0.8349 Train AUC: 0.9221 Val AUC: 0.9194 Time: 14.68\n",
      "Epoch: 47 Train Loss: 0.3456 Val Loss: 0.3453 Acc: 0.8406 Pre: 0.8450 Recall: 0.8195 F1: 0.8321 Train AUC: 0.9226 Val AUC: 0.9204 Time: 14.81\n",
      "Epoch: 48 Train Loss: 0.3475 Val Loss: 0.3415 Acc: 0.8406 Pre: 0.8504 Recall: 0.8120 F1: 0.8308 Train AUC: 0.9223 Val AUC: 0.9216 Time: 13.57\n",
      "Epoch: 49 Train Loss: 0.3666 Val Loss: 0.3427 Acc: 0.8424 Pre: 0.8538 Recall: 0.8120 F1: 0.8324 Train AUC: 0.9159 Val AUC: 0.9215 Time: 12.59\n",
      "Epoch: 50 Train Loss: 0.3404 Val Loss: 0.3430 Acc: 0.8388 Pre: 0.8554 Recall: 0.8008 F1: 0.8272 Train AUC: 0.9281 Val AUC: 0.9219 Time: 12.64\n",
      "Epoch: 51 Train Loss: 0.3354 Val Loss: 0.3415 Acc: 0.8388 Pre: 0.8583 Recall: 0.7970 F1: 0.8265 Train AUC: 0.9268 Val AUC: 0.9233 Time: 13.46\n",
      "Epoch: 52 Train Loss: 0.3418 Val Loss: 0.3407 Acc: 0.8388 Pre: 0.8583 Recall: 0.7970 F1: 0.8265 Train AUC: 0.9253 Val AUC: 0.9241 Time: 13.28\n",
      "Epoch: 53 Train Loss: 0.3465 Val Loss: 0.3406 Acc: 0.8424 Pre: 0.8566 Recall: 0.8083 F1: 0.8317 Train AUC: 0.9232 Val AUC: 0.9244 Time: 14.22\n",
      "Epoch: 54 Train Loss: 0.3364 Val Loss: 0.3407 Acc: 0.8442 Pre: 0.8543 Recall: 0.8158 F1: 0.8346 Train AUC: 0.9275 Val AUC: 0.9247 Time: 14.04\n",
      "Epoch: 55 Train Loss: 0.3406 Val Loss: 0.3369 Acc: 0.8460 Pre: 0.8549 Recall: 0.8195 F1: 0.8369 Train AUC: 0.9262 Val AUC: 0.9258 Time: 13.89\n",
      "Epoch: 56 Train Loss: 0.3378 Val Loss: 0.3326 Acc: 0.8460 Pre: 0.8577 Recall: 0.8158 F1: 0.8362 Train AUC: 0.9275 Val AUC: 0.9275 Time: 14.25\n",
      "Epoch: 57 Train Loss: 0.3294 Val Loss: 0.3269 Acc: 0.8496 Pre: 0.8704 Recall: 0.8083 F1: 0.8382 Train AUC: 0.9309 Val AUC: 0.9301 Time: 12.51\n",
      "Epoch: 58 Train Loss: 0.3279 Val Loss: 0.3236 Acc: 0.8496 Pre: 0.8765 Recall: 0.8008 F1: 0.8369 Train AUC: 0.9332 Val AUC: 0.9318 Time: 13.28\n",
      "Epoch: 59 Train Loss: 0.3363 Val Loss: 0.3217 Acc: 0.8496 Pre: 0.8765 Recall: 0.8008 F1: 0.8369 Train AUC: 0.9300 Val AUC: 0.9327 Time: 14.03\n",
      "Epoch: 60 Train Loss: 0.3337 Val Loss: 0.3216 Acc: 0.8496 Pre: 0.8735 Recall: 0.8045 F1: 0.8376 Train AUC: 0.9325 Val AUC: 0.9331 Time: 14.49\n",
      "Epoch: 61 Train Loss: 0.3206 Val Loss: 0.3229 Acc: 0.8478 Pre: 0.8699 Recall: 0.8045 F1: 0.8359 Train AUC: 0.9333 Val AUC: 0.9325 Time: 14.60\n",
      "Epoch: 62 Train Loss: 0.3332 Val Loss: 0.3263 Acc: 0.8478 Pre: 0.8611 Recall: 0.8158 F1: 0.8378 Train AUC: 0.9301 Val AUC: 0.9316 Time: 12.53\n",
      "Epoch: 63 Train Loss: 0.3212 Val Loss: 0.3282 Acc: 0.8478 Pre: 0.8583 Recall: 0.8195 F1: 0.8385 Train AUC: 0.9352 Val AUC: 0.9314 Time: 12.41\n",
      "Epoch: 64 Train Loss: 0.3300 Val Loss: 0.3255 Acc: 0.8460 Pre: 0.8606 Recall: 0.8120 F1: 0.8356 Train AUC: 0.9301 Val AUC: 0.9320 Time: 12.70\n",
      "Epoch: 65 Train Loss: 0.3272 Val Loss: 0.3214 Acc: 0.8496 Pre: 0.8704 Recall: 0.8083 F1: 0.8382 Train AUC: 0.9305 Val AUC: 0.9331 Time: 12.67\n",
      "Epoch: 66 Train Loss: 0.3129 Val Loss: 0.3180 Acc: 0.8514 Pre: 0.8770 Recall: 0.8045 F1: 0.8392 Train AUC: 0.9365 Val AUC: 0.9344 Time: 13.24\n",
      "Epoch: 67 Train Loss: 0.3193 Val Loss: 0.3148 Acc: 0.8514 Pre: 0.8866 Recall: 0.7932 F1: 0.8373 Train AUC: 0.9344 Val AUC: 0.9359 Time: 13.94\n",
      "Epoch: 68 Train Loss: 0.3144 Val Loss: 0.3129 Acc: 0.8551 Pre: 0.8908 Recall: 0.7970 F1: 0.8413 Train AUC: 0.9363 Val AUC: 0.9370 Time: 14.71\n",
      "Epoch: 69 Train Loss: 0.3255 Val Loss: 0.3124 Acc: 0.8551 Pre: 0.8908 Recall: 0.7970 F1: 0.8413 Train AUC: 0.9339 Val AUC: 0.9375 Time: 14.73\n",
      "Epoch: 70 Train Loss: 0.3281 Val Loss: 0.3135 Acc: 0.8587 Pre: 0.8917 Recall: 0.8045 F1: 0.8458 Train AUC: 0.9336 Val AUC: 0.9368 Time: 14.78\n",
      "Epoch: 71 Train Loss: 0.3267 Val Loss: 0.3224 Acc: 0.8533 Pre: 0.8571 Recall: 0.8346 F1: 0.8457 Train AUC: 0.9353 Val AUC: 0.9337 Time: 12.56\n",
      "Epoch: 72 Train Loss: 0.3078 Val Loss: 0.3308 Acc: 0.8460 Pre: 0.8415 Recall: 0.8383 F1: 0.8399 Train AUC: 0.9397 Val AUC: 0.9324 Time: 12.53\n",
      "Epoch: 73 Train Loss: 0.3294 Val Loss: 0.3280 Acc: 0.8514 Pre: 0.8538 Recall: 0.8346 F1: 0.8441 Train AUC: 0.9330 Val AUC: 0.9329 Time: 12.78\n",
      "Epoch: 74 Train Loss: 0.3223 Val Loss: 0.3210 Acc: 0.8424 Pre: 0.8623 Recall: 0.8008 F1: 0.8304 Train AUC: 0.9350 Val AUC: 0.9340 Time: 12.79\n",
      "Epoch: 75 Train Loss: 0.3071 Val Loss: 0.3196 Acc: 0.8424 Pre: 0.8683 Recall: 0.7932 F1: 0.8291 Train AUC: 0.9400 Val AUC: 0.9348 Time: 14.00\n",
      "Epoch: 76 Train Loss: 0.3248 Val Loss: 0.3174 Acc: 0.8460 Pre: 0.8755 Recall: 0.7932 F1: 0.8323 Train AUC: 0.9354 Val AUC: 0.9357 Time: 14.31\n",
      "Epoch: 77 Train Loss: 0.3234 Val Loss: 0.3136 Acc: 0.8478 Pre: 0.8760 Recall: 0.7970 F1: 0.8346 Train AUC: 0.9363 Val AUC: 0.9362 Time: 14.93\n",
      "Epoch: 78 Train Loss: 0.3156 Val Loss: 0.3142 Acc: 0.8551 Pre: 0.8750 Recall: 0.8158 F1: 0.8444 Train AUC: 0.9378 Val AUC: 0.9368 Time: 14.80\n",
      "Epoch: 79 Train Loss: 0.3173 Val Loss: 0.3196 Acc: 0.8587 Pre: 0.8643 Recall: 0.8383 F1: 0.8511 Train AUC: 0.9374 Val AUC: 0.9362 Time: 14.62\n",
      "Epoch: 80 Train Loss: 0.3104 Val Loss: 0.3205 Acc: 0.8605 Pre: 0.8621 Recall: 0.8459 F1: 0.8539 Train AUC: 0.9411 Val AUC: 0.9364 Time: 13.73\n",
      "Epoch: 81 Train Loss: 0.3124 Val Loss: 0.3139 Acc: 0.8605 Pre: 0.8765 Recall: 0.8271 F1: 0.8511 Train AUC: 0.9398 Val AUC: 0.9372 Time: 12.67\n",
      "Epoch: 82 Train Loss: 0.3255 Val Loss: 0.3097 Acc: 0.8514 Pre: 0.8770 Recall: 0.8045 F1: 0.8392 Train AUC: 0.9328 Val AUC: 0.9382 Time: 12.74\n",
      "Epoch: 83 Train Loss: 0.3013 Val Loss: 0.3086 Acc: 0.8478 Pre: 0.8760 Recall: 0.7970 F1: 0.8346 Train AUC: 0.9423 Val AUC: 0.9388 Time: 13.29\n",
      "Epoch: 84 Train Loss: 0.3108 Val Loss: 0.3078 Acc: 0.8478 Pre: 0.8760 Recall: 0.7970 F1: 0.8346 Train AUC: 0.9398 Val AUC: 0.9390 Time: 13.96\n",
      "Epoch: 85 Train Loss: 0.3099 Val Loss: 0.3083 Acc: 0.8569 Pre: 0.8785 Recall: 0.8158 F1: 0.8460 Train AUC: 0.9418 Val AUC: 0.9388 Time: 14.42\n",
      "Epoch: 86 Train Loss: 0.3041 Val Loss: 0.3144 Acc: 0.8587 Pre: 0.8643 Recall: 0.8383 F1: 0.8511 Train AUC: 0.9408 Val AUC: 0.9382 Time: 14.96\n",
      "Epoch: 87 Train Loss: 0.3184 Val Loss: 0.3204 Acc: 0.8605 Pre: 0.8593 Recall: 0.8496 F1: 0.8544 Train AUC: 0.9379 Val AUC: 0.9375 Time: 14.67\n",
      "Epoch: 88 Train Loss: 0.3091 Val Loss: 0.3116 Acc: 0.8605 Pre: 0.8706 Recall: 0.8346 F1: 0.8522 Train AUC: 0.9425 Val AUC: 0.9387 Time: 12.51\n",
      "Epoch: 89 Train Loss: 0.3148 Val Loss: 0.3065 Acc: 0.8551 Pre: 0.8811 Recall: 0.8083 F1: 0.8431 Train AUC: 0.9386 Val AUC: 0.9396 Time: 13.22\n",
      "Epoch: 90 Train Loss: 0.3068 Val Loss: 0.3079 Acc: 0.8496 Pre: 0.8765 Recall: 0.8008 F1: 0.8369 Train AUC: 0.9423 Val AUC: 0.9391 Time: 13.66\n",
      "Epoch: 91 Train Loss: 0.3088 Val Loss: 0.3092 Acc: 0.8496 Pre: 0.8735 Recall: 0.8045 F1: 0.8376 Train AUC: 0.9412 Val AUC: 0.9387 Time: 14.73\n",
      "Epoch: 92 Train Loss: 0.3094 Val Loss: 0.3108 Acc: 0.8551 Pre: 0.8750 Recall: 0.8158 F1: 0.8444 Train AUC: 0.9402 Val AUC: 0.9385 Time: 14.88\n",
      "Epoch: 93 Train Loss: 0.2972 Val Loss: 0.3104 Acc: 0.8659 Pre: 0.8840 Recall: 0.8308 F1: 0.8566 Train AUC: 0.9434 Val AUC: 0.9389 Time: 13.61\n",
      "Epoch: 94 Train Loss: 0.3091 Val Loss: 0.3100 Acc: 0.8678 Pre: 0.8814 Recall: 0.8383 F1: 0.8593 Train AUC: 0.9386 Val AUC: 0.9390 Time: 13.40\n",
      "Epoch: 95 Train Loss: 0.3026 Val Loss: 0.3038 Acc: 0.8678 Pre: 0.8939 Recall: 0.8233 F1: 0.8571 Train AUC: 0.9419 Val AUC: 0.9408 Time: 12.60\n",
      "Epoch: 96 Train Loss: 0.3093 Val Loss: 0.3016 Acc: 0.8641 Pre: 0.8930 Recall: 0.8158 F1: 0.8527 Train AUC: 0.9413 Val AUC: 0.9414 Time: 12.54\n",
      "Epoch: 97 Train Loss: 0.2957 Val Loss: 0.3003 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9446 Val AUC: 0.9419 Time: 12.48\n",
      "Epoch: 98 Train Loss: 0.3001 Val Loss: 0.3022 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9458 Val AUC: 0.9410 Time: 12.82\n",
      "Epoch: 99 Train Loss: 0.3017 Val Loss: 0.3055 Acc: 0.8659 Pre: 0.8902 Recall: 0.8233 F1: 0.8555 Train AUC: 0.9424 Val AUC: 0.9402 Time: 13.18\n",
      "Epoch: 100 Train Loss: 0.2932 Val Loss: 0.3063 Acc: 0.8714 Pre: 0.8884 Recall: 0.8383 F1: 0.8627 Train AUC: 0.9444 Val AUC: 0.9403 Time: 14.10\n",
      "Epoch: 101 Train Loss: 0.3127 Val Loss: 0.3064 Acc: 0.8696 Pre: 0.8880 Recall: 0.8346 F1: 0.8605 Train AUC: 0.9397 Val AUC: 0.9405 Time: 14.64\n",
      "Epoch: 102 Train Loss: 0.2966 Val Loss: 0.3011 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9451 Val AUC: 0.9419 Time: 15.30\n",
      "Epoch: 103 Train Loss: 0.2998 Val Loss: 0.2977 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9441 Val AUC: 0.9430 Time: 13.43\n",
      "Epoch: 104 Train Loss: 0.2989 Val Loss: 0.2963 Acc: 0.8605 Pre: 0.8954 Recall: 0.8045 F1: 0.8475 Train AUC: 0.9447 Val AUC: 0.9439 Time: 13.12\n",
      "Epoch: 105 Train Loss: 0.2893 Val Loss: 0.2962 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9492 Val AUC: 0.9442 Time: 12.50\n",
      "Epoch: 106 Train Loss: 0.2908 Val Loss: 0.2971 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9474 Val AUC: 0.9441 Time: 12.76\n",
      "Epoch: 107 Train Loss: 0.2948 Val Loss: 0.2984 Acc: 0.8659 Pre: 0.8967 Recall: 0.8158 F1: 0.8543 Train AUC: 0.9459 Val AUC: 0.9437 Time: 12.67\n",
      "Epoch: 108 Train Loss: 0.2913 Val Loss: 0.2972 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9461 Val AUC: 0.9438 Time: 13.32\n",
      "Epoch: 109 Train Loss: 0.2907 Val Loss: 0.2960 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9456 Val AUC: 0.9444 Time: 14.45\n",
      "Epoch: 110 Train Loss: 0.2924 Val Loss: 0.2953 Acc: 0.8659 Pre: 0.8934 Recall: 0.8195 F1: 0.8549 Train AUC: 0.9473 Val AUC: 0.9448 Time: 14.70\n",
      "Epoch: 111 Train Loss: 0.2851 Val Loss: 0.2937 Acc: 0.8659 Pre: 0.8967 Recall: 0.8158 F1: 0.8543 Train AUC: 0.9495 Val AUC: 0.9453 Time: 14.14\n",
      "Epoch: 112 Train Loss: 0.2814 Val Loss: 0.2925 Acc: 0.8678 Pre: 0.9004 Recall: 0.8158 F1: 0.8560 Train AUC: 0.9499 Val AUC: 0.9454 Time: 14.05\n",
      "Epoch: 113 Train Loss: 0.2868 Val Loss: 0.2931 Acc: 0.8678 Pre: 0.8971 Recall: 0.8195 F1: 0.8566 Train AUC: 0.9475 Val AUC: 0.9450 Time: 12.37\n",
      "Epoch: 114 Train Loss: 0.2827 Val Loss: 0.2940 Acc: 0.8678 Pre: 0.8939 Recall: 0.8233 F1: 0.8571 Train AUC: 0.9509 Val AUC: 0.9445 Time: 12.61\n",
      "Epoch: 115 Train Loss: 0.2858 Val Loss: 0.2919 Acc: 0.8659 Pre: 0.8934 Recall: 0.8195 F1: 0.8549 Train AUC: 0.9480 Val AUC: 0.9451 Time: 12.46\n",
      "Epoch: 116 Train Loss: 0.2824 Val Loss: 0.2903 Acc: 0.8696 Pre: 0.8975 Recall: 0.8233 F1: 0.8588 Train AUC: 0.9490 Val AUC: 0.9463 Time: 12.86\n",
      "Epoch: 117 Train Loss: 0.2828 Val Loss: 0.2890 Acc: 0.8714 Pre: 0.8980 Recall: 0.8271 F1: 0.8611 Train AUC: 0.9492 Val AUC: 0.9471 Time: 13.86\n",
      "Epoch: 118 Train Loss: 0.2837 Val Loss: 0.2863 Acc: 0.8678 Pre: 0.8971 Recall: 0.8195 F1: 0.8566 Train AUC: 0.9509 Val AUC: 0.9482 Time: 14.09\n",
      "Epoch: 119 Train Loss: 0.2895 Val Loss: 0.2853 Acc: 0.8678 Pre: 0.8971 Recall: 0.8195 F1: 0.8566 Train AUC: 0.9486 Val AUC: 0.9485 Time: 14.86\n",
      "Epoch: 120 Train Loss: 0.2793 Val Loss: 0.2845 Acc: 0.8659 Pre: 0.9000 Recall: 0.8120 F1: 0.8538 Train AUC: 0.9519 Val AUC: 0.9488 Time: 15.25\n",
      "Epoch: 121 Train Loss: 0.2781 Val Loss: 0.2839 Acc: 0.8678 Pre: 0.9004 Recall: 0.8158 F1: 0.8560 Train AUC: 0.9514 Val AUC: 0.9493 Time: 14.47\n",
      "Epoch: 122 Train Loss: 0.2853 Val Loss: 0.2849 Acc: 0.8732 Pre: 0.8984 Recall: 0.8308 F1: 0.8633 Train AUC: 0.9507 Val AUC: 0.9495 Time: 13.35\n",
      "Epoch: 123 Train Loss: 0.2794 Val Loss: 0.2821 Acc: 0.8732 Pre: 0.9016 Recall: 0.8271 F1: 0.8627 Train AUC: 0.9511 Val AUC: 0.9507 Time: 12.74\n",
      "Epoch: 124 Train Loss: 0.2817 Val Loss: 0.2804 Acc: 0.8732 Pre: 0.9050 Recall: 0.8233 F1: 0.8622 Train AUC: 0.9502 Val AUC: 0.9514 Time: 12.71\n",
      "Epoch: 125 Train Loss: 0.2896 Val Loss: 0.2795 Acc: 0.8696 Pre: 0.9042 Recall: 0.8158 F1: 0.8577 Train AUC: 0.9471 Val AUC: 0.9518 Time: 12.74\n",
      "Epoch: 126 Train Loss: 0.2708 Val Loss: 0.2798 Acc: 0.8659 Pre: 0.9034 Recall: 0.8083 F1: 0.8532 Train AUC: 0.9552 Val AUC: 0.9513 Time: 13.06\n",
      "Epoch: 127 Train Loss: 0.2844 Val Loss: 0.2835 Acc: 0.8678 Pre: 0.8939 Recall: 0.8233 F1: 0.8571 Train AUC: 0.9515 Val AUC: 0.9493 Time: 14.19\n",
      "Epoch: 128 Train Loss: 0.2664 Val Loss: 0.2909 Acc: 0.8678 Pre: 0.8845 Recall: 0.8346 F1: 0.8588 Train AUC: 0.9559 Val AUC: 0.9468 Time: 14.44\n",
      "Epoch: 129 Train Loss: 0.2656 Val Loss: 0.2955 Acc: 0.8750 Pre: 0.8833 Recall: 0.8534 F1: 0.8681 Train AUC: 0.9555 Val AUC: 0.9458 Time: 15.12\n",
      "Epoch: 130 Train Loss: 0.2720 Val Loss: 0.2884 Acc: 0.8659 Pre: 0.8902 Recall: 0.8233 F1: 0.8555 Train AUC: 0.9545 Val AUC: 0.9469 Time: 14.40\n",
      "Epoch: 131 Train Loss: 0.2701 Val Loss: 0.2859 Acc: 0.8696 Pre: 0.9042 Recall: 0.8158 F1: 0.8577 Train AUC: 0.9540 Val AUC: 0.9481 Time: 14.13\n",
      "Epoch: 132 Train Loss: 0.2726 Val Loss: 0.2832 Acc: 0.8678 Pre: 0.9072 Recall: 0.8083 F1: 0.8549 Train AUC: 0.9540 Val AUC: 0.9495 Time: 12.60\n",
      "Epoch: 133 Train Loss: 0.2814 Val Loss: 0.2837 Acc: 0.8678 Pre: 0.8876 Recall: 0.8308 F1: 0.8583 Train AUC: 0.9511 Val AUC: 0.9492 Time: 12.74\n",
      "Epoch: 134 Train Loss: 0.2734 Val Loss: 0.2891 Acc: 0.8786 Pre: 0.8842 Recall: 0.8609 F1: 0.8724 Train AUC: 0.9540 Val AUC: 0.9492 Time: 13.68\n",
      "Epoch: 135 Train Loss: 0.2787 Val Loss: 0.2817 Acc: 0.8732 Pre: 0.8920 Recall: 0.8383 F1: 0.8643 Train AUC: 0.9525 Val AUC: 0.9511 Time: 14.13\n",
      "Epoch: 136 Train Loss: 0.2699 Val Loss: 0.2776 Acc: 0.8659 Pre: 0.9068 Recall: 0.8045 F1: 0.8526 Train AUC: 0.9546 Val AUC: 0.9524 Time: 14.61\n",
      "Epoch: 137 Train Loss: 0.2691 Val Loss: 0.2765 Acc: 0.8678 Pre: 0.9072 Recall: 0.8083 F1: 0.8549 Train AUC: 0.9564 Val AUC: 0.9528 Time: 15.74\n",
      "Epoch: 138 Train Loss: 0.2697 Val Loss: 0.2793 Acc: 0.8804 Pre: 0.8968 Recall: 0.8496 F1: 0.8726 Train AUC: 0.9539 Val AUC: 0.9526 Time: 14.35\n",
      "Epoch: 139 Train Loss: 0.2686 Val Loss: 0.2809 Acc: 0.8786 Pre: 0.8872 Recall: 0.8571 F1: 0.8719 Train AUC: 0.9554 Val AUC: 0.9523 Time: 12.48\n",
      "Epoch: 140 Train Loss: 0.2712 Val Loss: 0.2806 Acc: 0.8696 Pre: 0.8880 Recall: 0.8346 F1: 0.8605 Train AUC: 0.9556 Val AUC: 0.9514 Time: 12.44\n",
      "Epoch: 141 Train Loss: 0.2656 Val Loss: 0.2810 Acc: 0.8641 Pre: 0.8898 Recall: 0.8195 F1: 0.8532 Train AUC: 0.9551 Val AUC: 0.9506 Time: 12.42\n",
      "Epoch: 142 Train Loss: 0.2624 Val Loss: 0.2813 Acc: 0.8641 Pre: 0.8996 Recall: 0.8083 F1: 0.8515 Train AUC: 0.9566 Val AUC: 0.9505 Time: 12.53\n",
      "Epoch: 143 Train Loss: 0.2702 Val Loss: 0.2815 Acc: 0.8659 Pre: 0.8902 Recall: 0.8233 F1: 0.8555 Train AUC: 0.9549 Val AUC: 0.9499 Time: 13.78\n",
      "Epoch: 144 Train Loss: 0.2559 Val Loss: 0.2883 Acc: 0.8750 Pre: 0.8863 Recall: 0.8496 F1: 0.8676 Train AUC: 0.9602 Val AUC: 0.9484 Time: 14.12\n",
      "Epoch: 145 Train Loss: 0.2671 Val Loss: 0.2860 Acc: 0.8822 Pre: 0.8880 Recall: 0.8647 F1: 0.8762 Train AUC: 0.9563 Val AUC: 0.9501 Time: 13.73\n",
      "Epoch: 146 Train Loss: 0.2747 Val Loss: 0.2731 Acc: 0.8678 Pre: 0.9038 Recall: 0.8120 F1: 0.8554 Train AUC: 0.9541 Val AUC: 0.9539 Time: 14.35\n",
      "Epoch: 147 Train Loss: 0.2722 Val Loss: 0.2730 Acc: 0.8605 Pre: 0.9056 Recall: 0.7932 F1: 0.8457 Train AUC: 0.9551 Val AUC: 0.9548 Time: 14.71\n",
      "Epoch: 148 Train Loss: 0.2791 Val Loss: 0.2748 Acc: 0.8678 Pre: 0.9004 Recall: 0.8158 F1: 0.8560 Train AUC: 0.9519 Val AUC: 0.9542 Time: 12.56\n",
      "Epoch: 149 Train Loss: 0.2706 Val Loss: 0.2781 Acc: 0.8804 Pre: 0.8937 Recall: 0.8534 F1: 0.8731 Train AUC: 0.9549 Val AUC: 0.9538 Time: 12.70\n",
      "Epoch: 150 Train Loss: 0.2727 Val Loss: 0.2769 Acc: 0.8768 Pre: 0.8867 Recall: 0.8534 F1: 0.8697 Train AUC: 0.9539 Val AUC: 0.9542 Time: 12.79\n",
      "Epoch: 151 Train Loss: 0.2562 Val Loss: 0.2718 Acc: 0.8696 Pre: 0.8975 Recall: 0.8233 F1: 0.8588 Train AUC: 0.9592 Val AUC: 0.9542 Time: 13.90\n",
      "Epoch: 152 Train Loss: 0.2688 Val Loss: 0.2743 Acc: 0.8659 Pre: 0.8967 Recall: 0.8158 F1: 0.8543 Train AUC: 0.9547 Val AUC: 0.9519 Time: 14.37\n",
      "Epoch: 153 Train Loss: 0.2686 Val Loss: 0.2804 Acc: 0.8714 Pre: 0.8884 Recall: 0.8383 F1: 0.8627 Train AUC: 0.9558 Val AUC: 0.9489 Time: 13.99\n",
      "Epoch: 154 Train Loss: 0.2605 Val Loss: 0.2873 Acc: 0.8750 Pre: 0.8774 Recall: 0.8609 F1: 0.8691 Train AUC: 0.9579 Val AUC: 0.9477 Time: 14.34\n",
      "Epoch: 155 Train Loss: 0.2615 Val Loss: 0.2793 Acc: 0.8714 Pre: 0.8824 Recall: 0.8459 F1: 0.8637 Train AUC: 0.9585 Val AUC: 0.9502 Time: 14.25\n",
      "Epoch: 156 Train Loss: 0.2664 Val Loss: 0.2732 Acc: 0.8659 Pre: 0.9000 Recall: 0.8120 F1: 0.8538 Train AUC: 0.9571 Val AUC: 0.9537 Time: 12.49\n",
      "Epoch: 157 Train Loss: 0.2481 Val Loss: 0.2745 Acc: 0.8605 Pre: 0.9056 Recall: 0.7932 F1: 0.8457 Train AUC: 0.9625 Val AUC: 0.9547 Time: 12.39\n",
      "Epoch: 158 Train Loss: 0.2695 Val Loss: 0.2763 Acc: 0.8750 Pre: 0.8988 Recall: 0.8346 F1: 0.8655 Train AUC: 0.9573 Val AUC: 0.9539 Time: 12.66\n",
      "Epoch: 159 Train Loss: 0.2569 Val Loss: 0.2849 Acc: 0.8786 Pre: 0.8755 Recall: 0.8722 F1: 0.8738 Train AUC: 0.9586 Val AUC: 0.9533 Time: 12.91\n",
      "Epoch: 160 Train Loss: 0.2668 Val Loss: 0.2776 Acc: 0.8768 Pre: 0.8779 Recall: 0.8647 F1: 0.8712 Train AUC: 0.9568 Val AUC: 0.9541 Time: 13.70\n",
      "Epoch: 161 Train Loss: 0.2573 Val Loss: 0.2705 Acc: 0.8696 Pre: 0.9008 Recall: 0.8195 F1: 0.8583 Train AUC: 0.9594 Val AUC: 0.9549 Time: 14.88\n",
      "Epoch: 162 Train Loss: 0.2594 Val Loss: 0.2709 Acc: 0.8641 Pre: 0.8963 Recall: 0.8120 F1: 0.8521 Train AUC: 0.9576 Val AUC: 0.9541 Time: 14.66\n",
      "Epoch: 163 Train Loss: 0.2521 Val Loss: 0.2737 Acc: 0.8659 Pre: 0.8871 Recall: 0.8271 F1: 0.8560 Train AUC: 0.9624 Val AUC: 0.9521 Time: 14.13\n",
      "Epoch: 164 Train Loss: 0.2604 Val Loss: 0.2754 Acc: 0.8732 Pre: 0.8828 Recall: 0.8496 F1: 0.8659 Train AUC: 0.9587 Val AUC: 0.9515 Time: 12.53\n",
      "Epoch: 165 Train Loss: 0.2551 Val Loss: 0.2760 Acc: 0.8732 Pre: 0.8798 Recall: 0.8534 F1: 0.8664 Train AUC: 0.9605 Val AUC: 0.9520 Time: 12.42\n",
      "Epoch: 166 Train Loss: 0.2588 Val Loss: 0.2702 Acc: 0.8678 Pre: 0.8814 Recall: 0.8383 F1: 0.8593 Train AUC: 0.9602 Val AUC: 0.9545 Time: 12.61\n",
      "Epoch: 167 Train Loss: 0.2536 Val Loss: 0.2685 Acc: 0.8696 Pre: 0.8911 Recall: 0.8308 F1: 0.8599 Train AUC: 0.9626 Val AUC: 0.9557 Time: 13.25\n",
      "Epoch: 168 Train Loss: 0.2545 Val Loss: 0.2692 Acc: 0.8714 Pre: 0.8884 Recall: 0.8383 F1: 0.8627 Train AUC: 0.9603 Val AUC: 0.9561 Time: 13.93\n",
      "Epoch: 169 Train Loss: 0.2478 Val Loss: 0.2706 Acc: 0.8750 Pre: 0.8863 Recall: 0.8496 F1: 0.8676 Train AUC: 0.9621 Val AUC: 0.9558 Time: 14.40\n",
      "Epoch: 170 Train Loss: 0.2524 Val Loss: 0.2746 Acc: 0.8750 Pre: 0.8774 Recall: 0.8609 F1: 0.8691 Train AUC: 0.9607 Val AUC: 0.9555 Time: 15.04\n",
      "Epoch: 171 Train Loss: 0.2557 Val Loss: 0.2759 Acc: 0.8786 Pre: 0.8842 Recall: 0.8609 F1: 0.8724 Train AUC: 0.9603 Val AUC: 0.9547 Time: 14.96\n",
      "Epoch: 172 Train Loss: 0.2460 Val Loss: 0.2726 Acc: 0.8750 Pre: 0.8863 Recall: 0.8496 F1: 0.8676 Train AUC: 0.9633 Val AUC: 0.9536 Time: 13.01\n",
      "Epoch: 173 Train Loss: 0.2472 Val Loss: 0.2723 Acc: 0.8641 Pre: 0.8866 Recall: 0.8233 F1: 0.8538 Train AUC: 0.9627 Val AUC: 0.9534 Time: 12.88\n",
      "Epoch: 174 Train Loss: 0.2542 Val Loss: 0.2708 Acc: 0.8659 Pre: 0.8840 Recall: 0.8308 F1: 0.8566 Train AUC: 0.9612 Val AUC: 0.9534 Time: 12.68\n",
      "Epoch: 175 Train Loss: 0.2458 Val Loss: 0.2680 Acc: 0.8696 Pre: 0.8760 Recall: 0.8496 F1: 0.8626 Train AUC: 0.9632 Val AUC: 0.9543 Time: 13.34\n",
      "Epoch: 176 Train Loss: 0.2548 Val Loss: 0.2670 Acc: 0.8696 Pre: 0.8760 Recall: 0.8496 F1: 0.8626 Train AUC: 0.9616 Val AUC: 0.9563 Time: 13.99\n",
      "Epoch: 177 Train Loss: 0.2534 Val Loss: 0.2641 Acc: 0.8750 Pre: 0.8774 Recall: 0.8609 F1: 0.8691 Train AUC: 0.9622 Val AUC: 0.9576 Time: 14.33\n",
      "Epoch: 178 Train Loss: 0.2384 Val Loss: 0.2637 Acc: 0.8714 Pre: 0.8980 Recall: 0.8271 F1: 0.8611 Train AUC: 0.9657 Val AUC: 0.9575 Time: 14.88\n",
      "Epoch: 179 Train Loss: 0.2447 Val Loss: 0.2670 Acc: 0.8714 Pre: 0.9046 Recall: 0.8195 F1: 0.8600 Train AUC: 0.9635 Val AUC: 0.9569 Time: 13.27\n",
      "Epoch: 180 Train Loss: 0.2578 Val Loss: 0.2690 Acc: 0.8768 Pre: 0.8837 Recall: 0.8571 F1: 0.8702 Train AUC: 0.9594 Val AUC: 0.9570 Time: 12.55\n",
      "Epoch: 181 Train Loss: 0.2453 Val Loss: 0.2744 Acc: 0.8768 Pre: 0.8722 Recall: 0.8722 F1: 0.8722 Train AUC: 0.9633 Val AUC: 0.9562 Time: 12.48\n",
      "Epoch: 182 Train Loss: 0.2537 Val Loss: 0.2689 Acc: 0.8768 Pre: 0.8837 Recall: 0.8571 F1: 0.8702 Train AUC: 0.9619 Val AUC: 0.9557 Time: 12.54\n",
      "Epoch: 183 Train Loss: 0.2458 Val Loss: 0.2659 Acc: 0.8696 Pre: 0.8911 Recall: 0.8308 F1: 0.8599 Train AUC: 0.9643 Val AUC: 0.9556 Time: 12.71\n",
      "Epoch: 184 Train Loss: 0.2447 Val Loss: 0.2666 Acc: 0.8659 Pre: 0.8967 Recall: 0.8158 F1: 0.8543 Train AUC: 0.9637 Val AUC: 0.9558 Time: 12.48\n",
      "Epoch: 185 Train Loss: 0.2547 Val Loss: 0.2689 Acc: 0.8714 Pre: 0.8764 Recall: 0.8534 F1: 0.8648 Train AUC: 0.9643 Val AUC: 0.9553 Time: 12.87\n",
      "Epoch: 186 Train Loss: 0.2401 Val Loss: 0.2836 Acc: 0.8714 Pre: 0.8571 Recall: 0.8797 F1: 0.8683 Train AUC: 0.9656 Val AUC: 0.9540 Time: 14.30\n",
      "Epoch: 187 Train Loss: 0.2534 Val Loss: 0.2685 Acc: 0.8750 Pre: 0.8833 Recall: 0.8534 F1: 0.8681 Train AUC: 0.9635 Val AUC: 0.9569 Time: 14.46\n",
      "Epoch: 188 Train Loss: 0.2381 Val Loss: 0.2684 Acc: 0.8587 Pre: 0.9017 Recall: 0.7932 F1: 0.8440 Train AUC: 0.9659 Val AUC: 0.9576 Time: 15.08\n",
      "Epoch: 189 Train Loss: 0.2476 Val Loss: 0.2649 Acc: 0.8714 Pre: 0.8980 Recall: 0.8271 F1: 0.8611 Train AUC: 0.9636 Val AUC: 0.9581 Time: 15.09\n",
      "Epoch: 190 Train Loss: 0.2490 Val Loss: 0.2707 Acc: 0.8786 Pre: 0.8783 Recall: 0.8684 F1: 0.8733 Train AUC: 0.9621 Val AUC: 0.9566 Time: 13.08\n",
      "Epoch: 191 Train Loss: 0.2469 Val Loss: 0.2807 Acc: 0.8732 Pre: 0.8630 Recall: 0.8759 F1: 0.8694 Train AUC: 0.9625 Val AUC: 0.9535 Time: 12.55\n",
      "Epoch: 192 Train Loss: 0.2454 Val Loss: 0.2724 Acc: 0.8750 Pre: 0.8745 Recall: 0.8647 F1: 0.8696 Train AUC: 0.9637 Val AUC: 0.9540 Time: 12.41\n",
      "Epoch: 193 Train Loss: 0.2440 Val Loss: 0.2639 Acc: 0.8714 Pre: 0.9046 Recall: 0.8195 F1: 0.8600 Train AUC: 0.9655 Val AUC: 0.9575 Time: 12.74\n",
      "Epoch: 194 Train Loss: 0.2452 Val Loss: 0.2615 Acc: 0.8750 Pre: 0.9053 Recall: 0.8271 F1: 0.8644 Train AUC: 0.9654 Val AUC: 0.9579 Time: 12.69\n",
      "Epoch: 195 Train Loss: 0.2359 Val Loss: 0.2641 Acc: 0.8750 Pre: 0.8803 Recall: 0.8571 F1: 0.8686 Train AUC: 0.9675 Val AUC: 0.9567 Time: 13.89\n",
      "Epoch: 196 Train Loss: 0.2421 Val Loss: 0.2757 Acc: 0.8822 Pre: 0.8736 Recall: 0.8835 F1: 0.8785 Train AUC: 0.9657 Val AUC: 0.9550 Time: 14.00\n",
      "Epoch: 197 Train Loss: 0.2390 Val Loss: 0.2685 Acc: 0.8768 Pre: 0.8779 Recall: 0.8647 F1: 0.8712 Train AUC: 0.9662 Val AUC: 0.9567 Time: 14.74\n",
      "Epoch: 198 Train Loss: 0.2347 Val Loss: 0.2610 Acc: 0.8768 Pre: 0.8898 Recall: 0.8496 F1: 0.8692 Train AUC: 0.9678 Val AUC: 0.9581 Time: 14.92\n",
      "Epoch: 199 Train Loss: 0.2331 Val Loss: 0.2582 Acc: 0.8750 Pre: 0.8988 Recall: 0.8346 F1: 0.8655 Train AUC: 0.9670 Val AUC: 0.9589 Time: 14.72\n",
      "Epoch: 200 Train Loss: 0.2356 Val Loss: 0.2578 Acc: 0.8750 Pre: 0.8988 Recall: 0.8346 F1: 0.8655 Train AUC: 0.9662 Val AUC: 0.9591 Time: 13.03\n",
      "Epoch: 201 Train Loss: 0.2242 Val Loss: 0.2624 Acc: 0.8750 Pre: 0.8803 Recall: 0.8571 F1: 0.8686 Train AUC: 0.9703 Val AUC: 0.9580 Time: 13.60\n",
      "Epoch: 202 Train Loss: 0.2414 Val Loss: 0.2634 Acc: 0.8696 Pre: 0.8702 Recall: 0.8571 F1: 0.8636 Train AUC: 0.9652 Val AUC: 0.9578 Time: 13.95\n",
      "Epoch: 203 Train Loss: 0.2335 Val Loss: 0.2623 Acc: 0.8714 Pre: 0.8794 Recall: 0.8496 F1: 0.8642 Train AUC: 0.9680 Val AUC: 0.9578 Time: 14.06\n",
      "Epoch: 204 Train Loss: 0.2309 Val Loss: 0.2577 Acc: 0.8696 Pre: 0.8975 Recall: 0.8233 F1: 0.8588 Train AUC: 0.9674 Val AUC: 0.9596 Time: 14.24\n",
      "Epoch: 205 Train Loss: 0.2373 Val Loss: 0.2583 Acc: 0.8732 Pre: 0.9050 Recall: 0.8233 F1: 0.8622 Train AUC: 0.9662 Val AUC: 0.9595 Time: 13.13\n",
      "Epoch: 206 Train Loss: 0.2330 Val Loss: 0.2581 Acc: 0.8768 Pre: 0.8898 Recall: 0.8496 F1: 0.8692 Train AUC: 0.9678 Val AUC: 0.9589 Time: 12.90\n",
      "Epoch: 207 Train Loss: 0.2288 Val Loss: 0.2672 Acc: 0.8768 Pre: 0.8750 Recall: 0.8684 F1: 0.8717 Train AUC: 0.9697 Val AUC: 0.9576 Time: 13.29\n",
      "Epoch: 208 Train Loss: 0.2397 Val Loss: 0.2613 Acc: 0.8786 Pre: 0.8812 Recall: 0.8647 F1: 0.8729 Train AUC: 0.9659 Val AUC: 0.9581 Time: 14.10\n",
      "Epoch: 209 Train Loss: 0.2302 Val Loss: 0.2603 Acc: 0.8786 Pre: 0.8933 Recall: 0.8496 F1: 0.8709 Train AUC: 0.9684 Val AUC: 0.9582 Time: 14.82\n",
      "Epoch: 210 Train Loss: 0.2269 Val Loss: 0.2604 Acc: 0.8786 Pre: 0.8933 Recall: 0.8496 F1: 0.8709 Train AUC: 0.9686 Val AUC: 0.9584 Time: 14.28\n",
      "Epoch: 211 Train Loss: 0.2338 Val Loss: 0.2648 Acc: 0.8768 Pre: 0.8779 Recall: 0.8647 F1: 0.8712 Train AUC: 0.9672 Val AUC: 0.9573 Time: 14.53\n",
      "Epoch: 212 Train Loss: 0.2367 Val Loss: 0.2619 Acc: 0.8732 Pre: 0.8712 Recall: 0.8647 F1: 0.8679 Train AUC: 0.9660 Val AUC: 0.9580 Time: 12.78\n",
      "Epoch: 213 Train Loss: 0.2386 Val Loss: 0.2565 Acc: 0.8696 Pre: 0.8760 Recall: 0.8496 F1: 0.8626 Train AUC: 0.9663 Val AUC: 0.9591 Time: 12.70\n",
      "Epoch: 214 Train Loss: 0.2280 Val Loss: 0.2575 Acc: 0.8750 Pre: 0.8924 Recall: 0.8421 F1: 0.8665 Train AUC: 0.9694 Val AUC: 0.9591 Time: 12.68\n",
      "Epoch: 215 Train Loss: 0.2222 Val Loss: 0.2615 Acc: 0.8732 Pre: 0.8798 Recall: 0.8534 F1: 0.8664 Train AUC: 0.9703 Val AUC: 0.9582 Time: 14.05\n",
      "Epoch: 216 Train Loss: 0.2252 Val Loss: 0.2671 Acc: 0.8750 Pre: 0.8745 Recall: 0.8647 F1: 0.8696 Train AUC: 0.9696 Val AUC: 0.9572 Time: 14.37\n",
      "Epoch: 217 Train Loss: 0.2176 Val Loss: 0.2632 Acc: 0.8768 Pre: 0.8779 Recall: 0.8647 F1: 0.8712 Train AUC: 0.9719 Val AUC: 0.9579 Time: 14.79\n",
      "Epoch: 218 Train Loss: 0.2271 Val Loss: 0.2591 Acc: 0.8750 Pre: 0.8833 Recall: 0.8534 F1: 0.8681 Train AUC: 0.9693 Val AUC: 0.9590 Time: 14.43\n",
      "Epoch: 219 Train Loss: 0.2249 Val Loss: 0.2565 Acc: 0.8714 Pre: 0.8854 Recall: 0.8421 F1: 0.8632 Train AUC: 0.9692 Val AUC: 0.9598 Time: 14.55\n",
      "Epoch: 220 Train Loss: 0.2263 Val Loss: 0.2567 Acc: 0.8714 Pre: 0.8794 Recall: 0.8496 F1: 0.8642 Train AUC: 0.9690 Val AUC: 0.9596 Time: 12.68\n",
      "Epoch: 221 Train Loss: 0.2185 Val Loss: 0.2616 Acc: 0.8696 Pre: 0.8702 Recall: 0.8571 F1: 0.8636 Train AUC: 0.9715 Val AUC: 0.9580 Time: 12.64\n",
      "Epoch: 222 Train Loss: 0.2293 Val Loss: 0.2604 Acc: 0.8750 Pre: 0.8863 Recall: 0.8496 F1: 0.8676 Train AUC: 0.9697 Val AUC: 0.9579 Time: 12.65\n",
      "Epoch: 223 Train Loss: 0.2339 Val Loss: 0.2622 Acc: 0.8786 Pre: 0.8872 Recall: 0.8571 F1: 0.8719 Train AUC: 0.9668 Val AUC: 0.9578 Time: 12.52\n",
      "Epoch: 224 Train Loss: 0.2224 Val Loss: 0.2610 Acc: 0.8804 Pre: 0.8906 Recall: 0.8571 F1: 0.8736 Train AUC: 0.9700 Val AUC: 0.9583 Time: 12.64\n",
      "Epoch: 225 Train Loss: 0.2226 Val Loss: 0.2560 Acc: 0.8768 Pre: 0.8898 Recall: 0.8496 F1: 0.8692 Train AUC: 0.9697 Val AUC: 0.9594 Time: 13.41\n",
      "Epoch: 226 Train Loss: 0.2146 Val Loss: 0.2508 Acc: 0.8786 Pre: 0.8933 Recall: 0.8496 F1: 0.8709 Train AUC: 0.9722 Val AUC: 0.9606 Time: 14.20\n",
      "Epoch: 227 Train Loss: 0.2203 Val Loss: 0.2510 Acc: 0.8804 Pre: 0.8817 Recall: 0.8684 F1: 0.8750 Train AUC: 0.9711 Val AUC: 0.9610 Time: 14.90\n",
      "Epoch: 228 Train Loss: 0.2266 Val Loss: 0.2515 Acc: 0.8714 Pre: 0.8794 Recall: 0.8496 F1: 0.8642 Train AUC: 0.9696 Val AUC: 0.9599 Time: 15.27\n",
      "Epoch: 229 Train Loss: 0.2161 Val Loss: 0.2547 Acc: 0.8678 Pre: 0.8784 Recall: 0.8421 F1: 0.8599 Train AUC: 0.9725 Val AUC: 0.9588 Time: 15.16\n",
      "Epoch: 230 Train Loss: 0.2240 Val Loss: 0.2569 Acc: 0.8678 Pre: 0.8784 Recall: 0.8421 F1: 0.8599 Train AUC: 0.9702 Val AUC: 0.9584 Time: 13.58\n",
      "Epoch: 231 Train Loss: 0.2201 Val Loss: 0.2614 Acc: 0.8822 Pre: 0.8764 Recall: 0.8797 F1: 0.8780 Train AUC: 0.9716 Val AUC: 0.9579 Time: 12.46\n",
      "Epoch: 232 Train Loss: 0.2247 Val Loss: 0.2618 Acc: 0.8859 Pre: 0.8830 Recall: 0.8797 F1: 0.8814 Train AUC: 0.9685 Val AUC: 0.9582 Time: 12.47\n",
      "Epoch: 233 Train Loss: 0.2119 Val Loss: 0.2604 Acc: 0.8841 Pre: 0.8826 Recall: 0.8759 F1: 0.8792 Train AUC: 0.9726 Val AUC: 0.9586 Time: 12.72\n",
      "Epoch: 234 Train Loss: 0.2255 Val Loss: 0.2553 Acc: 0.8786 Pre: 0.8902 Recall: 0.8534 F1: 0.8714 Train AUC: 0.9695 Val AUC: 0.9592 Time: 12.55\n",
      "Epoch: 235 Train Loss: 0.2263 Val Loss: 0.2511 Acc: 0.8768 Pre: 0.8867 Recall: 0.8534 F1: 0.8697 Train AUC: 0.9705 Val AUC: 0.9603 Time: 12.94\n",
      "Epoch: 236 Train Loss: 0.2177 Val Loss: 0.2557 Acc: 0.8859 Pre: 0.8745 Recall: 0.8910 F1: 0.8827 Train AUC: 0.9715 Val AUC: 0.9598 Time: 13.73\n",
      "Epoch: 237 Train Loss: 0.2163 Val Loss: 0.2646 Acc: 0.8859 Pre: 0.8718 Recall: 0.8947 F1: 0.8831 Train AUC: 0.9733 Val AUC: 0.9578 Time: 13.77\n",
      "Epoch: 238 Train Loss: 0.2167 Val Loss: 0.2624 Acc: 0.8696 Pre: 0.8849 Recall: 0.8383 F1: 0.8610 Train AUC: 0.9730 Val AUC: 0.9571 Time: 14.86\n",
      "Epoch: 239 Train Loss: 0.2183 Val Loss: 0.2630 Acc: 0.8696 Pre: 0.8819 Recall: 0.8421 F1: 0.8615 Train AUC: 0.9734 Val AUC: 0.9571 Time: 15.11\n",
      "Epoch: 240 Train Loss: 0.2158 Val Loss: 0.2708 Acc: 0.8877 Pre: 0.8696 Recall: 0.9023 F1: 0.8856 Train AUC: 0.9729 Val AUC: 0.9574 Time: 14.99\n",
      "Epoch: 241 Train Loss: 0.2192 Val Loss: 0.2571 Acc: 0.8877 Pre: 0.8750 Recall: 0.8947 F1: 0.8848 Train AUC: 0.9730 Val AUC: 0.9602 Time: 12.57\n",
      "Epoch: 242 Train Loss: 0.2138 Val Loss: 0.2476 Acc: 0.8641 Pre: 0.8930 Recall: 0.8158 F1: 0.8527 Train AUC: 0.9739 Val AUC: 0.9616 Time: 12.54\n",
      "Epoch: 243 Train Loss: 0.2189 Val Loss: 0.2500 Acc: 0.8623 Pre: 0.8926 Recall: 0.8120 F1: 0.8504 Train AUC: 0.9716 Val AUC: 0.9614 Time: 12.46\n",
      "Epoch: 244 Train Loss: 0.2149 Val Loss: 0.2535 Acc: 0.8768 Pre: 0.8750 Recall: 0.8684 F1: 0.8717 Train AUC: 0.9735 Val AUC: 0.9598 Time: 12.58\n",
      "Epoch: 245 Train Loss: 0.2129 Val Loss: 0.2711 Acc: 0.8804 Pre: 0.8597 Recall: 0.8985 F1: 0.8787 Train AUC: 0.9729 Val AUC: 0.9569 Time: 13.06\n",
      "Epoch: 246 Train Loss: 0.2122 Val Loss: 0.2655 Acc: 0.8859 Pre: 0.8773 Recall: 0.8872 F1: 0.8822 Train AUC: 0.9742 Val AUC: 0.9575 Time: 13.77\n",
      "Epoch: 247 Train Loss: 0.2189 Val Loss: 0.2584 Acc: 0.8786 Pre: 0.8842 Recall: 0.8609 F1: 0.8724 Train AUC: 0.9707 Val AUC: 0.9590 Time: 13.99\n",
      "Epoch: 248 Train Loss: 0.2042 Val Loss: 0.2524 Acc: 0.8804 Pre: 0.8846 Recall: 0.8647 F1: 0.8745 Train AUC: 0.9750 Val AUC: 0.9607 Time: 14.70\n",
      "Epoch: 249 Train Loss: 0.2107 Val Loss: 0.2603 Acc: 0.8913 Pre: 0.8705 Recall: 0.9098 F1: 0.8897 Train AUC: 0.9740 Val AUC: 0.9614 Time: 14.57\n",
      "Epoch: 250 Train Loss: 0.2178 Val Loss: 0.2502 Acc: 0.8877 Pre: 0.8750 Recall: 0.8947 F1: 0.8848 Train AUC: 0.9723 Val AUC: 0.9619 Time: 12.62\n",
      "Epoch: 251 Train Loss: 0.2123 Val Loss: 0.2523 Acc: 0.8659 Pre: 0.9000 Recall: 0.8120 F1: 0.8538 Train AUC: 0.9734 Val AUC: 0.9616 Time: 13.01\n",
      "Epoch: 252 Train Loss: 0.2232 Val Loss: 0.2520 Acc: 0.8678 Pre: 0.8784 Recall: 0.8421 F1: 0.8599 Train AUC: 0.9723 Val AUC: 0.9598 Time: 12.61\n",
      "Epoch: 253 Train Loss: 0.2176 Val Loss: 0.2585 Acc: 0.8786 Pre: 0.8672 Recall: 0.8835 F1: 0.8752 Train AUC: 0.9727 Val AUC: 0.9594 Time: 13.26\n",
      "Epoch: 254 Train Loss: 0.2188 Val Loss: 0.2530 Acc: 0.8877 Pre: 0.8750 Recall: 0.8947 F1: 0.8848 Train AUC: 0.9719 Val AUC: 0.9612 Time: 13.95\n",
      "Epoch: 255 Train Loss: 0.2056 Val Loss: 0.2467 Acc: 0.8804 Pre: 0.8968 Recall: 0.8496 F1: 0.8726 Train AUC: 0.9754 Val AUC: 0.9627 Time: 14.26\n",
      "Epoch: 256 Train Loss: 0.2090 Val Loss: 0.2497 Acc: 0.8804 Pre: 0.8968 Recall: 0.8496 F1: 0.8726 Train AUC: 0.9732 Val AUC: 0.9622 Time: 14.11\n",
      "Epoch: 257 Train Loss: 0.2147 Val Loss: 0.2574 Acc: 0.8913 Pre: 0.8787 Recall: 0.8985 F1: 0.8885 Train AUC: 0.9724 Val AUC: 0.9610 Time: 14.18\n",
      "Epoch: 258 Train Loss: 0.2115 Val Loss: 0.2546 Acc: 0.8895 Pre: 0.8782 Recall: 0.8947 F1: 0.8864 Train AUC: 0.9741 Val AUC: 0.9598 Time: 12.47\n",
      "Epoch: 259 Train Loss: 0.2137 Val Loss: 0.2497 Acc: 0.8732 Pre: 0.8889 Recall: 0.8421 F1: 0.8649 Train AUC: 0.9730 Val AUC: 0.9601 Time: 12.97\n",
      "Epoch: 260 Train Loss: 0.2092 Val Loss: 0.2506 Acc: 0.8750 Pre: 0.8924 Recall: 0.8421 F1: 0.8665 Train AUC: 0.9747 Val AUC: 0.9603 Time: 13.39\n",
      "Epoch: 261 Train Loss: 0.2107 Val Loss: 0.2588 Acc: 0.8877 Pre: 0.8835 Recall: 0.8835 F1: 0.8835 Train AUC: 0.9741 Val AUC: 0.9593 Time: 13.81\n",
      "Epoch: 262 Train Loss: 0.2059 Val Loss: 0.2648 Acc: 0.8913 Pre: 0.8759 Recall: 0.9023 F1: 0.8889 Train AUC: 0.9752 Val AUC: 0.9594 Time: 14.41\n",
      "Epoch: 263 Train Loss: 0.2101 Val Loss: 0.2568 Acc: 0.8859 Pre: 0.8859 Recall: 0.8759 F1: 0.8809 Train AUC: 0.9751 Val AUC: 0.9607 Time: 14.36\n",
      "Epoch: 264 Train Loss: 0.2122 Val Loss: 0.2559 Acc: 0.8750 Pre: 0.9020 Recall: 0.8308 F1: 0.8650 Train AUC: 0.9730 Val AUC: 0.9618 Time: 14.00\n",
      "Epoch: 265 Train Loss: 0.2110 Val Loss: 0.2504 Acc: 0.8841 Pre: 0.8885 Recall: 0.8684 F1: 0.8783 Train AUC: 0.9749 Val AUC: 0.9619 Time: 12.40\n",
      "Epoch: 266 Train Loss: 0.2067 Val Loss: 0.2718 Acc: 0.8750 Pre: 0.8385 Recall: 0.9173 F1: 0.8761 Train AUC: 0.9741 Val AUC: 0.9593 Time: 13.17\n",
      "Epoch: 267 Train Loss: 0.2157 Val Loss: 0.2596 Acc: 0.8841 Pre: 0.8633 Recall: 0.9023 F1: 0.8824 Train AUC: 0.9763 Val AUC: 0.9598 Time: 13.17\n",
      "Epoch: 268 Train Loss: 0.2060 Val Loss: 0.2517 Acc: 0.8714 Pre: 0.8854 Recall: 0.8421 F1: 0.8632 Train AUC: 0.9762 Val AUC: 0.9604 Time: 14.45\n",
      "Epoch: 269 Train Loss: 0.2082 Val Loss: 0.2542 Acc: 0.8768 Pre: 0.8929 Recall: 0.8459 F1: 0.8687 Train AUC: 0.9760 Val AUC: 0.9606 Time: 13.97\n",
      "Epoch: 270 Train Loss: 0.2055 Val Loss: 0.2520 Acc: 0.8877 Pre: 0.8893 Recall: 0.8759 F1: 0.8826 Train AUC: 0.9746 Val AUC: 0.9619 Time: 14.24\n",
      "Epoch: 271 Train Loss: 0.2032 Val Loss: 0.2627 Acc: 0.9004 Pre: 0.8781 Recall: 0.9211 F1: 0.8991 Train AUC: 0.9748 Val AUC: 0.9618 Time: 12.55\n",
      "Epoch: 272 Train Loss: 0.2016 Val Loss: 0.2609 Acc: 0.8931 Pre: 0.8764 Recall: 0.9060 F1: 0.8909 Train AUC: 0.9765 Val AUC: 0.9617 Time: 12.64\n",
      "Epoch: 273 Train Loss: 0.2031 Val Loss: 0.2523 Acc: 0.8859 Pre: 0.8949 Recall: 0.8647 F1: 0.8795 Train AUC: 0.9765 Val AUC: 0.9614 Time: 13.58\n",
      "Epoch: 274 Train Loss: 0.1970 Val Loss: 0.2595 Acc: 0.8732 Pre: 0.8952 Recall: 0.8346 F1: 0.8638 Train AUC: 0.9788 Val AUC: 0.9594 Time: 14.05\n",
      "Epoch: 275 Train Loss: 0.2104 Val Loss: 0.2643 Acc: 0.8895 Pre: 0.8839 Recall: 0.8872 F1: 0.8856 Train AUC: 0.9740 Val AUC: 0.9581 Time: 14.52\n",
      "Epoch: 276 Train Loss: 0.2017 Val Loss: 0.2689 Acc: 0.8841 Pre: 0.8633 Recall: 0.9023 F1: 0.8824 Train AUC: 0.9752 Val AUC: 0.9592 Time: 14.62\n",
      "Epoch: 277 Train Loss: 0.2023 Val Loss: 0.2529 Acc: 0.8967 Pre: 0.8746 Recall: 0.9173 F1: 0.8954 Train AUC: 0.9763 Val AUC: 0.9626 Time: 13.64\n",
      "Epoch: 278 Train Loss: 0.1986 Val Loss: 0.2383 Acc: 0.8822 Pre: 0.8941 Recall: 0.8571 F1: 0.8752 Train AUC: 0.9789 Val AUC: 0.9646 Time: 12.62\n",
      "Epoch: 279 Train Loss: 0.2096 Val Loss: 0.2369 Acc: 0.8804 Pre: 0.8937 Recall: 0.8534 F1: 0.8731 Train AUC: 0.9740 Val AUC: 0.9649 Time: 12.61\n",
      "Epoch: 280 Train Loss: 0.2019 Val Loss: 0.2406 Acc: 0.8949 Pre: 0.8881 Recall: 0.8947 F1: 0.8914 Train AUC: 0.9753 Val AUC: 0.9637 Time: 12.78\n",
      "Epoch: 281 Train Loss: 0.2066 Val Loss: 0.2475 Acc: 0.8913 Pre: 0.8759 Recall: 0.9023 F1: 0.8889 Train AUC: 0.9740 Val AUC: 0.9626 Time: 14.21\n",
      "Epoch: 282 Train Loss: 0.1917 Val Loss: 0.2504 Acc: 0.8859 Pre: 0.8718 Recall: 0.8947 F1: 0.8831 Train AUC: 0.9783 Val AUC: 0.9613 Time: 14.08\n",
      "Epoch: 283 Train Loss: 0.1951 Val Loss: 0.2477 Acc: 0.8877 Pre: 0.8778 Recall: 0.8910 F1: 0.8843 Train AUC: 0.9777 Val AUC: 0.9620 Time: 14.68\n",
      "Epoch: 284 Train Loss: 0.1965 Val Loss: 0.2438 Acc: 0.8859 Pre: 0.8980 Recall: 0.8609 F1: 0.8791 Train AUC: 0.9777 Val AUC: 0.9630 Time: 15.70\n",
      "Epoch: 285 Train Loss: 0.2039 Val Loss: 0.2450 Acc: 0.8822 Pre: 0.8880 Recall: 0.8647 F1: 0.8762 Train AUC: 0.9757 Val AUC: 0.9632 Time: 13.86\n",
      "Epoch: 286 Train Loss: 0.2010 Val Loss: 0.2556 Acc: 0.8931 Pre: 0.8791 Recall: 0.9023 F1: 0.8905 Train AUC: 0.9767 Val AUC: 0.9623 Time: 12.74\n",
      "Epoch: 287 Train Loss: 0.1938 Val Loss: 0.2570 Acc: 0.8986 Pre: 0.8860 Recall: 0.9060 F1: 0.8959 Train AUC: 0.9788 Val AUC: 0.9619 Time: 12.69\n",
      "Epoch: 288 Train Loss: 0.1988 Val Loss: 0.2533 Acc: 0.8877 Pre: 0.8864 Recall: 0.8797 F1: 0.8830 Train AUC: 0.9775 Val AUC: 0.9614 Time: 12.48\n",
      "Epoch: 289 Train Loss: 0.1972 Val Loss: 0.2512 Acc: 0.8895 Pre: 0.8868 Recall: 0.8835 F1: 0.8851 Train AUC: 0.9763 Val AUC: 0.9616 Time: 12.56\n",
      "Epoch: 290 Train Loss: 0.1991 Val Loss: 0.2508 Acc: 0.8949 Pre: 0.8881 Recall: 0.8947 F1: 0.8914 Train AUC: 0.9765 Val AUC: 0.9612 Time: 13.58\n",
      "Epoch: 291 Train Loss: 0.1955 Val Loss: 0.2539 Acc: 0.8859 Pre: 0.8638 Recall: 0.9060 F1: 0.8844 Train AUC: 0.9774 Val AUC: 0.9617 Time: 14.02\n",
      "Epoch: 292 Train Loss: 0.1990 Val Loss: 0.2383 Acc: 0.8913 Pre: 0.8843 Recall: 0.8910 F1: 0.8876 Train AUC: 0.9778 Val AUC: 0.9637 Time: 14.46\n",
      "Epoch: 293 Train Loss: 0.1996 Val Loss: 0.2375 Acc: 0.8859 Pre: 0.8949 Recall: 0.8647 F1: 0.8795 Train AUC: 0.9768 Val AUC: 0.9639 Time: 13.55\n",
      "Epoch: 294 Train Loss: 0.2009 Val Loss: 0.2494 Acc: 0.9022 Pre: 0.8897 Recall: 0.9098 F1: 0.8996 Train AUC: 0.9767 Val AUC: 0.9629 Time: 14.27\n",
      "Epoch: 295 Train Loss: 0.1881 Val Loss: 0.2611 Acc: 0.9022 Pre: 0.8897 Recall: 0.9098 F1: 0.8996 Train AUC: 0.9787 Val AUC: 0.9617 Time: 13.55\n",
      "Epoch: 296 Train Loss: 0.1905 Val Loss: 0.2594 Acc: 0.8967 Pre: 0.8885 Recall: 0.8985 F1: 0.8935 Train AUC: 0.9783 Val AUC: 0.9621 Time: 12.42\n",
      "Epoch: 297 Train Loss: 0.1911 Val Loss: 0.2558 Acc: 0.8913 Pre: 0.8872 Recall: 0.8872 F1: 0.8872 Train AUC: 0.9778 Val AUC: 0.9617 Time: 13.43\n",
      "Epoch: 298 Train Loss: 0.1920 Val Loss: 0.2473 Acc: 0.8822 Pre: 0.8764 Recall: 0.8797 F1: 0.8780 Train AUC: 0.9776 Val AUC: 0.9627 Time: 13.26\n",
      "Epoch: 299 Train Loss: 0.1933 Val Loss: 0.2451 Acc: 0.8895 Pre: 0.8755 Recall: 0.8985 F1: 0.8868 Train AUC: 0.9792 Val AUC: 0.9626 Time: 14.25\n",
      "Epoch: 300 Train Loss: 0.1904 Val Loss: 0.2430 Acc: 0.8913 Pre: 0.8759 Recall: 0.9023 F1: 0.8889 Train AUC: 0.9792 Val AUC: 0.9629 Time: 14.58\n",
      "Epoch: 301 Train Loss: 0.1903 Val Loss: 0.2475 Acc: 0.8931 Pre: 0.8683 Recall: 0.9173 F1: 0.8921 Train AUC: 0.9791 Val AUC: 0.9630 Time: 15.25\n",
      "Epoch: 302 Train Loss: 0.1926 Val Loss: 0.2434 Acc: 0.9004 Pre: 0.8836 Recall: 0.9135 F1: 0.8983 Train AUC: 0.9789 Val AUC: 0.9642 Time: 13.12\n",
      "Epoch: 303 Train Loss: 0.1923 Val Loss: 0.2458 Acc: 0.8986 Pre: 0.8918 Recall: 0.8985 F1: 0.8951 Train AUC: 0.9784 Val AUC: 0.9637 Time: 12.36\n",
      "Epoch: 304 Train Loss: 0.1961 Val Loss: 0.2497 Acc: 0.8913 Pre: 0.8872 Recall: 0.8872 F1: 0.8872 Train AUC: 0.9764 Val AUC: 0.9625 Time: 12.87\n",
      "Epoch: 305 Train Loss: 0.1888 Val Loss: 0.2635 Acc: 0.8877 Pre: 0.8723 Recall: 0.8985 F1: 0.8852 Train AUC: 0.9796 Val AUC: 0.9606 Time: 12.95\n",
      "Epoch: 306 Train Loss: 0.1912 Val Loss: 0.2617 Acc: 0.8895 Pre: 0.8727 Recall: 0.9023 F1: 0.8872 Train AUC: 0.9780 Val AUC: 0.9612 Time: 13.87\n",
      "Epoch: 307 Train Loss: 0.1930 Val Loss: 0.2438 Acc: 0.8877 Pre: 0.8835 Recall: 0.8835 F1: 0.8835 Train AUC: 0.9786 Val AUC: 0.9640 Time: 14.26\n",
      "Epoch: 308 Train Loss: 0.1857 Val Loss: 0.2378 Acc: 0.8967 Pre: 0.8856 Recall: 0.9023 F1: 0.8939 Train AUC: 0.9794 Val AUC: 0.9654 Time: 14.56\n",
      "Epoch: 309 Train Loss: 0.1853 Val Loss: 0.2369 Acc: 0.9004 Pre: 0.8864 Recall: 0.9098 F1: 0.8980 Train AUC: 0.9797 Val AUC: 0.9654 Time: 14.37\n",
      "Epoch: 310 Train Loss: 0.1961 Val Loss: 0.2453 Acc: 0.8967 Pre: 0.8746 Recall: 0.9173 F1: 0.8954 Train AUC: 0.9765 Val AUC: 0.9641 Time: 12.30\n",
      "Epoch: 311 Train Loss: 0.1845 Val Loss: 0.2530 Acc: 0.8913 Pre: 0.8679 Recall: 0.9135 F1: 0.8901 Train AUC: 0.9797 Val AUC: 0.9622 Time: 12.46\n",
      "Epoch: 312 Train Loss: 0.1935 Val Loss: 0.2459 Acc: 0.8877 Pre: 0.8806 Recall: 0.8872 F1: 0.8839 Train AUC: 0.9784 Val AUC: 0.9621 Time: 12.76\n",
      "Epoch: 313 Train Loss: 0.1950 Val Loss: 0.2426 Acc: 0.8841 Pre: 0.8945 Recall: 0.8609 F1: 0.8774 Train AUC: 0.9769 Val AUC: 0.9629 Time: 13.59\n",
      "Epoch: 314 Train Loss: 0.1970 Val Loss: 0.2458 Acc: 0.8967 Pre: 0.8773 Recall: 0.9135 F1: 0.8950 Train AUC: 0.9794 Val AUC: 0.9631 Time: 14.04\n",
      "Epoch: 315 Train Loss: 0.1844 Val Loss: 0.2609 Acc: 0.9040 Pre: 0.8817 Recall: 0.9248 F1: 0.9028 Train AUC: 0.9803 Val AUC: 0.9625 Time: 14.56\n",
      "Epoch: 316 Train Loss: 0.1842 Val Loss: 0.2528 Acc: 0.8895 Pre: 0.8810 Recall: 0.8910 F1: 0.8860 Train AUC: 0.9812 Val AUC: 0.9630 Time: 14.70\n",
      "Epoch: 317 Train Loss: 0.1846 Val Loss: 0.2458 Acc: 0.8877 Pre: 0.8893 Recall: 0.8759 F1: 0.8826 Train AUC: 0.9805 Val AUC: 0.9637 Time: 14.63\n",
      "Epoch: 318 Train Loss: 0.1876 Val Loss: 0.2422 Acc: 0.8859 Pre: 0.8801 Recall: 0.8835 F1: 0.8818 Train AUC: 0.9804 Val AUC: 0.9643 Time: 12.60\n",
      "Epoch: 319 Train Loss: 0.1862 Val Loss: 0.2518 Acc: 0.8986 Pre: 0.8750 Recall: 0.9211 F1: 0.8974 Train AUC: 0.9801 Val AUC: 0.9647 Time: 12.53\n",
      "Epoch: 320 Train Loss: 0.1854 Val Loss: 0.2427 Acc: 0.9076 Pre: 0.8909 Recall: 0.9211 F1: 0.9057 Train AUC: 0.9807 Val AUC: 0.9650 Time: 12.41\n",
      "Epoch: 321 Train Loss: 0.1942 Val Loss: 0.2336 Acc: 0.8931 Pre: 0.8996 Recall: 0.8759 F1: 0.8876 Train AUC: 0.9769 Val AUC: 0.9660 Time: 12.54\n",
      "Epoch: 322 Train Loss: 0.1841 Val Loss: 0.2340 Acc: 0.8986 Pre: 0.8947 Recall: 0.8947 F1: 0.8947 Train AUC: 0.9804 Val AUC: 0.9660 Time: 13.50\n",
      "Epoch: 323 Train Loss: 0.1893 Val Loss: 0.2403 Acc: 0.8931 Pre: 0.8606 Recall: 0.9286 F1: 0.8933 Train AUC: 0.9784 Val AUC: 0.9656 Time: 13.97\n",
      "Epoch: 324 Train Loss: 0.1804 Val Loss: 0.2395 Acc: 0.8949 Pre: 0.8662 Recall: 0.9248 F1: 0.8945 Train AUC: 0.9813 Val AUC: 0.9658 Time: 14.64\n",
      "Epoch: 325 Train Loss: 0.1904 Val Loss: 0.2386 Acc: 0.8967 Pre: 0.8856 Recall: 0.9023 F1: 0.8939 Train AUC: 0.9790 Val AUC: 0.9654 Time: 14.91\n",
      "Epoch: 326 Train Loss: 0.1804 Val Loss: 0.2473 Acc: 0.8949 Pre: 0.8939 Recall: 0.8872 F1: 0.8906 Train AUC: 0.9813 Val AUC: 0.9634 Time: 13.69\n",
      "Epoch: 327 Train Loss: 0.1819 Val Loss: 0.2560 Acc: 0.9004 Pre: 0.8781 Recall: 0.9211 F1: 0.8991 Train AUC: 0.9807 Val AUC: 0.9633 Time: 12.45\n",
      "Epoch: 328 Train Loss: 0.1857 Val Loss: 0.2478 Acc: 0.9058 Pre: 0.8794 Recall: 0.9323 F1: 0.9051 Train AUC: 0.9799 Val AUC: 0.9651 Time: 12.60\n",
      "Epoch: 329 Train Loss: 0.1841 Val Loss: 0.2307 Acc: 0.9022 Pre: 0.8869 Recall: 0.9135 F1: 0.9000 Train AUC: 0.9813 Val AUC: 0.9672 Time: 12.80\n",
      "Epoch: 330 Train Loss: 0.1872 Val Loss: 0.2257 Acc: 0.9058 Pre: 0.9053 Recall: 0.8985 F1: 0.9019 Train AUC: 0.9793 Val AUC: 0.9680 Time: 13.43\n",
      "Epoch: 331 Train Loss: 0.1795 Val Loss: 0.2336 Acc: 0.8913 Pre: 0.8843 Recall: 0.8910 F1: 0.8876 Train AUC: 0.9822 Val AUC: 0.9660 Time: 14.10\n",
      "Epoch: 332 Train Loss: 0.1833 Val Loss: 0.2555 Acc: 0.8931 Pre: 0.8710 Recall: 0.9135 F1: 0.8917 Train AUC: 0.9804 Val AUC: 0.9633 Time: 14.56\n",
      "Epoch: 333 Train Loss: 0.1822 Val Loss: 0.2455 Acc: 0.8967 Pre: 0.8856 Recall: 0.9023 F1: 0.8939 Train AUC: 0.9809 Val AUC: 0.9643 Time: 14.64\n",
      "Epoch: 334 Train Loss: 0.1726 Val Loss: 0.2404 Acc: 0.8931 Pre: 0.8935 Recall: 0.8835 F1: 0.8885 Train AUC: 0.9823 Val AUC: 0.9658 Time: 13.02\n",
      "Epoch: 335 Train Loss: 0.1769 Val Loss: 0.2358 Acc: 0.8913 Pre: 0.8872 Recall: 0.8872 F1: 0.8872 Train AUC: 0.9807 Val AUC: 0.9663 Time: 12.78\n",
      "Epoch: 336 Train Loss: 0.1757 Val Loss: 0.2346 Acc: 0.9040 Pre: 0.8817 Recall: 0.9248 F1: 0.9028 Train AUC: 0.9816 Val AUC: 0.9670 Time: 13.25\n",
      "Epoch: 337 Train Loss: 0.1860 Val Loss: 0.2492 Acc: 0.9094 Pre: 0.8803 Recall: 0.9398 F1: 0.9091 Train AUC: 0.9817 Val AUC: 0.9658 Time: 13.70\n",
      "Epoch: 338 Train Loss: 0.1775 Val Loss: 0.2450 Acc: 0.8913 Pre: 0.8843 Recall: 0.8910 F1: 0.8876 Train AUC: 0.9833 Val AUC: 0.9647 Time: 14.15\n",
      "Epoch: 339 Train Loss: 0.1745 Val Loss: 0.2537 Acc: 0.8913 Pre: 0.8843 Recall: 0.8910 F1: 0.8876 Train AUC: 0.9821 Val AUC: 0.9629 Time: 13.85\n",
      "Epoch: 340 Train Loss: 0.1803 Val Loss: 0.2522 Acc: 0.8949 Pre: 0.8796 Recall: 0.9060 F1: 0.8926 Train AUC: 0.9808 Val AUC: 0.9642 Time: 13.59\n",
      "Epoch: 341 Train Loss: 0.1770 Val Loss: 0.2457 Acc: 0.8967 Pre: 0.8746 Recall: 0.9173 F1: 0.8954 Train AUC: 0.9817 Val AUC: 0.9651 Time: 12.69\n",
      "Epoch: 342 Train Loss: 0.1739 Val Loss: 0.2337 Acc: 0.8986 Pre: 0.8889 Recall: 0.9023 F1: 0.8955 Train AUC: 0.9830 Val AUC: 0.9667 Time: 12.84\n",
      "Epoch: 343 Train Loss: 0.1749 Val Loss: 0.2385 Acc: 0.8967 Pre: 0.8943 Recall: 0.8910 F1: 0.8927 Train AUC: 0.9825 Val AUC: 0.9661 Time: 14.46\n",
      "Epoch: 344 Train Loss: 0.1689 Val Loss: 0.2442 Acc: 0.8895 Pre: 0.8810 Recall: 0.8910 F1: 0.8860 Train AUC: 0.9839 Val AUC: 0.9657 Time: 13.99\n",
      "Epoch: 345 Train Loss: 0.1683 Val Loss: 0.2596 Acc: 0.9022 Pre: 0.8813 Recall: 0.9211 F1: 0.9007 Train AUC: 0.9843 Val AUC: 0.9643 Time: 14.53\n",
      "Epoch: 346 Train Loss: 0.1872 Val Loss: 0.2422 Acc: 0.8986 Pre: 0.8860 Recall: 0.9060 F1: 0.8959 Train AUC: 0.9809 Val AUC: 0.9661 Time: 14.65\n",
      "Epoch: 347 Train Loss: 0.1694 Val Loss: 0.2301 Acc: 0.9004 Pre: 0.8981 Recall: 0.8947 F1: 0.8964 Train AUC: 0.9831 Val AUC: 0.9682 Time: 14.65\n",
      "Epoch: 348 Train Loss: 0.1804 Val Loss: 0.2310 Acc: 0.9022 Pre: 0.8813 Recall: 0.9211 F1: 0.9007 Train AUC: 0.9802 Val AUC: 0.9678 Time: 14.91\n",
      "Epoch: 349 Train Loss: 0.1716 Val Loss: 0.2322 Acc: 0.8986 Pre: 0.8832 Recall: 0.9098 F1: 0.8963 Train AUC: 0.9825 Val AUC: 0.9675 Time: 12.58\n",
      "Epoch: 350 Train Loss: 0.1666 Val Loss: 0.2404 Acc: 0.8895 Pre: 0.8755 Recall: 0.8985 F1: 0.8868 Train AUC: 0.9848 Val AUC: 0.9652 Time: 12.59\n",
      "Epoch: 351 Train Loss: 0.1653 Val Loss: 0.2413 Acc: 0.8895 Pre: 0.8727 Recall: 0.9023 F1: 0.8872 Train AUC: 0.9838 Val AUC: 0.9652 Time: 12.48\n",
      "Epoch: 352 Train Loss: 0.1722 Val Loss: 0.2355 Acc: 0.9004 Pre: 0.8951 Recall: 0.8985 F1: 0.8968 Train AUC: 0.9833 Val AUC: 0.9666 Time: 12.65\n",
      "Epoch: 353 Train Loss: 0.1745 Val Loss: 0.2444 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9838 Val AUC: 0.9661 Time: 13.74\n",
      "Epoch: 354 Train Loss: 0.1715 Val Loss: 0.2545 Acc: 0.9076 Pre: 0.8772 Recall: 0.9398 F1: 0.9074 Train AUC: 0.9828 Val AUC: 0.9650 Time: 13.91\n",
      "Epoch: 355 Train Loss: 0.1729 Val Loss: 0.2355 Acc: 0.9112 Pre: 0.8945 Recall: 0.9248 F1: 0.9094 Train AUC: 0.9830 Val AUC: 0.9667 Time: 14.55\n",
      "Epoch: 356 Train Loss: 0.1730 Val Loss: 0.2306 Acc: 0.9058 Pre: 0.8963 Recall: 0.9098 F1: 0.9030 Train AUC: 0.9822 Val AUC: 0.9674 Time: 13.82\n",
      "Epoch: 357 Train Loss: 0.1677 Val Loss: 0.2403 Acc: 0.8967 Pre: 0.8800 Recall: 0.9098 F1: 0.8946 Train AUC: 0.9843 Val AUC: 0.9658 Time: 14.08\n",
      "Epoch: 358 Train Loss: 0.1670 Val Loss: 0.2439 Acc: 0.8949 Pre: 0.8741 Recall: 0.9135 F1: 0.8934 Train AUC: 0.9843 Val AUC: 0.9648 Time: 12.42\n",
      "Epoch: 359 Train Loss: 0.1676 Val Loss: 0.2400 Acc: 0.8931 Pre: 0.8819 Recall: 0.8985 F1: 0.8901 Train AUC: 0.9847 Val AUC: 0.9649 Time: 12.61\n",
      "Epoch: 360 Train Loss: 0.1677 Val Loss: 0.2421 Acc: 0.8931 Pre: 0.8819 Recall: 0.8985 F1: 0.8901 Train AUC: 0.9843 Val AUC: 0.9651 Time: 12.64\n",
      "Epoch: 361 Train Loss: 0.1652 Val Loss: 0.2480 Acc: 0.9112 Pre: 0.8834 Recall: 0.9398 F1: 0.9107 Train AUC: 0.9844 Val AUC: 0.9656 Time: 13.80\n",
      "Epoch: 362 Train Loss: 0.1659 Val Loss: 0.2524 Acc: 0.9112 Pre: 0.8780 Recall: 0.9474 F1: 0.9114 Train AUC: 0.9844 Val AUC: 0.9660 Time: 14.14\n",
      "Epoch: 363 Train Loss: 0.1698 Val Loss: 0.2282 Acc: 0.9094 Pre: 0.8942 Recall: 0.9211 F1: 0.9074 Train AUC: 0.9846 Val AUC: 0.9684 Time: 14.66\n",
      "Epoch: 364 Train Loss: 0.1588 Val Loss: 0.2289 Acc: 0.9076 Pre: 0.8996 Recall: 0.9098 F1: 0.9047 Train AUC: 0.9857 Val AUC: 0.9678 Time: 14.25\n",
      "Epoch: 365 Train Loss: 0.1631 Val Loss: 0.2365 Acc: 0.8967 Pre: 0.8828 Recall: 0.9060 F1: 0.8942 Train AUC: 0.9847 Val AUC: 0.9661 Time: 13.22\n",
      "Epoch: 366 Train Loss: 0.1604 Val Loss: 0.2357 Acc: 0.8986 Pre: 0.8804 Recall: 0.9135 F1: 0.8967 Train AUC: 0.9854 Val AUC: 0.9669 Time: 12.33\n",
      "Epoch: 367 Train Loss: 0.1622 Val Loss: 0.2361 Acc: 0.9004 Pre: 0.8836 Recall: 0.9135 F1: 0.8983 Train AUC: 0.9859 Val AUC: 0.9673 Time: 12.60\n",
      "Epoch: 368 Train Loss: 0.1635 Val Loss: 0.2324 Acc: 0.9004 Pre: 0.8836 Recall: 0.9135 F1: 0.8983 Train AUC: 0.9850 Val AUC: 0.9679 Time: 12.79\n",
      "Epoch: 369 Train Loss: 0.1666 Val Loss: 0.2279 Acc: 0.9058 Pre: 0.8963 Recall: 0.9098 F1: 0.9030 Train AUC: 0.9851 Val AUC: 0.9685 Time: 12.65\n",
      "Epoch: 370 Train Loss: 0.1618 Val Loss: 0.2271 Acc: 0.9022 Pre: 0.8813 Recall: 0.9211 F1: 0.9007 Train AUC: 0.9847 Val AUC: 0.9686 Time: 13.21\n",
      "Epoch: 371 Train Loss: 0.1587 Val Loss: 0.2355 Acc: 0.8986 Pre: 0.8804 Recall: 0.9135 F1: 0.8967 Train AUC: 0.9852 Val AUC: 0.9669 Time: 14.31\n",
      "Epoch: 372 Train Loss: 0.1603 Val Loss: 0.2420 Acc: 0.9004 Pre: 0.8893 Recall: 0.9060 F1: 0.8976 Train AUC: 0.9857 Val AUC: 0.9654 Time: 14.67\n",
      "Epoch: 373 Train Loss: 0.1709 Val Loss: 0.2439 Acc: 0.8949 Pre: 0.8741 Recall: 0.9135 F1: 0.8934 Train AUC: 0.9842 Val AUC: 0.9661 Time: 14.93\n",
      "Epoch: 374 Train Loss: 0.1620 Val Loss: 0.2366 Acc: 0.9094 Pre: 0.8830 Recall: 0.9361 F1: 0.9088 Train AUC: 0.9856 Val AUC: 0.9684 Time: 12.39\n",
      "Epoch: 375 Train Loss: 0.1660 Val Loss: 0.2350 Acc: 0.9167 Pre: 0.9044 Recall: 0.9248 F1: 0.9145 Train AUC: 0.9832 Val AUC: 0.9684 Time: 12.42\n",
      "Epoch: 376 Train Loss: 0.1691 Val Loss: 0.2252 Acc: 0.9185 Pre: 0.8989 Recall: 0.9361 F1: 0.9171 Train AUC: 0.9826 Val AUC: 0.9706 Time: 12.43\n",
      "Epoch: 377 Train Loss: 0.1659 Val Loss: 0.2355 Acc: 0.9058 Pre: 0.8741 Recall: 0.9398 F1: 0.9058 Train AUC: 0.9838 Val AUC: 0.9689 Time: 13.17\n",
      "Epoch: 378 Train Loss: 0.1677 Val Loss: 0.2317 Acc: 0.9076 Pre: 0.8881 Recall: 0.9248 F1: 0.9061 Train AUC: 0.9850 Val AUC: 0.9681 Time: 13.66\n",
      "Epoch: 379 Train Loss: 0.1550 Val Loss: 0.2311 Acc: 0.9058 Pre: 0.8993 Recall: 0.9060 F1: 0.9026 Train AUC: 0.9865 Val AUC: 0.9680 Time: 14.65\n",
      "Epoch: 380 Train Loss: 0.1604 Val Loss: 0.2366 Acc: 0.8986 Pre: 0.8777 Recall: 0.9173 F1: 0.8971 Train AUC: 0.9852 Val AUC: 0.9674 Time: 14.10\n",
      "Epoch: 381 Train Loss: 0.1479 Val Loss: 0.2404 Acc: 0.9058 Pre: 0.8821 Recall: 0.9286 F1: 0.9048 Train AUC: 0.9877 Val AUC: 0.9676 Time: 14.37\n",
      "Epoch: 382 Train Loss: 0.1595 Val Loss: 0.2271 Acc: 0.9076 Pre: 0.8938 Recall: 0.9173 F1: 0.9054 Train AUC: 0.9852 Val AUC: 0.9691 Time: 13.18\n",
      "Epoch: 383 Train Loss: 0.1557 Val Loss: 0.2207 Acc: 0.9221 Pre: 0.9055 Recall: 0.9361 F1: 0.9205 Train AUC: 0.9860 Val AUC: 0.9706 Time: 12.58\n",
      "Epoch: 384 Train Loss: 0.1605 Val Loss: 0.2240 Acc: 0.9130 Pre: 0.8893 Recall: 0.9361 F1: 0.9121 Train AUC: 0.9861 Val AUC: 0.9706 Time: 12.72\n",
      "Epoch: 385 Train Loss: 0.1512 Val Loss: 0.2338 Acc: 0.9094 Pre: 0.8776 Recall: 0.9436 F1: 0.9094 Train AUC: 0.9871 Val AUC: 0.9680 Time: 13.26\n",
      "Epoch: 386 Train Loss: 0.1512 Val Loss: 0.2369 Acc: 0.9022 Pre: 0.8869 Recall: 0.9135 F1: 0.9000 Train AUC: 0.9873 Val AUC: 0.9671 Time: 13.73\n",
      "Epoch: 387 Train Loss: 0.1518 Val Loss: 0.2340 Acc: 0.9094 Pre: 0.9186 Recall: 0.8910 F1: 0.9046 Train AUC: 0.9864 Val AUC: 0.9680 Time: 14.05\n",
      "Epoch: 388 Train Loss: 0.1623 Val Loss: 0.2292 Acc: 0.9076 Pre: 0.8909 Recall: 0.9211 F1: 0.9057 Train AUC: 0.9854 Val AUC: 0.9682 Time: 14.49\n",
      "Epoch: 389 Train Loss: 0.1568 Val Loss: 0.2225 Acc: 0.9130 Pre: 0.8921 Recall: 0.9323 F1: 0.9118 Train AUC: 0.9859 Val AUC: 0.9705 Time: 13.21\n",
      "Epoch: 390 Train Loss: 0.1503 Val Loss: 0.2204 Acc: 0.9149 Pre: 0.8925 Recall: 0.9361 F1: 0.9138 Train AUC: 0.9877 Val AUC: 0.9714 Time: 12.71\n",
      "Epoch: 391 Train Loss: 0.1556 Val Loss: 0.2211 Acc: 0.9130 Pre: 0.9098 Recall: 0.9098 F1: 0.9098 Train AUC: 0.9873 Val AUC: 0.9709 Time: 12.81\n",
      "Epoch: 392 Train Loss: 0.1490 Val Loss: 0.2334 Acc: 0.8967 Pre: 0.8800 Recall: 0.9098 F1: 0.8946 Train AUC: 0.9883 Val AUC: 0.9690 Time: 13.51\n",
      "Epoch: 393 Train Loss: 0.1568 Val Loss: 0.2452 Acc: 0.9022 Pre: 0.8732 Recall: 0.9323 F1: 0.9018 Train AUC: 0.9855 Val AUC: 0.9681 Time: 14.72\n",
      "Epoch: 394 Train Loss: 0.1567 Val Loss: 0.2352 Acc: 0.9040 Pre: 0.8711 Recall: 0.9398 F1: 0.9042 Train AUC: 0.9860 Val AUC: 0.9706 Time: 14.81\n",
      "Epoch: 395 Train Loss: 0.1656 Val Loss: 0.2125 Acc: 0.9185 Pre: 0.9170 Recall: 0.9135 F1: 0.9153 Train AUC: 0.9855 Val AUC: 0.9719 Time: 14.87\n",
      "Epoch: 396 Train Loss: 0.1610 Val Loss: 0.2259 Acc: 0.9185 Pre: 0.9048 Recall: 0.9286 F1: 0.9165 Train AUC: 0.9865 Val AUC: 0.9698 Time: 13.04\n",
      "Epoch: 397 Train Loss: 0.1454 Val Loss: 0.2491 Acc: 0.9040 Pre: 0.8737 Recall: 0.9361 F1: 0.9038 Train AUC: 0.9876 Val AUC: 0.9668 Time: 12.56\n",
      "Epoch: 398 Train Loss: 0.1538 Val Loss: 0.2297 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9869 Val AUC: 0.9695 Time: 12.95\n",
      "Epoch: 399 Train Loss: 0.1467 Val Loss: 0.2138 Acc: 0.9185 Pre: 0.9234 Recall: 0.9060 F1: 0.9146 Train AUC: 0.9879 Val AUC: 0.9722 Time: 13.43\n",
      "Epoch: 400 Train Loss: 0.1567 Val Loss: 0.2119 Acc: 0.9149 Pre: 0.9071 Recall: 0.9173 F1: 0.9121 Train AUC: 0.9862 Val AUC: 0.9727 Time: 13.63\n",
      "Epoch: 401 Train Loss: 0.1523 Val Loss: 0.2212 Acc: 0.9112 Pre: 0.8945 Recall: 0.9248 F1: 0.9094 Train AUC: 0.9867 Val AUC: 0.9715 Time: 14.48\n",
      "Epoch: 402 Train Loss: 0.1418 Val Loss: 0.2386 Acc: 0.8967 Pre: 0.8693 Recall: 0.9248 F1: 0.8962 Train AUC: 0.9894 Val AUC: 0.9687 Time: 14.79\n",
      "Epoch: 403 Train Loss: 0.1532 Val Loss: 0.2407 Acc: 0.8949 Pre: 0.8714 Recall: 0.9173 F1: 0.8938 Train AUC: 0.9862 Val AUC: 0.9675 Time: 15.26\n",
      "Epoch: 404 Train Loss: 0.1498 Val Loss: 0.2323 Acc: 0.9076 Pre: 0.8909 Recall: 0.9211 F1: 0.9057 Train AUC: 0.9869 Val AUC: 0.9688 Time: 13.16\n",
      "Epoch: 405 Train Loss: 0.1508 Val Loss: 0.2213 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9863 Val AUC: 0.9709 Time: 12.68\n",
      "Epoch: 406 Train Loss: 0.1520 Val Loss: 0.2270 Acc: 0.9130 Pre: 0.8865 Recall: 0.9398 F1: 0.9124 Train AUC: 0.9872 Val AUC: 0.9707 Time: 12.51\n",
      "Epoch: 407 Train Loss: 0.1516 Val Loss: 0.2318 Acc: 0.9058 Pre: 0.8849 Recall: 0.9248 F1: 0.9044 Train AUC: 0.9864 Val AUC: 0.9690 Time: 12.69\n",
      "Epoch: 408 Train Loss: 0.1505 Val Loss: 0.2337 Acc: 0.9004 Pre: 0.8951 Recall: 0.8985 F1: 0.8968 Train AUC: 0.9863 Val AUC: 0.9685 Time: 13.38\n",
      "Epoch: 409 Train Loss: 0.1545 Val Loss: 0.2274 Acc: 0.9130 Pre: 0.8949 Recall: 0.9286 F1: 0.9114 Train AUC: 0.9859 Val AUC: 0.9699 Time: 14.00\n",
      "Epoch: 410 Train Loss: 0.1438 Val Loss: 0.2233 Acc: 0.9130 Pre: 0.8921 Recall: 0.9323 F1: 0.9118 Train AUC: 0.9893 Val AUC: 0.9713 Time: 14.61\n",
      "Epoch: 411 Train Loss: 0.1552 Val Loss: 0.2225 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9863 Val AUC: 0.9712 Time: 15.07\n",
      "Epoch: 412 Train Loss: 0.1414 Val Loss: 0.2331 Acc: 0.9094 Pre: 0.8830 Recall: 0.9361 F1: 0.9088 Train AUC: 0.9886 Val AUC: 0.9686 Time: 15.00\n",
      "Epoch: 413 Train Loss: 0.1454 Val Loss: 0.2281 Acc: 0.9112 Pre: 0.8917 Recall: 0.9286 F1: 0.9098 Train AUC: 0.9876 Val AUC: 0.9696 Time: 12.75\n",
      "Epoch: 414 Train Loss: 0.1472 Val Loss: 0.2264 Acc: 0.9076 Pre: 0.8772 Recall: 0.9398 F1: 0.9074 Train AUC: 0.9874 Val AUC: 0.9699 Time: 12.82\n",
      "Epoch: 415 Train Loss: 0.1433 Val Loss: 0.2171 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9892 Val AUC: 0.9712 Time: 12.56\n",
      "Epoch: 416 Train Loss: 0.1496 Val Loss: 0.2261 Acc: 0.9094 Pre: 0.8942 Recall: 0.9211 F1: 0.9074 Train AUC: 0.9880 Val AUC: 0.9700 Time: 12.66\n",
      "Epoch: 417 Train Loss: 0.1434 Val Loss: 0.2430 Acc: 0.9004 Pre: 0.8728 Recall: 0.9286 F1: 0.8998 Train AUC: 0.9884 Val AUC: 0.9672 Time: 12.52\n",
      "Epoch: 418 Train Loss: 0.1470 Val Loss: 0.2373 Acc: 0.9022 Pre: 0.8732 Recall: 0.9323 F1: 0.9018 Train AUC: 0.9873 Val AUC: 0.9687 Time: 12.64\n",
      "Epoch: 419 Train Loss: 0.1408 Val Loss: 0.2141 Acc: 0.9167 Pre: 0.9104 Recall: 0.9173 F1: 0.9139 Train AUC: 0.9895 Val AUC: 0.9728 Time: 13.82\n",
      "Epoch: 420 Train Loss: 0.1367 Val Loss: 0.2091 Acc: 0.9185 Pre: 0.9108 Recall: 0.9211 F1: 0.9159 Train AUC: 0.9906 Val AUC: 0.9732 Time: 14.40\n",
      "Epoch: 421 Train Loss: 0.1569 Val Loss: 0.2244 Acc: 0.9076 Pre: 0.8853 Recall: 0.9286 F1: 0.9064 Train AUC: 0.9872 Val AUC: 0.9721 Time: 15.25\n",
      "Epoch: 422 Train Loss: 0.1413 Val Loss: 0.2294 Acc: 0.9076 Pre: 0.8853 Recall: 0.9286 F1: 0.9064 Train AUC: 0.9893 Val AUC: 0.9710 Time: 13.37\n",
      "Epoch: 423 Train Loss: 0.1515 Val Loss: 0.2257 Acc: 0.9112 Pre: 0.8945 Recall: 0.9248 F1: 0.9094 Train AUC: 0.9861 Val AUC: 0.9699 Time: 13.03\n",
      "Epoch: 424 Train Loss: 0.1537 Val Loss: 0.2264 Acc: 0.9167 Pre: 0.8957 Recall: 0.9361 F1: 0.9154 Train AUC: 0.9863 Val AUC: 0.9702 Time: 13.62\n",
      "Epoch: 425 Train Loss: 0.1437 Val Loss: 0.2355 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9890 Val AUC: 0.9686 Time: 14.13\n",
      "Epoch: 426 Train Loss: 0.1489 Val Loss: 0.2262 Acc: 0.9149 Pre: 0.8925 Recall: 0.9361 F1: 0.9138 Train AUC: 0.9888 Val AUC: 0.9709 Time: 14.28\n",
      "Epoch: 427 Train Loss: 0.1514 Val Loss: 0.2164 Acc: 0.9149 Pre: 0.9132 Recall: 0.9098 F1: 0.9115 Train AUC: 0.9877 Val AUC: 0.9728 Time: 12.65\n",
      "Epoch: 428 Train Loss: 0.1538 Val Loss: 0.2288 Acc: 0.9058 Pre: 0.8849 Recall: 0.9248 F1: 0.9044 Train AUC: 0.9873 Val AUC: 0.9718 Time: 12.62\n",
      "Epoch: 429 Train Loss: 0.1457 Val Loss: 0.2471 Acc: 0.9058 Pre: 0.8715 Recall: 0.9436 F1: 0.9061 Train AUC: 0.9874 Val AUC: 0.9705 Time: 13.04\n",
      "Epoch: 430 Train Loss: 0.1456 Val Loss: 0.2206 Acc: 0.9076 Pre: 0.8853 Recall: 0.9286 F1: 0.9064 Train AUC: 0.9882 Val AUC: 0.9718 Time: 13.73\n",
      "Epoch: 431 Train Loss: 0.1400 Val Loss: 0.2236 Acc: 0.9130 Pre: 0.9291 Recall: 0.8872 F1: 0.9077 Train AUC: 0.9889 Val AUC: 0.9718 Time: 14.18\n",
      "Epoch: 432 Train Loss: 0.1654 Val Loss: 0.2261 Acc: 0.9058 Pre: 0.8963 Recall: 0.9098 F1: 0.9030 Train AUC: 0.9860 Val AUC: 0.9696 Time: 14.75\n",
      "Epoch: 433 Train Loss: 0.1507 Val Loss: 0.2336 Acc: 0.9022 Pre: 0.8681 Recall: 0.9398 F1: 0.9025 Train AUC: 0.9878 Val AUC: 0.9705 Time: 12.81\n",
      "Epoch: 434 Train Loss: 0.1322 Val Loss: 0.2341 Acc: 0.9040 Pre: 0.8790 Recall: 0.9286 F1: 0.9031 Train AUC: 0.9909 Val AUC: 0.9699 Time: 12.92\n",
      "Epoch: 435 Train Loss: 0.1406 Val Loss: 0.2255 Acc: 0.9022 Pre: 0.8841 Recall: 0.9173 F1: 0.9004 Train AUC: 0.9883 Val AUC: 0.9710 Time: 12.70\n",
      "Epoch: 436 Train Loss: 0.1399 Val Loss: 0.2137 Acc: 0.9130 Pre: 0.9037 Recall: 0.9173 F1: 0.9104 Train AUC: 0.9883 Val AUC: 0.9731 Time: 13.21\n",
      "Epoch: 437 Train Loss: 0.1428 Val Loss: 0.2166 Acc: 0.9167 Pre: 0.8873 Recall: 0.9474 F1: 0.9164 Train AUC: 0.9888 Val AUC: 0.9737 Time: 14.03\n",
      "Epoch: 438 Train Loss: 0.1363 Val Loss: 0.2273 Acc: 0.9149 Pre: 0.8925 Recall: 0.9361 F1: 0.9138 Train AUC: 0.9899 Val AUC: 0.9721 Time: 14.85\n",
      "Epoch: 439 Train Loss: 0.1328 Val Loss: 0.2247 Acc: 0.9185 Pre: 0.9018 Recall: 0.9323 F1: 0.9168 Train AUC: 0.9913 Val AUC: 0.9719 Time: 13.90\n",
      "Epoch: 440 Train Loss: 0.1401 Val Loss: 0.2192 Acc: 0.9221 Pre: 0.9176 Recall: 0.9211 F1: 0.9193 Train AUC: 0.9889 Val AUC: 0.9731 Time: 13.16\n",
      "Epoch: 441 Train Loss: 0.1392 Val Loss: 0.2188 Acc: 0.9203 Pre: 0.8936 Recall: 0.9474 F1: 0.9197 Train AUC: 0.9902 Val AUC: 0.9739 Time: 12.37\n",
      "Epoch: 442 Train Loss: 0.1388 Val Loss: 0.2234 Acc: 0.9076 Pre: 0.8799 Recall: 0.9361 F1: 0.9071 Train AUC: 0.9891 Val AUC: 0.9739 Time: 12.93\n",
      "Epoch: 443 Train Loss: 0.1419 Val Loss: 0.2108 Acc: 0.9112 Pre: 0.8974 Recall: 0.9211 F1: 0.9091 Train AUC: 0.9891 Val AUC: 0.9741 Time: 13.89\n",
      "Epoch: 444 Train Loss: 0.1477 Val Loss: 0.2145 Acc: 0.9112 Pre: 0.9033 Recall: 0.9135 F1: 0.9084 Train AUC: 0.9868 Val AUC: 0.9735 Time: 14.16\n",
      "Epoch: 445 Train Loss: 0.1457 Val Loss: 0.2579 Acc: 0.8949 Pre: 0.8636 Recall: 0.9286 F1: 0.8949 Train AUC: 0.9882 Val AUC: 0.9681 Time: 14.59\n",
      "Epoch: 446 Train Loss: 0.1440 Val Loss: 0.2460 Acc: 0.9022 Pre: 0.8786 Recall: 0.9248 F1: 0.9011 Train AUC: 0.9893 Val AUC: 0.9684 Time: 14.34\n",
      "Epoch: 447 Train Loss: 0.1430 Val Loss: 0.2143 Acc: 0.9149 Pre: 0.9195 Recall: 0.9023 F1: 0.9108 Train AUC: 0.9882 Val AUC: 0.9740 Time: 13.18\n",
      "Epoch: 448 Train Loss: 0.1369 Val Loss: 0.1998 Acc: 0.9293 Pre: 0.9251 Recall: 0.9286 F1: 0.9268 Train AUC: 0.9897 Val AUC: 0.9768 Time: 12.60\n",
      "Epoch: 449 Train Loss: 0.1378 Val Loss: 0.2026 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9896 Val AUC: 0.9758 Time: 12.72\n",
      "Epoch: 450 Train Loss: 0.1482 Val Loss: 0.2126 Acc: 0.9149 Pre: 0.9011 Recall: 0.9248 F1: 0.9128 Train AUC: 0.9880 Val AUC: 0.9739 Time: 12.70\n",
      "Epoch: 451 Train Loss: 0.1370 Val Loss: 0.2236 Acc: 0.9076 Pre: 0.8967 Recall: 0.9135 F1: 0.9050 Train AUC: 0.9890 Val AUC: 0.9717 Time: 12.69\n",
      "Epoch: 452 Train Loss: 0.1449 Val Loss: 0.2286 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9877 Val AUC: 0.9717 Time: 12.65\n",
      "Epoch: 453 Train Loss: 0.1339 Val Loss: 0.2179 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9894 Val AUC: 0.9734 Time: 12.87\n",
      "Epoch: 454 Train Loss: 0.1396 Val Loss: 0.2125 Acc: 0.9221 Pre: 0.9055 Recall: 0.9361 F1: 0.9205 Train AUC: 0.9890 Val AUC: 0.9739 Time: 14.19\n",
      "Epoch: 455 Train Loss: 0.1372 Val Loss: 0.2136 Acc: 0.9239 Pre: 0.9088 Recall: 0.9361 F1: 0.9222 Train AUC: 0.9904 Val AUC: 0.9742 Time: 14.66\n",
      "Epoch: 456 Train Loss: 0.1246 Val Loss: 0.2183 Acc: 0.9130 Pre: 0.8949 Recall: 0.9286 F1: 0.9114 Train AUC: 0.9914 Val AUC: 0.9734 Time: 15.37\n",
      "Epoch: 457 Train Loss: 0.1288 Val Loss: 0.2300 Acc: 0.9076 Pre: 0.8799 Recall: 0.9361 F1: 0.9071 Train AUC: 0.9905 Val AUC: 0.9720 Time: 13.63\n",
      "Epoch: 458 Train Loss: 0.1350 Val Loss: 0.2197 Acc: 0.9130 Pre: 0.8921 Recall: 0.9323 F1: 0.9118 Train AUC: 0.9901 Val AUC: 0.9732 Time: 12.64\n",
      "Epoch: 459 Train Loss: 0.1382 Val Loss: 0.2071 Acc: 0.9221 Pre: 0.9176 Recall: 0.9211 F1: 0.9193 Train AUC: 0.9899 Val AUC: 0.9750 Time: 12.98\n",
      "Epoch: 460 Train Loss: 0.1378 Val Loss: 0.2106 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9896 Val AUC: 0.9746 Time: 12.66\n",
      "Epoch: 461 Train Loss: 0.1335 Val Loss: 0.2297 Acc: 0.9130 Pre: 0.8811 Recall: 0.9474 F1: 0.9130 Train AUC: 0.9911 Val AUC: 0.9729 Time: 12.78\n",
      "Epoch: 462 Train Loss: 0.1340 Val Loss: 0.2235 Acc: 0.9130 Pre: 0.8811 Recall: 0.9474 F1: 0.9130 Train AUC: 0.9901 Val AUC: 0.9737 Time: 13.63\n",
      "Epoch: 463 Train Loss: 0.1381 Val Loss: 0.2055 Acc: 0.9203 Pre: 0.9173 Recall: 0.9173 F1: 0.9173 Train AUC: 0.9897 Val AUC: 0.9761 Time: 14.03\n",
      "Epoch: 464 Train Loss: 0.1391 Val Loss: 0.2037 Acc: 0.9203 Pre: 0.9173 Recall: 0.9173 F1: 0.9173 Train AUC: 0.9898 Val AUC: 0.9759 Time: 14.81\n",
      "Epoch: 465 Train Loss: 0.1294 Val Loss: 0.2308 Acc: 0.9022 Pre: 0.8681 Recall: 0.9398 F1: 0.9025 Train AUC: 0.9919 Val AUC: 0.9736 Time: 14.67\n",
      "Epoch: 466 Train Loss: 0.1355 Val Loss: 0.2340 Acc: 0.9004 Pre: 0.8728 Recall: 0.9286 F1: 0.8998 Train AUC: 0.9913 Val AUC: 0.9717 Time: 12.75\n",
      "Epoch: 467 Train Loss: 0.1286 Val Loss: 0.2398 Acc: 0.9040 Pre: 0.9019 Recall: 0.8985 F1: 0.9002 Train AUC: 0.9913 Val AUC: 0.9700 Time: 12.73\n",
      "Epoch: 468 Train Loss: 0.1421 Val Loss: 0.2274 Acc: 0.9094 Pre: 0.8913 Recall: 0.9248 F1: 0.9077 Train AUC: 0.9889 Val AUC: 0.9718 Time: 13.07\n",
      "Epoch: 469 Train Loss: 0.1300 Val Loss: 0.2234 Acc: 0.9149 Pre: 0.8925 Recall: 0.9361 F1: 0.9138 Train AUC: 0.9902 Val AUC: 0.9730 Time: 13.95\n",
      "Epoch: 470 Train Loss: 0.1306 Val Loss: 0.2064 Acc: 0.9293 Pre: 0.9188 Recall: 0.9361 F1: 0.9274 Train AUC: 0.9920 Val AUC: 0.9745 Time: 13.75\n",
      "Epoch: 471 Train Loss: 0.1305 Val Loss: 0.2046 Acc: 0.9239 Pre: 0.9275 Recall: 0.9135 F1: 0.9205 Train AUC: 0.9907 Val AUC: 0.9762 Time: 14.15\n",
      "Epoch: 472 Train Loss: 0.1449 Val Loss: 0.2305 Acc: 0.9094 Pre: 0.8750 Recall: 0.9474 F1: 0.9097 Train AUC: 0.9897 Val AUC: 0.9728 Time: 14.09\n",
      "Epoch: 473 Train Loss: 0.1320 Val Loss: 0.2466 Acc: 0.9058 Pre: 0.8690 Recall: 0.9474 F1: 0.9065 Train AUC: 0.9902 Val AUC: 0.9716 Time: 13.42\n",
      "Epoch: 474 Train Loss: 0.1427 Val Loss: 0.2127 Acc: 0.9167 Pre: 0.9015 Recall: 0.9286 F1: 0.9148 Train AUC: 0.9886 Val AUC: 0.9749 Time: 12.36\n",
      "Epoch: 475 Train Loss: 0.1285 Val Loss: 0.2060 Acc: 0.9221 Pre: 0.9176 Recall: 0.9211 F1: 0.9193 Train AUC: 0.9907 Val AUC: 0.9752 Time: 12.81\n",
      "Epoch: 476 Train Loss: 0.1354 Val Loss: 0.2126 Acc: 0.9149 Pre: 0.9041 Recall: 0.9211 F1: 0.9125 Train AUC: 0.9908 Val AUC: 0.9734 Time: 13.47\n",
      "Epoch: 477 Train Loss: 0.1295 Val Loss: 0.2167 Acc: 0.9094 Pre: 0.8913 Recall: 0.9248 F1: 0.9077 Train AUC: 0.9915 Val AUC: 0.9730 Time: 14.04\n",
      "Epoch: 478 Train Loss: 0.1258 Val Loss: 0.2303 Acc: 0.9040 Pre: 0.8737 Recall: 0.9361 F1: 0.9038 Train AUC: 0.9917 Val AUC: 0.9717 Time: 13.98\n",
      "Epoch: 479 Train Loss: 0.1273 Val Loss: 0.2340 Acc: 0.9076 Pre: 0.8772 Recall: 0.9398 F1: 0.9074 Train AUC: 0.9911 Val AUC: 0.9713 Time: 13.57\n",
      "Epoch: 480 Train Loss: 0.1240 Val Loss: 0.2204 Acc: 0.9112 Pre: 0.8889 Recall: 0.9323 F1: 0.9101 Train AUC: 0.9912 Val AUC: 0.9731 Time: 13.19\n",
      "Epoch: 481 Train Loss: 0.1230 Val Loss: 0.2150 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9916 Val AUC: 0.9740 Time: 13.34\n",
      "Epoch: 482 Train Loss: 0.1239 Val Loss: 0.2163 Acc: 0.9149 Pre: 0.9041 Recall: 0.9211 F1: 0.9125 Train AUC: 0.9920 Val AUC: 0.9735 Time: 14.13\n",
      "Epoch: 483 Train Loss: 0.1220 Val Loss: 0.2196 Acc: 0.9167 Pre: 0.9044 Recall: 0.9248 F1: 0.9145 Train AUC: 0.9921 Val AUC: 0.9729 Time: 13.82\n",
      "Epoch: 484 Train Loss: 0.1246 Val Loss: 0.2225 Acc: 0.9149 Pre: 0.8925 Recall: 0.9361 F1: 0.9138 Train AUC: 0.9916 Val AUC: 0.9739 Time: 12.44\n",
      "Epoch: 485 Train Loss: 0.1303 Val Loss: 0.2197 Acc: 0.9167 Pre: 0.8873 Recall: 0.9474 F1: 0.9164 Train AUC: 0.9904 Val AUC: 0.9750 Time: 12.93\n",
      "Epoch: 486 Train Loss: 0.1320 Val Loss: 0.2176 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9898 Val AUC: 0.9758 Time: 13.10\n",
      "Epoch: 487 Train Loss: 0.1357 Val Loss: 0.2028 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9898 Val AUC: 0.9761 Time: 14.15\n",
      "Epoch: 488 Train Loss: 0.1239 Val Loss: 0.2092 Acc: 0.9149 Pre: 0.9163 Recall: 0.9060 F1: 0.9112 Train AUC: 0.9914 Val AUC: 0.9749 Time: 14.52\n",
      "Epoch: 489 Train Loss: 0.1309 Val Loss: 0.2313 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9924 Val AUC: 0.9707 Time: 14.29\n",
      "Epoch: 490 Train Loss: 0.1342 Val Loss: 0.2398 Acc: 0.9058 Pre: 0.8821 Recall: 0.9286 F1: 0.9048 Train AUC: 0.9899 Val AUC: 0.9715 Time: 12.72\n",
      "Epoch: 491 Train Loss: 0.1290 Val Loss: 0.2268 Acc: 0.8986 Pre: 0.8804 Recall: 0.9135 F1: 0.8967 Train AUC: 0.9913 Val AUC: 0.9734 Time: 12.68\n",
      "Epoch: 492 Train Loss: 0.1307 Val Loss: 0.2194 Acc: 0.9185 Pre: 0.9139 Recall: 0.9173 F1: 0.9156 Train AUC: 0.9898 Val AUC: 0.9744 Time: 12.56\n",
      "Epoch: 493 Train Loss: 0.1523 Val Loss: 0.2082 Acc: 0.9112 Pre: 0.9004 Recall: 0.9173 F1: 0.9088 Train AUC: 0.9868 Val AUC: 0.9760 Time: 13.67\n",
      "Epoch: 494 Train Loss: 0.1271 Val Loss: 0.2134 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9908 Val AUC: 0.9751 Time: 14.21\n",
      "Epoch: 495 Train Loss: 0.1281 Val Loss: 0.2347 Acc: 0.9094 Pre: 0.9000 Recall: 0.9135 F1: 0.9067 Train AUC: 0.9915 Val AUC: 0.9701 Time: 14.26\n",
      "Epoch: 496 Train Loss: 0.1327 Val Loss: 0.2398 Acc: 0.9094 Pre: 0.8971 Recall: 0.9173 F1: 0.9071 Train AUC: 0.9907 Val AUC: 0.9699 Time: 14.19\n",
      "Epoch: 497 Train Loss: 0.1345 Val Loss: 0.2267 Acc: 0.9112 Pre: 0.8834 Recall: 0.9398 F1: 0.9107 Train AUC: 0.9893 Val AUC: 0.9745 Time: 12.53\n",
      "Epoch: 498 Train Loss: 0.1256 Val Loss: 0.2285 Acc: 0.9112 Pre: 0.8917 Recall: 0.9286 F1: 0.9098 Train AUC: 0.9909 Val AUC: 0.9744 Time: 12.49\n",
      "Epoch: 499 Train Loss: 0.1380 Val Loss: 0.2156 Acc: 0.9094 Pre: 0.8913 Recall: 0.9248 F1: 0.9077 Train AUC: 0.9892 Val AUC: 0.9749 Time: 12.47\n",
      "Epoch: 500 Train Loss: 0.1276 Val Loss: 0.2158 Acc: 0.9112 Pre: 0.8945 Recall: 0.9248 F1: 0.9094 Train AUC: 0.9905 Val AUC: 0.9749 Time: 12.77\n",
      "Epoch: 501 Train Loss: 0.1166 Val Loss: 0.2313 Acc: 0.9076 Pre: 0.8826 Recall: 0.9323 F1: 0.9068 Train AUC: 0.9927 Val AUC: 0.9718 Time: 13.31\n",
      "Epoch: 502 Train Loss: 0.1247 Val Loss: 0.2373 Acc: 0.9058 Pre: 0.8849 Recall: 0.9248 F1: 0.9044 Train AUC: 0.9923 Val AUC: 0.9705 Time: 14.10\n",
      "Epoch: 503 Train Loss: 0.1274 Val Loss: 0.2103 Acc: 0.9203 Pre: 0.9142 Recall: 0.9211 F1: 0.9176 Train AUC: 0.9911 Val AUC: 0.9761 Time: 14.62\n",
      "Epoch: 504 Train Loss: 0.1200 Val Loss: 0.2061 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9933 Val AUC: 0.9769 Time: 14.81\n",
      "Epoch: 505 Train Loss: 0.1211 Val Loss: 0.2216 Acc: 0.9112 Pre: 0.8834 Recall: 0.9398 F1: 0.9107 Train AUC: 0.9919 Val AUC: 0.9752 Time: 12.94\n",
      "Epoch: 506 Train Loss: 0.1340 Val Loss: 0.2170 Acc: 0.9040 Pre: 0.8901 Recall: 0.9135 F1: 0.9017 Train AUC: 0.9910 Val AUC: 0.9751 Time: 12.64\n",
      "Epoch: 507 Train Loss: 0.1310 Val Loss: 0.2228 Acc: 0.9058 Pre: 0.8934 Recall: 0.9135 F1: 0.9033 Train AUC: 0.9897 Val AUC: 0.9739 Time: 12.35\n",
      "Epoch: 508 Train Loss: 0.1246 Val Loss: 0.2243 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9913 Val AUC: 0.9724 Time: 12.84\n",
      "Epoch: 509 Train Loss: 0.1374 Val Loss: 0.2185 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9896 Val AUC: 0.9743 Time: 14.02\n",
      "Epoch: 510 Train Loss: 0.1217 Val Loss: 0.2102 Acc: 0.9130 Pre: 0.8949 Recall: 0.9286 F1: 0.9114 Train AUC: 0.9928 Val AUC: 0.9761 Time: 14.20\n",
      "Epoch: 511 Train Loss: 0.1080 Val Loss: 0.2040 Acc: 0.9130 Pre: 0.9037 Recall: 0.9173 F1: 0.9104 Train AUC: 0.9948 Val AUC: 0.9773 Time: 14.47\n",
      "Epoch: 512 Train Loss: 0.1124 Val Loss: 0.2101 Acc: 0.9022 Pre: 0.8841 Recall: 0.9173 F1: 0.9004 Train AUC: 0.9932 Val AUC: 0.9766 Time: 14.53\n",
      "Epoch: 513 Train Loss: 0.1207 Val Loss: 0.2145 Acc: 0.9076 Pre: 0.8799 Recall: 0.9361 F1: 0.9071 Train AUC: 0.9916 Val AUC: 0.9765 Time: 12.35\n",
      "Epoch: 514 Train Loss: 0.1210 Val Loss: 0.2101 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9920 Val AUC: 0.9759 Time: 12.42\n",
      "Epoch: 515 Train Loss: 0.1300 Val Loss: 0.2040 Acc: 0.9239 Pre: 0.9211 Recall: 0.9211 F1: 0.9211 Train AUC: 0.9908 Val AUC: 0.9767 Time: 12.69\n",
      "Epoch: 516 Train Loss: 0.1204 Val Loss: 0.2063 Acc: 0.9185 Pre: 0.9108 Recall: 0.9211 F1: 0.9159 Train AUC: 0.9926 Val AUC: 0.9759 Time: 12.82\n",
      "Epoch: 517 Train Loss: 0.1187 Val Loss: 0.2293 Acc: 0.9149 Pre: 0.8869 Recall: 0.9436 F1: 0.9144 Train AUC: 0.9924 Val AUC: 0.9739 Time: 13.75\n",
      "Epoch: 518 Train Loss: 0.1255 Val Loss: 0.2353 Acc: 0.9094 Pre: 0.8750 Recall: 0.9474 F1: 0.9097 Train AUC: 0.9913 Val AUC: 0.9734 Time: 14.35\n",
      "Epoch: 519 Train Loss: 0.1235 Val Loss: 0.2149 Acc: 0.9076 Pre: 0.8909 Recall: 0.9211 F1: 0.9057 Train AUC: 0.9924 Val AUC: 0.9752 Time: 14.58\n",
      "Epoch: 520 Train Loss: 0.1199 Val Loss: 0.2105 Acc: 0.9112 Pre: 0.9094 Recall: 0.9060 F1: 0.9077 Train AUC: 0.9921 Val AUC: 0.9766 Time: 14.70\n",
      "Epoch: 521 Train Loss: 0.1310 Val Loss: 0.2146 Acc: 0.9076 Pre: 0.8881 Recall: 0.9248 F1: 0.9061 Train AUC: 0.9910 Val AUC: 0.9756 Time: 12.51\n",
      "Epoch: 522 Train Loss: 0.1173 Val Loss: 0.2168 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9927 Val AUC: 0.9746 Time: 12.68\n",
      "Epoch: 523 Train Loss: 0.1296 Val Loss: 0.2094 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9922 Val AUC: 0.9768 Time: 12.69\n",
      "Epoch: 524 Train Loss: 0.1179 Val Loss: 0.2089 Acc: 0.9167 Pre: 0.9044 Recall: 0.9248 F1: 0.9145 Train AUC: 0.9921 Val AUC: 0.9763 Time: 13.05\n",
      "Epoch: 525 Train Loss: 0.1143 Val Loss: 0.2165 Acc: 0.9076 Pre: 0.8826 Recall: 0.9323 F1: 0.9068 Train AUC: 0.9929 Val AUC: 0.9753 Time: 14.18\n",
      "Epoch: 526 Train Loss: 0.1185 Val Loss: 0.2220 Acc: 0.9076 Pre: 0.8799 Recall: 0.9361 F1: 0.9071 Train AUC: 0.9923 Val AUC: 0.9746 Time: 14.97\n",
      "Epoch: 527 Train Loss: 0.1183 Val Loss: 0.2101 Acc: 0.9185 Pre: 0.9048 Recall: 0.9286 F1: 0.9165 Train AUC: 0.9924 Val AUC: 0.9754 Time: 14.34\n",
      "Epoch: 528 Train Loss: 0.1124 Val Loss: 0.2070 Acc: 0.9167 Pre: 0.9044 Recall: 0.9248 F1: 0.9145 Train AUC: 0.9934 Val AUC: 0.9760 Time: 13.41\n",
      "Epoch: 529 Train Loss: 0.1164 Val Loss: 0.2110 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9926 Val AUC: 0.9763 Time: 12.68\n",
      "Epoch: 530 Train Loss: 0.1143 Val Loss: 0.2203 Acc: 0.9094 Pre: 0.8803 Recall: 0.9398 F1: 0.9091 Train AUC: 0.9928 Val AUC: 0.9761 Time: 12.58\n",
      "Epoch: 531 Train Loss: 0.1166 Val Loss: 0.2133 Acc: 0.9076 Pre: 0.8853 Recall: 0.9286 F1: 0.9064 Train AUC: 0.9935 Val AUC: 0.9766 Time: 12.31\n",
      "Epoch: 532 Train Loss: 0.1140 Val Loss: 0.2088 Acc: 0.9130 Pre: 0.9007 Recall: 0.9211 F1: 0.9108 Train AUC: 0.9929 Val AUC: 0.9770 Time: 12.48\n",
      "Epoch: 533 Train Loss: 0.1206 Val Loss: 0.2091 Acc: 0.9040 Pre: 0.8873 Recall: 0.9173 F1: 0.9020 Train AUC: 0.9917 Val AUC: 0.9766 Time: 13.50\n",
      "Epoch: 534 Train Loss: 0.1204 Val Loss: 0.2189 Acc: 0.9149 Pre: 0.8982 Recall: 0.9286 F1: 0.9131 Train AUC: 0.9920 Val AUC: 0.9744 Time: 13.91\n",
      "Epoch: 535 Train Loss: 0.1151 Val Loss: 0.2146 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9931 Val AUC: 0.9749 Time: 14.45\n",
      "Epoch: 536 Train Loss: 0.1175 Val Loss: 0.2053 Acc: 0.9167 Pre: 0.9104 Recall: 0.9173 F1: 0.9139 Train AUC: 0.9927 Val AUC: 0.9774 Time: 14.92\n",
      "Epoch: 537 Train Loss: 0.1196 Val Loss: 0.2089 Acc: 0.9094 Pre: 0.8913 Recall: 0.9248 F1: 0.9077 Train AUC: 0.9927 Val AUC: 0.9767 Time: 14.42\n",
      "Epoch: 538 Train Loss: 0.1178 Val Loss: 0.2181 Acc: 0.9076 Pre: 0.8799 Recall: 0.9361 F1: 0.9071 Train AUC: 0.9924 Val AUC: 0.9759 Time: 12.95\n",
      "Epoch: 539 Train Loss: 0.1118 Val Loss: 0.2072 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9938 Val AUC: 0.9768 Time: 12.54\n",
      "Epoch: 540 Train Loss: 0.1113 Val Loss: 0.2037 Acc: 0.9185 Pre: 0.9139 Recall: 0.9173 F1: 0.9156 Train AUC: 0.9937 Val AUC: 0.9774 Time: 12.47\n",
      "Epoch: 541 Train Loss: 0.1142 Val Loss: 0.2183 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9935 Val AUC: 0.9748 Time: 12.71\n",
      "Epoch: 542 Train Loss: 0.1106 Val Loss: 0.2137 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9934 Val AUC: 0.9757 Time: 13.38\n",
      "Epoch: 543 Train Loss: 0.1099 Val Loss: 0.2002 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9939 Val AUC: 0.9772 Time: 13.71\n",
      "Epoch: 544 Train Loss: 0.1170 Val Loss: 0.2061 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9932 Val AUC: 0.9767 Time: 14.52\n",
      "Epoch: 545 Train Loss: 0.1134 Val Loss: 0.2270 Acc: 0.9058 Pre: 0.8741 Recall: 0.9398 F1: 0.9058 Train AUC: 0.9928 Val AUC: 0.9744 Time: 15.04\n",
      "Epoch: 546 Train Loss: 0.1119 Val Loss: 0.2261 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9935 Val AUC: 0.9738 Time: 14.85\n",
      "Epoch: 547 Train Loss: 0.1116 Val Loss: 0.2118 Acc: 0.9149 Pre: 0.9011 Recall: 0.9248 F1: 0.9128 Train AUC: 0.9935 Val AUC: 0.9758 Time: 12.58\n",
      "Epoch: 548 Train Loss: 0.1091 Val Loss: 0.2022 Acc: 0.9239 Pre: 0.9308 Recall: 0.9098 F1: 0.9202 Train AUC: 0.9933 Val AUC: 0.9774 Time: 12.58\n",
      "Epoch: 549 Train Loss: 0.1114 Val Loss: 0.2043 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9936 Val AUC: 0.9759 Time: 12.60\n",
      "Epoch: 550 Train Loss: 0.1038 Val Loss: 0.2155 Acc: 0.9203 Pre: 0.9173 Recall: 0.9173 F1: 0.9173 Train AUC: 0.9949 Val AUC: 0.9738 Time: 12.50\n",
      "Epoch: 551 Train Loss: 0.1130 Val Loss: 0.2158 Acc: 0.9076 Pre: 0.8967 Recall: 0.9135 F1: 0.9050 Train AUC: 0.9939 Val AUC: 0.9756 Time: 12.52\n",
      "Epoch: 552 Train Loss: 0.1085 Val Loss: 0.2166 Acc: 0.9112 Pre: 0.8945 Recall: 0.9248 F1: 0.9094 Train AUC: 0.9936 Val AUC: 0.9758 Time: 13.28\n",
      "Epoch: 553 Train Loss: 0.1117 Val Loss: 0.2250 Acc: 0.9094 Pre: 0.8885 Recall: 0.9286 F1: 0.9081 Train AUC: 0.9933 Val AUC: 0.9749 Time: 14.07\n",
      "Epoch: 554 Train Loss: 0.1168 Val Loss: 0.2169 Acc: 0.9149 Pre: 0.9071 Recall: 0.9173 F1: 0.9121 Train AUC: 0.9928 Val AUC: 0.9755 Time: 14.56\n",
      "Epoch: 555 Train Loss: 0.1131 Val Loss: 0.2106 Acc: 0.9185 Pre: 0.9139 Recall: 0.9173 F1: 0.9156 Train AUC: 0.9936 Val AUC: 0.9762 Time: 15.05\n",
      "Epoch: 556 Train Loss: 0.1207 Val Loss: 0.2119 Acc: 0.9094 Pre: 0.8971 Recall: 0.9173 F1: 0.9071 Train AUC: 0.9923 Val AUC: 0.9761 Time: 14.14\n",
      "Epoch: 557 Train Loss: 0.1057 Val Loss: 0.2161 Acc: 0.9040 Pre: 0.8873 Recall: 0.9173 F1: 0.9020 Train AUC: 0.9943 Val AUC: 0.9760 Time: 12.65\n",
      "Epoch: 558 Train Loss: 0.1204 Val Loss: 0.2133 Acc: 0.9239 Pre: 0.9118 Recall: 0.9323 F1: 0.9219 Train AUC: 0.9929 Val AUC: 0.9767 Time: 12.42\n",
      "Epoch: 559 Train Loss: 0.1231 Val Loss: 0.2190 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9912 Val AUC: 0.9757 Time: 12.86\n",
      "Epoch: 560 Train Loss: 0.1186 Val Loss: 0.2203 Acc: 0.9167 Pre: 0.8957 Recall: 0.9361 F1: 0.9154 Train AUC: 0.9917 Val AUC: 0.9749 Time: 13.55\n",
      "Epoch: 561 Train Loss: 0.1308 Val Loss: 0.2150 Acc: 0.9130 Pre: 0.9067 Recall: 0.9135 F1: 0.9101 Train AUC: 0.9919 Val AUC: 0.9752 Time: 14.00\n",
      "Epoch: 562 Train Loss: 0.1151 Val Loss: 0.2315 Acc: 0.9004 Pre: 0.9105 Recall: 0.8797 F1: 0.8948 Train AUC: 0.9927 Val AUC: 0.9747 Time: 14.23\n",
      "Epoch: 563 Train Loss: 0.1470 Val Loss: 0.2569 Acc: 0.9149 Pre: 0.8842 Recall: 0.9474 F1: 0.9147 Train AUC: 0.9899 Val AUC: 0.9745 Time: 14.56\n",
      "Epoch: 564 Train Loss: 0.1262 Val Loss: 0.2305 Acc: 0.9040 Pre: 0.8763 Recall: 0.9323 F1: 0.9035 Train AUC: 0.9925 Val AUC: 0.9746 Time: 12.96\n",
      "Epoch: 565 Train Loss: 0.1294 Val Loss: 0.2133 Acc: 0.9330 Pre: 0.9490 Recall: 0.9098 F1: 0.9290 Train AUC: 0.9915 Val AUC: 0.9745 Time: 12.52\n",
      "Epoch: 566 Train Loss: 0.1505 Val Loss: 0.2229 Acc: 0.9130 Pre: 0.9098 Recall: 0.9098 F1: 0.9098 Train AUC: 0.9878 Val AUC: 0.9726 Time: 12.77\n",
      "Epoch: 567 Train Loss: 0.1262 Val Loss: 0.2520 Acc: 0.9058 Pre: 0.8821 Recall: 0.9286 F1: 0.9048 Train AUC: 0.9913 Val AUC: 0.9662 Time: 12.81\n",
      "Epoch: 568 Train Loss: 0.1718 Val Loss: 0.2345 Acc: 0.9022 Pre: 0.8813 Recall: 0.9211 F1: 0.9007 Train AUC: 0.9839 Val AUC: 0.9740 Time: 13.66\n",
      "Epoch: 569 Train Loss: 0.1192 Val Loss: 0.2529 Acc: 0.9022 Pre: 0.8841 Recall: 0.9173 F1: 0.9004 Train AUC: 0.9918 Val AUC: 0.9710 Time: 14.16\n",
      "Epoch: 570 Train Loss: 0.1459 Val Loss: 0.2428 Acc: 0.9076 Pre: 0.8909 Recall: 0.9211 F1: 0.9057 Train AUC: 0.9869 Val AUC: 0.9725 Time: 15.07\n",
      "Epoch: 571 Train Loss: 0.1346 Val Loss: 0.2138 Acc: 0.9257 Pre: 0.9213 Recall: 0.9248 F1: 0.9231 Train AUC: 0.9888 Val AUC: 0.9753 Time: 13.19\n",
      "Epoch: 572 Train Loss: 0.1273 Val Loss: 0.2258 Acc: 0.9130 Pre: 0.9291 Recall: 0.8872 F1: 0.9077 Train AUC: 0.9906 Val AUC: 0.9735 Time: 12.76\n",
      "Epoch: 573 Train Loss: 0.1259 Val Loss: 0.2369 Acc: 0.9058 Pre: 0.8934 Recall: 0.9135 F1: 0.9033 Train AUC: 0.9914 Val AUC: 0.9703 Time: 13.46\n",
      "Epoch: 574 Train Loss: 0.1362 Val Loss: 0.2290 Acc: 0.9112 Pre: 0.8889 Recall: 0.9323 F1: 0.9101 Train AUC: 0.9895 Val AUC: 0.9727 Time: 13.83\n",
      "Epoch: 575 Train Loss: 0.1210 Val Loss: 0.2166 Acc: 0.9040 Pre: 0.8817 Recall: 0.9248 F1: 0.9028 Train AUC: 0.9922 Val AUC: 0.9752 Time: 14.41\n",
      "Epoch: 576 Train Loss: 0.1205 Val Loss: 0.2210 Acc: 0.9040 Pre: 0.8817 Recall: 0.9248 F1: 0.9028 Train AUC: 0.9914 Val AUC: 0.9747 Time: 14.41\n",
      "Epoch: 577 Train Loss: 0.1314 Val Loss: 0.2315 Acc: 0.9058 Pre: 0.8741 Recall: 0.9398 F1: 0.9058 Train AUC: 0.9896 Val AUC: 0.9750 Time: 12.68\n",
      "Epoch: 578 Train Loss: 0.1264 Val Loss: 0.2332 Acc: 0.9130 Pre: 0.8759 Recall: 0.9549 F1: 0.9137 Train AUC: 0.9904 Val AUC: 0.9741 Time: 12.58\n",
      "Epoch: 579 Train Loss: 0.1116 Val Loss: 0.2470 Acc: 0.9112 Pre: 0.8834 Recall: 0.9398 F1: 0.9107 Train AUC: 0.9937 Val AUC: 0.9703 Time: 12.56\n",
      "Epoch: 580 Train Loss: 0.1361 Val Loss: 0.2293 Acc: 0.9022 Pre: 0.9109 Recall: 0.8835 F1: 0.8969 Train AUC: 0.9904 Val AUC: 0.9732 Time: 12.57\n",
      "Epoch: 581 Train Loss: 0.1398 Val Loss: 0.2175 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9906 Val AUC: 0.9757 Time: 13.51\n",
      "Epoch: 582 Train Loss: 0.1179 Val Loss: 0.2485 Acc: 0.9130 Pre: 0.8759 Recall: 0.9549 F1: 0.9137 Train AUC: 0.9920 Val AUC: 0.9751 Time: 13.84\n",
      "Epoch: 583 Train Loss: 0.1278 Val Loss: 0.2293 Acc: 0.9094 Pre: 0.8830 Recall: 0.9361 F1: 0.9088 Train AUC: 0.9926 Val AUC: 0.9763 Time: 14.41\n",
      "Epoch: 584 Train Loss: 0.1197 Val Loss: 0.2095 Acc: 0.9185 Pre: 0.9234 Recall: 0.9060 F1: 0.9146 Train AUC: 0.9912 Val AUC: 0.9774 Time: 14.03\n",
      "Epoch: 585 Train Loss: 0.1260 Val Loss: 0.1983 Acc: 0.9185 Pre: 0.9139 Recall: 0.9173 F1: 0.9156 Train AUC: 0.9914 Val AUC: 0.9757 Time: 14.24\n",
      "Epoch: 586 Train Loss: 0.1154 Val Loss: 0.2150 Acc: 0.9149 Pre: 0.8953 Recall: 0.9323 F1: 0.9134 Train AUC: 0.9927 Val AUC: 0.9730 Time: 12.82\n",
      "Epoch: 587 Train Loss: 0.1360 Val Loss: 0.2203 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9907 Val AUC: 0.9751 Time: 12.61\n",
      "Epoch: 588 Train Loss: 0.1055 Val Loss: 0.2303 Acc: 0.9076 Pre: 0.8772 Recall: 0.9398 F1: 0.9074 Train AUC: 0.9942 Val AUC: 0.9742 Time: 12.66\n",
      "Epoch: 589 Train Loss: 0.1102 Val Loss: 0.2287 Acc: 0.9112 Pre: 0.8889 Recall: 0.9323 F1: 0.9101 Train AUC: 0.9928 Val AUC: 0.9739 Time: 13.95\n",
      "Epoch: 590 Train Loss: 0.1138 Val Loss: 0.2204 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9923 Val AUC: 0.9749 Time: 14.14\n",
      "Epoch: 591 Train Loss: 0.1229 Val Loss: 0.2023 Acc: 0.9257 Pre: 0.9182 Recall: 0.9286 F1: 0.9234 Train AUC: 0.9914 Val AUC: 0.9772 Time: 14.05\n",
      "Epoch: 592 Train Loss: 0.1278 Val Loss: 0.1992 Acc: 0.9257 Pre: 0.9278 Recall: 0.9173 F1: 0.9225 Train AUC: 0.9906 Val AUC: 0.9776 Time: 12.41\n",
      "Epoch: 593 Train Loss: 0.1192 Val Loss: 0.2182 Acc: 0.9185 Pre: 0.9048 Recall: 0.9286 F1: 0.9165 Train AUC: 0.9925 Val AUC: 0.9761 Time: 12.68\n",
      "Epoch: 594 Train Loss: 0.1175 Val Loss: 0.2157 Acc: 0.9167 Pre: 0.9044 Recall: 0.9248 F1: 0.9145 Train AUC: 0.9929 Val AUC: 0.9766 Time: 13.41\n",
      "Epoch: 595 Train Loss: 0.1150 Val Loss: 0.2033 Acc: 0.9130 Pre: 0.9037 Recall: 0.9173 F1: 0.9104 Train AUC: 0.9926 Val AUC: 0.9772 Time: 13.73\n",
      "Epoch: 596 Train Loss: 0.1216 Val Loss: 0.1999 Acc: 0.9203 Pre: 0.9173 Recall: 0.9173 F1: 0.9173 Train AUC: 0.9916 Val AUC: 0.9779 Time: 14.35\n",
      "Epoch: 597 Train Loss: 0.1242 Val Loss: 0.2154 Acc: 0.9094 Pre: 0.8913 Recall: 0.9248 F1: 0.9077 Train AUC: 0.9918 Val AUC: 0.9768 Time: 15.35\n",
      "Epoch: 598 Train Loss: 0.1074 Val Loss: 0.2527 Acc: 0.9004 Pre: 0.8601 Recall: 0.9474 F1: 0.9016 Train AUC: 0.9942 Val AUC: 0.9724 Time: 13.59\n",
      "Epoch: 599 Train Loss: 0.1255 Val Loss: 0.2245 Acc: 0.9076 Pre: 0.8826 Recall: 0.9323 F1: 0.9068 Train AUC: 0.9926 Val AUC: 0.9749 Time: 12.64\n",
      "Epoch: 600 Train Loss: 0.1110 Val Loss: 0.2032 Acc: 0.9312 Pre: 0.9351 Recall: 0.9211 F1: 0.9280 Train AUC: 0.9934 Val AUC: 0.9780 Time: 12.48\n",
      "Epoch: 601 Train Loss: 0.1165 Val Loss: 0.2021 Acc: 0.9330 Pre: 0.9288 Recall: 0.9323 F1: 0.9306 Train AUC: 0.9928 Val AUC: 0.9771 Time: 12.62\n",
      "Epoch: 602 Train Loss: 0.1125 Val Loss: 0.2174 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9930 Val AUC: 0.9759 Time: 12.90\n",
      "Epoch: 603 Train Loss: 0.1175 Val Loss: 0.2352 Acc: 0.9076 Pre: 0.8826 Recall: 0.9323 F1: 0.9068 Train AUC: 0.9934 Val AUC: 0.9737 Time: 12.53\n",
      "Epoch: 604 Train Loss: 0.1095 Val Loss: 0.2476 Acc: 0.9076 Pre: 0.8938 Recall: 0.9173 F1: 0.9054 Train AUC: 0.9938 Val AUC: 0.9713 Time: 12.51\n",
      "Epoch: 605 Train Loss: 0.1222 Val Loss: 0.2262 Acc: 0.9149 Pre: 0.9041 Recall: 0.9211 F1: 0.9125 Train AUC: 0.9914 Val AUC: 0.9742 Time: 14.05\n",
      "Epoch: 606 Train Loss: 0.1055 Val Loss: 0.2096 Acc: 0.9130 Pre: 0.9037 Recall: 0.9173 F1: 0.9104 Train AUC: 0.9943 Val AUC: 0.9757 Time: 14.68\n",
      "Epoch: 607 Train Loss: 0.1040 Val Loss: 0.2161 Acc: 0.9167 Pre: 0.9015 Recall: 0.9286 F1: 0.9148 Train AUC: 0.9946 Val AUC: 0.9754 Time: 14.74\n",
      "Epoch: 608 Train Loss: 0.1169 Val Loss: 0.2135 Acc: 0.9185 Pre: 0.9018 Recall: 0.9323 F1: 0.9168 Train AUC: 0.9930 Val AUC: 0.9764 Time: 14.16\n",
      "Epoch: 609 Train Loss: 0.1055 Val Loss: 0.2159 Acc: 0.9094 Pre: 0.9030 Recall: 0.9098 F1: 0.9064 Train AUC: 0.9939 Val AUC: 0.9763 Time: 13.89\n",
      "Epoch: 610 Train Loss: 0.1094 Val Loss: 0.2386 Acc: 0.9040 Pre: 0.8817 Recall: 0.9248 F1: 0.9028 Train AUC: 0.9935 Val AUC: 0.9731 Time: 12.40\n",
      "Epoch: 611 Train Loss: 0.1219 Val Loss: 0.2582 Acc: 0.8986 Pre: 0.8671 Recall: 0.9323 F1: 0.8986 Train AUC: 0.9915 Val AUC: 0.9714 Time: 12.63\n",
      "Epoch: 612 Train Loss: 0.1258 Val Loss: 0.2156 Acc: 0.9149 Pre: 0.8953 Recall: 0.9323 F1: 0.9134 Train AUC: 0.9915 Val AUC: 0.9758 Time: 12.73\n",
      "Epoch: 613 Train Loss: 0.1058 Val Loss: 0.1972 Acc: 0.9348 Pre: 0.9323 Recall: 0.9323 F1: 0.9323 Train AUC: 0.9946 Val AUC: 0.9775 Time: 12.59\n",
      "Epoch: 614 Train Loss: 0.1133 Val Loss: 0.1986 Acc: 0.9293 Pre: 0.9251 Recall: 0.9286 F1: 0.9268 Train AUC: 0.9934 Val AUC: 0.9769 Time: 12.85\n",
      "Epoch: 615 Train Loss: 0.1205 Val Loss: 0.2006 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9924 Val AUC: 0.9776 Time: 13.30\n",
      "Epoch: 616 Train Loss: 0.1076 Val Loss: 0.2163 Acc: 0.9149 Pre: 0.8953 Recall: 0.9323 F1: 0.9134 Train AUC: 0.9935 Val AUC: 0.9763 Time: 14.28\n",
      "Epoch: 617 Train Loss: 0.1004 Val Loss: 0.2379 Acc: 0.9004 Pre: 0.8754 Recall: 0.9248 F1: 0.8995 Train AUC: 0.9950 Val AUC: 0.9741 Time: 14.70\n",
      "Epoch: 618 Train Loss: 0.1040 Val Loss: 0.2199 Acc: 0.9149 Pre: 0.9071 Recall: 0.9173 F1: 0.9121 Train AUC: 0.9947 Val AUC: 0.9755 Time: 14.21\n",
      "Epoch: 619 Train Loss: 0.1139 Val Loss: 0.2083 Acc: 0.9221 Pre: 0.9208 Recall: 0.9173 F1: 0.9190 Train AUC: 0.9932 Val AUC: 0.9769 Time: 14.23\n",
      "Epoch: 620 Train Loss: 0.1137 Val Loss: 0.2101 Acc: 0.9221 Pre: 0.9055 Recall: 0.9361 F1: 0.9205 Train AUC: 0.9941 Val AUC: 0.9763 Time: 12.54\n",
      "Epoch: 621 Train Loss: 0.1021 Val Loss: 0.2229 Acc: 0.9167 Pre: 0.8929 Recall: 0.9398 F1: 0.9158 Train AUC: 0.9953 Val AUC: 0.9753 Time: 12.56\n",
      "Epoch: 622 Train Loss: 0.1099 Val Loss: 0.2171 Acc: 0.9058 Pre: 0.8821 Recall: 0.9286 F1: 0.9048 Train AUC: 0.9952 Val AUC: 0.9763 Time: 12.49\n",
      "Epoch: 623 Train Loss: 0.1032 Val Loss: 0.2148 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9945 Val AUC: 0.9765 Time: 12.52\n",
      "Epoch: 624 Train Loss: 0.1098 Val Loss: 0.2100 Acc: 0.9221 Pre: 0.9145 Recall: 0.9248 F1: 0.9196 Train AUC: 0.9936 Val AUC: 0.9766 Time: 14.20\n",
      "Epoch: 625 Train Loss: 0.1069 Val Loss: 0.2103 Acc: 0.9167 Pre: 0.9015 Recall: 0.9286 F1: 0.9148 Train AUC: 0.9936 Val AUC: 0.9764 Time: 14.21\n",
      "Epoch: 626 Train Loss: 0.0960 Val Loss: 0.2094 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9960 Val AUC: 0.9764 Time: 14.74\n",
      "Epoch: 627 Train Loss: 0.0943 Val Loss: 0.2127 Acc: 0.9221 Pre: 0.9114 Recall: 0.9286 F1: 0.9199 Train AUC: 0.9962 Val AUC: 0.9763 Time: 14.35\n",
      "Epoch: 628 Train Loss: 0.0967 Val Loss: 0.2135 Acc: 0.9221 Pre: 0.9114 Recall: 0.9286 F1: 0.9199 Train AUC: 0.9953 Val AUC: 0.9764 Time: 12.33\n",
      "Epoch: 629 Train Loss: 0.1069 Val Loss: 0.2174 Acc: 0.9149 Pre: 0.8982 Recall: 0.9286 F1: 0.9131 Train AUC: 0.9941 Val AUC: 0.9759 Time: 12.53\n",
      "Epoch: 630 Train Loss: 0.1090 Val Loss: 0.2095 Acc: 0.9185 Pre: 0.9077 Recall: 0.9248 F1: 0.9162 Train AUC: 0.9936 Val AUC: 0.9766 Time: 12.48\n",
      "Epoch: 631 Train Loss: 0.1029 Val Loss: 0.2051 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9942 Val AUC: 0.9770 Time: 13.08\n",
      "Epoch: 632 Train Loss: 0.1039 Val Loss: 0.2092 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9949 Val AUC: 0.9767 Time: 14.16\n",
      "Epoch: 633 Train Loss: 0.0966 Val Loss: 0.2241 Acc: 0.9130 Pre: 0.8921 Recall: 0.9323 F1: 0.9118 Train AUC: 0.9954 Val AUC: 0.9753 Time: 14.11\n",
      "Epoch: 634 Train Loss: 0.1045 Val Loss: 0.2300 Acc: 0.9076 Pre: 0.8881 Recall: 0.9248 F1: 0.9061 Train AUC: 0.9943 Val AUC: 0.9743 Time: 14.18\n",
      "Epoch: 635 Train Loss: 0.0988 Val Loss: 0.2172 Acc: 0.9112 Pre: 0.9033 Recall: 0.9135 F1: 0.9084 Train AUC: 0.9953 Val AUC: 0.9756 Time: 14.25\n",
      "Epoch: 636 Train Loss: 0.1075 Val Loss: 0.2112 Acc: 0.9203 Pre: 0.9173 Recall: 0.9173 F1: 0.9173 Train AUC: 0.9940 Val AUC: 0.9754 Time: 12.86\n",
      "Epoch: 637 Train Loss: 0.0995 Val Loss: 0.2134 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9958 Val AUC: 0.9760 Time: 12.55\n",
      "Epoch: 638 Train Loss: 0.1094 Val Loss: 0.2142 Acc: 0.9221 Pre: 0.9114 Recall: 0.9286 F1: 0.9199 Train AUC: 0.9944 Val AUC: 0.9766 Time: 13.00\n",
      "Epoch: 639 Train Loss: 0.1002 Val Loss: 0.2170 Acc: 0.9221 Pre: 0.9208 Recall: 0.9173 F1: 0.9190 Train AUC: 0.9952 Val AUC: 0.9759 Time: 14.77\n",
      "Epoch: 640 Train Loss: 0.1043 Val Loss: 0.2165 Acc: 0.9257 Pre: 0.9278 Recall: 0.9173 F1: 0.9225 Train AUC: 0.9942 Val AUC: 0.9757 Time: 16.31\n",
      "Epoch: 641 Train Loss: 0.0983 Val Loss: 0.2179 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9955 Val AUC: 0.9753 Time: 14.30\n",
      "Epoch: 642 Train Loss: 0.1016 Val Loss: 0.2245 Acc: 0.9185 Pre: 0.9048 Recall: 0.9286 F1: 0.9165 Train AUC: 0.9945 Val AUC: 0.9749 Time: 12.88\n",
      "Epoch: 643 Train Loss: 0.1071 Val Loss: 0.2137 Acc: 0.9221 Pre: 0.9176 Recall: 0.9211 F1: 0.9193 Train AUC: 0.9947 Val AUC: 0.9766 Time: 12.55\n",
      "Epoch: 644 Train Loss: 0.1005 Val Loss: 0.2153 Acc: 0.9112 Pre: 0.8945 Recall: 0.9248 F1: 0.9094 Train AUC: 0.9951 Val AUC: 0.9768 Time: 12.89\n",
      "Epoch: 645 Train Loss: 0.1031 Val Loss: 0.2190 Acc: 0.9040 Pre: 0.8817 Recall: 0.9248 F1: 0.9028 Train AUC: 0.9943 Val AUC: 0.9770 Time: 12.98\n",
      "Epoch: 646 Train Loss: 0.1037 Val Loss: 0.2139 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9944 Val AUC: 0.9769 Time: 14.06\n",
      "Epoch: 647 Train Loss: 0.1011 Val Loss: 0.2147 Acc: 0.9257 Pre: 0.9121 Recall: 0.9361 F1: 0.9239 Train AUC: 0.9944 Val AUC: 0.9763 Time: 12.94\n",
      "Epoch: 648 Train Loss: 0.1047 Val Loss: 0.2131 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9942 Val AUC: 0.9767 Time: 12.43\n",
      "Epoch: 649 Train Loss: 0.0952 Val Loss: 0.2172 Acc: 0.9221 Pre: 0.9208 Recall: 0.9173 F1: 0.9190 Train AUC: 0.9953 Val AUC: 0.9763 Time: 12.86\n",
      "Epoch: 650 Train Loss: 0.1012 Val Loss: 0.2201 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9949 Val AUC: 0.9757 Time: 13.50\n",
      "Epoch: 651 Train Loss: 0.0997 Val Loss: 0.2213 Acc: 0.9257 Pre: 0.9182 Recall: 0.9286 F1: 0.9234 Train AUC: 0.9945 Val AUC: 0.9753 Time: 14.39\n",
      "Epoch: 652 Train Loss: 0.1087 Val Loss: 0.2159 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9936 Val AUC: 0.9762 Time: 14.43\n",
      "Epoch: 653 Train Loss: 0.0984 Val Loss: 0.2145 Acc: 0.9257 Pre: 0.9278 Recall: 0.9173 F1: 0.9225 Train AUC: 0.9951 Val AUC: 0.9768 Time: 12.61\n",
      "Epoch: 654 Train Loss: 0.1003 Val Loss: 0.2160 Acc: 0.9257 Pre: 0.9245 Recall: 0.9211 F1: 0.9228 Train AUC: 0.9944 Val AUC: 0.9767 Time: 13.01\n",
      "Epoch: 655 Train Loss: 0.1003 Val Loss: 0.2184 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9945 Val AUC: 0.9769 Time: 13.77\n",
      "Epoch: 656 Train Loss: 0.0965 Val Loss: 0.2136 Acc: 0.9221 Pre: 0.9145 Recall: 0.9248 F1: 0.9196 Train AUC: 0.9954 Val AUC: 0.9770 Time: 14.70\n",
      "Epoch: 657 Train Loss: 0.0964 Val Loss: 0.2099 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9953 Val AUC: 0.9771 Time: 13.24\n",
      "Epoch: 658 Train Loss: 0.1007 Val Loss: 0.2111 Acc: 0.9257 Pre: 0.9278 Recall: 0.9173 F1: 0.9225 Train AUC: 0.9947 Val AUC: 0.9768 Time: 12.97\n",
      "Epoch: 659 Train Loss: 0.0979 Val Loss: 0.2188 Acc: 0.9203 Pre: 0.9205 Recall: 0.9135 F1: 0.9170 Train AUC: 0.9950 Val AUC: 0.9760 Time: 12.81\n",
      "Epoch: 660 Train Loss: 0.1067 Val Loss: 0.2213 Acc: 0.9221 Pre: 0.9145 Recall: 0.9248 F1: 0.9196 Train AUC: 0.9943 Val AUC: 0.9753 Time: 12.69\n",
      "Epoch: 661 Train Loss: 0.0902 Val Loss: 0.2289 Acc: 0.9293 Pre: 0.9097 Recall: 0.9474 F1: 0.9282 Train AUC: 0.9966 Val AUC: 0.9756 Time: 12.90\n",
      "Epoch: 662 Train Loss: 0.1072 Val Loss: 0.2080 Acc: 0.9312 Pre: 0.9254 Recall: 0.9323 F1: 0.9288 Train AUC: 0.9955 Val AUC: 0.9776 Time: 13.86\n",
      "Epoch: 663 Train Loss: 0.0941 Val Loss: 0.2098 Acc: 0.9239 Pre: 0.9375 Recall: 0.9023 F1: 0.9195 Train AUC: 0.9957 Val AUC: 0.9780 Time: 14.23\n",
      "Epoch: 664 Train Loss: 0.1220 Val Loss: 0.2094 Acc: 0.9293 Pre: 0.9283 Recall: 0.9248 F1: 0.9266 Train AUC: 0.9923 Val AUC: 0.9774 Time: 14.54\n",
      "Epoch: 665 Train Loss: 0.0997 Val Loss: 0.2594 Acc: 0.9076 Pre: 0.8746 Recall: 0.9436 F1: 0.9078 Train AUC: 0.9950 Val AUC: 0.9712 Time: 14.81\n",
      "Epoch: 666 Train Loss: 0.1218 Val Loss: 0.2287 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9934 Val AUC: 0.9743 Time: 12.48\n",
      "Epoch: 667 Train Loss: 0.1070 Val Loss: 0.2033 Acc: 0.9312 Pre: 0.9318 Recall: 0.9248 F1: 0.9283 Train AUC: 0.9944 Val AUC: 0.9778 Time: 12.46\n",
      "Epoch: 668 Train Loss: 0.0994 Val Loss: 0.2042 Acc: 0.9293 Pre: 0.9316 Recall: 0.9211 F1: 0.9263 Train AUC: 0.9957 Val AUC: 0.9781 Time: 12.65\n",
      "Epoch: 669 Train Loss: 0.1061 Val Loss: 0.2189 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9946 Val AUC: 0.9770 Time: 12.56\n",
      "Epoch: 670 Train Loss: 0.0979 Val Loss: 0.2619 Acc: 0.9130 Pre: 0.8759 Recall: 0.9549 F1: 0.9137 Train AUC: 0.9949 Val AUC: 0.9741 Time: 12.69\n",
      "Epoch: 671 Train Loss: 0.1163 Val Loss: 0.2331 Acc: 0.9185 Pre: 0.8905 Recall: 0.9474 F1: 0.9180 Train AUC: 0.9946 Val AUC: 0.9756 Time: 13.91\n",
      "Epoch: 672 Train Loss: 0.0955 Val Loss: 0.2047 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9954 Val AUC: 0.9784 Time: 14.25\n",
      "Epoch: 673 Train Loss: 0.1009 Val Loss: 0.2005 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9945 Val AUC: 0.9780 Time: 15.43\n",
      "Epoch: 674 Train Loss: 0.1011 Val Loss: 0.2053 Acc: 0.9257 Pre: 0.9121 Recall: 0.9361 F1: 0.9239 Train AUC: 0.9951 Val AUC: 0.9757 Time: 13.81\n",
      "Epoch: 675 Train Loss: 0.1104 Val Loss: 0.2266 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9940 Val AUC: 0.9758 Time: 12.67\n",
      "Epoch: 676 Train Loss: 0.0914 Val Loss: 0.2296 Acc: 0.9221 Pre: 0.8968 Recall: 0.9474 F1: 0.9214 Train AUC: 0.9962 Val AUC: 0.9756 Time: 12.49\n",
      "Epoch: 677 Train Loss: 0.0974 Val Loss: 0.2178 Acc: 0.9293 Pre: 0.9283 Recall: 0.9248 F1: 0.9266 Train AUC: 0.9950 Val AUC: 0.9760 Time: 12.58\n",
      "Epoch: 678 Train Loss: 0.1102 Val Loss: 0.2175 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9932 Val AUC: 0.9759 Time: 13.43\n",
      "Epoch: 679 Train Loss: 0.1016 Val Loss: 0.2272 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9946 Val AUC: 0.9743 Time: 13.73\n",
      "Epoch: 680 Train Loss: 0.1073 Val Loss: 0.2154 Acc: 0.9221 Pre: 0.9145 Recall: 0.9248 F1: 0.9196 Train AUC: 0.9941 Val AUC: 0.9764 Time: 14.44\n",
      "Epoch: 681 Train Loss: 0.0989 Val Loss: 0.2193 Acc: 0.9293 Pre: 0.9188 Recall: 0.9361 F1: 0.9274 Train AUC: 0.9947 Val AUC: 0.9768 Time: 14.00\n",
      "Epoch: 682 Train Loss: 0.0957 Val Loss: 0.2370 Acc: 0.9149 Pre: 0.8897 Recall: 0.9398 F1: 0.9141 Train AUC: 0.9952 Val AUC: 0.9755 Time: 14.29\n",
      "Epoch: 683 Train Loss: 0.1040 Val Loss: 0.2314 Acc: 0.9221 Pre: 0.8968 Recall: 0.9474 F1: 0.9214 Train AUC: 0.9939 Val AUC: 0.9756 Time: 12.37\n",
      "Epoch: 684 Train Loss: 0.1079 Val Loss: 0.2093 Acc: 0.9239 Pre: 0.9211 Recall: 0.9211 F1: 0.9211 Train AUC: 0.9942 Val AUC: 0.9768 Time: 12.72\n",
      "Epoch: 685 Train Loss: 0.1039 Val Loss: 0.2020 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9950 Val AUC: 0.9776 Time: 12.61\n",
      "Epoch: 686 Train Loss: 0.0988 Val Loss: 0.2065 Acc: 0.9312 Pre: 0.9222 Recall: 0.9361 F1: 0.9291 Train AUC: 0.9958 Val AUC: 0.9776 Time: 12.57\n",
      "Epoch: 687 Train Loss: 0.1009 Val Loss: 0.2287 Acc: 0.9293 Pre: 0.9127 Recall: 0.9436 F1: 0.9279 Train AUC: 0.9948 Val AUC: 0.9757 Time: 12.88\n",
      "Epoch: 688 Train Loss: 0.0992 Val Loss: 0.2457 Acc: 0.9130 Pre: 0.8811 Recall: 0.9474 F1: 0.9130 Train AUC: 0.9947 Val AUC: 0.9737 Time: 13.86\n",
      "Epoch: 689 Train Loss: 0.1020 Val Loss: 0.2259 Acc: 0.9221 Pre: 0.9145 Recall: 0.9248 F1: 0.9196 Train AUC: 0.9952 Val AUC: 0.9750 Time: 14.56\n",
      "Epoch: 690 Train Loss: 0.0985 Val Loss: 0.2104 Acc: 0.9257 Pre: 0.9278 Recall: 0.9173 F1: 0.9225 Train AUC: 0.9955 Val AUC: 0.9774 Time: 14.37\n",
      "Epoch: 691 Train Loss: 0.0966 Val Loss: 0.2080 Acc: 0.9293 Pre: 0.9251 Recall: 0.9286 F1: 0.9268 Train AUC: 0.9951 Val AUC: 0.9771 Time: 13.35\n",
      "Epoch: 692 Train Loss: 0.1005 Val Loss: 0.2245 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9954 Val AUC: 0.9761 Time: 13.54\n",
      "Epoch: 693 Train Loss: 0.0988 Val Loss: 0.2218 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9959 Val AUC: 0.9768 Time: 13.56\n",
      "Epoch: 694 Train Loss: 0.0931 Val Loss: 0.2216 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9955 Val AUC: 0.9767 Time: 13.65\n",
      "Epoch: 695 Train Loss: 0.0924 Val Loss: 0.2278 Acc: 0.9167 Pre: 0.9135 Recall: 0.9135 F1: 0.9135 Train AUC: 0.9960 Val AUC: 0.9761 Time: 13.00\n",
      "Epoch: 696 Train Loss: 0.0904 Val Loss: 0.2284 Acc: 0.9257 Pre: 0.9151 Recall: 0.9323 F1: 0.9236 Train AUC: 0.9958 Val AUC: 0.9756 Time: 13.44\n",
      "Epoch: 697 Train Loss: 0.0901 Val Loss: 0.2252 Acc: 0.9275 Pre: 0.9154 Recall: 0.9361 F1: 0.9257 Train AUC: 0.9960 Val AUC: 0.9749 Time: 13.84\n",
      "Epoch: 698 Train Loss: 0.0995 Val Loss: 0.2137 Acc: 0.9293 Pre: 0.9188 Recall: 0.9361 F1: 0.9274 Train AUC: 0.9957 Val AUC: 0.9759 Time: 14.07\n",
      "Epoch: 699 Train Loss: 0.1122 Val Loss: 0.2103 Acc: 0.9275 Pre: 0.9280 Recall: 0.9211 F1: 0.9245 Train AUC: 0.9929 Val AUC: 0.9775 Time: 12.35\n",
      "Epoch: 700 Train Loss: 0.0984 Val Loss: 0.2193 Acc: 0.9312 Pre: 0.9254 Recall: 0.9323 F1: 0.9288 Train AUC: 0.9955 Val AUC: 0.9770 Time: 12.38\n",
      "Epoch: 701 Train Loss: 0.0901 Val Loss: 0.2326 Acc: 0.9239 Pre: 0.9000 Recall: 0.9474 F1: 0.9231 Train AUC: 0.9954 Val AUC: 0.9763 Time: 12.57\n",
      "Epoch: 702 Train Loss: 0.1007 Val Loss: 0.2264 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9946 Val AUC: 0.9761 Time: 12.76\n",
      "Epoch: 703 Train Loss: 0.1037 Val Loss: 0.2119 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9946 Val AUC: 0.9777 Time: 13.76\n",
      "Epoch: 704 Train Loss: 0.1040 Val Loss: 0.2053 Acc: 0.9293 Pre: 0.9316 Recall: 0.9211 F1: 0.9263 Train AUC: 0.9938 Val AUC: 0.9776 Time: 14.08\n",
      "Epoch: 705 Train Loss: 0.1041 Val Loss: 0.2101 Acc: 0.9239 Pre: 0.9118 Recall: 0.9323 F1: 0.9219 Train AUC: 0.9943 Val AUC: 0.9760 Time: 14.59\n",
      "Epoch: 706 Train Loss: 0.0974 Val Loss: 0.2182 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9958 Val AUC: 0.9772 Time: 14.61\n",
      "Epoch: 707 Train Loss: 0.0924 Val Loss: 0.2241 Acc: 0.9149 Pre: 0.8897 Recall: 0.9398 F1: 0.9141 Train AUC: 0.9961 Val AUC: 0.9775 Time: 12.99\n",
      "Epoch: 708 Train Loss: 0.0942 Val Loss: 0.2184 Acc: 0.9293 Pre: 0.9158 Recall: 0.9398 F1: 0.9276 Train AUC: 0.9960 Val AUC: 0.9779 Time: 12.39\n",
      "Epoch: 709 Train Loss: 0.1059 Val Loss: 0.2061 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9935 Val AUC: 0.9783 Time: 12.49\n",
      "Epoch: 710 Train Loss: 0.1044 Val Loss: 0.2211 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9945 Val AUC: 0.9756 Time: 12.94\n",
      "Epoch: 711 Train Loss: 0.1179 Val Loss: 0.2236 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9925 Val AUC: 0.9776 Time: 13.84\n",
      "Epoch: 712 Train Loss: 0.1004 Val Loss: 0.2298 Acc: 0.9149 Pre: 0.9101 Recall: 0.9135 F1: 0.9118 Train AUC: 0.9952 Val AUC: 0.9761 Time: 13.95\n",
      "Epoch: 713 Train Loss: 0.1125 Val Loss: 0.2287 Acc: 0.9167 Pre: 0.9167 Recall: 0.9098 F1: 0.9132 Train AUC: 0.9929 Val AUC: 0.9766 Time: 14.67\n",
      "Epoch: 714 Train Loss: 0.1088 Val Loss: 0.2247 Acc: 0.9112 Pre: 0.8917 Recall: 0.9286 F1: 0.9098 Train AUC: 0.9933 Val AUC: 0.9753 Time: 14.53\n",
      "Epoch: 715 Train Loss: 0.0973 Val Loss: 0.2295 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9952 Val AUC: 0.9740 Time: 12.52\n",
      "Epoch: 716 Train Loss: 0.1203 Val Loss: 0.2062 Acc: 0.9348 Pre: 0.9323 Recall: 0.9323 F1: 0.9323 Train AUC: 0.9932 Val AUC: 0.9774 Time: 12.55\n",
      "Epoch: 717 Train Loss: 0.0927 Val Loss: 0.2113 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9958 Val AUC: 0.9771 Time: 12.36\n",
      "Epoch: 718 Train Loss: 0.1039 Val Loss: 0.2284 Acc: 0.9239 Pre: 0.9148 Recall: 0.9286 F1: 0.9216 Train AUC: 0.9955 Val AUC: 0.9752 Time: 12.45\n",
      "Epoch: 719 Train Loss: 0.0944 Val Loss: 0.2490 Acc: 0.9185 Pre: 0.8905 Recall: 0.9474 F1: 0.9180 Train AUC: 0.9957 Val AUC: 0.9735 Time: 12.63\n",
      "Epoch: 720 Train Loss: 0.1057 Val Loss: 0.2258 Acc: 0.9239 Pre: 0.9088 Recall: 0.9361 F1: 0.9222 Train AUC: 0.9941 Val AUC: 0.9765 Time: 13.99\n",
      "Epoch: 721 Train Loss: 0.0949 Val Loss: 0.2054 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9963 Val AUC: 0.9783 Time: 14.32\n",
      "Epoch: 722 Train Loss: 0.1003 Val Loss: 0.2029 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9947 Val AUC: 0.9791 Time: 14.79\n",
      "Epoch: 723 Train Loss: 0.0973 Val Loss: 0.2081 Acc: 0.9275 Pre: 0.9185 Recall: 0.9323 F1: 0.9254 Train AUC: 0.9950 Val AUC: 0.9785 Time: 14.70\n",
      "Epoch: 724 Train Loss: 0.0995 Val Loss: 0.2124 Acc: 0.9167 Pre: 0.9044 Recall: 0.9248 F1: 0.9145 Train AUC: 0.9950 Val AUC: 0.9758 Time: 13.40\n",
      "Epoch: 725 Train Loss: 0.0906 Val Loss: 0.2118 Acc: 0.9112 Pre: 0.9033 Recall: 0.9135 F1: 0.9084 Train AUC: 0.9965 Val AUC: 0.9744 Time: 12.65\n",
      "Epoch: 726 Train Loss: 0.1031 Val Loss: 0.2102 Acc: 0.9203 Pre: 0.9205 Recall: 0.9135 F1: 0.9170 Train AUC: 0.9952 Val AUC: 0.9774 Time: 12.51\n",
      "Epoch: 727 Train Loss: 0.0884 Val Loss: 0.2183 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9966 Val AUC: 0.9768 Time: 12.88\n",
      "Epoch: 728 Train Loss: 0.0989 Val Loss: 0.2354 Acc: 0.9149 Pre: 0.8897 Recall: 0.9398 F1: 0.9141 Train AUC: 0.9954 Val AUC: 0.9754 Time: 12.85\n",
      "Epoch: 729 Train Loss: 0.1000 Val Loss: 0.2425 Acc: 0.9149 Pre: 0.8897 Recall: 0.9398 F1: 0.9141 Train AUC: 0.9950 Val AUC: 0.9741 Time: 13.83\n",
      "Epoch: 730 Train Loss: 0.1042 Val Loss: 0.2222 Acc: 0.9185 Pre: 0.8961 Recall: 0.9398 F1: 0.9174 Train AUC: 0.9941 Val AUC: 0.9762 Time: 14.06\n",
      "Epoch: 731 Train Loss: 0.0951 Val Loss: 0.2129 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9958 Val AUC: 0.9765 Time: 14.72\n",
      "Epoch: 732 Train Loss: 0.0924 Val Loss: 0.2160 Acc: 0.9257 Pre: 0.9278 Recall: 0.9173 F1: 0.9225 Train AUC: 0.9965 Val AUC: 0.9762 Time: 13.36\n",
      "Epoch: 733 Train Loss: 0.1054 Val Loss: 0.2233 Acc: 0.9130 Pre: 0.8893 Recall: 0.9361 F1: 0.9121 Train AUC: 0.9949 Val AUC: 0.9750 Time: 12.73\n",
      "Epoch: 734 Train Loss: 0.0934 Val Loss: 0.2363 Acc: 0.9076 Pre: 0.8720 Recall: 0.9474 F1: 0.9081 Train AUC: 0.9956 Val AUC: 0.9754 Time: 12.66\n",
      "Epoch: 735 Train Loss: 0.1001 Val Loss: 0.2201 Acc: 0.9149 Pre: 0.8925 Recall: 0.9361 F1: 0.9138 Train AUC: 0.9950 Val AUC: 0.9777 Time: 12.57\n",
      "Epoch: 736 Train Loss: 0.0962 Val Loss: 0.2144 Acc: 0.9257 Pre: 0.9151 Recall: 0.9323 F1: 0.9236 Train AUC: 0.9948 Val AUC: 0.9775 Time: 12.99\n",
      "Epoch: 737 Train Loss: 0.0928 Val Loss: 0.2223 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9954 Val AUC: 0.9759 Time: 13.68\n",
      "Epoch: 738 Train Loss: 0.0955 Val Loss: 0.2204 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9960 Val AUC: 0.9759 Time: 14.36\n",
      "Epoch: 739 Train Loss: 0.1050 Val Loss: 0.2196 Acc: 0.9257 Pre: 0.9213 Recall: 0.9248 F1: 0.9231 Train AUC: 0.9939 Val AUC: 0.9764 Time: 14.78\n",
      "Epoch: 740 Train Loss: 0.0900 Val Loss: 0.2373 Acc: 0.9094 Pre: 0.8885 Recall: 0.9286 F1: 0.9081 Train AUC: 0.9958 Val AUC: 0.9753 Time: 14.11\n",
      "Epoch: 741 Train Loss: 0.0999 Val Loss: 0.2298 Acc: 0.9185 Pre: 0.9018 Recall: 0.9323 F1: 0.9168 Train AUC: 0.9942 Val AUC: 0.9756 Time: 14.24\n",
      "Epoch: 742 Train Loss: 0.0880 Val Loss: 0.2209 Acc: 0.9275 Pre: 0.9185 Recall: 0.9323 F1: 0.9254 Train AUC: 0.9959 Val AUC: 0.9754 Time: 12.37\n",
      "Epoch: 743 Train Loss: 0.0925 Val Loss: 0.2188 Acc: 0.9312 Pre: 0.9222 Recall: 0.9361 F1: 0.9291 Train AUC: 0.9960 Val AUC: 0.9756 Time: 12.39\n",
      "Epoch: 744 Train Loss: 0.0964 Val Loss: 0.2103 Acc: 0.9312 Pre: 0.9318 Recall: 0.9248 F1: 0.9283 Train AUC: 0.9953 Val AUC: 0.9776 Time: 12.45\n",
      "Epoch: 745 Train Loss: 0.1013 Val Loss: 0.2248 Acc: 0.9076 Pre: 0.8799 Recall: 0.9361 F1: 0.9071 Train AUC: 0.9946 Val AUC: 0.9769 Time: 12.45\n",
      "Epoch: 746 Train Loss: 0.0971 Val Loss: 0.2579 Acc: 0.9040 Pre: 0.8660 Recall: 0.9474 F1: 0.9048 Train AUC: 0.9954 Val AUC: 0.9743 Time: 12.75\n",
      "Epoch: 747 Train Loss: 0.1012 Val Loss: 0.2388 Acc: 0.9130 Pre: 0.8865 Recall: 0.9398 F1: 0.9124 Train AUC: 0.9953 Val AUC: 0.9755 Time: 13.99\n",
      "Epoch: 748 Train Loss: 0.0945 Val Loss: 0.2196 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9954 Val AUC: 0.9761 Time: 14.21\n",
      "Epoch: 749 Train Loss: 0.0989 Val Loss: 0.2252 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9952 Val AUC: 0.9742 Time: 14.86\n",
      "Epoch: 750 Train Loss: 0.0965 Val Loss: 0.2236 Acc: 0.9257 Pre: 0.9213 Recall: 0.9248 F1: 0.9231 Train AUC: 0.9954 Val AUC: 0.9755 Time: 14.18\n",
      "Epoch: 751 Train Loss: 0.0905 Val Loss: 0.2376 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9959 Val AUC: 0.9752 Time: 14.13\n",
      "Epoch: 752 Train Loss: 0.0873 Val Loss: 0.2421 Acc: 0.9094 Pre: 0.8857 Recall: 0.9323 F1: 0.9084 Train AUC: 0.9965 Val AUC: 0.9755 Time: 12.49\n",
      "Epoch: 753 Train Loss: 0.0919 Val Loss: 0.2244 Acc: 0.9185 Pre: 0.9048 Recall: 0.9286 F1: 0.9165 Train AUC: 0.9960 Val AUC: 0.9771 Time: 12.74\n",
      "Epoch: 754 Train Loss: 0.0901 Val Loss: 0.2115 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9955 Val AUC: 0.9769 Time: 12.62\n",
      "Epoch: 755 Train Loss: 0.0890 Val Loss: 0.2104 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9961 Val AUC: 0.9747 Time: 12.85\n",
      "Epoch: 756 Train Loss: 0.1012 Val Loss: 0.2135 Acc: 0.9257 Pre: 0.9245 Recall: 0.9211 F1: 0.9228 Train AUC: 0.9948 Val AUC: 0.9751 Time: 13.85\n",
      "Epoch: 757 Train Loss: 0.0918 Val Loss: 0.2258 Acc: 0.9239 Pre: 0.9088 Recall: 0.9361 F1: 0.9222 Train AUC: 0.9964 Val AUC: 0.9760 Time: 14.35\n",
      "Epoch: 758 Train Loss: 0.0928 Val Loss: 0.2386 Acc: 0.9149 Pre: 0.8953 Recall: 0.9323 F1: 0.9134 Train AUC: 0.9960 Val AUC: 0.9757 Time: 14.69\n",
      "Epoch: 759 Train Loss: 0.0955 Val Loss: 0.2407 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9951 Val AUC: 0.9755 Time: 13.68\n",
      "Epoch: 760 Train Loss: 0.0908 Val Loss: 0.2307 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9953 Val AUC: 0.9758 Time: 13.28\n",
      "Epoch: 761 Train Loss: 0.0941 Val Loss: 0.2170 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9958 Val AUC: 0.9756 Time: 12.67\n",
      "Epoch: 762 Train Loss: 0.0840 Val Loss: 0.2130 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9963 Val AUC: 0.9774 Time: 12.44\n",
      "Epoch: 763 Train Loss: 0.0990 Val Loss: 0.2179 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9955 Val AUC: 0.9766 Time: 12.64\n",
      "Epoch: 764 Train Loss: 0.0857 Val Loss: 0.2338 Acc: 0.9112 Pre: 0.8780 Recall: 0.9474 F1: 0.9114 Train AUC: 0.9966 Val AUC: 0.9752 Time: 12.85\n",
      "Epoch: 765 Train Loss: 0.0980 Val Loss: 0.2178 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9956 Val AUC: 0.9766 Time: 13.73\n",
      "Epoch: 766 Train Loss: 0.0995 Val Loss: 0.2203 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9951 Val AUC: 0.9766 Time: 14.20\n",
      "Epoch: 767 Train Loss: 0.0862 Val Loss: 0.2400 Acc: 0.9293 Pre: 0.9158 Recall: 0.9398 F1: 0.9276 Train AUC: 0.9969 Val AUC: 0.9735 Time: 15.48\n",
      "Epoch: 768 Train Loss: 0.0953 Val Loss: 0.2379 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9953 Val AUC: 0.9733 Time: 13.60\n",
      "Epoch: 769 Train Loss: 0.0961 Val Loss: 0.2321 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9955 Val AUC: 0.9748 Time: 12.88\n",
      "Epoch: 770 Train Loss: 0.0968 Val Loss: 0.2272 Acc: 0.9185 Pre: 0.9077 Recall: 0.9248 F1: 0.9162 Train AUC: 0.9945 Val AUC: 0.9762 Time: 12.62\n",
      "Epoch: 771 Train Loss: 0.0993 Val Loss: 0.2210 Acc: 0.9239 Pre: 0.9118 Recall: 0.9323 F1: 0.9219 Train AUC: 0.9946 Val AUC: 0.9776 Time: 12.63\n",
      "Epoch: 772 Train Loss: 0.0918 Val Loss: 0.2228 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9958 Val AUC: 0.9761 Time: 13.20\n",
      "Epoch: 773 Train Loss: 0.0899 Val Loss: 0.2168 Acc: 0.9239 Pre: 0.9118 Recall: 0.9323 F1: 0.9219 Train AUC: 0.9971 Val AUC: 0.9773 Time: 13.98\n",
      "Epoch: 774 Train Loss: 0.0966 Val Loss: 0.2061 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9952 Val AUC: 0.9788 Time: 14.54\n",
      "Epoch: 775 Train Loss: 0.0979 Val Loss: 0.2066 Acc: 0.9239 Pre: 0.9211 Recall: 0.9211 F1: 0.9211 Train AUC: 0.9946 Val AUC: 0.9789 Time: 14.07\n",
      "Epoch: 776 Train Loss: 0.0961 Val Loss: 0.2240 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9951 Val AUC: 0.9769 Time: 13.03\n",
      "Epoch: 777 Train Loss: 0.0888 Val Loss: 0.2422 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9962 Val AUC: 0.9747 Time: 12.43\n",
      "Epoch: 778 Train Loss: 0.0981 Val Loss: 0.2400 Acc: 0.9149 Pre: 0.8982 Recall: 0.9286 F1: 0.9131 Train AUC: 0.9955 Val AUC: 0.9750 Time: 12.90\n",
      "Epoch: 779 Train Loss: 0.0944 Val Loss: 0.2200 Acc: 0.9239 Pre: 0.9242 Recall: 0.9173 F1: 0.9208 Train AUC: 0.9954 Val AUC: 0.9770 Time: 13.53\n",
      "Epoch: 780 Train Loss: 0.1015 Val Loss: 0.2097 Acc: 0.9275 Pre: 0.9185 Recall: 0.9323 F1: 0.9254 Train AUC: 0.9952 Val AUC: 0.9780 Time: 13.83\n",
      "Epoch: 781 Train Loss: 0.0944 Val Loss: 0.2217 Acc: 0.9185 Pre: 0.8961 Recall: 0.9398 F1: 0.9174 Train AUC: 0.9954 Val AUC: 0.9761 Time: 14.81\n",
      "Epoch: 782 Train Loss: 0.0919 Val Loss: 0.2178 Acc: 0.9257 Pre: 0.9032 Recall: 0.9474 F1: 0.9248 Train AUC: 0.9963 Val AUC: 0.9763 Time: 13.76\n",
      "Epoch: 783 Train Loss: 0.0889 Val Loss: 0.2150 Acc: 0.9239 Pre: 0.9118 Recall: 0.9323 F1: 0.9219 Train AUC: 0.9964 Val AUC: 0.9774 Time: 12.43\n",
      "Epoch: 784 Train Loss: 0.0949 Val Loss: 0.2200 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9958 Val AUC: 0.9776 Time: 12.34\n",
      "Epoch: 785 Train Loss: 0.0863 Val Loss: 0.2196 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9967 Val AUC: 0.9777 Time: 12.48\n",
      "Epoch: 786 Train Loss: 0.0951 Val Loss: 0.2238 Acc: 0.9275 Pre: 0.9094 Recall: 0.9436 F1: 0.9262 Train AUC: 0.9952 Val AUC: 0.9768 Time: 12.36\n",
      "Epoch: 787 Train Loss: 0.0969 Val Loss: 0.2175 Acc: 0.9275 Pre: 0.9124 Recall: 0.9398 F1: 0.9259 Train AUC: 0.9949 Val AUC: 0.9765 Time: 14.14\n",
      "Epoch: 788 Train Loss: 0.0887 Val Loss: 0.2101 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9957 Val AUC: 0.9770 Time: 14.41\n",
      "Epoch: 789 Train Loss: 0.0938 Val Loss: 0.2183 Acc: 0.9221 Pre: 0.9145 Recall: 0.9248 F1: 0.9196 Train AUC: 0.9950 Val AUC: 0.9763 Time: 14.54\n",
      "Epoch: 790 Train Loss: 0.0887 Val Loss: 0.2203 Acc: 0.9239 Pre: 0.9211 Recall: 0.9211 F1: 0.9211 Train AUC: 0.9958 Val AUC: 0.9758 Time: 14.44\n",
      "Epoch: 791 Train Loss: 0.0993 Val Loss: 0.2299 Acc: 0.9167 Pre: 0.8957 Recall: 0.9361 F1: 0.9154 Train AUC: 0.9952 Val AUC: 0.9752 Time: 12.93\n",
      "Epoch: 792 Train Loss: 0.0930 Val Loss: 0.2354 Acc: 0.9112 Pre: 0.8834 Recall: 0.9398 F1: 0.9107 Train AUC: 0.9955 Val AUC: 0.9749 Time: 12.45\n",
      "Epoch: 793 Train Loss: 0.0914 Val Loss: 0.2366 Acc: 0.9221 Pre: 0.8996 Recall: 0.9436 F1: 0.9211 Train AUC: 0.9954 Val AUC: 0.9748 Time: 12.39\n",
      "Epoch: 794 Train Loss: 0.0933 Val Loss: 0.2120 Acc: 0.9221 Pre: 0.9114 Recall: 0.9286 F1: 0.9199 Train AUC: 0.9954 Val AUC: 0.9768 Time: 12.73\n",
      "Epoch: 795 Train Loss: 0.0901 Val Loss: 0.2105 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9959 Val AUC: 0.9773 Time: 12.80\n",
      "Epoch: 796 Train Loss: 0.0838 Val Loss: 0.2131 Acc: 0.9312 Pre: 0.9254 Recall: 0.9323 F1: 0.9288 Train AUC: 0.9967 Val AUC: 0.9775 Time: 13.73\n",
      "Epoch: 797 Train Loss: 0.0884 Val Loss: 0.2118 Acc: 0.9257 Pre: 0.9213 Recall: 0.9248 F1: 0.9231 Train AUC: 0.9968 Val AUC: 0.9784 Time: 14.12\n",
      "Epoch: 798 Train Loss: 0.0846 Val Loss: 0.2195 Acc: 0.9167 Pre: 0.8929 Recall: 0.9398 F1: 0.9158 Train AUC: 0.9969 Val AUC: 0.9780 Time: 14.56\n",
      "Epoch: 799 Train Loss: 0.1027 Val Loss: 0.2210 Acc: 0.9239 Pre: 0.9000 Recall: 0.9474 F1: 0.9231 Train AUC: 0.9940 Val AUC: 0.9775 Time: 14.27\n",
      "Epoch: 800 Train Loss: 0.0924 Val Loss: 0.2060 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9954 Val AUC: 0.9777 Time: 14.73\n",
      "Epoch: 801 Train Loss: 0.0867 Val Loss: 0.2090 Acc: 0.9312 Pre: 0.9318 Recall: 0.9248 F1: 0.9283 Train AUC: 0.9969 Val AUC: 0.9760 Time: 12.42\n",
      "Epoch: 802 Train Loss: 0.0941 Val Loss: 0.2161 Acc: 0.9275 Pre: 0.9185 Recall: 0.9323 F1: 0.9254 Train AUC: 0.9958 Val AUC: 0.9770 Time: 12.37\n",
      "Epoch: 803 Train Loss: 0.0989 Val Loss: 0.2187 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9955 Val AUC: 0.9778 Time: 12.35\n",
      "Epoch: 804 Train Loss: 0.0949 Val Loss: 0.2301 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9951 Val AUC: 0.9769 Time: 12.64\n",
      "Epoch: 805 Train Loss: 0.0937 Val Loss: 0.2318 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9954 Val AUC: 0.9768 Time: 13.99\n",
      "Epoch: 806 Train Loss: 0.0912 Val Loss: 0.2258 Acc: 0.9257 Pre: 0.9151 Recall: 0.9323 F1: 0.9236 Train AUC: 0.9959 Val AUC: 0.9759 Time: 14.47\n",
      "Epoch: 807 Train Loss: 0.0992 Val Loss: 0.2235 Acc: 0.9275 Pre: 0.9185 Recall: 0.9323 F1: 0.9254 Train AUC: 0.9956 Val AUC: 0.9763 Time: 14.62\n",
      "Epoch: 808 Train Loss: 0.0885 Val Loss: 0.2146 Acc: 0.9167 Pre: 0.9074 Recall: 0.9211 F1: 0.9142 Train AUC: 0.9965 Val AUC: 0.9775 Time: 14.44\n",
      "Epoch: 809 Train Loss: 0.0828 Val Loss: 0.2128 Acc: 0.9257 Pre: 0.9151 Recall: 0.9323 F1: 0.9236 Train AUC: 0.9968 Val AUC: 0.9772 Time: 13.90\n",
      "Epoch: 810 Train Loss: 0.0967 Val Loss: 0.2176 Acc: 0.9239 Pre: 0.9088 Recall: 0.9361 F1: 0.9222 Train AUC: 0.9945 Val AUC: 0.9757 Time: 12.44\n",
      "Epoch: 811 Train Loss: 0.0958 Val Loss: 0.2410 Acc: 0.9112 Pre: 0.8780 Recall: 0.9474 F1: 0.9114 Train AUC: 0.9957 Val AUC: 0.9742 Time: 12.41\n",
      "Epoch: 812 Train Loss: 0.0944 Val Loss: 0.2399 Acc: 0.9076 Pre: 0.8826 Recall: 0.9323 F1: 0.9068 Train AUC: 0.9967 Val AUC: 0.9756 Time: 12.66\n",
      "Epoch: 813 Train Loss: 0.0937 Val Loss: 0.2355 Acc: 0.9058 Pre: 0.8963 Recall: 0.9098 F1: 0.9030 Train AUC: 0.9951 Val AUC: 0.9755 Time: 12.81\n",
      "Epoch: 814 Train Loss: 0.0855 Val Loss: 0.2341 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9963 Val AUC: 0.9750 Time: 12.48\n",
      "Epoch: 815 Train Loss: 0.0854 Val Loss: 0.2492 Acc: 0.9167 Pre: 0.9015 Recall: 0.9286 F1: 0.9148 Train AUC: 0.9963 Val AUC: 0.9710 Time: 12.53\n",
      "Epoch: 816 Train Loss: 0.0926 Val Loss: 0.2368 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9964 Val AUC: 0.9724 Time: 12.92\n",
      "Epoch: 817 Train Loss: 0.1018 Val Loss: 0.2191 Acc: 0.9203 Pre: 0.9237 Recall: 0.9098 F1: 0.9167 Train AUC: 0.9950 Val AUC: 0.9773 Time: 14.38\n",
      "Epoch: 818 Train Loss: 0.1012 Val Loss: 0.2178 Acc: 0.9167 Pre: 0.9015 Recall: 0.9286 F1: 0.9148 Train AUC: 0.9957 Val AUC: 0.9777 Time: 14.69\n",
      "Epoch: 819 Train Loss: 0.0874 Val Loss: 0.2333 Acc: 0.9312 Pre: 0.9014 Recall: 0.9624 F1: 0.9309 Train AUC: 0.9960 Val AUC: 0.9770 Time: 13.92\n",
      "Epoch: 820 Train Loss: 0.0927 Val Loss: 0.2243 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9962 Val AUC: 0.9769 Time: 14.03\n",
      "Epoch: 821 Train Loss: 0.0933 Val Loss: 0.2150 Acc: 0.9348 Pre: 0.9323 Recall: 0.9323 F1: 0.9323 Train AUC: 0.9968 Val AUC: 0.9769 Time: 12.45\n",
      "Epoch: 822 Train Loss: 0.0909 Val Loss: 0.2171 Acc: 0.9293 Pre: 0.9283 Recall: 0.9248 F1: 0.9266 Train AUC: 0.9961 Val AUC: 0.9772 Time: 13.06\n",
      "Epoch: 823 Train Loss: 0.0938 Val Loss: 0.2307 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9954 Val AUC: 0.9757 Time: 13.22\n",
      "Epoch: 824 Train Loss: 0.0860 Val Loss: 0.2495 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9965 Val AUC: 0.9725 Time: 13.58\n",
      "Epoch: 825 Train Loss: 0.0908 Val Loss: 0.2340 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9966 Val AUC: 0.9739 Time: 13.93\n",
      "Epoch: 826 Train Loss: 0.0944 Val Loss: 0.2284 Acc: 0.9185 Pre: 0.9077 Recall: 0.9248 F1: 0.9162 Train AUC: 0.9954 Val AUC: 0.9762 Time: 14.44\n",
      "Epoch: 827 Train Loss: 0.0841 Val Loss: 0.2207 Acc: 0.9239 Pre: 0.9179 Recall: 0.9248 F1: 0.9213 Train AUC: 0.9968 Val AUC: 0.9771 Time: 12.80\n",
      "Epoch: 828 Train Loss: 0.0948 Val Loss: 0.2197 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9955 Val AUC: 0.9779 Time: 12.68\n",
      "Epoch: 829 Train Loss: 0.0828 Val Loss: 0.2203 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9972 Val AUC: 0.9777 Time: 13.34\n",
      "Epoch: 830 Train Loss: 0.0860 Val Loss: 0.2189 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9968 Val AUC: 0.9772 Time: 13.73\n",
      "Epoch: 831 Train Loss: 0.0881 Val Loss: 0.2170 Acc: 0.9312 Pre: 0.9222 Recall: 0.9361 F1: 0.9291 Train AUC: 0.9964 Val AUC: 0.9769 Time: 14.13\n",
      "Epoch: 832 Train Loss: 0.0853 Val Loss: 0.2181 Acc: 0.9221 Pre: 0.9208 Recall: 0.9173 F1: 0.9190 Train AUC: 0.9966 Val AUC: 0.9777 Time: 14.45\n",
      "Epoch: 833 Train Loss: 0.0942 Val Loss: 0.2268 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9953 Val AUC: 0.9768 Time: 13.21\n",
      "Epoch: 834 Train Loss: 0.0882 Val Loss: 0.2455 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9959 Val AUC: 0.9744 Time: 12.70\n",
      "Epoch: 835 Train Loss: 0.0823 Val Loss: 0.2381 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9968 Val AUC: 0.9743 Time: 12.59\n",
      "Epoch: 836 Train Loss: 0.0871 Val Loss: 0.2222 Acc: 0.9275 Pre: 0.9124 Recall: 0.9398 F1: 0.9259 Train AUC: 0.9963 Val AUC: 0.9756 Time: 12.62\n",
      "Epoch: 837 Train Loss: 0.0887 Val Loss: 0.2138 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9961 Val AUC: 0.9764 Time: 13.03\n",
      "Epoch: 838 Train Loss: 0.0867 Val Loss: 0.2156 Acc: 0.9275 Pre: 0.9248 Recall: 0.9248 F1: 0.9248 Train AUC: 0.9966 Val AUC: 0.9771 Time: 14.04\n",
      "Epoch: 839 Train Loss: 0.0907 Val Loss: 0.2283 Acc: 0.9167 Pre: 0.8929 Recall: 0.9398 F1: 0.9158 Train AUC: 0.9956 Val AUC: 0.9772 Time: 14.39\n",
      "Epoch: 840 Train Loss: 0.0773 Val Loss: 0.2417 Acc: 0.9149 Pre: 0.8869 Recall: 0.9436 F1: 0.9144 Train AUC: 0.9975 Val AUC: 0.9757 Time: 13.99\n",
      "Epoch: 841 Train Loss: 0.0921 Val Loss: 0.2134 Acc: 0.9203 Pre: 0.9111 Recall: 0.9248 F1: 0.9179 Train AUC: 0.9964 Val AUC: 0.9783 Time: 14.22\n",
      "Epoch: 842 Train Loss: 0.0822 Val Loss: 0.2075 Acc: 0.9275 Pre: 0.9313 Recall: 0.9173 F1: 0.9242 Train AUC: 0.9970 Val AUC: 0.9783 Time: 12.69\n",
      "Epoch: 843 Train Loss: 0.0859 Val Loss: 0.2092 Acc: 0.9330 Pre: 0.9257 Recall: 0.9361 F1: 0.9308 Train AUC: 0.9966 Val AUC: 0.9780 Time: 12.49\n",
      "Epoch: 844 Train Loss: 0.0854 Val Loss: 0.2261 Acc: 0.9257 Pre: 0.8975 Recall: 0.9549 F1: 0.9253 Train AUC: 0.9965 Val AUC: 0.9763 Time: 12.28\n",
      "Epoch: 845 Train Loss: 0.0877 Val Loss: 0.2252 Acc: 0.9185 Pre: 0.8905 Recall: 0.9474 F1: 0.9180 Train AUC: 0.9967 Val AUC: 0.9773 Time: 12.59\n",
      "Epoch: 846 Train Loss: 0.0823 Val Loss: 0.2204 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9968 Val AUC: 0.9782 Time: 13.14\n",
      "Epoch: 847 Train Loss: 0.0865 Val Loss: 0.2157 Acc: 0.9239 Pre: 0.9148 Recall: 0.9286 F1: 0.9216 Train AUC: 0.9960 Val AUC: 0.9782 Time: 14.20\n",
      "Epoch: 848 Train Loss: 0.0920 Val Loss: 0.2224 Acc: 0.9257 Pre: 0.9061 Recall: 0.9436 F1: 0.9245 Train AUC: 0.9962 Val AUC: 0.9771 Time: 14.43\n",
      "Epoch: 849 Train Loss: 0.0795 Val Loss: 0.2547 Acc: 0.9257 Pre: 0.8947 Recall: 0.9586 F1: 0.9256 Train AUC: 0.9975 Val AUC: 0.9752 Time: 14.26\n",
      "Epoch: 850 Train Loss: 0.0999 Val Loss: 0.2393 Acc: 0.9221 Pre: 0.8968 Recall: 0.9474 F1: 0.9214 Train AUC: 0.9959 Val AUC: 0.9757 Time: 12.75\n",
      "Epoch: 851 Train Loss: 0.1001 Val Loss: 0.2139 Acc: 0.9312 Pre: 0.9318 Recall: 0.9248 F1: 0.9283 Train AUC: 0.9956 Val AUC: 0.9776 Time: 12.51\n",
      "Epoch: 852 Train Loss: 0.0888 Val Loss: 0.2066 Acc: 0.9312 Pre: 0.9318 Recall: 0.9248 F1: 0.9283 Train AUC: 0.9962 Val AUC: 0.9787 Time: 12.57\n",
      "Epoch: 853 Train Loss: 0.0945 Val Loss: 0.2133 Acc: 0.9257 Pre: 0.9032 Recall: 0.9474 F1: 0.9248 Train AUC: 0.9960 Val AUC: 0.9760 Time: 13.74\n",
      "Epoch: 854 Train Loss: 0.0877 Val Loss: 0.2310 Acc: 0.9130 Pre: 0.8759 Recall: 0.9549 F1: 0.9137 Train AUC: 0.9965 Val AUC: 0.9753 Time: 14.14\n",
      "Epoch: 855 Train Loss: 0.0903 Val Loss: 0.2315 Acc: 0.9167 Pre: 0.8873 Recall: 0.9474 F1: 0.9164 Train AUC: 0.9971 Val AUC: 0.9764 Time: 14.44\n",
      "Epoch: 856 Train Loss: 0.0875 Val Loss: 0.2253 Acc: 0.9185 Pre: 0.9048 Recall: 0.9286 F1: 0.9165 Train AUC: 0.9963 Val AUC: 0.9771 Time: 12.70\n",
      "Epoch: 857 Train Loss: 0.0896 Val Loss: 0.2239 Acc: 0.9185 Pre: 0.9077 Recall: 0.9248 F1: 0.9162 Train AUC: 0.9957 Val AUC: 0.9767 Time: 13.43\n",
      "Epoch: 858 Train Loss: 0.0917 Val Loss: 0.2325 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9959 Val AUC: 0.9747 Time: 12.96\n",
      "Epoch: 859 Train Loss: 0.0969 Val Loss: 0.2409 Acc: 0.9221 Pre: 0.9055 Recall: 0.9361 F1: 0.9205 Train AUC: 0.9947 Val AUC: 0.9737 Time: 13.62\n",
      "Epoch: 860 Train Loss: 0.0885 Val Loss: 0.2330 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9964 Val AUC: 0.9746 Time: 14.16\n",
      "Epoch: 861 Train Loss: 0.0898 Val Loss: 0.2181 Acc: 0.9185 Pre: 0.9077 Recall: 0.9248 F1: 0.9162 Train AUC: 0.9960 Val AUC: 0.9775 Time: 14.92\n",
      "Epoch: 862 Train Loss: 0.0895 Val Loss: 0.2276 Acc: 0.9185 Pre: 0.8989 Recall: 0.9361 F1: 0.9171 Train AUC: 0.9967 Val AUC: 0.9762 Time: 13.07\n",
      "Epoch: 863 Train Loss: 0.0945 Val Loss: 0.2434 Acc: 0.9167 Pre: 0.8873 Recall: 0.9474 F1: 0.9164 Train AUC: 0.9951 Val AUC: 0.9742 Time: 12.64\n",
      "Epoch: 864 Train Loss: 0.0968 Val Loss: 0.2257 Acc: 0.9257 Pre: 0.9032 Recall: 0.9474 F1: 0.9248 Train AUC: 0.9953 Val AUC: 0.9755 Time: 12.61\n",
      "Epoch: 865 Train Loss: 0.0826 Val Loss: 0.2214 Acc: 0.9330 Pre: 0.9288 Recall: 0.9323 F1: 0.9306 Train AUC: 0.9971 Val AUC: 0.9758 Time: 12.36\n",
      "Epoch: 866 Train Loss: 0.0822 Val Loss: 0.2323 Acc: 0.9257 Pre: 0.9245 Recall: 0.9211 F1: 0.9228 Train AUC: 0.9969 Val AUC: 0.9741 Time: 12.51\n",
      "Epoch: 867 Train Loss: 0.0940 Val Loss: 0.2313 Acc: 0.9221 Pre: 0.9145 Recall: 0.9248 F1: 0.9196 Train AUC: 0.9950 Val AUC: 0.9753 Time: 12.73\n",
      "Epoch: 868 Train Loss: 0.0980 Val Loss: 0.2430 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9946 Val AUC: 0.9746 Time: 13.73\n",
      "Epoch: 869 Train Loss: 0.0870 Val Loss: 0.2515 Acc: 0.9185 Pre: 0.8932 Recall: 0.9436 F1: 0.9177 Train AUC: 0.9961 Val AUC: 0.9726 Time: 14.35\n",
      "Epoch: 870 Train Loss: 0.0972 Val Loss: 0.2198 Acc: 0.9167 Pre: 0.9104 Recall: 0.9173 F1: 0.9139 Train AUC: 0.9952 Val AUC: 0.9741 Time: 14.62\n",
      "Epoch: 871 Train Loss: 0.1019 Val Loss: 0.2049 Acc: 0.9293 Pre: 0.9316 Recall: 0.9211 F1: 0.9263 Train AUC: 0.9951 Val AUC: 0.9779 Time: 14.36\n",
      "Epoch: 872 Train Loss: 0.0916 Val Loss: 0.2185 Acc: 0.9402 Pre: 0.9299 Recall: 0.9474 F1: 0.9385 Train AUC: 0.9964 Val AUC: 0.9770 Time: 12.57\n",
      "Epoch: 873 Train Loss: 0.0850 Val Loss: 0.2401 Acc: 0.9293 Pre: 0.8982 Recall: 0.9624 F1: 0.9292 Train AUC: 0.9967 Val AUC: 0.9763 Time: 12.35\n",
      "Epoch: 874 Train Loss: 0.1039 Val Loss: 0.2329 Acc: 0.9312 Pre: 0.8986 Recall: 0.9662 F1: 0.9312 Train AUC: 0.9952 Val AUC: 0.9766 Time: 12.67\n",
      "Epoch: 875 Train Loss: 0.1018 Val Loss: 0.2263 Acc: 0.9221 Pre: 0.8996 Recall: 0.9436 F1: 0.9211 Train AUC: 0.9950 Val AUC: 0.9779 Time: 13.53\n",
      "Epoch: 876 Train Loss: 0.0953 Val Loss: 0.2242 Acc: 0.9167 Pre: 0.9104 Recall: 0.9173 F1: 0.9139 Train AUC: 0.9950 Val AUC: 0.9772 Time: 13.48\n",
      "Epoch: 877 Train Loss: 0.0937 Val Loss: 0.2306 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9960 Val AUC: 0.9731 Time: 14.50\n",
      "Epoch: 878 Train Loss: 0.0892 Val Loss: 0.2327 Acc: 0.9167 Pre: 0.8957 Recall: 0.9361 F1: 0.9154 Train AUC: 0.9961 Val AUC: 0.9718 Time: 14.95\n",
      "Epoch: 879 Train Loss: 0.0912 Val Loss: 0.2190 Acc: 0.9221 Pre: 0.9114 Recall: 0.9286 F1: 0.9199 Train AUC: 0.9964 Val AUC: 0.9759 Time: 12.73\n",
      "Epoch: 880 Train Loss: 0.0828 Val Loss: 0.2132 Acc: 0.9257 Pre: 0.9213 Recall: 0.9248 F1: 0.9231 Train AUC: 0.9971 Val AUC: 0.9777 Time: 12.96\n",
      "Epoch: 881 Train Loss: 0.0901 Val Loss: 0.2180 Acc: 0.9257 Pre: 0.9213 Recall: 0.9248 F1: 0.9231 Train AUC: 0.9957 Val AUC: 0.9770 Time: 13.45\n",
      "Epoch: 882 Train Loss: 0.0920 Val Loss: 0.2355 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9955 Val AUC: 0.9743 Time: 13.49\n",
      "Epoch: 883 Train Loss: 0.0830 Val Loss: 0.2468 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9967 Val AUC: 0.9736 Time: 13.87\n",
      "Epoch: 884 Train Loss: 0.0900 Val Loss: 0.2258 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9966 Val AUC: 0.9764 Time: 14.09\n",
      "Epoch: 885 Train Loss: 0.0927 Val Loss: 0.2197 Acc: 0.9167 Pre: 0.9044 Recall: 0.9248 F1: 0.9145 Train AUC: 0.9958 Val AUC: 0.9757 Time: 12.80\n",
      "Epoch: 886 Train Loss: 0.0953 Val Loss: 0.2203 Acc: 0.9149 Pre: 0.8925 Recall: 0.9361 F1: 0.9138 Train AUC: 0.9958 Val AUC: 0.9766 Time: 12.52\n",
      "Epoch: 887 Train Loss: 0.0903 Val Loss: 0.2256 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9957 Val AUC: 0.9761 Time: 12.54\n",
      "Epoch: 888 Train Loss: 0.0813 Val Loss: 0.2207 Acc: 0.9293 Pre: 0.9158 Recall: 0.9398 F1: 0.9276 Train AUC: 0.9972 Val AUC: 0.9764 Time: 12.83\n",
      "Epoch: 889 Train Loss: 0.0929 Val Loss: 0.2169 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9956 Val AUC: 0.9773 Time: 13.71\n",
      "Epoch: 890 Train Loss: 0.0875 Val Loss: 0.2198 Acc: 0.9185 Pre: 0.9018 Recall: 0.9323 F1: 0.9168 Train AUC: 0.9962 Val AUC: 0.9776 Time: 14.23\n",
      "Epoch: 891 Train Loss: 0.0855 Val Loss: 0.2222 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9967 Val AUC: 0.9766 Time: 14.19\n",
      "Epoch: 892 Train Loss: 0.0915 Val Loss: 0.2207 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9954 Val AUC: 0.9775 Time: 12.97\n",
      "Epoch: 893 Train Loss: 0.0885 Val Loss: 0.2224 Acc: 0.9275 Pre: 0.9124 Recall: 0.9398 F1: 0.9259 Train AUC: 0.9959 Val AUC: 0.9762 Time: 13.08\n",
      "Epoch: 894 Train Loss: 0.0840 Val Loss: 0.2294 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9968 Val AUC: 0.9730 Time: 14.32\n",
      "Epoch: 895 Train Loss: 0.0941 Val Loss: 0.2229 Acc: 0.9257 Pre: 0.9061 Recall: 0.9436 F1: 0.9245 Train AUC: 0.9955 Val AUC: 0.9769 Time: 13.89\n",
      "Epoch: 896 Train Loss: 0.0716 Val Loss: 0.2249 Acc: 0.9239 Pre: 0.9000 Recall: 0.9474 F1: 0.9231 Train AUC: 0.9981 Val AUC: 0.9777 Time: 14.14\n",
      "Epoch: 897 Train Loss: 0.0847 Val Loss: 0.2167 Acc: 0.9185 Pre: 0.8989 Recall: 0.9361 F1: 0.9171 Train AUC: 0.9966 Val AUC: 0.9785 Time: 12.94\n",
      "Epoch: 898 Train Loss: 0.0819 Val Loss: 0.2127 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9967 Val AUC: 0.9783 Time: 12.44\n",
      "Epoch: 899 Train Loss: 0.0937 Val Loss: 0.2233 Acc: 0.9293 Pre: 0.9158 Recall: 0.9398 F1: 0.9276 Train AUC: 0.9954 Val AUC: 0.9763 Time: 12.82\n",
      "Epoch: 900 Train Loss: 0.0897 Val Loss: 0.2194 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9964 Val AUC: 0.9764 Time: 13.43\n",
      "Epoch: 901 Train Loss: 0.0892 Val Loss: 0.2149 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9961 Val AUC: 0.9774 Time: 13.90\n",
      "Epoch: 902 Train Loss: 0.0865 Val Loss: 0.2128 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9964 Val AUC: 0.9785 Time: 14.39\n",
      "Epoch: 903 Train Loss: 0.0925 Val Loss: 0.2181 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9955 Val AUC: 0.9761 Time: 14.23\n",
      "Epoch: 904 Train Loss: 0.0869 Val Loss: 0.2325 Acc: 0.9112 Pre: 0.8754 Recall: 0.9511 F1: 0.9117 Train AUC: 0.9962 Val AUC: 0.9735 Time: 14.06\n",
      "Epoch: 905 Train Loss: 0.0887 Val Loss: 0.2280 Acc: 0.9167 Pre: 0.8929 Recall: 0.9398 F1: 0.9158 Train AUC: 0.9967 Val AUC: 0.9735 Time: 12.50\n",
      "Epoch: 906 Train Loss: 0.0897 Val Loss: 0.2091 Acc: 0.9330 Pre: 0.9321 Recall: 0.9286 F1: 0.9303 Train AUC: 0.9971 Val AUC: 0.9779 Time: 12.45\n",
      "Epoch: 907 Train Loss: 0.0873 Val Loss: 0.2208 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9970 Val AUC: 0.9769 Time: 12.56\n",
      "Epoch: 908 Train Loss: 0.0925 Val Loss: 0.2603 Acc: 0.9130 Pre: 0.8865 Recall: 0.9398 F1: 0.9124 Train AUC: 0.9957 Val AUC: 0.9749 Time: 12.80\n",
      "Epoch: 909 Train Loss: 0.0962 Val Loss: 0.2453 Acc: 0.9094 Pre: 0.8803 Recall: 0.9398 F1: 0.9091 Train AUC: 0.9950 Val AUC: 0.9750 Time: 12.46\n",
      "Epoch: 910 Train Loss: 0.0897 Val Loss: 0.2251 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9965 Val AUC: 0.9754 Time: 13.01\n",
      "Epoch: 911 Train Loss: 0.0933 Val Loss: 0.2155 Acc: 0.9348 Pre: 0.9323 Recall: 0.9323 F1: 0.9323 Train AUC: 0.9955 Val AUC: 0.9750 Time: 14.02\n",
      "Epoch: 912 Train Loss: 0.0921 Val Loss: 0.2180 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9962 Val AUC: 0.9747 Time: 14.35\n",
      "Epoch: 913 Train Loss: 0.0828 Val Loss: 0.2364 Acc: 0.9239 Pre: 0.8944 Recall: 0.9549 F1: 0.9236 Train AUC: 0.9973 Val AUC: 0.9753 Time: 14.47\n",
      "Epoch: 914 Train Loss: 0.0841 Val Loss: 0.2349 Acc: 0.9112 Pre: 0.8834 Recall: 0.9398 F1: 0.9107 Train AUC: 0.9966 Val AUC: 0.9771 Time: 12.72\n",
      "Epoch: 915 Train Loss: 0.0953 Val Loss: 0.2202 Acc: 0.9275 Pre: 0.9154 Recall: 0.9361 F1: 0.9257 Train AUC: 0.9950 Val AUC: 0.9775 Time: 12.44\n",
      "Epoch: 916 Train Loss: 0.0856 Val Loss: 0.2208 Acc: 0.9312 Pre: 0.9191 Recall: 0.9398 F1: 0.9294 Train AUC: 0.9960 Val AUC: 0.9768 Time: 12.73\n",
      "Epoch: 917 Train Loss: 0.0936 Val Loss: 0.2281 Acc: 0.9330 Pre: 0.9134 Recall: 0.9511 F1: 0.9319 Train AUC: 0.9956 Val AUC: 0.9766 Time: 13.84\n",
      "Epoch: 918 Train Loss: 0.0860 Val Loss: 0.2176 Acc: 0.9239 Pre: 0.9088 Recall: 0.9361 F1: 0.9222 Train AUC: 0.9972 Val AUC: 0.9779 Time: 13.93\n",
      "Epoch: 919 Train Loss: 0.0784 Val Loss: 0.2192 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9973 Val AUC: 0.9780 Time: 14.33\n",
      "Epoch: 920 Train Loss: 0.0812 Val Loss: 0.2267 Acc: 0.9185 Pre: 0.8989 Recall: 0.9361 F1: 0.9171 Train AUC: 0.9968 Val AUC: 0.9770 Time: 14.36\n",
      "Epoch: 921 Train Loss: 0.0909 Val Loss: 0.2216 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9956 Val AUC: 0.9751 Time: 12.60\n",
      "Epoch: 922 Train Loss: 0.0864 Val Loss: 0.2229 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9966 Val AUC: 0.9740 Time: 12.65\n",
      "Epoch: 923 Train Loss: 0.0836 Val Loss: 0.2229 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9969 Val AUC: 0.9768 Time: 12.72\n",
      "Epoch: 924 Train Loss: 0.0797 Val Loss: 0.2269 Acc: 0.9221 Pre: 0.8996 Recall: 0.9436 F1: 0.9211 Train AUC: 0.9974 Val AUC: 0.9775 Time: 12.76\n",
      "Epoch: 925 Train Loss: 0.0792 Val Loss: 0.2307 Acc: 0.9076 Pre: 0.8881 Recall: 0.9248 F1: 0.9061 Train AUC: 0.9970 Val AUC: 0.9774 Time: 13.51\n",
      "Epoch: 926 Train Loss: 0.0931 Val Loss: 0.2199 Acc: 0.9221 Pre: 0.9055 Recall: 0.9361 F1: 0.9205 Train AUC: 0.9951 Val AUC: 0.9777 Time: 14.20\n",
      "Epoch: 927 Train Loss: 0.0784 Val Loss: 0.2254 Acc: 0.9293 Pre: 0.9097 Recall: 0.9474 F1: 0.9282 Train AUC: 0.9972 Val AUC: 0.9760 Time: 13.89\n",
      "Epoch: 928 Train Loss: 0.0851 Val Loss: 0.2242 Acc: 0.9293 Pre: 0.9011 Recall: 0.9586 F1: 0.9290 Train AUC: 0.9970 Val AUC: 0.9751 Time: 14.29\n",
      "Epoch: 929 Train Loss: 0.0941 Val Loss: 0.2266 Acc: 0.9275 Pre: 0.8979 Recall: 0.9586 F1: 0.9273 Train AUC: 0.9958 Val AUC: 0.9766 Time: 14.21\n",
      "Epoch: 930 Train Loss: 0.0880 Val Loss: 0.2176 Acc: 0.9167 Pre: 0.9015 Recall: 0.9286 F1: 0.9148 Train AUC: 0.9961 Val AUC: 0.9783 Time: 12.62\n",
      "Epoch: 931 Train Loss: 0.0855 Val Loss: 0.2239 Acc: 0.9149 Pre: 0.8953 Recall: 0.9323 F1: 0.9134 Train AUC: 0.9968 Val AUC: 0.9777 Time: 12.42\n",
      "Epoch: 932 Train Loss: 0.0844 Val Loss: 0.2302 Acc: 0.9185 Pre: 0.8989 Recall: 0.9361 F1: 0.9171 Train AUC: 0.9965 Val AUC: 0.9763 Time: 12.63\n",
      "Epoch: 933 Train Loss: 0.0884 Val Loss: 0.2295 Acc: 0.9275 Pre: 0.9124 Recall: 0.9398 F1: 0.9259 Train AUC: 0.9960 Val AUC: 0.9744 Time: 12.69\n",
      "Epoch: 934 Train Loss: 0.0840 Val Loss: 0.2197 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9973 Val AUC: 0.9761 Time: 12.62\n",
      "Epoch: 935 Train Loss: 0.0828 Val Loss: 0.2142 Acc: 0.9185 Pre: 0.9108 Recall: 0.9211 F1: 0.9159 Train AUC: 0.9966 Val AUC: 0.9781 Time: 13.12\n",
      "Epoch: 936 Train Loss: 0.1005 Val Loss: 0.2242 Acc: 0.9167 Pre: 0.8957 Recall: 0.9361 F1: 0.9154 Train AUC: 0.9946 Val AUC: 0.9779 Time: 14.08\n",
      "Epoch: 937 Train Loss: 0.0872 Val Loss: 0.2417 Acc: 0.9094 Pre: 0.8750 Recall: 0.9474 F1: 0.9097 Train AUC: 0.9964 Val AUC: 0.9760 Time: 15.04\n",
      "Epoch: 938 Train Loss: 0.0907 Val Loss: 0.2189 Acc: 0.9257 Pre: 0.9004 Recall: 0.9511 F1: 0.9250 Train AUC: 0.9964 Val AUC: 0.9776 Time: 13.83\n",
      "Epoch: 939 Train Loss: 0.0806 Val Loss: 0.2094 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9971 Val AUC: 0.9768 Time: 12.71\n",
      "Epoch: 940 Train Loss: 0.0857 Val Loss: 0.2094 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9965 Val AUC: 0.9769 Time: 12.71\n",
      "Epoch: 941 Train Loss: 0.0850 Val Loss: 0.2201 Acc: 0.9275 Pre: 0.9124 Recall: 0.9398 F1: 0.9259 Train AUC: 0.9966 Val AUC: 0.9758 Time: 12.64\n",
      "Epoch: 942 Train Loss: 0.0809 Val Loss: 0.2284 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9973 Val AUC: 0.9763 Time: 12.39\n",
      "Epoch: 943 Train Loss: 0.0883 Val Loss: 0.2337 Acc: 0.9167 Pre: 0.8929 Recall: 0.9398 F1: 0.9158 Train AUC: 0.9962 Val AUC: 0.9771 Time: 13.69\n",
      "Epoch: 944 Train Loss: 0.0823 Val Loss: 0.2353 Acc: 0.9221 Pre: 0.8996 Recall: 0.9436 F1: 0.9211 Train AUC: 0.9973 Val AUC: 0.9772 Time: 14.19\n",
      "Epoch: 945 Train Loss: 0.0937 Val Loss: 0.2170 Acc: 0.9149 Pre: 0.9011 Recall: 0.9248 F1: 0.9128 Train AUC: 0.9948 Val AUC: 0.9784 Time: 14.65\n",
      "Epoch: 946 Train Loss: 0.0885 Val Loss: 0.2175 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9964 Val AUC: 0.9774 Time: 14.65\n",
      "Epoch: 947 Train Loss: 0.0765 Val Loss: 0.2182 Acc: 0.9293 Pre: 0.9158 Recall: 0.9398 F1: 0.9276 Train AUC: 0.9976 Val AUC: 0.9761 Time: 12.82\n",
      "Epoch: 948 Train Loss: 0.0780 Val Loss: 0.2120 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9976 Val AUC: 0.9780 Time: 12.62\n",
      "Epoch: 949 Train Loss: 0.0812 Val Loss: 0.2125 Acc: 0.9167 Pre: 0.8986 Recall: 0.9323 F1: 0.9151 Train AUC: 0.9972 Val AUC: 0.9789 Time: 12.60\n",
      "Epoch: 950 Train Loss: 0.0846 Val Loss: 0.2210 Acc: 0.9275 Pre: 0.9007 Recall: 0.9549 F1: 0.9270 Train AUC: 0.9965 Val AUC: 0.9784 Time: 12.74\n",
      "Epoch: 951 Train Loss: 0.0753 Val Loss: 0.2225 Acc: 0.9239 Pre: 0.9058 Recall: 0.9398 F1: 0.9225 Train AUC: 0.9977 Val AUC: 0.9776 Time: 13.69\n",
      "Epoch: 952 Train Loss: 0.0787 Val Loss: 0.2183 Acc: 0.9312 Pre: 0.9191 Recall: 0.9398 F1: 0.9294 Train AUC: 0.9974 Val AUC: 0.9774 Time: 14.30\n",
      "Epoch: 953 Train Loss: 0.0858 Val Loss: 0.2183 Acc: 0.9293 Pre: 0.9219 Recall: 0.9323 F1: 0.9271 Train AUC: 0.9969 Val AUC: 0.9776 Time: 14.75\n",
      "Epoch: 954 Train Loss: 0.0986 Val Loss: 0.2118 Acc: 0.9330 Pre: 0.9225 Recall: 0.9398 F1: 0.9311 Train AUC: 0.9951 Val AUC: 0.9781 Time: 14.34\n",
      "Epoch: 955 Train Loss: 0.0780 Val Loss: 0.2092 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9971 Val AUC: 0.9785 Time: 12.36\n",
      "Epoch: 956 Train Loss: 0.0783 Val Loss: 0.2106 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9973 Val AUC: 0.9787 Time: 12.53\n",
      "Epoch: 957 Train Loss: 0.0805 Val Loss: 0.2227 Acc: 0.9257 Pre: 0.8975 Recall: 0.9549 F1: 0.9253 Train AUC: 0.9971 Val AUC: 0.9776 Time: 12.58\n",
      "Epoch: 958 Train Loss: 0.0849 Val Loss: 0.2274 Acc: 0.9221 Pre: 0.8968 Recall: 0.9474 F1: 0.9214 Train AUC: 0.9969 Val AUC: 0.9775 Time: 13.09\n",
      "Epoch: 959 Train Loss: 0.0875 Val Loss: 0.2140 Acc: 0.9293 Pre: 0.9158 Recall: 0.9398 F1: 0.9276 Train AUC: 0.9963 Val AUC: 0.9785 Time: 14.03\n",
      "Epoch: 960 Train Loss: 0.0848 Val Loss: 0.2145 Acc: 0.9312 Pre: 0.9222 Recall: 0.9361 F1: 0.9291 Train AUC: 0.9967 Val AUC: 0.9789 Time: 14.11\n",
      "Epoch: 961 Train Loss: 0.0839 Val Loss: 0.2128 Acc: 0.9221 Pre: 0.8968 Recall: 0.9474 F1: 0.9214 Train AUC: 0.9969 Val AUC: 0.9792 Time: 14.21\n",
      "Epoch: 962 Train Loss: 0.0862 Val Loss: 0.2150 Acc: 0.9312 Pre: 0.9014 Recall: 0.9624 F1: 0.9309 Train AUC: 0.9962 Val AUC: 0.9778 Time: 12.56\n",
      "Epoch: 963 Train Loss: 0.0830 Val Loss: 0.2156 Acc: 0.9312 Pre: 0.9014 Recall: 0.9624 F1: 0.9309 Train AUC: 0.9968 Val AUC: 0.9782 Time: 12.58\n",
      "Epoch: 964 Train Loss: 0.0844 Val Loss: 0.2152 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9970 Val AUC: 0.9786 Time: 13.88\n",
      "Epoch: 965 Train Loss: 0.0740 Val Loss: 0.2288 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9978 Val AUC: 0.9775 Time: 13.87\n",
      "Epoch: 966 Train Loss: 0.0828 Val Loss: 0.2329 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9966 Val AUC: 0.9774 Time: 13.70\n",
      "Epoch: 967 Train Loss: 0.0850 Val Loss: 0.2203 Acc: 0.9167 Pre: 0.9104 Recall: 0.9173 F1: 0.9139 Train AUC: 0.9963 Val AUC: 0.9777 Time: 13.01\n",
      "Epoch: 968 Train Loss: 0.0808 Val Loss: 0.2185 Acc: 0.9257 Pre: 0.9151 Recall: 0.9323 F1: 0.9236 Train AUC: 0.9967 Val AUC: 0.9767 Time: 13.21\n",
      "Epoch: 969 Train Loss: 0.0847 Val Loss: 0.2264 Acc: 0.9239 Pre: 0.9000 Recall: 0.9474 F1: 0.9231 Train AUC: 0.9969 Val AUC: 0.9767 Time: 12.53\n",
      "Epoch: 970 Train Loss: 0.0795 Val Loss: 0.2402 Acc: 0.9112 Pre: 0.8754 Recall: 0.9511 F1: 0.9117 Train AUC: 0.9970 Val AUC: 0.9755 Time: 13.23\n",
      "Epoch: 971 Train Loss: 0.0827 Val Loss: 0.2209 Acc: 0.9221 Pre: 0.8968 Recall: 0.9474 F1: 0.9214 Train AUC: 0.9974 Val AUC: 0.9784 Time: 13.25\n",
      "Epoch: 972 Train Loss: 0.0784 Val Loss: 0.2025 Acc: 0.9312 Pre: 0.9254 Recall: 0.9323 F1: 0.9288 Train AUC: 0.9976 Val AUC: 0.9798 Time: 14.57\n",
      "Epoch: 973 Train Loss: 0.0863 Val Loss: 0.2078 Acc: 0.9275 Pre: 0.9124 Recall: 0.9398 F1: 0.9259 Train AUC: 0.9964 Val AUC: 0.9782 Time: 14.21\n",
      "Epoch: 974 Train Loss: 0.0842 Val Loss: 0.2275 Acc: 0.9275 Pre: 0.8951 Recall: 0.9624 F1: 0.9275 Train AUC: 0.9968 Val AUC: 0.9765 Time: 13.91\n",
      "Epoch: 975 Train Loss: 0.0800 Val Loss: 0.2307 Acc: 0.9239 Pre: 0.8944 Recall: 0.9549 F1: 0.9236 Train AUC: 0.9973 Val AUC: 0.9770 Time: 12.51\n",
      "Epoch: 976 Train Loss: 0.0798 Val Loss: 0.2244 Acc: 0.9167 Pre: 0.8929 Recall: 0.9398 F1: 0.9158 Train AUC: 0.9973 Val AUC: 0.9777 Time: 12.44\n",
      "Epoch: 977 Train Loss: 0.0801 Val Loss: 0.2186 Acc: 0.9167 Pre: 0.8957 Recall: 0.9361 F1: 0.9154 Train AUC: 0.9969 Val AUC: 0.9781 Time: 12.69\n",
      "Epoch: 978 Train Loss: 0.0889 Val Loss: 0.2084 Acc: 0.9293 Pre: 0.9039 Recall: 0.9549 F1: 0.9287 Train AUC: 0.9962 Val AUC: 0.9787 Time: 12.62\n",
      "Epoch: 979 Train Loss: 0.0772 Val Loss: 0.2107 Acc: 0.9275 Pre: 0.8951 Recall: 0.9624 F1: 0.9275 Train AUC: 0.9972 Val AUC: 0.9776 Time: 12.38\n",
      "Epoch: 980 Train Loss: 0.0890 Val Loss: 0.2071 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9960 Val AUC: 0.9782 Time: 13.69\n",
      "Epoch: 981 Train Loss: 0.0857 Val Loss: 0.2181 Acc: 0.9221 Pre: 0.9025 Recall: 0.9398 F1: 0.9208 Train AUC: 0.9965 Val AUC: 0.9783 Time: 14.46\n",
      "Epoch: 982 Train Loss: 0.0849 Val Loss: 0.2239 Acc: 0.9149 Pre: 0.8953 Recall: 0.9323 F1: 0.9134 Train AUC: 0.9970 Val AUC: 0.9780 Time: 14.61\n",
      "Epoch: 983 Train Loss: 0.0806 Val Loss: 0.2156 Acc: 0.9203 Pre: 0.9051 Recall: 0.9323 F1: 0.9185 Train AUC: 0.9969 Val AUC: 0.9785 Time: 14.34\n",
      "Epoch: 984 Train Loss: 0.0801 Val Loss: 0.2139 Acc: 0.9130 Pre: 0.8978 Recall: 0.9248 F1: 0.9111 Train AUC: 0.9973 Val AUC: 0.9777 Time: 13.02\n",
      "Epoch: 985 Train Loss: 0.0900 Val Loss: 0.2124 Acc: 0.9312 Pre: 0.9130 Recall: 0.9474 F1: 0.9299 Train AUC: 0.9960 Val AUC: 0.9792 Time: 12.47\n",
      "Epoch: 986 Train Loss: 0.0775 Val Loss: 0.2190 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9972 Val AUC: 0.9784 Time: 12.41\n",
      "Epoch: 987 Train Loss: 0.0803 Val Loss: 0.2205 Acc: 0.9257 Pre: 0.9091 Recall: 0.9398 F1: 0.9242 Train AUC: 0.9971 Val AUC: 0.9781 Time: 12.90\n",
      "Epoch: 988 Train Loss: 0.0912 Val Loss: 0.2063 Acc: 0.9257 Pre: 0.9061 Recall: 0.9436 F1: 0.9245 Train AUC: 0.9963 Val AUC: 0.9792 Time: 13.61\n",
      "Epoch: 989 Train Loss: 0.0834 Val Loss: 0.2106 Acc: 0.9239 Pre: 0.9000 Recall: 0.9474 F1: 0.9231 Train AUC: 0.9966 Val AUC: 0.9775 Time: 14.45\n",
      "Epoch: 990 Train Loss: 0.0872 Val Loss: 0.2201 Acc: 0.9239 Pre: 0.9000 Recall: 0.9474 F1: 0.9231 Train AUC: 0.9959 Val AUC: 0.9766 Time: 14.74\n",
      "Epoch: 991 Train Loss: 0.0776 Val Loss: 0.2314 Acc: 0.9203 Pre: 0.8993 Recall: 0.9398 F1: 0.9191 Train AUC: 0.9977 Val AUC: 0.9754 Time: 13.37\n",
      "Epoch: 992 Train Loss: 0.0777 Val Loss: 0.2318 Acc: 0.9112 Pre: 0.8889 Recall: 0.9323 F1: 0.9101 Train AUC: 0.9970 Val AUC: 0.9751 Time: 12.50\n",
      "Epoch: 993 Train Loss: 0.0802 Val Loss: 0.2187 Acc: 0.9275 Pre: 0.9154 Recall: 0.9361 F1: 0.9257 Train AUC: 0.9969 Val AUC: 0.9775 Time: 12.53\n",
      "Epoch: 994 Train Loss: 0.0821 Val Loss: 0.2133 Acc: 0.9221 Pre: 0.9084 Recall: 0.9323 F1: 0.9202 Train AUC: 0.9973 Val AUC: 0.9783 Time: 12.42\n",
      "Epoch: 995 Train Loss: 0.0929 Val Loss: 0.2340 Acc: 0.9348 Pre: 0.9021 Recall: 0.9699 F1: 0.9348 Train AUC: 0.9960 Val AUC: 0.9777 Time: 12.86\n",
      "Epoch: 996 Train Loss: 0.0892 Val Loss: 0.2395 Acc: 0.9312 Pre: 0.8958 Recall: 0.9699 F1: 0.9314 Train AUC: 0.9961 Val AUC: 0.9786 Time: 13.84\n",
      "Epoch: 997 Train Loss: 0.0889 Val Loss: 0.2247 Acc: 0.9239 Pre: 0.9000 Recall: 0.9474 F1: 0.9231 Train AUC: 0.9964 Val AUC: 0.9789 Time: 13.92\n",
      "Epoch: 998 Train Loss: 0.0853 Val Loss: 0.2000 Acc: 0.9366 Pre: 0.9294 Recall: 0.9398 F1: 0.9346 Train AUC: 0.9967 Val AUC: 0.9800 Time: 13.59\n",
      "Epoch: 999 Train Loss: 0.0888 Val Loss: 0.1964 Acc: 0.9330 Pre: 0.9225 Recall: 0.9398 F1: 0.9311 Train AUC: 0.9964 Val AUC: 0.9783 Time: 13.92\n",
      "Epoch: 1000 Train Loss: 0.0803 Val Loss: 0.2150 Acc: 0.9275 Pre: 0.8951 Recall: 0.9624 F1: 0.9275 Train AUC: 0.9971 Val AUC: 0.9733 Time: 14.72\n",
      "Fold: 5 Best Epoch: 998 Test acc: 0.9366 Test Pre: 0.9294 Test Recall: 0.9398 Test F1: 0.9346 Test PRC: 0.9776 Test AUC: 0.9800\n",
      "## Training Finished !\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Auc [0.9767185200756779, 0.9609852476290832, 0.9660305343511449, 0.9650095500848896, 0.9799936905200062]\n",
      "Acc [0.9057971014492754, 0.8858695652173914, 0.927536231884058, 0.9057971014492754, 0.9365942028985508]\n",
      "Pre [0.889261744966443, 0.8907849829351536, 0.9464285714285714, 0.8712121212121212, 0.929368029739777]\n",
      "Recall [0.9330985915492958, 0.8938356164383562, 0.9137931034482759, 0.9274193548387096, 0.9398496240601504]\n",
      "F1 [0.9106529209621993, 0.8923076923076922, 0.9298245614035087, 0.8984375, 0.9345794392523363]\n",
      "Prc [0.9793753924505615, 0.9677933482667354, 0.973057102072935, 0.9654609591203148, 0.9775903339626306]\n",
      "AUC mean: 0.9697, variance: 0.0073 \n",
      " Accuracy mean: 0.9123, variance: 0.0179 \n",
      " Precision mean: 0.9054, variance: 0.0279 \n",
      " Recall mean: 0.9216, variance: 0.0163 \n",
      " F1-score mean: 0.9132, variance: 0.0167 \n",
      " PRC mean: 0.9727, variance: 0.0054 \n",
      "\n",
      "fprs [array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00373134, 0.00373134, 0.00746269,\n",
      "       0.00746269, 0.01119403, 0.01119403, 0.01492537, 0.01492537,\n",
      "       0.02238806, 0.02238806, 0.0261194 , 0.0261194 , 0.02985075,\n",
      "       0.02985075, 0.03731343, 0.03731343, 0.04104478, 0.04104478,\n",
      "       0.04477612, 0.04477612, 0.05970149, 0.05970149, 0.06343284,\n",
      "       0.06343284, 0.06716418, 0.06716418, 0.08208955, 0.08208955,\n",
      "       0.09328358, 0.09328358, 0.12313433, 0.12313433, 0.13432836,\n",
      "       0.13432836, 0.15671642, 0.15671642, 0.1641791 , 0.1641791 ,\n",
      "       0.16791045, 0.16791045, 0.20149254, 0.20149254, 0.21268657,\n",
      "       0.21268657, 0.22014925, 0.22014925, 0.2238806 , 0.2238806 ,\n",
      "       0.24253731, 0.24253731, 0.25373134, 0.25373134, 0.27985075,\n",
      "       0.27985075, 0.29477612, 0.29477612, 0.50746269, 0.50746269,\n",
      "       0.51119403, 0.51119403, 1.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00384615, 0.00384615, 0.00769231,\n",
      "       0.00769231, 0.01153846, 0.01153846, 0.01538462, 0.01538462,\n",
      "       0.02692308, 0.02692308, 0.03076923, 0.03076923, 0.03461538,\n",
      "       0.03461538, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
      "       0.05384615, 0.05384615, 0.06153846, 0.06153846, 0.06538462,\n",
      "       0.06538462, 0.06923077, 0.06923077, 0.07307692, 0.07307692,\n",
      "       0.07692308, 0.07692308, 0.09615385, 0.09615385, 0.10769231,\n",
      "       0.10769231, 0.11153846, 0.11153846, 0.12307692, 0.12307692,\n",
      "       0.13461538, 0.13461538, 0.13846154, 0.13846154, 0.14230769,\n",
      "       0.14230769, 0.15      , 0.15      , 0.16538462, 0.16538462,\n",
      "       0.16923077, 0.16923077, 0.17307692, 0.17307692, 0.17692308,\n",
      "       0.17692308, 0.18076923, 0.18076923, 0.18461538, 0.18461538,\n",
      "       0.2       , 0.2       , 0.20384615, 0.20384615, 0.20769231,\n",
      "       0.20769231, 0.21153846, 0.21153846, 0.23076923, 0.23076923,\n",
      "       0.33076923, 0.33076923, 0.35769231, 0.35769231, 0.36538462,\n",
      "       0.36538462, 0.39230769, 0.39230769, 0.40769231, 0.40769231,\n",
      "       0.41923077, 0.41923077, 0.50384615, 0.50384615, 0.51538462,\n",
      "       0.51538462, 0.54230769, 0.54230769, 0.55769231, 0.55769231,\n",
      "       1.        ]), array([0.        , 0.        , 0.        , 0.00381679, 0.00381679,\n",
      "       0.00763359, 0.00763359, 0.01145038, 0.01145038, 0.01526718,\n",
      "       0.01526718, 0.01908397, 0.01908397, 0.02290076, 0.02290076,\n",
      "       0.02671756, 0.02671756, 0.03435115, 0.03435115, 0.04198473,\n",
      "       0.04198473, 0.04580153, 0.04580153, 0.04961832, 0.04961832,\n",
      "       0.05343511, 0.05343511, 0.05725191, 0.05725191, 0.10305344,\n",
      "       0.10305344, 0.11450382, 0.11450382, 0.11832061, 0.11832061,\n",
      "       0.13358779, 0.13358779, 0.16793893, 0.16793893, 0.17557252,\n",
      "       0.17557252, 0.1870229 , 0.1870229 , 0.21374046, 0.21374046,\n",
      "       0.23282443, 0.23282443, 0.25954198, 0.25954198, 0.27480916,\n",
      "       0.27480916, 0.28244275, 0.28244275, 0.28625954, 0.28625954,\n",
      "       0.33206107, 0.33206107, 0.35114504, 0.35114504, 0.6259542 ,\n",
      "       0.6259542 , 0.82824427, 0.82824427, 0.83969466, 0.83969466,\n",
      "       1.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.00328947, 0.00328947, 0.00657895, 0.00657895, 0.00986842,\n",
      "       0.00986842, 0.01315789, 0.01315789, 0.02631579, 0.02631579,\n",
      "       0.02960526, 0.02960526, 0.03289474, 0.03289474, 0.03947368,\n",
      "       0.03947368, 0.04605263, 0.04605263, 0.04934211, 0.04934211,\n",
      "       0.05921053, 0.05921053, 0.06578947, 0.06578947, 0.07236842,\n",
      "       0.07236842, 0.09210526, 0.09210526, 0.09868421, 0.09868421,\n",
      "       0.14144737, 0.14144737, 0.16447368, 0.16447368, 0.21381579,\n",
      "       0.21381579, 0.22368421, 0.22368421, 0.24342105, 0.24342105,\n",
      "       0.26315789, 0.26315789, 0.29276316, 0.29276316, 0.30592105,\n",
      "       0.30592105, 0.44736842, 0.44736842, 0.46381579, 0.46381579,\n",
      "       0.50657895, 0.50657895, 0.54605263, 0.54605263, 0.86513158,\n",
      "       0.86513158, 0.88157895, 0.88157895, 1.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.0034965 , 0.0034965 ,\n",
      "       0.00699301, 0.00699301, 0.01048951, 0.01048951, 0.01748252,\n",
      "       0.01748252, 0.02097902, 0.02097902, 0.02447552, 0.02447552,\n",
      "       0.02797203, 0.02797203, 0.03496503, 0.03496503, 0.03846154,\n",
      "       0.03846154, 0.04195804, 0.04195804, 0.04545455, 0.04545455,\n",
      "       0.04895105, 0.04895105, 0.05244755, 0.05244755, 0.05594406,\n",
      "       0.05594406, 0.06293706, 0.06293706, 0.06643357, 0.06643357,\n",
      "       0.08741259, 0.08741259, 0.09440559, 0.09440559, 0.11538462,\n",
      "       0.11538462, 0.11888112, 0.11888112, 0.12237762, 0.12237762,\n",
      "       0.12937063, 0.12937063, 0.13286713, 0.13286713, 0.15734266,\n",
      "       0.15734266, 0.16083916, 0.16083916, 0.30769231, 0.30769231,\n",
      "       0.31118881, 0.31118881, 1.        ])]\n",
      "tprs [array([0.        , 0.00352113, 0.04929577, 0.05633803, 0.33450704,\n",
      "       0.3415493 , 0.58450704, 0.58450704, 0.58802817, 0.58802817,\n",
      "       0.73239437, 0.73239437, 0.74647887, 0.74647887, 0.78873239,\n",
      "       0.78873239, 0.81338028, 0.81338028, 0.82042254, 0.82042254,\n",
      "       0.83802817, 0.83802817, 0.86619718, 0.86619718, 0.88028169,\n",
      "       0.88028169, 0.8943662 , 0.8943662 , 0.90140845, 0.90140845,\n",
      "       0.9084507 , 0.9084507 , 0.92253521, 0.92253521, 0.92605634,\n",
      "       0.92605634, 0.92957746, 0.92957746, 0.93661972, 0.93661972,\n",
      "       0.95070423, 0.95070423, 0.95422535, 0.95422535, 0.95774648,\n",
      "       0.95774648, 0.96478873, 0.96478873, 0.96830986, 0.96830986,\n",
      "       0.97183099, 0.97183099, 0.97535211, 0.97535211, 0.97887324,\n",
      "       0.97887324, 0.98239437, 0.98239437, 0.98591549, 0.98591549,\n",
      "       0.98943662, 0.98943662, 0.99295775, 0.99295775, 0.99647887,\n",
      "       0.99647887, 1.        , 1.        ]), array([0.        , 0.00342466, 0.17123288, 0.17808219, 0.35616438,\n",
      "       0.3630137 , 0.53082192, 0.53082192, 0.55136986, 0.55136986,\n",
      "       0.63013699, 0.63013699, 0.65753425, 0.65753425, 0.71917808,\n",
      "       0.71917808, 0.7260274 , 0.7260274 , 0.75      , 0.75      ,\n",
      "       0.76369863, 0.76369863, 0.80479452, 0.80479452, 0.81164384,\n",
      "       0.81164384, 0.82534247, 0.82534247, 0.83219178, 0.83219178,\n",
      "       0.84246575, 0.84246575, 0.84589041, 0.84589041, 0.86643836,\n",
      "       0.86643836, 0.86986301, 0.86986301, 0.88356164, 0.88356164,\n",
      "       0.89041096, 0.89041096, 0.89383562, 0.89383562, 0.89726027,\n",
      "       0.89726027, 0.90068493, 0.90068493, 0.9109589 , 0.9109589 ,\n",
      "       0.91438356, 0.91438356, 0.91780822, 0.91780822, 0.92123288,\n",
      "       0.92123288, 0.92465753, 0.92465753, 0.92808219, 0.92808219,\n",
      "       0.93493151, 0.93493151, 0.93835616, 0.93835616, 0.94520548,\n",
      "       0.94520548, 0.94863014, 0.94863014, 0.95205479, 0.95205479,\n",
      "       0.95890411, 0.95890411, 0.96232877, 0.96232877, 0.96575342,\n",
      "       0.96575342, 0.96917808, 0.96917808, 0.97260274, 0.97260274,\n",
      "       0.9760274 , 0.9760274 , 0.97945205, 0.97945205, 0.98287671,\n",
      "       0.98287671, 0.98630137, 0.98630137, 0.98972603, 0.98972603,\n",
      "       0.99315068, 0.99315068, 0.99657534, 0.99657534, 1.        ,\n",
      "       1.        ]), array([0.        , 0.00344828, 0.44137931, 0.44137931, 0.55517241,\n",
      "       0.55517241, 0.70689655, 0.70689655, 0.74137931, 0.74137931,\n",
      "       0.75517241, 0.75517241, 0.7862069 , 0.7862069 , 0.78965517,\n",
      "       0.78965517, 0.79310345, 0.79310345, 0.82758621, 0.82758621,\n",
      "       0.84137931, 0.84137931, 0.85517241, 0.85517241, 0.8862069 ,\n",
      "       0.8862069 , 0.90689655, 0.90689655, 0.91724138, 0.91724138,\n",
      "       0.92068966, 0.92068966, 0.92413793, 0.92413793, 0.92758621,\n",
      "       0.92758621, 0.93103448, 0.93103448, 0.93448276, 0.93448276,\n",
      "       0.94137931, 0.94137931, 0.94482759, 0.94482759, 0.94827586,\n",
      "       0.94827586, 0.95862069, 0.95862069, 0.96206897, 0.96206897,\n",
      "       0.96551724, 0.96551724, 0.97586207, 0.97586207, 0.97931034,\n",
      "       0.97931034, 0.98275862, 0.98275862, 0.9862069 , 0.9862069 ,\n",
      "       0.99310345, 0.99310345, 0.99655172, 0.99655172, 1.        ,\n",
      "       1.        ]), array([0.        , 0.00403226, 0.35080645, 0.35887097, 0.44758065,\n",
      "       0.44758065, 0.46370968, 0.46370968, 0.76612903, 0.76612903,\n",
      "       0.77016129, 0.77016129, 0.7983871 , 0.7983871 , 0.81854839,\n",
      "       0.81854839, 0.83064516, 0.83064516, 0.83467742, 0.83467742,\n",
      "       0.83870968, 0.83870968, 0.87096774, 0.87096774, 0.875     ,\n",
      "       0.875     , 0.87903226, 0.87903226, 0.90322581, 0.90322581,\n",
      "       0.90725806, 0.90725806, 0.91532258, 0.91532258, 0.92741935,\n",
      "       0.92741935, 0.93548387, 0.93548387, 0.94354839, 0.94354839,\n",
      "       0.94758065, 0.94758065, 0.9516129 , 0.9516129 , 0.96370968,\n",
      "       0.96370968, 0.96774194, 0.96774194, 0.97177419, 0.97177419,\n",
      "       0.97580645, 0.97580645, 0.97983871, 0.97983871, 0.98387097,\n",
      "       0.98387097, 0.98790323, 0.98790323, 0.99193548, 0.99193548,\n",
      "       0.99596774, 0.99596774, 1.        , 1.        ]), array([0.        , 0.0037594 , 0.01503759, 0.03007519, 0.04135338,\n",
      "       0.04887218, 0.05639098, 0.62030075, 0.62030075, 0.63533835,\n",
      "       0.63533835, 0.63909774, 0.63909774, 0.64285714, 0.64285714,\n",
      "       0.65037594, 0.65037594, 0.65413534, 0.65413534, 0.67669173,\n",
      "       0.67669173, 0.79699248, 0.79699248, 0.80075188, 0.80075188,\n",
      "       0.82330827, 0.82330827, 0.83082707, 0.83082707, 0.83834586,\n",
      "       0.83834586, 0.89849624, 0.89849624, 0.90225564, 0.90225564,\n",
      "       0.93233083, 0.93233083, 0.93609023, 0.93609023, 0.93984962,\n",
      "       0.93984962, 0.94360902, 0.94360902, 0.94736842, 0.94736842,\n",
      "       0.95488722, 0.95488722, 0.96240602, 0.96240602, 0.97744361,\n",
      "       0.97744361, 0.98120301, 0.98120301, 0.98496241, 0.98496241,\n",
      "       0.9887218 , 0.9887218 , 0.9924812 , 0.9924812 , 0.9962406 ,\n",
      "       0.9962406 , 1.        , 1.        ])]\n",
      "precisions [array([0.51449275, 0.5154265 , 0.51636364, 0.51730419, 0.51824818,\n",
      "       0.51919561, 0.52014652, 0.52110092, 0.52205882, 0.52302026,\n",
      "       0.52398524, 0.52495379, 0.52592593, 0.52690167, 0.52788104,\n",
      "       0.52886406, 0.52985075, 0.53084112, 0.53183521, 0.53283302,\n",
      "       0.53383459, 0.53483992, 0.53584906, 0.536862  , 0.53787879,\n",
      "       0.53889943, 0.53992395, 0.54095238, 0.54198473, 0.54302103,\n",
      "       0.5440613 , 0.54510557, 0.54615385, 0.54720617, 0.54826255,\n",
      "       0.54932302, 0.5503876 , 0.55145631, 0.55252918, 0.55360624,\n",
      "       0.5546875 , 0.55577299, 0.55686275, 0.55795678, 0.55905512,\n",
      "       0.56015779, 0.56126482, 0.56237624, 0.56349206, 0.56461233,\n",
      "       0.56573705, 0.56686627, 0.568     , 0.56913828, 0.57028112,\n",
      "       0.57142857, 0.57258065, 0.57373737, 0.57489879, 0.57606491,\n",
      "       0.57723577, 0.57841141, 0.57959184, 0.5807771 , 0.58196721,\n",
      "       0.58316222, 0.58436214, 0.58556701, 0.58677686, 0.58799172,\n",
      "       0.58921162, 0.59043659, 0.59166667, 0.59290188, 0.59414226,\n",
      "       0.59538784, 0.59663866, 0.59789474, 0.59915612, 0.60042283,\n",
      "       0.60169492, 0.6029724 , 0.60425532, 0.60554371, 0.60683761,\n",
      "       0.60813704, 0.60944206, 0.61075269, 0.61206897, 0.61339093,\n",
      "       0.61471861, 0.61605206, 0.6173913 , 0.61873638, 0.62008734,\n",
      "       0.6214442 , 0.62280702, 0.62417582, 0.62555066, 0.62693157,\n",
      "       0.62831858, 0.62971175, 0.63111111, 0.6325167 , 0.63392857,\n",
      "       0.63534676, 0.6367713 , 0.63820225, 0.63963964, 0.64108352,\n",
      "       0.64253394, 0.64399093, 0.64545455, 0.64692483, 0.64840183,\n",
      "       0.64988558, 0.65137615, 0.65287356, 0.65437788, 0.65588915,\n",
      "       0.65740741, 0.65893271, 0.66046512, 0.66200466, 0.6635514 ,\n",
      "       0.66510539, 0.66666667, 0.66823529, 0.66981132, 0.6713948 ,\n",
      "       0.67298578, 0.67458432, 0.67380952, 0.67541766, 0.67464115,\n",
      "       0.67625899, 0.67788462, 0.67951807, 0.68115942, 0.68280872,\n",
      "       0.68446602, 0.68613139, 0.68780488, 0.68948655, 0.69117647,\n",
      "       0.69287469, 0.69458128, 0.6962963 , 0.6980198 , 0.69975186,\n",
      "       0.70149254, 0.7032419 , 0.705     , 0.70676692, 0.70854271,\n",
      "       0.71032746, 0.71212121, 0.71392405, 0.71573604, 0.71755725,\n",
      "       0.71938776, 0.72122762, 0.72307692, 0.72493573, 0.72680412,\n",
      "       0.72868217, 0.73056995, 0.73246753, 0.734375  , 0.73629243,\n",
      "       0.7382199 , 0.74015748, 0.74210526, 0.74406332, 0.74603175,\n",
      "       0.74801061, 0.75      , 0.752     , 0.7540107 , 0.75603217,\n",
      "       0.75806452, 0.76010782, 0.76216216, 0.76422764, 0.76630435,\n",
      "       0.76839237, 0.7704918 , 0.77260274, 0.77472527, 0.7768595 ,\n",
      "       0.77900552, 0.78116343, 0.78055556, 0.78272981, 0.7849162 ,\n",
      "       0.78711485, 0.78932584, 0.78873239, 0.79096045, 0.79320113,\n",
      "       0.79545455, 0.7977208 , 0.8       , 0.80229226, 0.8045977 ,\n",
      "       0.80403458, 0.80635838, 0.80869565, 0.81104651, 0.81049563,\n",
      "       0.8128655 , 0.81524927, 0.81764706, 0.820059  , 0.82248521,\n",
      "       0.82195846, 0.82440476, 0.8238806 , 0.82634731, 0.82882883,\n",
      "       0.82831325, 0.83081571, 0.83333333, 0.83586626, 0.83536585,\n",
      "       0.83792049, 0.8404908 , 0.84307692, 0.84567901, 0.84829721,\n",
      "       0.85093168, 0.85358255, 0.85625   , 0.85893417, 0.85849057,\n",
      "       0.85804416, 0.86075949, 0.86031746, 0.86305732, 0.8658147 ,\n",
      "       0.86538462, 0.8681672 , 0.87096774, 0.87378641, 0.87662338,\n",
      "       0.87947883, 0.88235294, 0.88196721, 0.88157895, 0.88118812,\n",
      "       0.8807947 , 0.88372093, 0.88666667, 0.88963211, 0.88926174,\n",
      "       0.88888889, 0.89189189, 0.89491525, 0.89795918, 0.90102389,\n",
      "       0.90410959, 0.90721649, 0.91034483, 0.91349481, 0.91319444,\n",
      "       0.91637631, 0.91958042, 0.92280702, 0.92253521, 0.92579505,\n",
      "       0.92907801, 0.93238434, 0.93571429, 0.93548387, 0.9352518 ,\n",
      "       0.93501805, 0.93478261, 0.93818182, 0.9379562 , 0.93772894,\n",
      "       0.94117647, 0.94095941, 0.94074074, 0.94423792, 0.94776119,\n",
      "       0.95131086, 0.95488722, 0.95471698, 0.95454545, 0.95437262,\n",
      "       0.95419847, 0.95785441, 0.95769231, 0.95752896, 0.95736434,\n",
      "       0.95719844, 0.9609375 , 0.96078431, 0.96062992, 0.96047431,\n",
      "       0.96031746, 0.96015936, 0.96      , 0.95983936, 0.95967742,\n",
      "       0.96356275, 0.96747967, 0.96734694, 0.96721311, 0.96707819,\n",
      "       0.96694215, 0.96680498, 0.97083333, 0.9707113 , 0.97058824,\n",
      "       0.97468354, 0.97457627, 0.97446809, 0.97435897, 0.97424893,\n",
      "       0.97413793, 0.97402597, 0.97391304, 0.97816594, 0.98245614,\n",
      "       0.98237885, 0.98230088, 0.98222222, 0.98214286, 0.98206278,\n",
      "       0.98198198, 0.98190045, 0.98181818, 0.98173516, 0.98165138,\n",
      "       0.98156682, 0.98148148, 0.98604651, 0.98598131, 0.98591549,\n",
      "       0.98584906, 0.98578199, 0.99047619, 0.99043062, 0.99038462,\n",
      "       0.99033816, 0.99029126, 0.9902439 , 0.99019608, 0.99014778,\n",
      "       0.99009901, 0.99004975, 0.99      , 0.98994975, 0.98989899,\n",
      "       0.98984772, 0.98979592, 0.98974359, 0.98969072, 0.98963731,\n",
      "       0.98958333, 0.9895288 , 0.98947368, 0.98941799, 0.9893617 ,\n",
      "       0.98930481, 0.98924731, 0.98918919, 0.98913043, 0.98907104,\n",
      "       0.98901099, 0.98895028, 0.98888889, 0.98882682, 0.98876404,\n",
      "       0.98870056, 0.98863636, 0.98857143, 0.98850575, 0.98843931,\n",
      "       0.98837209, 0.98830409, 0.98823529, 0.98816568, 0.99404762,\n",
      "       0.99401198, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        ]), array([0.52898551, 0.52994555, 0.53090909, 0.53187614, 0.53284672,\n",
      "       0.53382084, 0.53479853, 0.53577982, 0.53676471, 0.53775322,\n",
      "       0.53874539, 0.53974122, 0.54074074, 0.54174397, 0.54275093,\n",
      "       0.54376164, 0.54477612, 0.54579439, 0.54681648, 0.5478424 ,\n",
      "       0.54887218, 0.54990584, 0.5509434 , 0.55198488, 0.5530303 ,\n",
      "       0.5540797 , 0.55513308, 0.55619048, 0.55725191, 0.5583174 ,\n",
      "       0.55938697, 0.56046065, 0.56153846, 0.56262042, 0.56370656,\n",
      "       0.56479691, 0.56589147, 0.56699029, 0.56809339, 0.56920078,\n",
      "       0.5703125 , 0.57142857, 0.57254902, 0.57367387, 0.57480315,\n",
      "       0.57593688, 0.5770751 , 0.57821782, 0.57936508, 0.5805169 ,\n",
      "       0.58167331, 0.58283433, 0.584     , 0.58517034, 0.58634538,\n",
      "       0.58752515, 0.58870968, 0.58989899, 0.59109312, 0.59229209,\n",
      "       0.59349593, 0.59470468, 0.59591837, 0.59713701, 0.59836066,\n",
      "       0.59958932, 0.60082305, 0.60206186, 0.60330579, 0.60455487,\n",
      "       0.60580913, 0.60706861, 0.60833333, 0.60960334, 0.61087866,\n",
      "       0.61215933, 0.61344538, 0.61473684, 0.61603376, 0.61733615,\n",
      "       0.61864407, 0.61995754, 0.6212766 , 0.62260128, 0.62393162,\n",
      "       0.62526767, 0.62660944, 0.62795699, 0.62931034, 0.63066955,\n",
      "       0.63203463, 0.63340564, 0.63478261, 0.63616558, 0.63755459,\n",
      "       0.63894967, 0.64035088, 0.64175824, 0.64317181, 0.64459161,\n",
      "       0.6460177 , 0.64745011, 0.64888889, 0.65033408, 0.65178571,\n",
      "       0.65324385, 0.65470852, 0.65617978, 0.65765766, 0.65914221,\n",
      "       0.66063348, 0.66213152, 0.66363636, 0.66514806, 0.66666667,\n",
      "       0.66819222, 0.66743119, 0.66896552, 0.67050691, 0.67205543,\n",
      "       0.67361111, 0.67285383, 0.6744186 , 0.67599068, 0.67757009,\n",
      "       0.67915691, 0.68075117, 0.68235294, 0.68396226, 0.68321513,\n",
      "       0.68483412, 0.68646081, 0.68809524, 0.68735084, 0.68899522,\n",
      "       0.69064748, 0.69230769, 0.6939759 , 0.69565217, 0.69733656,\n",
      "       0.69902913, 0.70072993, 0.70243902, 0.70415648, 0.70588235,\n",
      "       0.70761671, 0.70935961, 0.71111111, 0.71287129, 0.7146402 ,\n",
      "       0.71641791, 0.71820449, 0.72      , 0.72180451, 0.72361809,\n",
      "       0.72544081, 0.72474747, 0.72658228, 0.7284264 , 0.7302799 ,\n",
      "       0.72959184, 0.7314578 , 0.73333333, 0.73521851, 0.7371134 ,\n",
      "       0.73643411, 0.73834197, 0.74025974, 0.7421875 , 0.74412533,\n",
      "       0.7460733 , 0.7480315 , 0.75      , 0.74934037, 0.75132275,\n",
      "       0.75331565, 0.75265957, 0.75466667, 0.75668449, 0.75871314,\n",
      "       0.76075269, 0.76280323, 0.76486486, 0.76693767, 0.76630435,\n",
      "       0.76839237, 0.7704918 , 0.77260274, 0.77472527, 0.7768595 ,\n",
      "       0.77900552, 0.78116343, 0.78333333, 0.78551532, 0.7877095 ,\n",
      "       0.78991597, 0.79213483, 0.7943662 , 0.79661017, 0.79886686,\n",
      "       0.80113636, 0.8034188 , 0.80571429, 0.80802292, 0.81034483,\n",
      "       0.81268012, 0.8150289 , 0.8173913 , 0.81976744, 0.82215743,\n",
      "       0.8245614 , 0.82404692, 0.82647059, 0.82890855, 0.83136095,\n",
      "       0.83382789, 0.83630952, 0.8358209 , 0.83832335, 0.83783784,\n",
      "       0.8373494 , 0.83987915, 0.83939394, 0.84194529, 0.84146341,\n",
      "       0.8440367 , 0.84662577, 0.84923077, 0.85185185, 0.85139319,\n",
      "       0.85093168, 0.85358255, 0.853125  , 0.85579937, 0.85534591,\n",
      "       0.85488959, 0.85759494, 0.85714286, 0.85987261, 0.85942492,\n",
      "       0.86217949, 0.86173633, 0.86451613, 0.86731392, 0.87012987,\n",
      "       0.87296417, 0.87254902, 0.87540984, 0.87828947, 0.87788779,\n",
      "       0.8807947 , 0.88039867, 0.88      , 0.87959866, 0.88255034,\n",
      "       0.88215488, 0.88513514, 0.88813559, 0.89115646, 0.89078498,\n",
      "       0.89383562, 0.89690722, 0.9       , 0.89965398, 0.90277778,\n",
      "       0.90243902, 0.9020979 , 0.90526316, 0.9084507 , 0.91166078,\n",
      "       0.91134752, 0.91103203, 0.91071429, 0.91039427, 0.91366906,\n",
      "       0.91696751, 0.92028986, 0.92363636, 0.9270073 , 0.92673993,\n",
      "       0.93014706, 0.9298893 , 0.92962963, 0.92936803, 0.92910448,\n",
      "       0.92883895, 0.92857143, 0.93207547, 0.93181818, 0.93536122,\n",
      "       0.9351145 , 0.9348659 , 0.93461538, 0.93822394, 0.9379845 ,\n",
      "       0.93774319, 0.94140625, 0.94509804, 0.94488189, 0.94466403,\n",
      "       0.94444444, 0.94422311, 0.948     , 0.95180723, 0.9516129 ,\n",
      "       0.951417  , 0.95528455, 0.95918367, 0.95901639, 0.95884774,\n",
      "       0.95867769, 0.95850622, 0.95833333, 0.958159  , 0.95798319,\n",
      "       0.95780591, 0.95762712, 0.95744681, 0.95726496, 0.95708155,\n",
      "       0.9612069 , 0.96103896, 0.96086957, 0.96069869, 0.96052632,\n",
      "       0.96475771, 0.96460177, 0.96444444, 0.96428571, 0.96412556,\n",
      "       0.96396396, 0.9638009 , 0.96363636, 0.96803653, 0.96788991,\n",
      "       0.96774194, 0.97222222, 0.97674419, 0.98130841, 0.98122066,\n",
      "       0.98113208, 0.98104265, 0.98095238, 0.98086124, 0.98076923,\n",
      "       0.98067633, 0.98058252, 0.9804878 , 0.98039216, 0.98029557,\n",
      "       0.98019802, 0.9800995 , 0.98      , 0.9798995 , 0.97979798,\n",
      "       0.97969543, 0.97959184, 0.98461538, 0.98453608, 0.98445596,\n",
      "       0.984375  , 0.98429319, 0.98421053, 0.98412698, 0.98404255,\n",
      "       0.98395722, 0.98924731, 0.98918919, 0.98913043, 0.98907104,\n",
      "       0.98901099, 0.98895028, 0.98888889, 0.98882682, 0.98876404,\n",
      "       0.98870056, 0.98863636, 0.98857143, 0.98850575, 0.98843931,\n",
      "       0.98837209, 0.98830409, 0.98823529, 0.98816568, 0.98809524,\n",
      "       0.98802395, 0.98795181, 0.98787879, 0.98780488, 0.98773006,\n",
      "       0.99382716, 0.99378882, 0.99375   , 0.99371069, 0.99367089,\n",
      "       0.99363057, 0.99358974, 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        ]), array([0.52536232, 0.52631579, 0.52727273, 0.52823315, 0.52919708,\n",
      "       0.53016453, 0.53113553, 0.53211009, 0.53308824, 0.53406998,\n",
      "       0.53505535, 0.53604436, 0.53703704, 0.5380334 , 0.53903346,\n",
      "       0.54003724, 0.54104478, 0.54205607, 0.54307116, 0.54409006,\n",
      "       0.54511278, 0.54613936, 0.54716981, 0.54820416, 0.54924242,\n",
      "       0.55028463, 0.5513308 , 0.55238095, 0.55343511, 0.55449331,\n",
      "       0.55555556, 0.55662188, 0.55769231, 0.55876686, 0.55984556,\n",
      "       0.56092843, 0.5620155 , 0.5631068 , 0.56420233, 0.56530214,\n",
      "       0.56640625, 0.56751468, 0.56862745, 0.56777996, 0.56889764,\n",
      "       0.57001972, 0.57114625, 0.57029703, 0.57142857, 0.57256461,\n",
      "       0.57370518, 0.5748503 , 0.576     , 0.57715431, 0.57831325,\n",
      "       0.57947686, 0.58064516, 0.58181818, 0.58299595, 0.5841785 ,\n",
      "       0.58536585, 0.58655804, 0.5877551 , 0.58895706, 0.59016393,\n",
      "       0.59137577, 0.59259259, 0.59381443, 0.59504132, 0.59627329,\n",
      "       0.59751037, 0.5987526 , 0.6       , 0.60125261, 0.60251046,\n",
      "       0.60377358, 0.60504202, 0.60631579, 0.60759494, 0.60887949,\n",
      "       0.61016949, 0.61146497, 0.61276596, 0.61407249, 0.61538462,\n",
      "       0.61670236, 0.61802575, 0.61935484, 0.62068966, 0.62203024,\n",
      "       0.62337662, 0.62472885, 0.62608696, 0.62745098, 0.62882096,\n",
      "       0.63019694, 0.63157895, 0.63296703, 0.63436123, 0.63576159,\n",
      "       0.63716814, 0.63636364, 0.63555556, 0.63697105, 0.63839286,\n",
      "       0.63982103, 0.64125561, 0.64269663, 0.64414414, 0.64559819,\n",
      "       0.64705882, 0.64852608, 0.65      , 0.65148064, 0.65296804,\n",
      "       0.65446224, 0.6559633 , 0.65747126, 0.65898618, 0.66050808,\n",
      "       0.66203704, 0.66357309, 0.66511628, 0.66666667, 0.6682243 ,\n",
      "       0.66978923, 0.6713615 , 0.67294118, 0.6745283 , 0.67612293,\n",
      "       0.67772512, 0.67933492, 0.68095238, 0.68257757, 0.68421053,\n",
      "       0.68585132, 0.6875    , 0.68915663, 0.69082126, 0.69249395,\n",
      "       0.69417476, 0.69586375, 0.69756098, 0.6992665 , 0.70098039,\n",
      "       0.7027027 , 0.7044335 , 0.70617284, 0.70792079, 0.70967742,\n",
      "       0.71144279, 0.71321696, 0.715     , 0.71679198, 0.71859296,\n",
      "       0.72040302, 0.72222222, 0.72405063, 0.72588832, 0.72773537,\n",
      "       0.72959184, 0.7314578 , 0.73333333, 0.73521851, 0.7371134 ,\n",
      "       0.73901809, 0.74093264, 0.74285714, 0.74479167, 0.74673629,\n",
      "       0.7486911 , 0.75065617, 0.75263158, 0.75461741, 0.75661376,\n",
      "       0.75596817, 0.75797872, 0.76      , 0.76203209, 0.76407507,\n",
      "       0.76612903, 0.76549865, 0.76756757, 0.7696477 , 0.77173913,\n",
      "       0.77384196, 0.77595628, 0.77808219, 0.78021978, 0.78236915,\n",
      "       0.78453039, 0.7867036 , 0.78888889, 0.79108635, 0.79050279,\n",
      "       0.79271709, 0.79213483, 0.7915493 , 0.79096045, 0.79320113,\n",
      "       0.79545455, 0.79487179, 0.79714286, 0.79942693, 0.80172414,\n",
      "       0.80403458, 0.80346821, 0.8057971 , 0.80813953, 0.81049563,\n",
      "       0.8128655 , 0.81524927, 0.81764706, 0.820059  , 0.81952663,\n",
      "       0.8189911 , 0.81845238, 0.82089552, 0.82335329, 0.82582583,\n",
      "       0.82831325, 0.83081571, 0.83030303, 0.83282675, 0.83536585,\n",
      "       0.83792049, 0.8404908 , 0.84307692, 0.84567901, 0.84829721,\n",
      "       0.84782609, 0.85046729, 0.853125  , 0.85579937, 0.85534591,\n",
      "       0.85488959, 0.85759494, 0.86031746, 0.85987261, 0.86261981,\n",
      "       0.86538462, 0.8681672 , 0.87096774, 0.87378641, 0.87662338,\n",
      "       0.87947883, 0.88235294, 0.8852459 , 0.88486842, 0.88778878,\n",
      "       0.89072848, 0.89368771, 0.89666667, 0.89632107, 0.89932886,\n",
      "       0.8989899 , 0.90202703, 0.90508475, 0.90816327, 0.90784983,\n",
      "       0.9109589 , 0.91408935, 0.91724138, 0.92041522, 0.92361111,\n",
      "       0.92682927, 0.93006993, 0.93333333, 0.93661972, 0.93992933,\n",
      "       0.94326241, 0.94661922, 0.94642857, 0.94623656, 0.94604317,\n",
      "       0.94945848, 0.94927536, 0.94909091, 0.94890511, 0.94871795,\n",
      "       0.94852941, 0.94833948, 0.95185185, 0.95167286, 0.95149254,\n",
      "       0.95131086, 0.95112782, 0.9509434 , 0.95075758, 0.95057034,\n",
      "       0.95038168, 0.95019157, 0.95384615, 0.95366795, 0.95348837,\n",
      "       0.95330739, 0.953125  , 0.95686275, 0.95669291, 0.95652174,\n",
      "       0.95634921, 0.9561753 , 0.96      , 0.96385542, 0.96370968,\n",
      "       0.96356275, 0.96341463, 0.96326531, 0.96311475, 0.96296296,\n",
      "       0.96280992, 0.9626556 , 0.9625    , 0.9623431 , 0.96638655,\n",
      "       0.97046414, 0.97033898, 0.97446809, 0.97435897, 0.97854077,\n",
      "       0.97844828, 0.97835498, 0.97826087, 0.97816594, 0.97807018,\n",
      "       0.97797357, 0.97787611, 0.97777778, 0.97767857, 0.98206278,\n",
      "       0.98198198, 0.98190045, 0.98181818, 0.98173516, 0.98623853,\n",
      "       0.98617512, 0.98611111, 0.98604651, 0.98598131, 0.98591549,\n",
      "       0.98584906, 0.98578199, 0.98571429, 0.98564593, 0.98557692,\n",
      "       0.99033816, 0.99029126, 0.9902439 , 0.99019608, 0.99014778,\n",
      "       0.99009901, 0.99004975, 0.99      , 0.98994975, 0.98989899,\n",
      "       0.98984772, 0.98979592, 0.98974359, 0.98969072, 0.98963731,\n",
      "       0.98958333, 0.9895288 , 0.98947368, 0.98941799, 0.9893617 ,\n",
      "       0.98930481, 0.98924731, 0.98918919, 0.98913043, 0.98907104,\n",
      "       0.98901099, 0.98895028, 0.98888889, 0.98882682, 0.98876404,\n",
      "       0.98870056, 0.98863636, 0.98857143, 0.98850575, 0.98843931,\n",
      "       0.98837209, 0.98830409, 0.98823529, 0.98816568, 0.98809524,\n",
      "       0.98802395, 0.98795181, 0.98787879, 0.98780488, 0.98773006,\n",
      "       0.99382716, 0.99378882, 0.99375   , 0.99371069, 0.99367089,\n",
      "       0.99363057, 0.99358974, 0.99354839, 0.99350649, 0.99346405,\n",
      "       0.99342105, 0.99337748, 0.99333333, 0.99328859, 0.99324324,\n",
      "       0.99319728, 0.99315068, 0.99310345, 0.99305556, 0.99300699,\n",
      "       0.99295775, 0.9929078 , 0.99285714, 0.99280576, 0.99275362,\n",
      "       0.99270073, 0.99264706, 0.99259259, 0.99253731, 0.9924812 ,\n",
      "       0.99242424, 0.99236641, 0.99230769, 0.99224806, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        ]), array([0.44927536, 0.45009074, 0.45090909, 0.45173042, 0.45255474,\n",
      "       0.45338208, 0.45421245, 0.45504587, 0.45588235, 0.45672192,\n",
      "       0.45756458, 0.45841035, 0.45925926, 0.46011132, 0.46096654,\n",
      "       0.46182495, 0.46268657, 0.4635514 , 0.46441948, 0.46529081,\n",
      "       0.46616541, 0.46704331, 0.46792453, 0.46880907, 0.46969697,\n",
      "       0.47058824, 0.47148289, 0.47238095, 0.47328244, 0.47418738,\n",
      "       0.47509579, 0.47600768, 0.47692308, 0.477842  , 0.47876448,\n",
      "       0.47969052, 0.48062016, 0.47961165, 0.48054475, 0.48148148,\n",
      "       0.48242188, 0.48336595, 0.48431373, 0.48330059, 0.48425197,\n",
      "       0.4852071 , 0.48616601, 0.48712871, 0.48809524, 0.48906561,\n",
      "       0.49003984, 0.49101796, 0.492     , 0.49298597, 0.4939759 ,\n",
      "       0.49496982, 0.49596774, 0.4969697 , 0.49797571, 0.4989858 ,\n",
      "       0.5       , 0.50101833, 0.50204082, 0.50306748, 0.50409836,\n",
      "       0.50513347, 0.50617284, 0.50721649, 0.50826446, 0.50931677,\n",
      "       0.51037344, 0.51143451, 0.5125    , 0.51356994, 0.51464435,\n",
      "       0.51572327, 0.51680672, 0.51789474, 0.51898734, 0.52008457,\n",
      "       0.52118644, 0.52229299, 0.52340426, 0.52452026, 0.52564103,\n",
      "       0.5267666 , 0.527897  , 0.52903226, 0.53017241, 0.53131749,\n",
      "       0.53246753, 0.53362256, 0.53478261, 0.53594771, 0.5371179 ,\n",
      "       0.53829322, 0.53947368, 0.54065934, 0.54185022, 0.54304636,\n",
      "       0.54424779, 0.54545455, 0.54666667, 0.54788419, 0.54910714,\n",
      "       0.55033557, 0.55156951, 0.55280899, 0.55405405, 0.55530474,\n",
      "       0.55656109, 0.55782313, 0.55909091, 0.56036446, 0.56164384,\n",
      "       0.56292906, 0.56422018, 0.56551724, 0.56682028, 0.56812933,\n",
      "       0.56944444, 0.57076566, 0.57209302, 0.57342657, 0.57476636,\n",
      "       0.57611241, 0.57746479, 0.57882353, 0.58018868, 0.58156028,\n",
      "       0.58293839, 0.58432304, 0.58571429, 0.58711217, 0.58851675,\n",
      "       0.58992806, 0.59134615, 0.59277108, 0.5942029 , 0.59564165,\n",
      "       0.59708738, 0.59610706, 0.59756098, 0.599022  , 0.6004902 ,\n",
      "       0.6019656 , 0.60344828, 0.60493827, 0.60643564, 0.60794045,\n",
      "       0.60945274, 0.61097257, 0.6125    , 0.61403509, 0.61306533,\n",
      "       0.61460957, 0.61616162, 0.61772152, 0.61928934, 0.62086514,\n",
      "       0.62244898, 0.62404092, 0.62564103, 0.62724936, 0.62886598,\n",
      "       0.63049096, 0.63212435, 0.63376623, 0.6328125 , 0.63446475,\n",
      "       0.63612565, 0.63779528, 0.63947368, 0.64116095, 0.64021164,\n",
      "       0.64190981, 0.64361702, 0.64533333, 0.64705882, 0.64879357,\n",
      "       0.65053763, 0.65229111, 0.65405405, 0.65582656, 0.6576087 ,\n",
      "       0.65940054, 0.66120219, 0.6630137 , 0.66483516, 0.66666667,\n",
      "       0.66850829, 0.67036011, 0.67222222, 0.67409471, 0.67597765,\n",
      "       0.67787115, 0.67977528, 0.68169014, 0.68361582, 0.68555241,\n",
      "       0.6875    , 0.68945869, 0.69142857, 0.69340974, 0.6954023 ,\n",
      "       0.69740634, 0.69942197, 0.70144928, 0.70348837, 0.70553936,\n",
      "       0.70760234, 0.70967742, 0.71176471, 0.71386431, 0.71597633,\n",
      "       0.71810089, 0.7202381 , 0.72238806, 0.72155689, 0.72372372,\n",
      "       0.72590361, 0.72809668, 0.73030303, 0.72948328, 0.73170732,\n",
      "       0.73394495, 0.73619632, 0.73846154, 0.74074074, 0.74303406,\n",
      "       0.74534161, 0.74766355, 0.75      , 0.7492163 , 0.75157233,\n",
      "       0.75394322, 0.75632911, 0.75873016, 0.7611465 , 0.76357827,\n",
      "       0.76282051, 0.76205788, 0.76129032, 0.76375405, 0.76623377,\n",
      "       0.76872964, 0.77124183, 0.77377049, 0.77631579, 0.77557756,\n",
      "       0.7781457 , 0.7807309 , 0.78333333, 0.7826087 , 0.7852349 ,\n",
      "       0.78787879, 0.79054054, 0.79322034, 0.79591837, 0.79863481,\n",
      "       0.80136986, 0.80412371, 0.80689655, 0.80968858, 0.8125    ,\n",
      "       0.81533101, 0.81818182, 0.82105263, 0.82394366, 0.82332155,\n",
      "       0.82269504, 0.82562278, 0.82857143, 0.83154122, 0.83453237,\n",
      "       0.83754513, 0.84057971, 0.84363636, 0.84306569, 0.84249084,\n",
      "       0.84558824, 0.84870849, 0.85185185, 0.85501859, 0.85820896,\n",
      "       0.86142322, 0.86466165, 0.86792453, 0.87121212, 0.87452471,\n",
      "       0.8778626 , 0.88122605, 0.88461538, 0.88416988, 0.88372093,\n",
      "       0.88326848, 0.88671875, 0.89019608, 0.88976378, 0.88932806,\n",
      "       0.89285714, 0.89641434, 0.9       , 0.90361446, 0.90725806,\n",
      "       0.91093117, 0.91056911, 0.91428571, 0.91803279, 0.91769547,\n",
      "       0.91735537, 0.91701245, 0.91666667, 0.91631799, 0.91596639,\n",
      "       0.91983122, 0.92372881, 0.92340426, 0.92735043, 0.93133047,\n",
      "       0.93534483, 0.93506494, 0.93913043, 0.93886463, 0.93859649,\n",
      "       0.93832599, 0.9380531 , 0.93777778, 0.9375    , 0.93721973,\n",
      "       0.93693694, 0.94117647, 0.94545455, 0.94520548, 0.94954128,\n",
      "       0.95391705, 0.9537037 , 0.95813953, 0.95794393, 0.95774648,\n",
      "       0.95754717, 0.96208531, 0.96190476, 0.96172249, 0.96153846,\n",
      "       0.96135266, 0.96116505, 0.96585366, 0.97058824, 0.97536946,\n",
      "       0.98019802, 0.9800995 , 0.98      , 0.9798995 , 0.97979798,\n",
      "       0.97969543, 0.97959184, 0.97948718, 0.98453608, 0.98445596,\n",
      "       0.98958333, 0.9895288 , 0.98947368, 0.98941799, 0.9893617 ,\n",
      "       0.98930481, 0.98924731, 0.98918919, 0.98913043, 0.98907104,\n",
      "       0.98901099, 0.98895028, 0.98888889, 0.98882682, 0.98876404,\n",
      "       0.98870056, 0.98863636, 0.98857143, 0.98850575, 0.98843931,\n",
      "       0.98837209, 0.98830409, 0.98823529, 0.98816568, 0.98809524,\n",
      "       0.98802395, 0.98795181, 0.98787879, 0.98780488, 0.98773006,\n",
      "       0.98765432, 0.98757764, 0.9875    , 0.98742138, 0.98734177,\n",
      "       0.98726115, 0.98717949, 0.98709677, 0.98701299, 0.9869281 ,\n",
      "       0.98684211, 0.98675497, 0.98666667, 0.98657718, 0.98648649,\n",
      "       0.98639456, 0.98630137, 0.9862069 , 0.98611111, 0.98601399,\n",
      "       0.98591549, 0.9858156 , 0.98571429, 0.98561151, 0.98550725,\n",
      "       0.98540146, 0.98529412, 0.98518519, 0.98507463, 0.98496241,\n",
      "       0.98484848, 0.98473282, 0.98461538, 0.98449612, 0.984375  ,\n",
      "       0.98425197, 0.98412698, 0.984     , 0.98387097, 0.98373984,\n",
      "       0.98360656, 0.98347107, 0.98333333, 0.98319328, 0.98305085,\n",
      "       0.98290598, 0.99137931, 0.99130435, 0.99122807, 0.99115044,\n",
      "       0.99107143, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        ]), array([0.48188406, 0.48275862, 0.48363636, 0.4845173 , 0.48540146,\n",
      "       0.48628885, 0.48717949, 0.48807339, 0.48897059, 0.48987109,\n",
      "       0.49077491, 0.49168207, 0.49259259, 0.49350649, 0.49442379,\n",
      "       0.49534451, 0.49626866, 0.49719626, 0.49812734, 0.49906191,\n",
      "       0.5       , 0.50094162, 0.50188679, 0.50283554, 0.50378788,\n",
      "       0.50474383, 0.50570342, 0.50666667, 0.50763359, 0.50860421,\n",
      "       0.50957854, 0.51055662, 0.51153846, 0.51252408, 0.51351351,\n",
      "       0.51450677, 0.51550388, 0.51650485, 0.51750973, 0.51851852,\n",
      "       0.51953125, 0.52054795, 0.52156863, 0.52259332, 0.52362205,\n",
      "       0.52465483, 0.5256917 , 0.52673267, 0.52777778, 0.52882704,\n",
      "       0.52988048, 0.53093812, 0.532     , 0.53306613, 0.53413655,\n",
      "       0.53521127, 0.53629032, 0.53737374, 0.53846154, 0.53955375,\n",
      "       0.54065041, 0.54175153, 0.54285714, 0.54396728, 0.54508197,\n",
      "       0.54620123, 0.5473251 , 0.54845361, 0.54958678, 0.55072464,\n",
      "       0.55186722, 0.55301455, 0.55416667, 0.55532359, 0.55648536,\n",
      "       0.55765199, 0.55882353, 0.56      , 0.56118143, 0.56236786,\n",
      "       0.56355932, 0.56475584, 0.56595745, 0.56716418, 0.56837607,\n",
      "       0.56959315, 0.57081545, 0.57204301, 0.57327586, 0.57451404,\n",
      "       0.57575758, 0.57700651, 0.57826087, 0.5795207 , 0.58078603,\n",
      "       0.58205689, 0.58333333, 0.58461538, 0.58590308, 0.58719647,\n",
      "       0.58849558, 0.58980044, 0.59111111, 0.59242762, 0.59375   ,\n",
      "       0.5950783 , 0.59641256, 0.59775281, 0.5990991 , 0.60045147,\n",
      "       0.60180995, 0.6031746 , 0.60454545, 0.60592255, 0.60730594,\n",
      "       0.60869565, 0.61009174, 0.61149425, 0.61290323, 0.61431871,\n",
      "       0.61574074, 0.61716937, 0.61860465, 0.62004662, 0.62149533,\n",
      "       0.62295082, 0.62441315, 0.62588235, 0.62735849, 0.62884161,\n",
      "       0.63033175, 0.63182898, 0.63333333, 0.63484487, 0.63636364,\n",
      "       0.63788969, 0.63942308, 0.64096386, 0.64251208, 0.6440678 ,\n",
      "       0.64563107, 0.64720195, 0.64878049, 0.65036675, 0.65196078,\n",
      "       0.65356265, 0.65517241, 0.65679012, 0.65841584, 0.66004963,\n",
      "       0.66169154, 0.66334165, 0.665     , 0.66666667, 0.66834171,\n",
      "       0.67002519, 0.67171717, 0.67341772, 0.6751269 , 0.67684478,\n",
      "       0.67857143, 0.68030691, 0.68205128, 0.68380463, 0.68556701,\n",
      "       0.6873385 , 0.68911917, 0.69090909, 0.69270833, 0.69451697,\n",
      "       0.69633508, 0.69816273, 0.7       , 0.70184697, 0.7037037 ,\n",
      "       0.70557029, 0.70744681, 0.70933333, 0.71122995, 0.71313673,\n",
      "       0.71505376, 0.71698113, 0.71891892, 0.72086721, 0.72282609,\n",
      "       0.72479564, 0.72677596, 0.72876712, 0.73076923, 0.73278237,\n",
      "       0.73480663, 0.73684211, 0.73888889, 0.74094708, 0.74301676,\n",
      "       0.74509804, 0.74719101, 0.74929577, 0.74858757, 0.75070822,\n",
      "       0.75      , 0.75213675, 0.75428571, 0.75644699, 0.75862069,\n",
      "       0.76080692, 0.76300578, 0.76521739, 0.76744186, 0.7696793 ,\n",
      "       0.77192982, 0.77419355, 0.77647059, 0.77876106, 0.78106509,\n",
      "       0.78338279, 0.78571429, 0.7880597 , 0.79041916, 0.79279279,\n",
      "       0.79518072, 0.79758308, 0.8       , 0.80243161, 0.80487805,\n",
      "       0.80733945, 0.80981595, 0.81230769, 0.81481481, 0.81733746,\n",
      "       0.81987578, 0.82242991, 0.825     , 0.82758621, 0.83018868,\n",
      "       0.83280757, 0.83544304, 0.83809524, 0.84076433, 0.84345048,\n",
      "       0.84615385, 0.8488746 , 0.8516129 , 0.85113269, 0.8538961 ,\n",
      "       0.8534202 , 0.85620915, 0.85901639, 0.86184211, 0.86468647,\n",
      "       0.86754967, 0.87043189, 0.87333333, 0.8729097 , 0.87583893,\n",
      "       0.87542088, 0.87837838, 0.88135593, 0.88095238, 0.88054608,\n",
      "       0.88013699, 0.87972509, 0.88275862, 0.88235294, 0.88194444,\n",
      "       0.88501742, 0.88461538, 0.88421053, 0.88732394, 0.89045936,\n",
      "       0.89361702, 0.89679715, 0.9       , 0.90322581, 0.9028777 ,\n",
      "       0.90613718, 0.90942029, 0.90909091, 0.91240876, 0.91575092,\n",
      "       0.91911765, 0.92250923, 0.92592593, 0.92936803, 0.92910448,\n",
      "       0.93258427, 0.93233083, 0.93584906, 0.93939394, 0.9391635 ,\n",
      "       0.9389313 , 0.93869732, 0.93846154, 0.93822394, 0.9379845 ,\n",
      "       0.93774319, 0.9375    , 0.94117647, 0.94094488, 0.94466403,\n",
      "       0.94444444, 0.94422311, 0.944     , 0.9437751 , 0.94354839,\n",
      "       0.94331984, 0.94308943, 0.94285714, 0.94262295, 0.94238683,\n",
      "       0.94214876, 0.94190871, 0.94166667, 0.94142259, 0.94117647,\n",
      "       0.94092827, 0.94491525, 0.94468085, 0.94444444, 0.94849785,\n",
      "       0.94827586, 0.94805195, 0.95217391, 0.95196507, 0.95175439,\n",
      "       0.95154185, 0.95132743, 0.95111111, 0.95089286, 0.95515695,\n",
      "       0.95495495, 0.95927602, 0.96363636, 0.96347032, 0.96330275,\n",
      "       0.96313364, 0.96296296, 0.9627907 , 0.96261682, 0.96244131,\n",
      "       0.96226415, 0.96208531, 0.96190476, 0.96172249, 0.96153846,\n",
      "       0.96135266, 0.96116505, 0.96097561, 0.96078431, 0.96059113,\n",
      "       0.96039604, 0.960199  , 0.96      , 0.95979899, 0.95959596,\n",
      "       0.95939086, 0.95918367, 0.95897436, 0.95876289, 0.95854922,\n",
      "       0.95833333, 0.95811518, 0.95789474, 0.95767196, 0.95744681,\n",
      "       0.96256684, 0.96236559, 0.96216216, 0.96195652, 0.96174863,\n",
      "       0.96153846, 0.96132597, 0.96666667, 0.96648045, 0.97191011,\n",
      "       0.97175141, 0.97159091, 0.97714286, 0.98275862, 0.98265896,\n",
      "       0.98837209, 0.98830409, 0.99411765, 0.99408284, 0.99404762,\n",
      "       0.99401198, 0.9939759 , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        ])]\n",
      "recalls [array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99647887, 0.99647887, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
      "       0.99295775, 0.99295775, 0.98943662, 0.98943662, 0.98943662,\n",
      "       0.98943662, 0.98943662, 0.98591549, 0.98591549, 0.98591549,\n",
      "       0.98591549, 0.98591549, 0.98591549, 0.98591549, 0.98591549,\n",
      "       0.98239437, 0.98239437, 0.98239437, 0.98239437, 0.97887324,\n",
      "       0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
      "       0.97535211, 0.97535211, 0.97183099, 0.97183099, 0.97183099,\n",
      "       0.96830986, 0.96830986, 0.96830986, 0.96830986, 0.96478873,\n",
      "       0.96478873, 0.96478873, 0.96478873, 0.96478873, 0.96478873,\n",
      "       0.96478873, 0.96478873, 0.96478873, 0.96478873, 0.96126761,\n",
      "       0.95774648, 0.95774648, 0.95422535, 0.95422535, 0.95422535,\n",
      "       0.95070423, 0.95070423, 0.95070423, 0.95070423, 0.95070423,\n",
      "       0.95070423, 0.95070423, 0.9471831 , 0.94366197, 0.94014085,\n",
      "       0.93661972, 0.93661972, 0.93661972, 0.93661972, 0.93309859,\n",
      "       0.92957746, 0.92957746, 0.92957746, 0.92957746, 0.92957746,\n",
      "       0.92957746, 0.92957746, 0.92957746, 0.92957746, 0.92605634,\n",
      "       0.92605634, 0.92605634, 0.92605634, 0.92253521, 0.92253521,\n",
      "       0.92253521, 0.92253521, 0.92253521, 0.91901408, 0.91549296,\n",
      "       0.91197183, 0.9084507 , 0.9084507 , 0.90492958, 0.90140845,\n",
      "       0.90140845, 0.89788732, 0.8943662 , 0.8943662 , 0.8943662 ,\n",
      "       0.8943662 , 0.8943662 , 0.89084507, 0.88732394, 0.88380282,\n",
      "       0.88028169, 0.88028169, 0.87676056, 0.87323944, 0.86971831,\n",
      "       0.86619718, 0.86619718, 0.86267606, 0.85915493, 0.8556338 ,\n",
      "       0.85211268, 0.84859155, 0.84507042, 0.8415493 , 0.83802817,\n",
      "       0.83802817, 0.83802817, 0.83450704, 0.83098592, 0.82746479,\n",
      "       0.82394366, 0.82042254, 0.82042254, 0.81690141, 0.81338028,\n",
      "       0.81338028, 0.80985915, 0.80633803, 0.8028169 , 0.79929577,\n",
      "       0.79577465, 0.79225352, 0.78873239, 0.78873239, 0.78873239,\n",
      "       0.78521127, 0.78169014, 0.77816901, 0.77464789, 0.77112676,\n",
      "       0.76760563, 0.76408451, 0.76056338, 0.75704225, 0.75352113,\n",
      "       0.75      , 0.74647887, 0.74647887, 0.74295775, 0.73943662,\n",
      "       0.73591549, 0.73239437, 0.73239437, 0.72887324, 0.72535211,\n",
      "       0.72183099, 0.71830986, 0.71478873, 0.71126761, 0.70774648,\n",
      "       0.70422535, 0.70070423, 0.6971831 , 0.69366197, 0.69014085,\n",
      "       0.68661972, 0.68309859, 0.67957746, 0.67605634, 0.67253521,\n",
      "       0.66901408, 0.66549296, 0.66197183, 0.6584507 , 0.65492958,\n",
      "       0.65140845, 0.64788732, 0.6443662 , 0.64084507, 0.63732394,\n",
      "       0.63380282, 0.63028169, 0.62676056, 0.62323944, 0.61971831,\n",
      "       0.61619718, 0.61267606, 0.60915493, 0.6056338 , 0.60211268,\n",
      "       0.59859155, 0.59507042, 0.5915493 , 0.58802817, 0.58802817,\n",
      "       0.58450704, 0.58450704, 0.58098592, 0.57746479, 0.57394366,\n",
      "       0.57042254, 0.56690141, 0.56338028, 0.55985915, 0.55633803,\n",
      "       0.5528169 , 0.54929577, 0.54577465, 0.54225352, 0.53873239,\n",
      "       0.53521127, 0.53169014, 0.52816901, 0.52464789, 0.52112676,\n",
      "       0.51760563, 0.51408451, 0.51056338, 0.50704225, 0.50352113,\n",
      "       0.5       , 0.49647887, 0.49295775, 0.48943662, 0.48591549,\n",
      "       0.48239437, 0.47887324, 0.47535211, 0.47183099, 0.46830986,\n",
      "       0.46478873, 0.46126761, 0.45774648, 0.45422535, 0.45070423,\n",
      "       0.4471831 , 0.44366197, 0.44014085, 0.43661972, 0.43309859,\n",
      "       0.42957746, 0.42605634, 0.42253521, 0.41901408, 0.41549296,\n",
      "       0.41197183, 0.4084507 , 0.40492958, 0.40140845, 0.39788732,\n",
      "       0.3943662 , 0.39084507, 0.38732394, 0.38380282, 0.38028169,\n",
      "       0.37676056, 0.37323944, 0.36971831, 0.36619718, 0.36267606,\n",
      "       0.35915493, 0.3556338 , 0.35211268, 0.34859155, 0.34507042,\n",
      "       0.3415493 , 0.33450704, 0.33098592, 0.32746479, 0.32394366,\n",
      "       0.32042254, 0.31690141, 0.31338028, 0.30985915, 0.30633803,\n",
      "       0.3028169 , 0.29929577, 0.29577465, 0.29225352, 0.28873239,\n",
      "       0.28521127, 0.28169014, 0.27816901, 0.27464789, 0.27112676,\n",
      "       0.26760563, 0.26408451, 0.26056338, 0.25704225, 0.25352113,\n",
      "       0.25      , 0.24647887, 0.24295775, 0.23943662, 0.23591549,\n",
      "       0.23239437, 0.22887324, 0.22535211, 0.22183099, 0.21830986,\n",
      "       0.21478873, 0.21126761, 0.20774648, 0.20422535, 0.20070423,\n",
      "       0.1971831 , 0.19366197, 0.19014085, 0.18661972, 0.18309859,\n",
      "       0.17957746, 0.17605634, 0.17253521, 0.16901408, 0.16549296,\n",
      "       0.16197183, 0.1584507 , 0.15492958, 0.15140845, 0.14788732,\n",
      "       0.1443662 , 0.14084507, 0.13732394, 0.13380282, 0.13028169,\n",
      "       0.12676056, 0.12323944, 0.11971831, 0.11619718, 0.11267606,\n",
      "       0.10915493, 0.1056338 , 0.10211268, 0.09859155, 0.09507042,\n",
      "       0.0915493 , 0.08802817, 0.08450704, 0.08098592, 0.07746479,\n",
      "       0.07394366, 0.07042254, 0.06690141, 0.06338028, 0.05985915,\n",
      "       0.05633803, 0.04929577, 0.04577465, 0.04225352, 0.03873239,\n",
      "       0.03521127, 0.03169014, 0.02816901, 0.02464789, 0.02112676,\n",
      "       0.01760563, 0.01408451, 0.01056338, 0.00704225, 0.00352113,\n",
      "       0.        ]), array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99657534, 0.99657534, 0.99657534, 0.99657534,\n",
      "       0.99657534, 0.99315068, 0.99315068, 0.99315068, 0.99315068,\n",
      "       0.99315068, 0.99315068, 0.99315068, 0.99315068, 0.98972603,\n",
      "       0.98972603, 0.98972603, 0.98972603, 0.98630137, 0.98630137,\n",
      "       0.98630137, 0.98630137, 0.98630137, 0.98630137, 0.98630137,\n",
      "       0.98630137, 0.98630137, 0.98630137, 0.98630137, 0.98630137,\n",
      "       0.98630137, 0.98630137, 0.98630137, 0.98630137, 0.98630137,\n",
      "       0.98630137, 0.98630137, 0.98630137, 0.98630137, 0.98630137,\n",
      "       0.98630137, 0.98287671, 0.98287671, 0.98287671, 0.98287671,\n",
      "       0.97945205, 0.97945205, 0.97945205, 0.97945205, 0.97945205,\n",
      "       0.9760274 , 0.9760274 , 0.9760274 , 0.9760274 , 0.9760274 ,\n",
      "       0.9760274 , 0.9760274 , 0.9760274 , 0.97260274, 0.97260274,\n",
      "       0.97260274, 0.96917808, 0.96917808, 0.96917808, 0.96917808,\n",
      "       0.96917808, 0.96917808, 0.96917808, 0.96917808, 0.96575342,\n",
      "       0.96575342, 0.96575342, 0.96575342, 0.96575342, 0.96575342,\n",
      "       0.96575342, 0.96575342, 0.96575342, 0.96575342, 0.96575342,\n",
      "       0.96575342, 0.96575342, 0.96575342, 0.96575342, 0.96575342,\n",
      "       0.96575342, 0.96575342, 0.96575342, 0.96575342, 0.96575342,\n",
      "       0.96575342, 0.96575342, 0.96575342, 0.96575342, 0.96575342,\n",
      "       0.96575342, 0.96232877, 0.96232877, 0.96232877, 0.96232877,\n",
      "       0.96232877, 0.96232877, 0.95890411, 0.95890411, 0.95547945,\n",
      "       0.95205479, 0.95205479, 0.94863014, 0.94863014, 0.94520548,\n",
      "       0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94178082,\n",
      "       0.93835616, 0.93835616, 0.93493151, 0.93493151, 0.93150685,\n",
      "       0.92808219, 0.92808219, 0.92465753, 0.92465753, 0.92123288,\n",
      "       0.92123288, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
      "       0.91780822, 0.91438356, 0.91438356, 0.91438356, 0.9109589 ,\n",
      "       0.9109589 , 0.90753425, 0.90410959, 0.90068493, 0.90068493,\n",
      "       0.89726027, 0.89726027, 0.89726027, 0.89726027, 0.89383562,\n",
      "       0.89383562, 0.89383562, 0.89383562, 0.89041096, 0.89041096,\n",
      "       0.8869863 , 0.88356164, 0.88356164, 0.88356164, 0.88356164,\n",
      "       0.88013699, 0.87671233, 0.87328767, 0.86986301, 0.86986301,\n",
      "       0.86986301, 0.86986301, 0.86986301, 0.86986301, 0.86643836,\n",
      "       0.86643836, 0.8630137 , 0.85958904, 0.85616438, 0.85273973,\n",
      "       0.84931507, 0.84589041, 0.84589041, 0.84246575, 0.84246575,\n",
      "       0.8390411 , 0.83561644, 0.83219178, 0.83219178, 0.82876712,\n",
      "       0.82534247, 0.82534247, 0.82534247, 0.82191781, 0.81849315,\n",
      "       0.81506849, 0.81164384, 0.81164384, 0.81164384, 0.80821918,\n",
      "       0.80479452, 0.80479452, 0.80479452, 0.80136986, 0.79794521,\n",
      "       0.79452055, 0.79109589, 0.78767123, 0.78424658, 0.78082192,\n",
      "       0.77739726, 0.7739726 , 0.77054795, 0.76712329, 0.76369863,\n",
      "       0.76369863, 0.76027397, 0.75684932, 0.75342466, 0.75      ,\n",
      "       0.75      , 0.74657534, 0.74315068, 0.73972603, 0.73630137,\n",
      "       0.73287671, 0.72945205, 0.7260274 , 0.7260274 , 0.72260274,\n",
      "       0.71917808, 0.71917808, 0.71917808, 0.71917808, 0.71575342,\n",
      "       0.71232877, 0.70890411, 0.70547945, 0.70205479, 0.69863014,\n",
      "       0.69520548, 0.69178082, 0.68835616, 0.68493151, 0.68150685,\n",
      "       0.67808219, 0.67465753, 0.67123288, 0.66780822, 0.66438356,\n",
      "       0.6609589 , 0.65753425, 0.65753425, 0.65410959, 0.65068493,\n",
      "       0.64726027, 0.64383562, 0.64041096, 0.6369863 , 0.63356164,\n",
      "       0.63013699, 0.63013699, 0.62671233, 0.62328767, 0.61986301,\n",
      "       0.61643836, 0.6130137 , 0.60958904, 0.60616438, 0.60273973,\n",
      "       0.59931507, 0.59589041, 0.59246575, 0.5890411 , 0.58561644,\n",
      "       0.58219178, 0.57876712, 0.57534247, 0.57191781, 0.56849315,\n",
      "       0.56506849, 0.56164384, 0.55821918, 0.55479452, 0.55136986,\n",
      "       0.55136986, 0.54794521, 0.54452055, 0.54109589, 0.53767123,\n",
      "       0.53424658, 0.53082192, 0.53082192, 0.52739726, 0.5239726 ,\n",
      "       0.52054795, 0.51712329, 0.51369863, 0.51027397, 0.50684932,\n",
      "       0.50342466, 0.5       , 0.49657534, 0.49315068, 0.48972603,\n",
      "       0.48630137, 0.48287671, 0.47945205, 0.4760274 , 0.47260274,\n",
      "       0.46917808, 0.46575342, 0.46232877, 0.45890411, 0.45547945,\n",
      "       0.45205479, 0.44863014, 0.44520548, 0.44178082, 0.43835616,\n",
      "       0.43493151, 0.43150685, 0.42808219, 0.42465753, 0.42123288,\n",
      "       0.41780822, 0.41438356, 0.4109589 , 0.40753425, 0.40410959,\n",
      "       0.40068493, 0.39726027, 0.39383562, 0.39041096, 0.3869863 ,\n",
      "       0.38356164, 0.38013699, 0.37671233, 0.37328767, 0.36986301,\n",
      "       0.36643836, 0.3630137 , 0.35616438, 0.35273973, 0.34931507,\n",
      "       0.34589041, 0.34246575, 0.3390411 , 0.33561644, 0.33219178,\n",
      "       0.32876712, 0.32534247, 0.32191781, 0.31849315, 0.31506849,\n",
      "       0.31164384, 0.30821918, 0.30479452, 0.30136986, 0.29794521,\n",
      "       0.29452055, 0.29109589, 0.28767123, 0.28424658, 0.28082192,\n",
      "       0.27739726, 0.2739726 , 0.27054795, 0.26712329, 0.26369863,\n",
      "       0.26027397, 0.25684932, 0.25342466, 0.25      , 0.24657534,\n",
      "       0.24315068, 0.23972603, 0.23630137, 0.23287671, 0.22945205,\n",
      "       0.2260274 , 0.22260274, 0.21917808, 0.21575342, 0.21232877,\n",
      "       0.20890411, 0.20547945, 0.20205479, 0.19863014, 0.19520548,\n",
      "       0.19178082, 0.18835616, 0.18493151, 0.18150685, 0.17808219,\n",
      "       0.17123288, 0.16780822, 0.16438356, 0.1609589 , 0.15753425,\n",
      "       0.15410959, 0.15068493, 0.14726027, 0.14383562, 0.14041096,\n",
      "       0.1369863 , 0.13356164, 0.13013699, 0.12671233, 0.12328767,\n",
      "       0.11986301, 0.11643836, 0.1130137 , 0.10958904, 0.10616438,\n",
      "       0.10273973, 0.09931507, 0.09589041, 0.09246575, 0.0890411 ,\n",
      "       0.08561644, 0.08219178, 0.07876712, 0.07534247, 0.07191781,\n",
      "       0.06849315, 0.06506849, 0.06164384, 0.05821918, 0.05479452,\n",
      "       0.05136986, 0.04794521, 0.04452055, 0.04109589, 0.03767123,\n",
      "       0.03424658, 0.03082192, 0.02739726, 0.0239726 , 0.02054795,\n",
      "       0.01712329, 0.01369863, 0.01027397, 0.00684932, 0.00342466,\n",
      "       0.        ]), array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.99655172, 0.99655172,\n",
      "       0.99655172, 0.99655172, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.99310345, 0.99310345, 0.99310345, 0.99310345,\n",
      "       0.99310345, 0.98965517, 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 , 0.9862069 ,\n",
      "       0.98275862, 0.98275862, 0.98275862, 0.98275862, 0.98275862,\n",
      "       0.98275862, 0.97931034, 0.97931034, 0.97931034, 0.97931034,\n",
      "       0.97931034, 0.97931034, 0.97931034, 0.97931034, 0.97931034,\n",
      "       0.97931034, 0.97931034, 0.97931034, 0.97931034, 0.97586207,\n",
      "       0.97586207, 0.97241379, 0.96896552, 0.96551724, 0.96551724,\n",
      "       0.96551724, 0.96206897, 0.96206897, 0.96206897, 0.96206897,\n",
      "       0.96206897, 0.95862069, 0.95862069, 0.95862069, 0.95862069,\n",
      "       0.95862069, 0.95862069, 0.95862069, 0.95862069, 0.95517241,\n",
      "       0.95172414, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
      "       0.94827586, 0.94827586, 0.94482759, 0.94482759, 0.94482759,\n",
      "       0.94482759, 0.94482759, 0.94482759, 0.94482759, 0.94482759,\n",
      "       0.94137931, 0.94137931, 0.94137931, 0.94137931, 0.93793103,\n",
      "       0.93448276, 0.93448276, 0.93448276, 0.93103448, 0.93103448,\n",
      "       0.93103448, 0.93103448, 0.93103448, 0.93103448, 0.93103448,\n",
      "       0.93103448, 0.93103448, 0.93103448, 0.92758621, 0.92758621,\n",
      "       0.92758621, 0.92758621, 0.92758621, 0.92413793, 0.92413793,\n",
      "       0.92068966, 0.92068966, 0.92068966, 0.92068966, 0.91724138,\n",
      "       0.91724138, 0.91724138, 0.91724138, 0.91724138, 0.91724138,\n",
      "       0.91724138, 0.91724138, 0.91724138, 0.91724138, 0.91724138,\n",
      "       0.91724138, 0.91724138, 0.9137931 , 0.91034483, 0.90689655,\n",
      "       0.90689655, 0.90344828, 0.9       , 0.89655172, 0.89310345,\n",
      "       0.88965517, 0.8862069 , 0.8862069 , 0.88275862, 0.87931034,\n",
      "       0.87586207, 0.87241379, 0.86896552, 0.86551724, 0.86206897,\n",
      "       0.85862069, 0.85517241, 0.85517241, 0.85172414, 0.84827586,\n",
      "       0.84482759, 0.84137931, 0.84137931, 0.83793103, 0.83448276,\n",
      "       0.83103448, 0.82758621, 0.82758621, 0.82758621, 0.82413793,\n",
      "       0.82068966, 0.81724138, 0.8137931 , 0.81034483, 0.80689655,\n",
      "       0.80344828, 0.8       , 0.79655172, 0.79310345, 0.79310345,\n",
      "       0.79310345, 0.78965517, 0.78965517, 0.7862069 , 0.7862069 ,\n",
      "       0.78275862, 0.77931034, 0.77586207, 0.77241379, 0.76896552,\n",
      "       0.76551724, 0.76206897, 0.75862069, 0.75517241, 0.75517241,\n",
      "       0.75172414, 0.74827586, 0.74482759, 0.74137931, 0.74137931,\n",
      "       0.73793103, 0.73448276, 0.73103448, 0.72758621, 0.72413793,\n",
      "       0.72068966, 0.71724138, 0.7137931 , 0.71034483, 0.70689655,\n",
      "       0.70689655, 0.70344828, 0.7       , 0.69655172, 0.69310345,\n",
      "       0.68965517, 0.6862069 , 0.68275862, 0.67931034, 0.67586207,\n",
      "       0.67241379, 0.66896552, 0.66551724, 0.66206897, 0.65862069,\n",
      "       0.65517241, 0.65172414, 0.64827586, 0.64482759, 0.64137931,\n",
      "       0.63793103, 0.63448276, 0.63103448, 0.62758621, 0.62413793,\n",
      "       0.62068966, 0.61724138, 0.6137931 , 0.61034483, 0.60689655,\n",
      "       0.60344828, 0.6       , 0.59655172, 0.59310345, 0.58965517,\n",
      "       0.5862069 , 0.58275862, 0.57931034, 0.57586207, 0.57241379,\n",
      "       0.56896552, 0.56551724, 0.56206897, 0.55862069, 0.55517241,\n",
      "       0.55517241, 0.55172414, 0.54827586, 0.54482759, 0.54137931,\n",
      "       0.53793103, 0.53448276, 0.53103448, 0.52758621, 0.52413793,\n",
      "       0.52068966, 0.51724138, 0.5137931 , 0.51034483, 0.50689655,\n",
      "       0.50344828, 0.5       , 0.49655172, 0.49310345, 0.48965517,\n",
      "       0.4862069 , 0.48275862, 0.47931034, 0.47586207, 0.47241379,\n",
      "       0.46896552, 0.46551724, 0.46206897, 0.45862069, 0.45517241,\n",
      "       0.45172414, 0.44827586, 0.44482759, 0.44137931, 0.44137931,\n",
      "       0.43793103, 0.43448276, 0.43103448, 0.42758621, 0.42413793,\n",
      "       0.42068966, 0.41724138, 0.4137931 , 0.41034483, 0.40689655,\n",
      "       0.40344828, 0.4       , 0.39655172, 0.39310345, 0.38965517,\n",
      "       0.3862069 , 0.38275862, 0.37931034, 0.37586207, 0.37241379,\n",
      "       0.36896552, 0.36551724, 0.36206897, 0.35862069, 0.35517241,\n",
      "       0.35172414, 0.34827586, 0.34482759, 0.34137931, 0.33793103,\n",
      "       0.33448276, 0.33103448, 0.32758621, 0.32413793, 0.32068966,\n",
      "       0.31724138, 0.3137931 , 0.31034483, 0.30689655, 0.30344828,\n",
      "       0.3       , 0.29655172, 0.29310345, 0.28965517, 0.2862069 ,\n",
      "       0.28275862, 0.27931034, 0.27586207, 0.27241379, 0.26896552,\n",
      "       0.26551724, 0.26206897, 0.25862069, 0.25517241, 0.25172414,\n",
      "       0.24827586, 0.24482759, 0.24137931, 0.23793103, 0.23448276,\n",
      "       0.23103448, 0.22758621, 0.22413793, 0.22068966, 0.21724138,\n",
      "       0.2137931 , 0.21034483, 0.20689655, 0.20344828, 0.2       ,\n",
      "       0.19655172, 0.19310345, 0.18965517, 0.1862069 , 0.18275862,\n",
      "       0.17931034, 0.17586207, 0.17241379, 0.16896552, 0.16551724,\n",
      "       0.16206897, 0.15862069, 0.15517241, 0.15172414, 0.14827586,\n",
      "       0.14482759, 0.14137931, 0.13793103, 0.13448276, 0.13103448,\n",
      "       0.12758621, 0.12413793, 0.12068966, 0.11724138, 0.1137931 ,\n",
      "       0.11034483, 0.10689655, 0.10344828, 0.1       , 0.09655172,\n",
      "       0.09310345, 0.08965517, 0.0862069 , 0.08275862, 0.07931034,\n",
      "       0.07586207, 0.07241379, 0.06896552, 0.06551724, 0.06206897,\n",
      "       0.05862069, 0.05517241, 0.05172414, 0.04827586, 0.04482759,\n",
      "       0.04137931, 0.03793103, 0.03448276, 0.03103448, 0.02758621,\n",
      "       0.02413793, 0.02068966, 0.01724138, 0.0137931 , 0.01034483,\n",
      "       0.00689655, 0.00344828, 0.        ]), array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99596774, 0.99596774, 0.99596774,\n",
      "       0.99596774, 0.99596774, 0.99596774, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.99193548, 0.99193548, 0.99193548, 0.99193548,\n",
      "       0.99193548, 0.98790323, 0.98790323, 0.98790323, 0.98790323,\n",
      "       0.98790323, 0.98790323, 0.98790323, 0.98790323, 0.98790323,\n",
      "       0.98790323, 0.98790323, 0.98790323, 0.98790323, 0.98387097,\n",
      "       0.98387097, 0.98387097, 0.98387097, 0.98387097, 0.98387097,\n",
      "       0.98387097, 0.98387097, 0.98387097, 0.98387097, 0.98387097,\n",
      "       0.98387097, 0.98387097, 0.98387097, 0.97983871, 0.97983871,\n",
      "       0.97983871, 0.97983871, 0.97983871, 0.97983871, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97580645, 0.97580645,\n",
      "       0.97580645, 0.97580645, 0.97580645, 0.97177419, 0.97177419,\n",
      "       0.97177419, 0.97177419, 0.97177419, 0.96774194, 0.96774194,\n",
      "       0.96774194, 0.96774194, 0.96774194, 0.96774194, 0.96774194,\n",
      "       0.96774194, 0.96774194, 0.96774194, 0.96370968, 0.96370968,\n",
      "       0.96370968, 0.96370968, 0.96370968, 0.96370968, 0.96370968,\n",
      "       0.95967742, 0.95564516, 0.9516129 , 0.9516129 , 0.9516129 ,\n",
      "       0.9516129 , 0.9516129 , 0.9516129 , 0.9516129 , 0.94758065,\n",
      "       0.94758065, 0.94758065, 0.94758065, 0.94354839, 0.94354839,\n",
      "       0.94354839, 0.94354839, 0.94354839, 0.94354839, 0.94354839,\n",
      "       0.94354839, 0.94354839, 0.94354839, 0.94354839, 0.94354839,\n",
      "       0.94354839, 0.94354839, 0.94354839, 0.94354839, 0.93951613,\n",
      "       0.93548387, 0.93548387, 0.93548387, 0.93548387, 0.93548387,\n",
      "       0.93548387, 0.93548387, 0.93548387, 0.93145161, 0.92741935,\n",
      "       0.92741935, 0.92741935, 0.92741935, 0.92741935, 0.92741935,\n",
      "       0.92741935, 0.92741935, 0.92741935, 0.92741935, 0.92741935,\n",
      "       0.92741935, 0.92741935, 0.92741935, 0.9233871 , 0.91935484,\n",
      "       0.91532258, 0.91532258, 0.91532258, 0.91129032, 0.90725806,\n",
      "       0.90725806, 0.90725806, 0.90725806, 0.90725806, 0.90725806,\n",
      "       0.90725806, 0.90322581, 0.90322581, 0.90322581, 0.89919355,\n",
      "       0.89516129, 0.89112903, 0.88709677, 0.88306452, 0.87903226,\n",
      "       0.87903226, 0.87903226, 0.875     , 0.875     , 0.875     ,\n",
      "       0.875     , 0.87096774, 0.87096774, 0.86693548, 0.86290323,\n",
      "       0.85887097, 0.85483871, 0.85080645, 0.84677419, 0.84274194,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83467742, 0.83467742,\n",
      "       0.83467742, 0.83064516, 0.83064516, 0.8266129 , 0.82258065,\n",
      "       0.81854839, 0.81854839, 0.81451613, 0.81048387, 0.80645161,\n",
      "       0.80241935, 0.7983871 , 0.7983871 , 0.7983871 , 0.7983871 ,\n",
      "       0.7983871 , 0.79435484, 0.79032258, 0.78629032, 0.78225806,\n",
      "       0.77822581, 0.77419355, 0.77016129, 0.77016129, 0.76612903,\n",
      "       0.76612903, 0.76209677, 0.75806452, 0.75403226, 0.75      ,\n",
      "       0.74596774, 0.74193548, 0.73790323, 0.73387097, 0.72983871,\n",
      "       0.72580645, 0.72177419, 0.71774194, 0.71370968, 0.70967742,\n",
      "       0.70564516, 0.7016129 , 0.69758065, 0.69354839, 0.68951613,\n",
      "       0.68548387, 0.68145161, 0.67741935, 0.6733871 , 0.66935484,\n",
      "       0.66532258, 0.66129032, 0.65725806, 0.65322581, 0.64919355,\n",
      "       0.64516129, 0.64112903, 0.63709677, 0.63306452, 0.62903226,\n",
      "       0.625     , 0.62096774, 0.61693548, 0.61290323, 0.60887097,\n",
      "       0.60483871, 0.60080645, 0.59677419, 0.59274194, 0.58870968,\n",
      "       0.58467742, 0.58064516, 0.5766129 , 0.57258065, 0.56854839,\n",
      "       0.56451613, 0.56048387, 0.55645161, 0.55241935, 0.5483871 ,\n",
      "       0.54435484, 0.54032258, 0.53629032, 0.53225806, 0.52822581,\n",
      "       0.52419355, 0.52016129, 0.51612903, 0.51209677, 0.50806452,\n",
      "       0.50403226, 0.5       , 0.49596774, 0.49193548, 0.48790323,\n",
      "       0.48387097, 0.47983871, 0.47580645, 0.47177419, 0.46774194,\n",
      "       0.46370968, 0.46370968, 0.45967742, 0.45564516, 0.4516129 ,\n",
      "       0.44758065, 0.44758065, 0.44354839, 0.43951613, 0.43548387,\n",
      "       0.43145161, 0.42741935, 0.4233871 , 0.41935484, 0.41532258,\n",
      "       0.41129032, 0.40725806, 0.40322581, 0.39919355, 0.39516129,\n",
      "       0.39112903, 0.38709677, 0.38306452, 0.37903226, 0.375     ,\n",
      "       0.37096774, 0.36693548, 0.36290323, 0.35887097, 0.35080645,\n",
      "       0.34677419, 0.34274194, 0.33870968, 0.33467742, 0.33064516,\n",
      "       0.3266129 , 0.32258065, 0.31854839, 0.31451613, 0.31048387,\n",
      "       0.30645161, 0.30241935, 0.2983871 , 0.29435484, 0.29032258,\n",
      "       0.28629032, 0.28225806, 0.27822581, 0.27419355, 0.27016129,\n",
      "       0.26612903, 0.26209677, 0.25806452, 0.25403226, 0.25      ,\n",
      "       0.24596774, 0.24193548, 0.23790323, 0.23387097, 0.22983871,\n",
      "       0.22580645, 0.22177419, 0.21774194, 0.21370968, 0.20967742,\n",
      "       0.20564516, 0.2016129 , 0.19758065, 0.19354839, 0.18951613,\n",
      "       0.18548387, 0.18145161, 0.17741935, 0.1733871 , 0.16935484,\n",
      "       0.16532258, 0.16129032, 0.15725806, 0.15322581, 0.14919355,\n",
      "       0.14516129, 0.14112903, 0.13709677, 0.13306452, 0.12903226,\n",
      "       0.125     , 0.12096774, 0.11693548, 0.11290323, 0.10887097,\n",
      "       0.10483871, 0.10080645, 0.09677419, 0.09274194, 0.08870968,\n",
      "       0.08467742, 0.08064516, 0.0766129 , 0.07258065, 0.06854839,\n",
      "       0.06451613, 0.06048387, 0.05645161, 0.05241935, 0.0483871 ,\n",
      "       0.04435484, 0.04032258, 0.03629032, 0.03225806, 0.02822581,\n",
      "       0.02419355, 0.02016129, 0.01612903, 0.01209677, 0.00806452,\n",
      "       0.00403226, 0.        ]), array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.9962406 , 0.9962406 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 , 0.9924812 ,\n",
      "       0.9924812 , 0.9924812 , 0.9924812 , 0.9887218 , 0.9887218 ,\n",
      "       0.98496241, 0.98496241, 0.98496241, 0.98496241, 0.98496241,\n",
      "       0.98496241, 0.98496241, 0.98496241, 0.98120301, 0.98120301,\n",
      "       0.97744361, 0.97744361, 0.97744361, 0.97368421, 0.96992481,\n",
      "       0.96616541, 0.96240602, 0.96240602, 0.95864662, 0.95488722,\n",
      "       0.95488722, 0.95112782, 0.94736842, 0.94736842, 0.94736842,\n",
      "       0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94360902,\n",
      "       0.94360902, 0.94360902, 0.93984962, 0.93984962, 0.93984962,\n",
      "       0.93984962, 0.93984962, 0.93984962, 0.93984962, 0.93609023,\n",
      "       0.93609023, 0.93233083, 0.93233083, 0.93233083, 0.92857143,\n",
      "       0.92481203, 0.92105263, 0.91729323, 0.91353383, 0.90977444,\n",
      "       0.90601504, 0.90225564, 0.90225564, 0.89849624, 0.89849624,\n",
      "       0.89473684, 0.89097744, 0.88721805, 0.88345865, 0.87969925,\n",
      "       0.87593985, 0.87218045, 0.86842105, 0.86466165, 0.86090226,\n",
      "       0.85714286, 0.85338346, 0.84962406, 0.84586466, 0.84210526,\n",
      "       0.83834586, 0.83834586, 0.83458647, 0.83082707, 0.83082707,\n",
      "       0.82706767, 0.82330827, 0.82330827, 0.81954887, 0.81578947,\n",
      "       0.81203008, 0.80827068, 0.80451128, 0.80075188, 0.80075188,\n",
      "       0.79699248, 0.79699248, 0.79699248, 0.79323308, 0.78947368,\n",
      "       0.78571429, 0.78195489, 0.77819549, 0.77443609, 0.77067669,\n",
      "       0.76691729, 0.76315789, 0.7593985 , 0.7556391 , 0.7518797 ,\n",
      "       0.7481203 , 0.7443609 , 0.7406015 , 0.73684211, 0.73308271,\n",
      "       0.72932331, 0.72556391, 0.72180451, 0.71804511, 0.71428571,\n",
      "       0.71052632, 0.70676692, 0.70300752, 0.69924812, 0.69548872,\n",
      "       0.69172932, 0.68796992, 0.68421053, 0.68045113, 0.67669173,\n",
      "       0.67669173, 0.67293233, 0.66917293, 0.66541353, 0.66165414,\n",
      "       0.65789474, 0.65413534, 0.65413534, 0.65037594, 0.65037594,\n",
      "       0.64661654, 0.64285714, 0.64285714, 0.64285714, 0.63909774,\n",
      "       0.63909774, 0.63533835, 0.63533835, 0.63157895, 0.62781955,\n",
      "       0.62406015, 0.62030075, 0.62030075, 0.61654135, 0.61278195,\n",
      "       0.60902256, 0.60526316, 0.60150376, 0.59774436, 0.59398496,\n",
      "       0.59022556, 0.58646617, 0.58270677, 0.57894737, 0.57518797,\n",
      "       0.57142857, 0.56766917, 0.56390977, 0.56015038, 0.55639098,\n",
      "       0.55263158, 0.54887218, 0.54511278, 0.54135338, 0.53759398,\n",
      "       0.53383459, 0.53007519, 0.52631579, 0.52255639, 0.51879699,\n",
      "       0.51503759, 0.5112782 , 0.5075188 , 0.5037594 , 0.5       ,\n",
      "       0.4962406 , 0.4924812 , 0.4887218 , 0.48496241, 0.48120301,\n",
      "       0.47744361, 0.47368421, 0.46992481, 0.46616541, 0.46240602,\n",
      "       0.45864662, 0.45488722, 0.45112782, 0.44736842, 0.44360902,\n",
      "       0.43984962, 0.43609023, 0.43233083, 0.42857143, 0.42481203,\n",
      "       0.42105263, 0.41729323, 0.41353383, 0.40977444, 0.40601504,\n",
      "       0.40225564, 0.39849624, 0.39473684, 0.39097744, 0.38721805,\n",
      "       0.38345865, 0.37969925, 0.37593985, 0.37218045, 0.36842105,\n",
      "       0.36466165, 0.36090226, 0.35714286, 0.35338346, 0.34962406,\n",
      "       0.34586466, 0.34210526, 0.33834586, 0.33458647, 0.33082707,\n",
      "       0.32706767, 0.32330827, 0.31954887, 0.31578947, 0.31203008,\n",
      "       0.30827068, 0.30451128, 0.30075188, 0.29699248, 0.29323308,\n",
      "       0.28947368, 0.28571429, 0.28195489, 0.27819549, 0.27443609,\n",
      "       0.27067669, 0.26691729, 0.26315789, 0.2593985 , 0.2556391 ,\n",
      "       0.2518797 , 0.2481203 , 0.2443609 , 0.2406015 , 0.23684211,\n",
      "       0.23308271, 0.22932331, 0.22556391, 0.22180451, 0.21804511,\n",
      "       0.21428571, 0.21052632, 0.20676692, 0.20300752, 0.19924812,\n",
      "       0.19548872, 0.19172932, 0.18796992, 0.18421053, 0.18045113,\n",
      "       0.17669173, 0.17293233, 0.16917293, 0.16541353, 0.16165414,\n",
      "       0.15789474, 0.15413534, 0.15037594, 0.14661654, 0.14285714,\n",
      "       0.13909774, 0.13533835, 0.13157895, 0.12781955, 0.12406015,\n",
      "       0.12030075, 0.11654135, 0.11278195, 0.10902256, 0.10526316,\n",
      "       0.10150376, 0.09774436, 0.09398496, 0.09022556, 0.08646617,\n",
      "       0.08270677, 0.07894737, 0.07518797, 0.07142857, 0.06766917,\n",
      "       0.06390977, 0.06015038, 0.05639098, 0.04887218, 0.04511278,\n",
      "       0.04135338, 0.03007519, 0.02255639, 0.01503759, 0.0112782 ,\n",
      "       0.0075188 , 0.0037594 , 0.        ])]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\")  # 在终端中忽略警告消息\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    fprs, tprs, auc, precisions, recalls, prc = Train(device, directory='..\\data',\n",
    "                                                      epochs=1000,\n",
    "                                                      attn_size=64,\n",
    "                                                      attn_heads=6,\n",
    "                                                      out_dim=64,\n",
    "                                                      dropout=0.2,\n",
    "                                                      slope=0.2,\n",
    "                                                      lr=0.001,\n",
    "                                                      wd=5e-3,\n",
    "                                                      random_seed=1234,\n",
    "                                                      sample_num=50,\n",
    "                                                      model_type='MAHN')\n",
    "\n",
    "    plot_auc_curves(fprs, tprs, auc, directory='../result', name='test_auc_1')\n",
    "    plot_prc_curves(precisions, recalls, prc, directory='../result', name='test_prc_1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T22:27:49.423970800Z",
     "start_time": "2024-05-07T03:39:01.382884300Z"
    }
   },
   "id": "8eb6b250556d4d18",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T22:27:49.423970800Z",
     "start_time": "2024-05-07T22:27:49.404970Z"
    }
   },
   "id": "cc838e26b01b9da6",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
